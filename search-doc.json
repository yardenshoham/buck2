[{"title":"APIs","type":0,"sectionRef":"#","url":"/docs/api/","content":"APIs A lot of Buck2 is driven by Starlark APIs. While there is a Starlark specification, for most purposes it can be considered a subset of Python. There are three main places you can write Starlark in Buck2: In BUCK files, where you can define the rules. The most interesting functions are the rules themselves, but you will often use the builtin Starlark functions (most of which are the same as in Python), and a few of the build functions (e.g. glob).In rule definitions, where you can use the same Starlark standard functions, but will heavily be using the build functions (e.g. rule and attrs).In BXL, where the context type is one of the more important ones.","keywords":""},{"title":"Introduction","type":0,"sectionRef":"#","url":"/docs/","content":"","keywords":""},{"title":"Buck2 Documentation Website Links​","type":1,"pageTitle":"Introduction","url":"/docs/#buck2-documentation-website-links","content":""},{"title":"For end users​","type":1,"pageTitle":"Introduction","url":"/docs/#for-end-users","content":"Getting Started - how to get started with using Buck2.Benefits - the benefits of using Buck2. "},{"title":"For people writing rules​","type":1,"pageTitle":"Introduction","url":"/docs/#for-people-writing-rules","content":"Writing Rules - how to write rules to support new languages.Rule APIs - gives the API available when writing rules.Starlark Types - rules are written in Starlark (which is approximately Python), but our version adds types. "},{"title":"For people integrating with Buck2​","type":1,"pageTitle":"Introduction","url":"/docs/#for-people-integrating-with-buck2","content":"Extending Buck via BXL - powerful Starlark scripts for introspection of Buck2's graphs. "},{"title":"External articles about Buck2​","type":1,"pageTitle":"Introduction","url":"/docs/#external-articles-about-buck2","content":"Introducing Buck2 - our initial introduction when we open sourced Buck2.Reddit AMA where the Buck2 team answered a number of questions.Using buck to build Rust projects - working through an initial small Rust project, by Steve Klabnik. Followed up by building from crates.io and updating Buck2.Awesome Buck2 is a collection of resources about Buck2.Buck2 Unboxing is a general review of Buck2 by Son Luong Ngoc.A tour around Buck2 gives an overview of Buck2 and how it differs from Bazel. "},{"title":"External projects using Buck2​","type":1,"pageTitle":"Introduction","url":"/docs/#external-projects-using-buck2","content":"System Initiative build their DevOps product using Buck2, with their own custom prelude.Rust cxx library has examples and tests with a wide variety of build systems, including Buck2.ocamlrep library allows for interop between OCaml and Rust code, and can be built with Buck2.buck2-nix is an experiment to integrate Buck2, Sapling and Nix together in a harmonious way. Feel free to send a PR adding your project. "},{"title":"artifact type","type":0,"sectionRef":"#","url":"/docs/api/build/artifact/","content":"","keywords":""},{"title":"artifact.as_output​","type":1,"pageTitle":"artifact type","url":"/docs/api/build/artifact/#artifactas_output","content":"def artifact.as_output() -&gt; &quot;output_artifact&quot;  Returns a StarlarkOutputArtifact instance, or fails if the artifact is either an Artifact, or is a bound Artifact (You cannot bind twice)  "},{"title":"artifact.basename​","type":1,"pageTitle":"artifact type","url":"/docs/api/build/artifact/#artifactbasename","content":"artifact.basename: str.type  The base name of this artifact. e.g. for an artifact at foo/bar, this is bar  "},{"title":"artifact.extension​","type":1,"pageTitle":"artifact type","url":"/docs/api/build/artifact/#artifactextension","content":"artifact.extension: str.type  The file extension of this artifact. e.g. for an artifact at foo/bar.sh, this is .sh. If no extension is present, &quot;&quot; is returned.  "},{"title":"artifact.is_source​","type":1,"pageTitle":"artifact type","url":"/docs/api/build/artifact/#artifactis_source","content":"artifact.is_source: bool.type  Whether the artifact represents a source file  "},{"title":"artifact.owner​","type":1,"pageTitle":"artifact type","url":"/docs/api/build/artifact/#artifactowner","content":"artifact.owner: [&quot;label&quot;, None]  The Label of the rule that originally created this artifact. May also be None in the case of source files, or if the artifact has not be used in an action, or if the action was not created by a rule.  "},{"title":"artifact.project​","type":1,"pageTitle":"artifact type","url":"/docs/api/build/artifact/#artifactproject","content":"def artifact.project( path: str.type, /, *, hide_prefix: bool.type = False ) -&gt; &quot;artifact&quot;  Create an artifact that lives at path relative from this artifact. For example, if artifact foo is a directory containing a file bar, then foo.project(&quot;bar&quot;) yields the file bar. It is possible for projected artifacts to hide the prefix in order to have the short name of the resulting artifact only contain the projected path, by passing hide_prefix = True to project().  "},{"title":"artifact.short_path​","type":1,"pageTitle":"artifact type","url":"/docs/api/build/artifact/#artifactshort_path","content":"artifact.short_path: str.type  The interesting part of the path, relative to somewhere in the output directory. For an artifact declared as foo/bar, this is foo/bar.  "},{"title":"artifact.without_associated_artifacts​","type":1,"pageTitle":"artifact type","url":"/docs/api/build/artifact/#artifactwithout_associated_artifacts","content":"def artifact.without_associated_artifacts() -&gt; &quot;artifact&quot;  "},{"title":"actions type","type":0,"sectionRef":"#","url":"/docs/api/build/actions/","content":"","keywords":""},{"title":"actions.anon_target​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionsanon_target","content":"def actions.anon_target(rule: &quot;rule&quot;, attrs: {str.type: &quot;&quot;}) -&gt; &quot;promise&quot;  An anonymous target is defined by the hash of its attributes, rather than its name. During analysis, rules can define and access the providers of anonymous targets before producing their own providers. Two distinct rules might ask for the same anonymous target, sharing the work it performs. For more details see https://buck2.build/docs/rule_authors/anon_targets/  "},{"title":"actions.anon_targets​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionsanon_targets","content":"def actions.anon_targets(rules: [(&quot;rule&quot;, {str.type: &quot;&quot;})]) -&gt; &quot;promise&quot;  Generate a series of anonymous targets  "},{"title":"actions.artifact_promise​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionsartifact_promise","content":"def actions.artifact_promise( promise: &quot;promise&quot;, *, short_path: [None, str.type] = None ) -&gt; &quot;promise_artifact&quot;  Converts a promise to an artifact. If the promise later resolves to a non-artifact, it is an error. Takes in an optional named parameter short_path that can be used to access the short path before the promise is resolved. It will be validated that the provided short path matches the built artifact's short path after analysis happens and the promise has been resolved. For more details see https://buck2.build/docs/rule_authors/anon_targets/.  "},{"title":"actions.artifact_tag​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionsartifact_tag","content":"def actions.artifact_tag() -&gt; &quot;artifact_tag&quot;  Allocate a new input tag. Used with the dep_files argument to run.  "},{"title":"actions.cas_artifact​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionscas_artifact","content":"def actions.cas_artifact( output: [&quot;artifact&quot;, &quot;output_artifact&quot;, &quot;promise_artifact&quot;, str.type], digest: str.type, use_case: str.type, /, *, expires_after_timestamp: int.type, is_executable: bool.type = False, is_tree: bool.type = False, is_directory: bool.type = False ) -&gt; &quot;artifact&quot;  Downloads a CAS artifact to an output digest: must look like SHA1:SIZEuse_case: your RE use caseexpires_after_timestamp: must be a UNIX timestamp. Your digest's TTL must exceed this timestamp. Your build will break once the digest expires, so make sure the expiry is long enough (preferably, in years).is_executable (optional): indicates the resulting file should be marked with executable permissions  "},{"title":"actions.copied_dir​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionscopied_dir","content":"def actions.copied_dir( output: [&quot;artifact&quot;, &quot;output_artifact&quot;, &quot;promise_artifact&quot;, str.type], srcs: {str.type: [&quot;artifact&quot;, &quot;promise_artifact&quot;]}, / ) -&gt; &quot;artifact&quot;  Returns an artifact which is a directory containing copied files. The srcs must be a dictionary of path (as string, relative to the result directory) to the bound artifact, which will be laid out in the directory.  "},{"title":"actions.copy_dir​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionscopy_dir","content":"def actions.copy_dir( dest: [&quot;artifact&quot;, &quot;output_artifact&quot;, &quot;promise_artifact&quot;, str.type], src: [&quot;artifact&quot;, &quot;promise_artifact&quot;], / ) -&gt; &quot;artifact&quot;  Make a copy of a directory.  "},{"title":"actions.copy_file​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionscopy_file","content":"def actions.copy_file( dest: [&quot;artifact&quot;, &quot;output_artifact&quot;, &quot;promise_artifact&quot;, str.type], src: [&quot;artifact&quot;, &quot;promise_artifact&quot;], / ) -&gt; &quot;artifact&quot;  Copies the source artifact to the destination (which can be a string representing a filename or an output artifact) and returns the output artifact. The copy works for files or directories.  "},{"title":"actions.declare_output​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionsdeclare_output","content":"def actions.declare_output( prefix: str.type, filename: str.type = _, /, *, dir: bool.type = False ) -&gt; &quot;artifact&quot;  Returns an unbound artifact which must be bound before analysis terminates. The usual way of binding an artifact is with ctx.actions.run. To construct an artifact with the name foo, call ctx.actions.declare_output(&quot;foo&quot;). Artifacts from a single target may not have the same name, so if you then want a second artifact also named foo you need to supply a prefix, e.g.ctx.actions.declare_output(&quot;directory&quot;, &quot;foo&quot;). The artifact will still report it has name foo, but will be located atdirectory/foo. The dir argument should be set to True if the binding will be a directory.  "},{"title":"actions.download_file​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionsdownload_file","content":"def actions.download_file( output: [&quot;artifact&quot;, &quot;output_artifact&quot;, &quot;promise_artifact&quot;, str.type], url: str.type, /, *, vpnless_url: [None, str.type] = None, sha1: [None, str.type] = None, sha256: [None, str.type] = None, is_executable: bool.type = False, is_deferrable: bool.type = False ) -&gt; &quot;artifact&quot;  Downloads a URL to an output (filename as string or output artifact). The file at the URL must have the given sha1 or the command will fail. The optional parameter is_executable indicates whether the resulting file should be marked with executable permissions. (Meta-internal) The optional parameter vpnless_url indicates a url from which this resource can be downloaded off VPN; this has the same restrictions as url above.  "},{"title":"actions.dynamic_output​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionsdynamic_output","content":"def actions.dynamic_output( *, dynamic: [&quot;artifact&quot;], inputs: [&quot;artifact&quot;], outputs: [[&quot;artifact&quot;, &quot;output_artifact&quot;]], f ) -&gt; None  dynamic_output allows a rule to use information that was not available when the rule was first run at analysis time. Examples include things like Distributed ThinLTO (where the index file is created by another action) or OCaml builds (where the dependencies are created by ocamldeps). The arguments are: dynamic - a list of artifacts whose values will be available in the function. These will be built before the function is run.inputs - a container of artifacts (cmd_args, list of artifacts, and so on). These inputs must include all the inputs that are referenced by the body of the function argument, apart from those listed in dynamic and outputs: extra inputs may be passed that are not used.The inputs are used for buck2 aquery functionality, but do not cause speculative building. In fact, these inputs may form a cycle with other dynamic_output actions if they were all required.In the future, it may be possible to not pass all the inputs if the repo is set to permissive mode, allowing a more powerful form of dynamic dependencies. outputs - a list of unbound artifacts (created with declare_artifact) which will be bound by the function.The function argument is given 3 arguments: ctx (context) - which is the same as that passed to the initial rule analysis.outputs - using one of the artifacts from the dynamic_output's outputs (example usage: outputs[artifact_from_dynamic_output_outputs]) gives an unbounded artifact. The function argument must use its outputs argument to bind output artifacts, rather than reusing artifacts from the outputs passed into dynamic_output directly.artifacts - using one of the artifacts from dynamic (example usage: artifacts[artifact_from_dynamic]) gives an artifact value containing the methods read_string, read_lines, and read_json to obtain the values from the disk in various formats. Anything too complex should be piped through a Python script for transformation to JSON. The function must call ctx.actions (probably ctx.actions.run) to bind all outputs. It can examine the values of the dynamic variables and depends on the inputs. The function will usually be a def, as lambda in Starlark does not allow statements, making it quite underpowered. For full details see http://localhost:3000/docs/rule_authors/dynamic_dependencies/.  "},{"title":"actions.run​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionsrun","content":"def actions.run( arguments, /, *, category: str.type, identifier: [None, str.type] = None, env: {str.type: &quot;&quot;} = _, local_only: bool.type = False, prefer_local: bool.type = False, prefer_remote: bool.type = False, low_pass_filter: bool.type = True, always_print_stderr: bool.type = False, weight: int.type = _, weight_percentage: int.type = _, dep_files: {str.type: &quot;artifact_tag&quot;} = _, metadata_env_var: str.type = _, metadata_path: str.type = _, no_outputs_cleanup: bool.type = False, allow_cache_upload: bool.type = False, force_full_hybrid_if_capable: bool.type = False, exe: [&quot;RunInfo&quot;, &quot;WorkerRunInfo&quot;] = _ ) -&gt; None  Runs a command arguments: must be of type cmd_args, or a type convertible to such (such as a list of strings and artifacts) and must contain at least one .as_output() artifactcategory: category and identifier - when used together, identify the action in Buck2's event stream, and must be unique for a given targetweight: used to note how heavy the command is and will typically be set to a higher value to indicate that less such commands should be run in parallel (if running locally)no_outputs_cleanup: if this flag is set then Buck2 won't clean the outputs of a previous build that might be present on a disk; in which case, command from arguments should be responsible for the cleanup (that is useful, for example, when an action is supporting incremental mode and its outputs are based on result from a previous build)metadata_env_var and meadata_path should be used together: both set or both unset metadata_path: defines a path relative to the result directory for a file with action metadata, which will be created right before the command will be run.Metadata contains the path relative to the Buck2 project root and hash digest for every action input (this excludes symlinks as they could be resolved by a user script if needed). The resolved path relative to the Buck2 project for the metadata file will be passed to command from arguments, via the environment variable, with its name set by metadata_env_varBoth metadata_env_var and metadata_path are useful when making actions behave in an incremental manner (for details, see Incremental Actions) The prefer_local, prefer_remote and local_only options allow selecting where the action should run if the executor selected for this target is a hybrid executor. * All those options disable concurrent execution: the action will run on the preferred platform first (concurrent execution only happens with a &quot;full&quot; hybrid executor). * Execution may be retried on the &quot;non-preferred&quot; platform if it fails due to a transient error, except for `local_only`, which does not allow this. * If the executor selected is a remote-only executor and you use `local_only`, that's an error. The other options will not raise errors. * Setting more than one of those options is an error. * Those flags behave the same way as the equivalent `--prefer-remote`, `--prefer-local` and `--local-only` CLI flags. The CLI flags take precedence. * The `force_full_hybrid_if_capable` option overrides the `use_limited_hybrid` hybrid. The options listed above take precedence if set.   "},{"title":"actions.symlink_dir​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionssymlink_dir","content":"def actions.symlink_dir( dest: [&quot;artifact&quot;, &quot;output_artifact&quot;, &quot;promise_artifact&quot;, str.type], src: [&quot;artifact&quot;, &quot;promise_artifact&quot;], / ) -&gt; &quot;artifact&quot;  Create a symlink to a directory.  "},{"title":"actions.symlink_file​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionssymlink_file","content":"def actions.symlink_file( dest: [&quot;artifact&quot;, &quot;output_artifact&quot;, &quot;promise_artifact&quot;, str.type], src: [&quot;artifact&quot;, &quot;promise_artifact&quot;], / ) -&gt; &quot;artifact&quot;  Creates a symlink to the source artifact at the destination (which can be a string representing a filename or an output artifact) and returns the output artifact. The symlink works for files or directories.  "},{"title":"actions.symlinked_dir​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionssymlinked_dir","content":"def actions.symlinked_dir( output: [&quot;artifact&quot;, &quot;output_artifact&quot;, &quot;promise_artifact&quot;, str.type], srcs: {str.type: [&quot;artifact&quot;, &quot;promise_artifact&quot;]}, / ) -&gt; &quot;artifact&quot;  Returns an artifact that is a directory containing symlinks. The srcs must be a dictionary of path (as string, relative to the result directory) to bound artifact, which will be laid out in the directory.  "},{"title":"actions.tset​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionstset","content":"def actions.tset( definition: &quot;transitive_set_definition&quot;, /, value = _, children: iter(&quot;&quot;) = _ )  Creates a new transitive set. For details, see https://buck2.build/docs/rule_authors/transitive_sets/.  "},{"title":"actions.write​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionswrite","content":"def actions.write( output: [&quot;artifact&quot;, &quot;output_artifact&quot;, &quot;promise_artifact&quot;, str.type], content, /, *, is_executable: bool.type = False, allow_args: bool.type = False, with_inputs: bool.type = False ) -&gt; [&quot;artifact&quot;, (&quot;artifact&quot;, [&quot;artifact&quot;])]  Returns an artifact whose contents are content is_executable (optional): indicates whether the resulting file should be marked with executable permissionsallow_args (optional): must be set to True if you want to write parameter arguments to the file (in particular, macros that write to file) If it is true, the result will be a pair of the artifact containing content and a list of artifact values that were written by macros, which should be used in hidden fields or similar  "},{"title":"actions.write_json​","type":1,"pageTitle":"actions type","url":"/docs/api/build/actions/#actionswrite_json","content":"def actions.write_json( output: [&quot;artifact&quot;, &quot;output_artifact&quot;, &quot;promise_artifact&quot;, str.type], content, /, *, with_inputs: bool.type = False ) -&gt; [&quot;artifact&quot;, &quot;write_json_cli_args&quot;]  Returns an artifact whose contents are content written as a JSON value. filename: can be a string, or an existing artifact created with declare_outputcontent: must be composed of the basic json types (boolean, number, string, list/tuple, dictionary) plus artifacts and command lines An artifact will be written as a string containing the pathA command line will be written as a list of strings, unless joined=True is set, in which case it will be a string If you pass with_inputs = True, you'll get back a cmd_args that expands to the JSON file but carries all the underlying inputs as dependencies (so you don't have to use, for example, hidden for them to be added to an action that already receives the JSON file) "},{"title":"attrs type","type":0,"sectionRef":"#","url":"/docs/api/build/attrs/","content":"","keywords":""},{"title":"attrs.any​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsany","content":"def attrs.any(*, doc: str.type = &quot;&quot;, default = _) -&gt; &quot;attribute&quot;  Takes most builtin literals and passes them to the rule as a string. Discouraged, as it provides little type safety and destroys the structure.  "},{"title":"attrs.arg​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsarg","content":"def attrs.arg( *, json: bool.type = False, default = _, doc: str.type = &quot;&quot;, anon_target_compatible: bool.type = False ) -&gt; &quot;attribute&quot;  Takes a command line argument from the user and supplies a cmd_args compatible value to the rule. The argument may contain special macros such as $(location :my_target) or $(exe :my_target) which will be replaced with references to those values in the rule. Takes in an optional anon_target_compatible flag, which indicates whether the args can be passed into anon targets. Note that there is a slight memory hit when using this flag.  "},{"title":"attrs.bool​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsbool","content":"def attrs.bool(*, default = _, doc: str.type = &quot;&quot;) -&gt; &quot;attribute&quot;  Takes a boolean and passes it to the rule as a boolean.  "},{"title":"attrs.configuration_label​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsconfiguration_label","content":"def attrs.configuration_label(*, doc: str.type = &quot;&quot;) -&gt; &quot;attribute&quot;   "},{"title":"attrs.configured_dep​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsconfigured_dep","content":"def attrs.configured_dep( *, providers: [&quot;&quot;] = [], default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;   "},{"title":"attrs.default_only​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsdefault_only","content":"def attrs.default_only( inner: &quot;attribute&quot;, /, *, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;  Rejects all values and uses the default for the inner argument. Often used to resolve dependencies, which otherwise can't be resolved inside a rule. attrs.default_only(attrs.dep(default = &quot;foo//my_package:my_target&quot;))   "},{"title":"attrs.dep​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsdep","content":"def attrs.dep( *, providers: [&quot;&quot;] = [], default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;  Takes a target from the user, as a string, and supplies a dependency to the rule. A target can be specified as an absolute dependency foo//bar:baz, omitting the cell (//bar:baz) or omitting the package name (:baz). If supplied the providers argument ensures that specific providers will be present on the dependency.  "},{"title":"attrs.dict​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsdict","content":"def attrs.dict( key: &quot;attribute&quot;, value: &quot;attribute&quot;, *, sorted: bool.type = False, default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;  Takes a dict from the user, supplies a dict to the rule.  "},{"title":"attrs.enum​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsenum","content":"def attrs.enum( variants: [str.type], /, *, default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;  Takes a string from one of the variants given, and gives that string to the rule. Strings are matched case-insensitively, and always passed to the rule lowercase.  "},{"title":"attrs.exec_dep​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsexec_dep","content":"def attrs.exec_dep( *, providers: [&quot;&quot;] = [], default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;  Takes a target from the user, as a string, and supplies a dependency to the rule. The dependency will transition to the execution platform. Use exec_dep if you plan to execute things from this dependency as part of the compilation.  "},{"title":"attrs.int​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsint","content":"def attrs.int(*, default = _, doc: str.type = &quot;&quot;) -&gt; &quot;attribute&quot;  Takes an int from the user, supplies an int to the rule.  "},{"title":"attrs.label​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrslabel","content":"def attrs.label(*, default = _, doc: str.type = &quot;&quot;) -&gt; &quot;attribute&quot;  Takes a target (as per deps) and passes a label to the rule. Validates that the target exists, but does not introduce a dependency on it.  "},{"title":"attrs.list​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrslist","content":"def attrs.list( inner: &quot;attribute&quot;, /, *, default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;  Takes a list from the user, supplies a list to the rule.  "},{"title":"attrs.named_set​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsnamed_set","content":"def attrs.named_set( value_type: &quot;attribute&quot;, /, *, sorted: bool.type = False, default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;   "},{"title":"attrs.one_of​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsone_of","content":"def attrs.one_of(*args, default = _, doc: str.type = &quot;&quot;) -&gt; &quot;attribute&quot;  Given a list of alternative attributes, selects the first that matches and gives that to the rule.  "},{"title":"attrs.option​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsoption","content":"def attrs.option( inner: &quot;attribute&quot;, /, *, default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;  Takes a value that may be None or some inner type, and passes either None or the value corresponding to the inner to the rule. Often used to make a rule optional: attrs.option(attr.string(), default = None)   "},{"title":"attrs.query​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsquery","content":"def attrs.query(*, doc: str.type = &quot;&quot;) -&gt; &quot;attribute&quot;   "},{"title":"attrs.regex​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsregex","content":"def attrs.regex(*, default = _, doc: str.type = &quot;&quot;) -&gt; &quot;attribute&quot;  Currently an alias for attrs.string.  "},{"title":"attrs.set​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsset","content":"def attrs.set( value_type: &quot;attribute&quot;, /, *, sorted: bool.type = False, default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;   "},{"title":"attrs.source​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrssource","content":"def attrs.source( *, allow_directory: bool.type = False, default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;  Takes a source file from the user, supplies an artifact to the rule. The source file may be specified as a literal string (representing the path within this package), or a target (which must have a DefaultInfo with a default_outputs value).  "},{"title":"attrs.split_transition_dep​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrssplit_transition_dep","content":"def attrs.split_transition_dep( *, providers: [&quot;&quot;] = [], cfg, default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;   "},{"title":"attrs.string​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsstring","content":"def attrs.string( *, default = _, validate = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;  Takes a string from the user, supplies a string to the rule.  "},{"title":"attrs.toolchain_dep​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrstoolchain_dep","content":"def attrs.toolchain_dep( *, providers: [&quot;&quot;] = [], default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;  Takes a target from the user, as a string, and supplies a dependency to the rule. The dependency will be a toolchain dependency, meaning that its execution platform dependencies will be used to select the execution platform for this rule.  "},{"title":"attrs.transition_dep​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrstransition_dep","content":"def attrs.transition_dep( *, providers: [&quot;&quot;] = [], cfg, default = _, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;   "},{"title":"attrs.tuple​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrstuple","content":"def attrs.tuple(*args, default = _, doc: str.type = &quot;&quot;) -&gt; &quot;attribute&quot;  Takes a tuple of values and gives a tuple to the rule.  "},{"title":"attrs.versioned​","type":1,"pageTitle":"attrs type","url":"/docs/api/build/attrs/#attrsversioned","content":"def attrs.versioned( value_type: &quot;attribute&quot;, *, doc: str.type = &quot;&quot; ) -&gt; &quot;attribute&quot;  "},{"title":"context type","type":0,"sectionRef":"#","url":"/docs/api/build/context/","content":"","keywords":""},{"title":"context.actions​","type":1,"pageTitle":"context type","url":"/docs/api/build/context/#contextactions","content":"context.actions: &quot;actions&quot;  Returns an actions value containing functions to define actual actions that are run. See the actions type for the operations that are available.  "},{"title":"context.attrs​","type":1,"pageTitle":"context type","url":"/docs/api/build/context/#contextattrs","content":"context.attrs: struct(..)  Returns the attributes of the target as a Starlark struct with a field for each attribute, which varies per rule. As an example, given a rule with the attrs argument of {&quot;foo&quot;: attrs.string()}, this field will be a struct containing a field foo of type string.  "},{"title":"context.label​","type":1,"pageTitle":"context type","url":"/docs/api/build/context/#contextlabel","content":"context.label: [&quot;label&quot;, None]  Returns a label representing the target, or None if being invoked from a dynamic_output in Bxl. "},{"title":"cmd_args type","type":0,"sectionRef":"#","url":"/docs/api/build/cmd_args/","content":"","keywords":""},{"title":"cmd_args.absolute_prefix​","type":1,"pageTitle":"cmd_args type","url":"/docs/api/build/cmd_args/#cmd_argsabsolute_prefix","content":"def cmd_args.absolute_prefix(prefix: str.type) -&gt; &quot;cmd_args&quot;  Adds a prefix to the end of start artifact. Often used if you have a $ROOT variable in a shell script and want to use it to make files absolute. cmd_args(script).absolute_prefix(&quot;$ROOT/&quot;)   "},{"title":"cmd_args.absolute_suffix​","type":1,"pageTitle":"cmd_args type","url":"/docs/api/build/cmd_args/#cmd_argsabsolute_suffix","content":"def cmd_args.absolute_suffix(suffix: str.type) -&gt; &quot;cmd_args&quot;  Adds a suffix to the end of every artifact. Useful in conjunction with absolute_prefix to wrap artifacts in function calls. cmd_args(script).absolute_prefix(&quot;call(&quot;).absolute_suffix(&quot;)&quot;)   "},{"title":"cmd_args.add​","type":1,"pageTitle":"cmd_args type","url":"/docs/api/build/cmd_args/#cmd_argsadd","content":"def cmd_args.add(*args) -&gt; &quot;cmd_args&quot;  A list of arguments to be added to the command line, which may including cmd_args, artifacts, strings, RunInfo or lists thereof. Note that this operation mutates the input cmd_args.  "},{"title":"cmd_args.copy​","type":1,"pageTitle":"cmd_args type","url":"/docs/api/build/cmd_args/#cmd_argscopy","content":"def cmd_args.copy() -&gt; &quot;cmd_args&quot;  Returns a copy of the cmd_args such that any modifications to the original or the returned value will not impact each other. Note that this is a shallow copy, so any inner cmd_args can still be modified.  "},{"title":"cmd_args.hidden​","type":1,"pageTitle":"cmd_args type","url":"/docs/api/build/cmd_args/#cmd_argshidden","content":"def cmd_args.hidden(*args) -&gt; &quot;cmd_args&quot;  Things to add to the command line which do not show up but are added as dependencies. The values can be anything normally permissible to pass to add. Typically used if the command you are running implicitly depends on files that are not passed on the command line, e.g. headers in the case of a C compilation.  "},{"title":"cmd_args.ignore_artifacts​","type":1,"pageTitle":"cmd_args type","url":"/docs/api/build/cmd_args/#cmd_argsignore_artifacts","content":"def cmd_args.ignore_artifacts() -&gt; &quot;cmd_args&quot;  Causes this cmd_args to have no declared dependencies. Allows you to reference the path of an artifact without introducing dependencies on it. As an example where this can be useful, consider passing a dependency that is only accessed at runtime, but whose path must be baked into the binary. As an example: resources = cmd_args(resource_file, format = &quot;-DFOO={}&quot;).ignore_artifacts() ctx.actions.run(cmd_args(&quot;gcc&quot;, &quot;-c&quot;, source_file, resources))  Note that ignore_artifacts sets all artifacts referenced by this cmd_args to be ignored, including those added afterwards, so generally create a special cmd_args and scope it quite tightly. If you actually do use the inputs referenced by this command, you will either error out due to missing dependencies (if running actions remotely) or have untracked dependencies that will fail to rebuild when it should.  "},{"title":"cmd_args.inputs​","type":1,"pageTitle":"cmd_args type","url":"/docs/api/build/cmd_args/#cmd_argsinputs","content":"cmd_args.inputs: &quot;command_line_inputs&quot;  Collect all the inputs (including hidden) referenced by this command line. The output can be compared for equality and have its len requested to see whether there are any inputs, but is otherwise mostly opaque.  "},{"title":"cmd_args.outputs​","type":1,"pageTitle":"cmd_args type","url":"/docs/api/build/cmd_args/#cmd_argsoutputs","content":"cmd_args.outputs: [&quot;output_artifact&quot;]  Collect all the outputs (including hidden) referenced by this command line.  "},{"title":"cmd_args.parent​","type":1,"pageTitle":"cmd_args type","url":"/docs/api/build/cmd_args/#cmd_argsparent","content":"def cmd_args.parent(count: int.type = _, /) -&gt; &quot;cmd_args&quot;  For all the artifacts listed in this cmd_args, use their parent directory. Typically used when the file name is passed one way, and the directory another, e.g. cmd_args(artifact, format=&quot;-L{}&quot;).parent().  "},{"title":"cmd_args.relative_to​","type":1,"pageTitle":"cmd_args type","url":"/docs/api/build/cmd_args/#cmd_argsrelative_to","content":"def cmd_args.relative_to( directory: [&quot;artifact&quot;, &quot;cell_root&quot;, &quot;promise_artifact&quot;], /, *, parent: int.type = 0 ) -&gt; &quot;cmd_args&quot;  Make all artifact paths relative to a given location. Typically used when the command you are running changes directory. dir = symlinked_dir(...) script = [ cmd_args(cmd_args(dir, format = &quot;cd {}&quot;), original_script.relative_to(dir) ]   "},{"title":"cmd_args.replace_regex​","type":1,"pageTitle":"cmd_args type","url":"/docs/api/build/cmd_args/#cmd_argsreplace_regex","content":"def cmd_args.replace_regex( pattern: str.type, replacement: str.type ) -&gt; &quot;cmd_args&quot;  Replaces all parts matching pattern regular expression in each argument with replacement string. Several replacements can be added by multiple replace_regex calls. "},{"title":"dependency type","type":0,"sectionRef":"#","url":"/docs/api/build/dependency/","content":"","keywords":""},{"title":"dependency.get​","type":1,"pageTitle":"dependency type","url":"/docs/api/build/dependency/#dependencyget","content":"def dependency.get(index)   "},{"title":"dependency.label​","type":1,"pageTitle":"dependency type","url":"/docs/api/build/dependency/#dependencylabel","content":"dependency.label: &quot;&quot;   "},{"title":"dependency.providers​","type":1,"pageTitle":"dependency type","url":"/docs/api/build/dependency/#dependencyproviders","content":"dependency.providers: [&quot;&quot;]   "},{"title":"dependency.sub_target​","type":1,"pageTitle":"dependency type","url":"/docs/api/build/dependency/#dependencysub_target","content":"def dependency.sub_target(subtarget: str.type, /) -&gt; &quot;dependency&quot;  Obtain the dependency representing a subtarget. In most cases you will want to use x[DefaultInfo].sub_targets[&quot;foo&quot;] to get the providers of the subtarget, but if you need a real &quot;dependency&quot; type (e.g. for use with ctx.action.anon_target) then use this method. "},{"title":"label_relative_path type","type":0,"sectionRef":"#","url":"/docs/api/build/label_relative_path/","content":"","keywords":""},{"title":"label_relative_path.add​","type":1,"pageTitle":"label_relative_path type","url":"/docs/api/build/label_relative_path/#label_relative_pathadd","content":"def label_relative_path.add(arg: str.type) -&gt; &quot;label_relative_path&quot;  "},{"title":"label type","type":0,"sectionRef":"#","url":"/docs/api/build/label/","content":"","keywords":""},{"title":"label.cell​","type":1,"pageTitle":"label type","url":"/docs/api/build/label/#labelcell","content":"label.cell: str.type  For the label fbcode//buck2/hello:world (ovr_config//platform/linux:x86_64-fbcode-46b26edb4b80a905) this gives back fbcode  "},{"title":"label.cell_root​","type":1,"pageTitle":"label type","url":"/docs/api/build/label/#labelcell_root","content":"label.cell_root: &quot;cell_root&quot;   "},{"title":"label.configured_target​","type":1,"pageTitle":"label type","url":"/docs/api/build/label/#labelconfigured_target","content":"def label.configured_target() -&gt; &quot;configured_target_label&quot;  Returns the underlying configured target label, dropping the sub target  "},{"title":"label.name​","type":1,"pageTitle":"label type","url":"/docs/api/build/label/#labelname","content":"label.name: str.type  For the label fbcode//buck2/hello:world (ovr_config//platform/linux:x86_64-fbcode-46b26edb4b80a905) this gives back world  "},{"title":"label.package​","type":1,"pageTitle":"label type","url":"/docs/api/build/label/#labelpackage","content":"label.package: str.type  For the label fbcode//buck2/hello:world (ovr_config//platform/linux:x86_64-fbcode-46b26edb4b80a905) this gives back buck2/hello  "},{"title":"label.path​","type":1,"pageTitle":"label type","url":"/docs/api/build/label/#labelpath","content":"label.path: &quot;label_relative_path&quot;  For the label fbcode//buck2/hello:world (ovr_config//platform/linux:x86_64-fbcode-46b26edb4b80a905) this gives back fbcode/buck2/hello  "},{"title":"label.raw_target​","type":1,"pageTitle":"label type","url":"/docs/api/build/label/#labelraw_target","content":"def label.raw_target() -&gt; &quot;target_label&quot;  For the label fbcode//buck2/hello:world (ovr_config//platform/linux:x86_64-fbcode-46b26edb4b80a905) this returns the unconfigured underlying target label (fbcode//buck2/hello:world)  "},{"title":"label.sub_target​","type":1,"pageTitle":"label type","url":"/docs/api/build/label/#labelsub_target","content":"label.sub_target: [None, [str.type]]  "},{"title":"promise type","type":0,"sectionRef":"#","url":"/docs/api/build/promise/","content":"","keywords":""},{"title":"promise.join​","type":1,"pageTitle":"promise type","url":"/docs/api/build/promise/#promisejoin","content":"def promise.join(*args) -&gt; &quot;promise&quot;  Join a set of promises together into a single promise. Given a series of promises, p4 = p1.join(p2, p3) will produce a promise where the value is promise that resolves to a tuple containing the three values, those from p1, p2 and p3 respectively.  "},{"title":"promise.map​","type":1,"pageTitle":"promise type","url":"/docs/api/build/promise/#promisemap","content":"def promise.map(func, /) -&gt; &quot;promise&quot;  Given a promise, apply a function to the value it contains, producing a promise with the resulting value. "},{"title":"action type","type":0,"sectionRef":"#","url":"/docs/api/bxl/action/","content":"","keywords":""},{"title":"action.owner​","type":1,"pageTitle":"action type","url":"/docs/api/bxl/action/#actionowner","content":"def action.owner() -&gt; &quot;configured_target_label&quot;  Gets the owning configured target label for an action. Sample usage: def _impl_action(ctx): action = ctx.audit().output(&quot;buck-out/path/to/__target__/artifact&quot;, &quot;your_target_platform&quot;) ctx.output.print(action.owner())  "},{"title":"analysis_result type","type":0,"sectionRef":"#","url":"/docs/api/bxl/analysis_result/","content":"","keywords":""},{"title":"analysis_result.providers​","type":1,"pageTitle":"analysis_result type","url":"/docs/api/bxl/analysis_result/#analysis_resultproviders","content":"def analysis_result.providers()  Access the providers of the rule. Returns a [ProviderCollection] the same as accessing providers of dependencies within a rule implementation. Sample usage: def _impl_providers(ctx): node = ctx.configured_targets(&quot;root//bin:the_binary&quot;) providers = ctx.analysis(node).providers() ctx.output.print(providers[FooInfo]) providers = ctx.analysis(&quot;//:bin&quot;).providers() ctx.output.print(providers[FooInfo])  "},{"title":"audit_ctx type","type":0,"sectionRef":"#","url":"/docs/api/bxl/audit_ctx/","content":"","keywords":""},{"title":"audit_ctx.output​","type":1,"pageTitle":"audit_ctx type","url":"/docs/api/bxl/audit_ctx/#audit_ctxoutput","content":"def audit_ctx.output(output_path: str.type, target_platform = None)  Returns either: - The StarlarkAction which created the buck-out path, if exists. - The StarlarkTargetLabel (unconfigured target label) constructed from the buck-out path, if the configuration hashes do not match. - None, if the configuration hash of the buck-out path matches the one passed into this function, or the default target configuration, but no action could be found that generated the buck-out path. Takes in an optional target platform, otherwise will use the default target platform. Sample usage: def _impl_audit_output(ctx): target_platform = &quot;foo&quot; result = ctx.audit().output(&quot;buck-out/v2/gen/fbcode/some_cfg_hash/path/to/__target__/artifact&quot;, target_platform) ctx.output.print(result)  "},{"title":"bxl_actions type","type":0,"sectionRef":"#","url":"/docs/api/bxl/bxl_actions/","content":"","keywords":""},{"title":"bxl_actions.actions​","type":1,"pageTitle":"bxl_actions type","url":"/docs/api/bxl/bxl_actions/#bxl_actionsactions","content":"bxl_actions.actions: &quot;actions&quot;  Gets the analysis action context to create and register actions on the execution platform corresponding to this bxl action's execution platform resolution.  "},{"title":"bxl_actions.exec_deps​","type":1,"pageTitle":"bxl_actions type","url":"/docs/api/bxl/bxl_actions/#bxl_actionsexec_deps","content":"bxl_actions.exec_deps: {&quot;&quot;: &quot;&quot;}  Gets the execution deps requested correctly configured for the current execution platform  "},{"title":"bxl_actions.toolchains​","type":1,"pageTitle":"bxl_actions type","url":"/docs/api/bxl/bxl_actions/#bxl_actionstoolchains","content":"bxl_actions.toolchains: {&quot;&quot;: &quot;&quot;}  Gets the toolchains requested configured for the current execution platform "},{"title":"bxl_build_result type","type":0,"sectionRef":"#","url":"/docs/api/bxl/bxl_build_result/","content":"","keywords":""},{"title":"bxl_build_result.artifacts​","type":1,"pageTitle":"bxl_build_result type","url":"/docs/api/bxl/bxl_build_result/#bxl_build_resultartifacts","content":"def bxl_build_result.artifacts() -&gt; [&quot;bxl_built_artifacts_iterable&quot;, None]  Returns an optional iterable of artifacts that was successfully built. Sample usage: def _impl(ctx): outputs = {} for target, value in ctx.build(ctx.cli_args.target).items(): ctx.output.print(value.artifacts())   "},{"title":"bxl_build_result.failures​","type":1,"pageTitle":"bxl_build_result type","url":"/docs/api/bxl/bxl_build_result/#bxl_build_resultfailures","content":"def bxl_build_result.failures() -&gt; [&quot;bxl_failed_artifacts_iterable&quot;, None]  Returns an optional of iterable of artifacts that failed to be built. Sample usage: def _impl(ctx): outputs = {} for target, value in ctx.build(ctx.cli_args.target).items(): ctx.output.print(value.failures())  "},{"title":"globals","type":0,"sectionRef":"#","url":"/docs/api/build/globals/","content":"","keywords":""},{"title":"CommandExecutorConfig​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#commandexecutorconfig","content":"def CommandExecutorConfig( *, local_enabled: bool.type, remote_enabled: bool.type, remote_cache_enabled: [None, bool.type] = None, remote_execution_properties = None, remote_execution_action_key = None, remote_execution_max_input_files_mebibytes: [None, int.type] = None, remote_execution_queue_time_threshold_s: [None, int.type] = None, remote_execution_use_case = None, use_limited_hybrid: bool.type = False, allow_limited_hybrid_fallbacks: bool.type = False, allow_hybrid_fallbacks_on_failure: bool.type = False, use_windows_path_separators: bool.type = False, use_persistent_workers: bool.type = False, allow_cache_uploads: bool.type = False, max_cache_upload_mebibytes: [None, int.type] = None, experimental_low_pass_filter: bool.type = False, remote_output_paths: [None, str.type] = None ) -&gt; &quot;command_executor_config&quot;  Contains configurations for how actions should be executed .type attribute​ Produces &quot;command_executor_config&quot; Details​ local_enabled : Whether to use local execution for this execution platform. If both remote_enabled and local_enabled are True, we will use the hybrid executorremote_enabled: Whether to use remote execution for this execution platformremote_cache_enabled: Whether to query RE cachesremote_execution_properties: Properties for remote execution for this platformremote_execution_action_key: A component to inject into the action key This should typically used to inject variability into the action key so that it's different across e.g. build modes (RE uses the action key for things like expected memory utilization)remote_execution_max_input_files_mebibytes: The maximum input file size (in bytes) that remote execution can supportremote_execution_queue_time_threshold_s: The maximum time in seconds we are willing to wait in the RE queue for remote execution to start running our actionremote_execution_use_case: The use case to use when communicating with REuse_limited_hybrid: Whether to use the limited hybrid executorallow_limited_hybrid_fallbacks: Whether to allow fallbacksallow_hybrid_fallbacks_on_failure: Whether to allow fallbacks when the result is failure (i.e. the command failed on the primary, but the infra worked)use_windows_path_separators: Whether to use Windows path separators in command line argumentsuse_persistent workers: Whether to use persistent workers for local execution if they are availableallow_cache_uploads: Whether to upload local actions to the RE cachemax_cache_upload_mebibytes: Maximum size to upload in cache uploadsexperimental_low_pass_filter: Whether to use the experimental low pass filterremote_output_paths: How to express output paths to RE  "},{"title":"ConfigurationInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#configurationinfo","content":"def ConfigurationInfo( *, constraints: {&quot;target_label&quot;: &quot;ConstraintValueInfo&quot;}, values: {str.type: str.type} ) -&gt; &quot;ConfigurationInfo&quot;  Provider that signals that a rule contains configuration info. This is used both as part of defining configurations (platform(), constraint_value()) and defining whether a target &quot;matches&quot; a configuration or not (config_setting(), constraint_value()) .type attribute​ Produces &quot;ConfigurationInfo&quot; Details​ Provides a number of fields that can be accessed: constraints: {&quot;target_label&quot;: &quot;ConstraintValueInfo&quot;} - field values: {str.type: str.type} - field  "},{"title":"ConstraintSettingInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#constraintsettinginfo","content":"def ConstraintSettingInfo(*, label: &quot;target_label&quot;) -&gt; &quot;ConstraintSettingInfo&quot;  Provider that signals that a target can be used as a constraint key. This is the only provider returned by a constraint_setting() target. .type attribute​ Produces &quot;ConstraintSettingInfo&quot; Details​ Provides a number of fields that can be accessed: label: &quot;target_label&quot; - field  "},{"title":"ConstraintValueInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#constraintvalueinfo","content":"def ConstraintValueInfo( *, setting: &quot;ConstraintSettingInfo&quot;, label: &quot;target_label&quot; ) -&gt; &quot;ConstraintValueInfo&quot;  Provider that signals that a target can be used as a constraint key. This is the only provider returned by a constraint_value() target. .type attribute​ Produces &quot;ConstraintValueInfo&quot; Details​ Provides a number of fields that can be accessed: setting: &quot;ConstraintSettingInfo&quot; - field label: &quot;target_label&quot; - field  "},{"title":"DefaultInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#defaultinfo","content":"def DefaultInfo( default_output = None, default_outputs = None, other_outputs = [], sub_targets: {str.type: &quot;&quot;} = {} ) -&gt; &quot;DefaultInfo&quot;  A provider that all rules' implementations must return .type attribute​ Produces &quot;DefaultInfo&quot; Details​ In many simple cases, this can be inferred for the user. Example of a rule's implementation function and how these fields are used by the framework: # //foo_binary.bzl def impl(ctx): ctx.action.run([ctx.attrs._cc[RunInfo], &quot;-o&quot;, ctx.attrs.out.as_output()] + ctx.attrs.srcs) ctx.action.run([ ctx.attrs._strip[RunInfo], &quot;--binary&quot;, ctx.attrs.out, &quot;--stripped-out&quot;, ctx.attrs.stripped.as_output(), &quot;--debug-symbols-out&quot;, ctx.attrs.debug_info.as_output(), ]) return [ DefaultInfo( sub_targets = { &quot;stripped&quot;: [ DefaultInfo(default_outputs = [ctx.attrs.stripped, ctx.attrs.debug_info]), ], }, default_output = ctx.attrs.out, ] foo_binary = rule( impl=impl, attrs={ &quot;srcs&quot;: attrs.list(attrs.source()), &quot;out&quot;: attrs.output(), &quot;stripped&quot;: attrs.output(), &quot;debug_info&quot;: attrs.output(), &quot;_cc&quot;: attrs.dep(default=&quot;//tools:cc&quot;, providers=[RunInfo]), &quot;_strip_script&quot;: attrs.dep(default=&quot;//tools:strip&quot;, providers=[RunInfo]) ) def foo_binary_wrapper(name, srcs): foo_binary( name = name, srcs = src, out = name, stripped = name + &quot;.stripped&quot;, debug_info = name + &quot;.debug_info&quot;, ) # //subdir/BUCK load(&quot;//:foo_binary.bzl&quot;, &quot;foo_binary_wrapper&quot;) genrule(name = &quot;gen_stuff&quot;, ...., default_outs = [&quot;foo.cpp&quot;]) # &quot;:gen_stuff&quot; pulls the default_outputs for //subdir:gen_stuff foo_binary_wrapper(name = &quot;foo&quot;, srcs = glob([&quot;*.cpp&quot;]) + [&quot;:gen_stuff&quot;]) # Builds just 'foo' binary. The strip command is never invoked. $ buck build //subdir:foo # builds the 'foo' binary, because it is needed by the 'strip' command. Ensures that # both the stripped binary and the debug symbols are built. $ buck build //subdir:foo[stripped]  Provides a number of fields that can be accessed: sub_targets: {str.type: &quot;provider_collection&quot;} - A mapping of names to ProviderCollections. The keys are used when resolving the ProviderName portion of a ProvidersLabel. These collections can contain, and actually /must/ contain a DefaultInfo provider. However, nested label syntax is not supported. That is, cell//foo:bar[baz] is valid, cell//foo:bar[baz][quz] is not. default_outputs: [&quot;artifact&quot;] - A list of Artifacts that are built by default if this rule is requested explicitly, or depended on as as a &quot;source&quot;. other_outputs: [&quot;artifact&quot;] - A list of ArtifactTraversable. The underlying Artifacts they define will be built by default if this rule is requested, but not when it's depended on as as a &quot;source&quot;. ArtifactTraversable can be an Artifact (which yields itself), or cmd_args, which expand to all their inputs.  "},{"title":"ExecutionPlatformInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#executionplatforminfo","content":"def ExecutionPlatformInfo( *, label, configuration, executor_config ) -&gt; &quot;ExecutionPlatformInfo&quot;  Provider that signals that a target represents an execution platform. Provides a number of fields that can be accessed: label: &quot;target_label&quot; - label of the defining rule, used in informative messages configuration: &quot;ConfigurationInfo&quot; - The configuration of the execution platform executor_config: &quot;command_executor_config&quot; - The executor config  "},{"title":"ExecutionPlatformRegistrationInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#executionplatformregistrationinfo","content":"def ExecutionPlatformRegistrationInfo( *, platforms, fallback = _ ) -&gt; &quot;ExecutionPlatformRegistrationInfo&quot;  Provider that gives the list of all execution platforms available for this build. Provides a number of fields that can be accessed: platforms: [&quot;ExecutionPlatformInfo&quot;] - field fallback: &quot;&quot; - field  "},{"title":"ExternalRunnerTestInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#externalrunnertestinfo","content":"def ExternalRunnerTestInfo( type, command = None, env = None, labels = None, contacts = None, use_project_relative_paths = None, run_from_project_root = None, default_executor = None, executor_overrides = None, local_resources = None ) -&gt; &quot;ExternalRunnerTestInfo&quot;  Provider that signals that a rule can be tested using an external runner. This is the Buck1-compatible API for tests. .type attribute​ Produces &quot;ExternalRunnerTestInfo&quot; Details​ Provides a number of fields that can be accessed: test_type: str.type - A Starlark value representing the type of this test. This is of type str.type command: [&quot;&quot;] - A Starlark value representing the command for this test. The external test runner is what gives meaning to this command. This is of type [[str.type, &quot;_arglike&quot;]] env: {str.type: &quot;&quot;} - A Starlark value representing the environment for this test. Here again, the external test runner is what will this meaning. This is of type {str.type: _arglike} labels: [str.type] - A starlark value representing the labels for this test. This is of type [str.type] contacts: [str.type] - A starlark value representing the contacts for this test. This is largely expected to be an oncall, though it's not validated in any way. This is of type [str.type] use_project_relative_paths: [bool.type] - Whether this test should use relative paths. The default is not to. This is of type [bool.type] run_from_project_root: [bool.type] - Whether this test should run from the project root, as opposed to the cell root. The default is not to. This is of type [bool.type] default_executor: &quot;command_executor_config&quot; - Default executor to use to run tests. This is of type CommandExecutorConfig. If none is passed we will default to the execution platform. executor_overrides: {str.type: &quot;command_executor_config&quot;} - Executors that Tpx can use to override the default executor. This is of type {str.type: CommandExecutorConfig} local_resources: {str.type: [&quot;LocalResourceInfo&quot;, None]} - Mapping from a local resource type to a corresponding provider. Required types are passed from test runner. If the value for a corresponding type is omitted it means local resource should be ignored when executing tests even if those are passed as required from test runner.  "},{"title":"InstallInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#installinfo","content":"def InstallInfo(installer: &quot;label&quot;, files: {str.type: &quot;&quot;}) -&gt; &quot;InstallInfo&quot;  A provider that can be constructed and have its fields accessed. Returned by rules. Provides a number of fields that can be accessed: installer: &quot;label&quot; - field files: {str.type: &quot;artifact&quot;} - field  "},{"title":"Label​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#label","content":"Label: &quot;type&quot;   "},{"title":"LocalResourceInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#localresourceinfo","content":"def LocalResourceInfo( *, source_target, setup, resource_env_vars ) -&gt; &quot;LocalResourceInfo&quot;  A provider that can be constructed and have its fields accessed. Returned by rules. .type attribute​ Produces &quot;LocalResourceInfo&quot; Details​ Provides a number of fields that can be accessed: source_target: &quot;label&quot; - Configured target that is providing this local resource. setup: &quot;cmd_args&quot; - Command to run to initialize a local resource. Running this command writes a JSON to stdout. This JSON represents a pool of local resources which are ready to be used. Example JSON would be: { &quot;pid&quot;: 42, &quot;resources&quot;: [ {&quot;socket_address&quot;: &quot;foo:1&quot;}, {&quot;socket_address&quot;: &quot;bar:2&quot;} ]} Where '&quot;pid&quot;maps to a PID of a process which should be sent SIGTERM to release the pool of resources when they are no longer needed.&quot;resources&quot;maps to the pool of resources. When a local resource from this particular pool is needed for an execution command, single entity will be reserved from the pool, for example{&quot;socket_address&quot;: &quot;bar:2&quot;}and environment variable with name resolved using mapping inresource_env_varsfield and&quot;socket_address&quot;` key will be added to execution command. resource_env_vars: {str.type: str.type} - Mapping from environment variable (appended to an execution command which is dependent on this local resource) to keys in setup command JSON output.  "},{"title":"PlatformInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#platforminfo","content":"def PlatformInfo( *, label: str.type, configuration: &quot;ConfigurationInfo&quot; ) -&gt; &quot;PlatformInfo&quot;  A provider that can be constructed and have its fields accessed. Returned by rules. .type attribute​ Produces &quot;PlatformInfo&quot; Details​ Provides a number of fields that can be accessed: label: str.type - field configuration: &quot;ConfigurationInfo&quot; - field  "},{"title":"RunInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#runinfo","content":"def RunInfo(args = []) -&gt; &quot;RunInfo&quot;  Provider that signals that a rule is runnable .type attribute​ Produces &quot;RunInfo&quot; Details​ Provides a number of fields that can be accessed: args: &quot;cmd_args&quot; - The command to run, stored as CommandLine  "},{"title":"TemplatePlaceholderInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#templateplaceholderinfo","content":"def TemplatePlaceholderInfo( unkeyed_variables = {}, keyed_variables = {} ) -&gt; &quot;TemplatePlaceholderInfo&quot;  A provider that is used for expansions in string attribute templates .type attribute​ Produces &quot;TemplatePlaceholderInfo&quot; Details​ String attribute templates allow two types of user-defined placeholders, &quot;unkeyed placeholders&quot; like $(CXX) or $(aapt) and &quot;keyed placeholders&quot; that include a target key like$(cxxppflags //some:target). The expansion of each of these types is based on theTemplatePlaceholderInfo providers. &quot;keyed placeholders&quot; are used for the form $(&lt;key&gt; &lt;target&gt;) or $(&lt;key&gt; &lt;target&gt; &lt;arg&gt;). In both cases the lookup will expect a TemplatePlaceholderInfo in the providers of &lt;target&gt;. It will then lookup&lt;key&gt; in the keyed_variables (call this the value). There are then four valid possibilities: no-arg placeholder, an arg-like value: resolve to valueno-arg placeholder, a dictionary value: resolve to value[&quot;DEFAULT&quot;]arg placeholder, a non-dictionary value: this is an errorarg placeholder, a dictionary value: resolve to value[&lt;arg&gt;] &quot;unkeyed placeholders&quot; are resolved by matching to any of the deps of the target. $(CXX) will resolve to the &quot;CXX&quot; value in any dep's TemplateProviderInfo.unkeyed_variables Fields: unkeyed_variables: A mapping of names to arg-like values. These are used for &quot;unkeyed placeholder&quot; expansion.keyed_variables: A mapping of names to arg-like values or dictionary of string to arg-like values. These are used for &quot;keyed placeholder&quot; expansion. Provides a number of fields that can be accessed: unkeyed_variables: &quot;&quot; - field keyed_variables: &quot;&quot; - field  "},{"title":"WorkerInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#workerinfo","content":"def WorkerInfo( exe = [], *, concurrency: [None, int.type] = None ) -&gt; &quot;WorkerInfo&quot;  Provider that signals that a rule is a worker tool .type attribute​ Produces &quot;WorkerInfo&quot; Details​ Provides a number of fields that can be accessed: exe: &quot;cmd_args&quot; - field concurrency: [None, int.type] - field  "},{"title":"WorkerRunInfo​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#workerruninfo","content":"def WorkerRunInfo(*, worker: &quot;WorkerInfo&quot;, exe = []) -&gt; &quot;WorkerRunInfo&quot;  Provider that signals that a rule can run using a worker .type attribute​ Produces &quot;WorkerRunInfo&quot; Details​ Provides a number of fields that can be accessed: worker: &quot;WorkerInfo&quot; - field exe: &quot;cmd_args&quot; - field  "},{"title":"__internal__​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#__internal__","content":"__internal__: struct(..)   "},{"title":"attrs​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#attrs","content":"attrs: &quot;attrs&quot;   "},{"title":"cmd_args​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#cmd_args","content":"def cmd_args( *args, delimiter: str.type = _, format: str.type = _, prepend: str.type = _, quote: str.type = _ ) -&gt; &quot;cmd_args&quot;  The cmd_args type is created by this function and is consumed by ctx.actions.run. The type is a mutable collection of strings and artifact values. In general, command lines, artifacts, strings, RunInfo and lists thereof can be added to or used to construct a cmd_args value. .type attribute​ Produces &quot;cmd_args&quot; Details​ The arguments are: *args - a list of things to add to the command line, each of which must be coercible to a command line. Further items can be added with cmd.add.format - a string that provides a format to apply to the argument. for example, cmd_args(x, format=&quot;--args={}&quot;) would prepend --args= before x, or if x was a list, before each element in x.delimiter - added between arguments to join them together. For example, cmd_args([&quot;--args=&quot;,x], delimiter=&quot;&quot;) would produce a single argument to the underlying tool.prepend - added as a separate argument before each argument.quote - indicates whether quoting is to be applied to each argument. The only current valid value is &quot;shell&quot;.  "},{"title":"dedupe​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#dedupe","content":"def dedupe(val, /)  Remove duplicates in a list. Uses identity of value (pointer), rather than by equality. In many cases you should use a transitive set instead.  "},{"title":"get_base_path​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#get_base_path","content":"def get_base_path() -&gt; str.type  get_base_path() can only be called in BUCK files, and returns the name of the package. E.g. inside foo//bar/baz/BUCK the output will be bar/baz. This function is identical to package_name.  "},{"title":"get_cell_name​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#get_cell_name","content":"def get_cell_name() -&gt; str.type  get_cell_name() can be called from either a BUCK file or a .bzl file, and returns the name of the cell where the BUCK file that started the call lives. For example, inside foo//bar/baz/BUCK the output will be foo. If that BUCK file does a load(&quot;hello//world.bzl&quot;, &quot;something&quot;) then the result in that .bzl file will also be foo.  "},{"title":"glob​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#glob","content":"def glob(include: [str.type], *, exclude: [str.type] = []) -&gt; [str.type]  The glob() function specifies a set of files using patterns. Only available from BUCK files. A typical glob call looks like: glob([&quot;foo/**/*.h&quot;])  This call will match all header files in the foo directory, recursively. You can also pass a named exclude parameter to remove files matching a pattern: glob([&quot;foo/**/*.h&quot;], exclude = [&quot;**/config.h&quot;])  This call will remove all config.h files from the initial match. The glob() call is evaluated against the list of files owned by this BUCK file. A file is owned by whichever BUCK file is closest above it - so given foo/BUCK andfoo/bar/BUCK the file foo/file.txt would be owned by foo/BUCK (and available from its glob results) but the file foo/bar/file.txt would be owned by foo/bar/BUCkand not appear in the glob result of foo/BUCK, even if you write glob([&quot;bar/file.txt&quot;]). As a consequence of this rule, glob([&quot;../foo.txt&quot;]) will always return an empty list of files. Currently glob is evaluated case-insensitively on all file systems, but we expect that to change to case sensitive in the near future.  "},{"title":"host_info​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#host_info","content":"def host_info() -&gt; struct(..)  The host_info() function is used to get the current OS and processor architecture on the host. The structure returned is laid out thusly: struct( os=struct( is_linux=True|False, is_macos=True|False, is_windows=True|False, is_freebsd=True|False, is_unknown=True|False, ), arch=struct( is_aarch64=True|False, is_arm=True|False, is_armeb=True|False, is_i386=True|False, is_mips=True|False, is_mips64=True|False, is_mipsel=True|False, is_mipsel64=True|False, is_powerpc=True|False, is_ppc64=True|False, is_x86_64=True|False, is_unknown=True|False, ), )   "},{"title":"implicit_package_symbol​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#implicit_package_symbol","content":"def implicit_package_symbol(name: str.type, default = _)   "},{"title":"load_symbols​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#load_symbols","content":"def load_symbols(symbols: {str.type: &quot;&quot;}) -&gt; None  Used in a .bzl file to set exported symbols. In most cases just defining the symbol as a top-level binding is sufficient, but sometimes the names might be programatically generated. It is undefined behaviour if you try and use any of the symbols exported here later in the same module, or if they overlap with existing definitions. This function should be used rarely.  "},{"title":"oncall​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#oncall","content":"def oncall(name: str.type, /) -&gt; None  Called in a BUCK file to declare the oncall contact details for all the targets defined. Must be called at most once, before any targets have been declared. Errors if called from a .bzl file.  "},{"title":"package​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#package","content":"def package( *, inherit: bool.type = False, visibility: [str.type] = [], within_view: [str.type] = [] ) -&gt; None   "},{"title":"package_name​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#package_name","content":"def package_name() -&gt; str.type  package_name() can only be called in BUCK files, and returns the name of the package. E.g. inside foo//bar/baz/BUCK the output will be bar/baz.  "},{"title":"provider​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#provider","content":"def provider( *, doc: str.type = &quot;&quot;, fields: [[str.type], {str.type: str.type}] ) -&gt; &quot;provider_callable&quot;  Create a &quot;provider&quot; type that can be returned from rule implementations. Used to pass information from a rule to the things that depend on it. Typically named with an Info suffix. GroovyLibraryInfo(fields = [ &quot;objects&quot;, # a list of artifacts &quot;options&quot;, # a string containing compiler options ])  Given a dependency you can obtain the provider with my_dep[GroovyLibraryInfo]which returns either None or a value of type GroovyLibraryInfo. For providers that accumulate upwards a transitive set is often a good choice.  "},{"title":"read_config​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#read_config","content":"def read_config(section: str.type, key: str.type, default = _)  Read a configuration from the nearest enclosing .buckconfig of the BUCK file that started evaluation of this code. As an example, if you have a .buckconfig of: [package_options] compile = super_fast  Then you would get the following results: read_config(&quot;package_options&quot;, &quot;compile&quot;) == &quot;super_fast&quot; read_config(&quot;package_options&quot;, &quot;linker&quot;) == None read_config(&quot;package_options&quot;, &quot;linker&quot;, &quot;a_default&quot;) == &quot;a_default&quot;  In general the use of .buckconfig is discouraged in favour of select, but it can still be useful.  "},{"title":"read_package_value​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#read_package_value","content":"def read_package_value(key: str.type, /)  Read value specified in the PACKAGE file. Returns None if value is not set.  "},{"title":"read_root_config​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#read_root_config","content":"def read_root_config( section: str.type, key: str.type, default: [None, str.type] = None, / ) -&gt; [None, str.type]  Like read_config but the project root .buckconfig is always consulted, regardless of the cell of the originating BUCK file.  "},{"title":"regex_match​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#regex_match","content":"def regex_match(regex: str.type, str: str.type, /) -&gt; bool.type  Test if a regular expression matches a string. Fails if the regular expression is malformed. As an example: regex_match(&quot;^[a-z]*$&quot;, &quot;hello&quot;) == True regex_match(&quot;^[a-z]*$&quot;, &quot;1234&quot;) == False   "},{"title":"repository_name​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#repository_name","content":"def repository_name() -&gt; str.type  Like get_cell_name() but prepends a leading @ for compatibility with Buck1. You should call get_cell_name() instead, and if you really want the @, prepend it yourself.  "},{"title":"rule​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#rule","content":"def rule( *, impl, attrs: {str.type: &quot;attribute&quot;}, cfg = _, doc: str.type = &quot;&quot;, is_configuration_rule: bool.type = False, is_toolchain_rule: bool.type = False ) -&gt; &quot;rule&quot;  Define a rule. As a simple example: def _my_rule(ctx: &quot;context&quot;) -&gt; [&quot;provider&quot;]: output = ctx.actions.write(&quot;hello.txt&quot;, ctx.attrs.contents, executable = ctx.attrs.exe) return [DefaultInfo(outputs = [output])] MyRule = rule(impl = _my_rule, attrs = { &quot;contents&quot;: attrs.string(), &quot;exe&quot;: attrs.option(attrs.bool(), default = False), })   "},{"title":"rule_exists​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#rule_exists","content":"def rule_exists(name: str.type) -&gt; bool.type  Check if the target with name has already been defined, returns True if it has. Note that this function checks for the existence of a target rather than a rule. In general use of this function is discouraged, as it makes definitions of rules not compose.  "},{"title":"select​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#select","content":"def select(d, /) -&gt; &quot;selector&quot;   "},{"title":"select_equal_internal​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#select_equal_internal","content":"def select_equal_internal(left, right, /) -&gt; bool.type  Tests that two selects are equal to each other. For testing use only.  "},{"title":"select_map​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#select_map","content":"def select_map(d, func, /)  Applies a mapping function to a selector. See [StarlarkSelector::select_map].  "},{"title":"select_test​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#select_test","content":"def select_test(d, func, /) -&gt; bool.type  Applies a test function to a selector. See [StarlarkSelector::select_test].  "},{"title":"sha256​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#sha256","content":"def sha256(val: str.type, /) -&gt; str.type  Computes a sha256 digest for a string. Returns the hex representation of the digest. sha256(&quot;Buck2 is the best build system&quot;) == &quot;bb99a3f19ecba6c4d2c7cd321b63b669684c713881baae21a6b1d759b3ec6ac9&quot;   "},{"title":"soft_error​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#soft_error","content":"def soft_error(category: str.type, message: str.type, /) -&gt; None  Produce an error that will become a hard error at some point in the future, but for now is a warning which is logged to the server. In the open source version of Buck2 this function always results in an error. Called passing a stable key (must be snake_case and start with starlark_, used for consistent reporting) and an arbitrary message (used for debugging). As an example: soft_error( &quot;starlark_rule_is_too_long&quot;, &quot;Length of property exceeds 100 characters in &quot; + repr(ctx.label), )   "},{"title":"transition​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#transition","content":"def transition( *, impl, refs: {str.type: str.type}, attrs: [str.type] = _, split: bool.type = False ) -&gt; &quot;transition&quot;   "},{"title":"transitive_set​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#transitive_set","content":"def transitive_set( args_projections: {str.type: &quot;&quot;} = _, json_projections: {str.type: &quot;&quot;} = _, reductions: {str.type: &quot;&quot;} = _ ) -&gt; &quot;transitive_set_definition&quot;   "},{"title":"warning​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#warning","content":"def warning(x: str.type, /) -&gt; None  Print a warning. The line will be decorated with the timestamp and other details, including the word WARN (colored, if the console supports it). If you are not writing a warning, use print instead. Be aware that printing lots of output (warnings or not) can be cause all information to be ignored by the user.  "},{"title":"write_package_value​","type":1,"pageTitle":"globals","url":"/docs/api/build/globals/#write_package_value","content":"def write_package_value( key: str.type, value, /, *, overwrite: bool.type = False ) -&gt; None  Set the value to be accessible in the nested PACKAGE files. "},{"title":"bxl_ctx type","type":0,"sectionRef":"#","url":"/docs/api/bxl/bxl_ctx/","content":"","keywords":""},{"title":"bxl_ctx.actions_factory​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxactions_factory","content":"bxl_ctx.actions_factory: &quot;&quot;  DO NOT USE - will be deprecated soon.  "},{"title":"bxl_ctx.analysis​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxanalysis","content":"def bxl_ctx.analysis( labels, target_platform = None, skip_incompatible: bool.type = True )  Runs analysis on the given labels, accepting an optional target_platform which is the target platform configuration used to resolve configurations of any unconfigured target nodes, and an optional skip_incompatible boolean that indicates whether to skip analysis of nodes that are incompatible with the target platform. The target_platform is either a string that can be parsed as a target label, or a target label. The given labels is a providers expression, which is either: - a single string that is a `target pattern`. - a single target node or label, configured or unconfigured - a single sub target label, configured or unconfigured - a list of the two options above.  This returns either a single [StarlarkAnalysisResult] if the given labels is &quot;singular&quot;, or a dict keyed by sub target labels of [StarlarkAnalysisResult] if the given labelsis list-like  "},{"title":"bxl_ctx.audit​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxaudit","content":"def bxl_ctx.audit() -&gt; &quot;audit_ctx&quot;  Returns the [StarlarkAuditCtx] that holds all the audit functions.  "},{"title":"bxl_ctx.build​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxbuild","content":"def bxl_ctx.build( spec, target_platform = None, *, materializations: str.type = &quot;default&quot; )  Runs a build on the given labels, accepting an optional target_platform which is the target platform configuration used to resolve configurations. Note that when build() is called, the artifacts are materialized without needing to additionally call ensure() on them. The given labels is a providers expression, which is either: - a single string that is a `target pattern`. - a single target node or label, configured or unconfigured - a single provider label, configured or unconfigured - a list of the two options above.  This returns a dict keyed by sub target labels of [StarlarkBuildResult] if the given labels is list-like  "},{"title":"bxl_ctx.bxl_actions​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxbxl_actions","content":"def bxl_ctx.bxl_actions( *, exec_deps = None, toolchains = None, target_platform = None, exec_compatible_with = None ) -&gt; &quot;bxl_actions&quot;  Returns the bxl actions to create and register actions for this bxl function. This will have the execution platform resolved according to the execution deps and toolchains you pass into this function. You'll be able to access the analysis action factory of the correct execution platform, toolchains, and execution deps of the corresponding configuration via this context. Actions created by bxl will not be built by default. Instead, they are marked to be built by ctx.output.ensure(artifact) on the output module of the [BxlContext]. Only artifacts marked by ensure will be built. Sample usage: def _impl_write_action(ctx): bxl_actions = ctx.bxl_actions() output = bxl_actions.actions.write(&quot;my_output&quot;, &quot;my_content&quot;) ensured = ctx.output.ensure(output) ctx.output.print(ensured)  There are several optional named parameters: exec_deps - These are dependencies you wish to access as executables for creating the action. This is usually the same set of targets one would pass to rule's attr.exec_dep.toolchains - The set of toolchains needed for the actions you intend to create.target_platform - The intended target platform for your toolchainsexec_compatible_with - Explicit list of configuration nodes (like platforms or constraints) that these actions are compatible with. This is the 'exec_compatible_with' attribute of a target.  "},{"title":"bxl_ctx.cli_args​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxcli_args","content":"bxl_ctx.cli_args: &quot;&quot;  A struct of the command line args as declared using the [cli_args] module. These command lines are resolved per the users input on the cli when invoking the bxl script. If you wish to pass in a kebab-cased arg, the arg accessed from the BXL context's cli_argsattrbute will always be in snakecase. For example, if you passed in my-arg, accessing it within BXL would look like ctx.cli_args.my_arg.  "},{"title":"bxl_ctx.configured_targets​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxconfigured_targets","content":"def bxl_ctx.configured_targets(labels, /, target_platform = None)  Gets the target nodes for the labels, accepting an optional target_platform which is the target platform configuration used to resolve configurations of any unconfigured target nodes. The target_platform is either a string that can be parsed as a target label, or a target label. The given labels is a [TargetExpr], which is either: - a single string that is a `target pattern`. - a single target node or label, configured or unconfigured - a list of the two options above.  Note that this function does not accept Label (which is a configured provider label), since this is the label of a subtarget. You can get the underlying configured target label on the Labelusing configured_targets() (ex: my_label.configured_target()). This returns either a single [StarlarkConfiguredTargetNode] if the given labelsis &quot;singular&quot;, a dict keyed by target labels of [StarlarkConfiguredTargetNode] if the given labels is list-like  "},{"title":"bxl_ctx.cquery​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxcquery","content":"def bxl_ctx.cquery(target_platform = None) -&gt; &quot;cqueryctx&quot;  Returns the [StarlarkCQueryCtx] that holds all the cquery functions. This function takes an optional parameter target_platform, which is the target platform configuration used to configured any unconfigured target nodes. The target_platform is a target label, or a string that is a target label.  "},{"title":"bxl_ctx.fs​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxfs","content":"bxl_ctx.fs: &quot;fs&quot;  Returns the [BxlFilesystem] for performing a basic set of filesystem operations within bxl  "},{"title":"bxl_ctx.instant_event​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxinstant_event","content":"def bxl_ctx.instant_event(*, id: str.type, metadata) -&gt; None  Emits a user-defined instant event, taking in a required string id and a metadata dictionary where the keys are strings, and values are either strings, bools, or ints. The id is user-supplied, and used to identify the instant events in the event logs more easily.  "},{"title":"bxl_ctx.output​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxoutput","content":"bxl_ctx.output: &quot;&quot;  Gets the output stream to the console via stdout. Items written to the output stream are considered to be the results of a bxl script, which will be displayed to stdout by buck2 even when the script is cached. Prints that are not result of the bxl should be printed via stderr via the stdlib printand pprint.  "},{"title":"bxl_ctx.resolve​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxresolve","content":"def bxl_ctx.resolve(action_factory: &quot;actions&quot;, promise: &quot;promise&quot;)  Awaits a promise and returns an optional value of the promise. Sample usage: load(&quot;//path/to/rules:rules.bzl&quot;, &quot;my_anon_targets_rule&quot;, &quot;my_map_function&quot;) def _resolve_impl(ctx): actions = ctx.bxl_actions().actions my_attrs = { &quot;false&quot;: False, &quot;int&quot;: 42, &quot;list_string&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], &quot;string&quot;: &quot;a-string&quot;, &quot;true&quot;: True, } promise = actions.anon_target(my_anon_targets_rule, attrs).map(my_map_function) providers_result = ctx.resolve(actions, promise) # result is `provider_callable` type, which is a collection of `provider`s ctx.output.print(providers_result[0].my_field)   "},{"title":"bxl_ctx.root​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxroot","content":"def bxl_ctx.root() -&gt; str.type  Returns the absolute path to the root of the repository  "},{"title":"bxl_ctx.unconfigured_targets​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxunconfigured_targets","content":"def bxl_ctx.unconfigured_targets(labels)  Gets the unconfigured target nodes for the labels The given labels is either: - a single string that is a `target pattern`. - a single unconfigured target node or label - a list of the two options above.  This returns either a single [StarlarkTargetNode] if the given labelsis &quot;singular&quot;, a dict keyed by target labels of [StarlarkTargetNode] if the given labels is list-like  "},{"title":"bxl_ctx.uquery​","type":1,"pageTitle":"bxl_ctx type","url":"/docs/api/bxl/bxl_ctx/#bxl_ctxuquery","content":"def bxl_ctx.uquery() -&gt; &quot;uqueryctx&quot;  Returns the [StarlarkUQueryCtx] that holds all uquery functions. "},{"title":"bxl_output_stream type","type":0,"sectionRef":"#","url":"/docs/api/bxl/bxl_output_stream/","content":"","keywords":""},{"title":"bxl_output_stream.ensure​","type":1,"pageTitle":"bxl_output_stream type","url":"/docs/api/bxl/bxl_output_stream/#bxl_output_streamensure","content":"def bxl_output_stream.ensure(artifact) -&gt; &quot;ensured_artifact&quot;  Marks the artifact as an artifact that should be available to the users at the end of the bxl invocation. Any artifacts that do not get registered via this call is not accessible by users at the end of bxl script. This function returns an ensured_artifact type that can be printed via ctx.output.print()to print its actual path on disk. Sample usage: def _impl_ensure(ctx): actions = ctx.bxl_actions().actions output = actions.write(&quot;my_output&quot;, &quot;my_content&quot;) ensured = ctx.output.ensure(output) ctx.output.print(ensured)   "},{"title":"bxl_output_stream.ensure_multiple​","type":1,"pageTitle":"bxl_output_stream type","url":"/docs/api/bxl/bxl_output_stream/#bxl_output_streamensure_multiple","content":"def bxl_output_stream.ensure_multiple(artifacts)  Same as ensure, but for multiple artifacts. Will preserve the shape of the inputs (i.e. if the resulting Dict of a ctx.build() is passed in, the output will be a Dict where the key is preserved, and the values are converted to EnsuredArtifacts). Note that is slower to loop through objects and ensure them one by one than it is to call ensure_multiple()on all the objects at once (if possible). So, it is suggested to use this method when you are only ensuring a few individual artifacts that are not stored in an iterable. Sample usage: def _impl_ensure_multiple(ctx): outputs = {} for target, value in ctx.build(ctx.cli_args.target).items(): outputs.update({target.raw_target(): ctx.output.ensure_multiple(value.artifacts())}) ctx.output.print_json(outputs)   "},{"title":"bxl_output_stream.print​","type":1,"pageTitle":"bxl_output_stream type","url":"/docs/api/bxl/bxl_output_stream/#bxl_output_streamprint","content":"def bxl_output_stream.print(*args, sep: str.type = &quot; &quot;) -&gt; None  Outputs results to the console via stdout. These outputs are considered to be the results of a bxl script, which will be displayed to stdout by buck2 even when the script is cached. Accepts an optional separator that defaults to &quot; &quot;. Prints that are not result of the bxl should be printed via stderr via the stdlib printand pprint. Note that ctx.output.print() is intended for simple outputs. For more complex outputs, the recommendation would be to write them to a file. Sample usage: def _impl_print(ctx): ctx.output.print(&quot;test&quot;)   "},{"title":"bxl_output_stream.print_json​","type":1,"pageTitle":"bxl_output_stream type","url":"/docs/api/bxl/bxl_output_stream/#bxl_output_streamprint_json","content":"def bxl_output_stream.print_json(value, *, pretty: bool.type = True) -&gt; None  Outputs results to the console via stdout as pretty-printed json. Pretty printing can be turned off by the pretty keyword-only parameter. These outputs are considered to be the results of a bxl script, which will be displayed to stdout by buck2 even when the script is cached. Prints that are not result of the bxl should be printed via stderr via the stdlib printand pprint. Sample usage: def _impl_print_json(ctx): outputs = {} outputs.update({&quot;foo&quot;: bar}) ctx.output.print_json(&quot;test&quot;)  "},{"title":"configured_attr_val type","type":0,"sectionRef":"#","url":"/docs/api/bxl/configured_attr_val/","content":"","keywords":""},{"title":"configured_attr_val.type​","type":1,"pageTitle":"configured_attr_val type","url":"/docs/api/bxl/configured_attr_val/#configured_attr_valtype","content":"configured_attr_val.type: str.type  Returns the type name of the attribute Sample usage: def _impl_type(ctx): node = ctx.cquery().owner(&quot;bin/TARGETS&quot;)[0] attrs = node.attrs_eager() ctx.output.print(attrs.name.type)   "},{"title":"configured_attr_val.value​","type":1,"pageTitle":"configured_attr_val type","url":"/docs/api/bxl/configured_attr_val/#configured_attr_valvalue","content":"def configured_attr_val.value()  Returns the value of this attribute. The value here is not fully resolved like in rules. Sample usage: def _impl_value(ctx): node = ctx.cquery().owner(&quot;bin/TARGETS&quot;)[0] attrs = node.attrs_eager() ctx.output.print(attrs.name.value())  "},{"title":"configured_sub_target type","type":0,"sectionRef":"#","url":"/docs/api/bxl/configured_sub_target/","content":"","keywords":""},{"title":"configured_sub_target.configured_sub_target​","type":1,"pageTitle":"configured_sub_target type","url":"/docs/api/bxl/configured_sub_target/#configured_sub_targetconfigured_sub_target","content":"def configured_sub_target.configured_sub_target( target: &quot;configured_target_label&quot;, subtarget_name = [] ) -&gt; &quot;label&quot;  Converts a TargetLabel into its corresponding ProvidersLabel given the subtarget name which is a list for each layer of subtarget Sample usage: def _impl_sub_target(ctx): owners = ctx.cquery().owner(&quot;bin/TARGETS.fixture&quot;) for owner in owners: configured_label = owner.label ctx.output.print(configured_sub_target(configured_label)) ctx.output.print(configured_sub_target(configured_label, &quot;subtarget1&quot;)) ctx.output.print(configured_sub_target(configured_label, [&quot;subtarget1&quot;, &quot;subtarget2&quot;))  "},{"title":"cqueryctx type","type":0,"sectionRef":"#","url":"/docs/api/bxl/cqueryctx/","content":"","keywords":""},{"title":"cqueryctx.allpaths​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxallpaths","content":"def cqueryctx.allpaths(from, to) -&gt; &quot;target_set&quot;  The allpaths query for computing all dependency paths.  "},{"title":"cqueryctx.attrfilter​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxattrfilter","content":"def cqueryctx.attrfilter( attr: str.type, value: str.type, targets ) -&gt; &quot;target_set&quot;  The attrfilter query for rule attribute filtering.  "},{"title":"cqueryctx.attrregexfilter​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxattrregexfilter","content":"def cqueryctx.attrregexfilter( attribute: str.type, value: str.type, targets ) -&gt; &quot;target_set&quot;  The attrregexfilter query for rule attribute filtering with regex. Sample usage: def _impl_attrregexfilter(ctx): filtered = ctx.cquery().attrregexfilter(&quot;foo&quot;, &quot;he.lo&quot;, &quot;bin/kind/...&quot;) ctx.output.print(filtered)   "},{"title":"cqueryctx.buildfile​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxbuildfile","content":"def cqueryctx.buildfile(targets) -&gt; &quot;file_set&quot;  Find the build file(s) that defines a target or a target set. Sample usage: def _buildfile_impl(ctx): owner = ctx.cquery().owner([&quot;bin/TARGET&quot;, &quot;bin/kind&quot;]) result = ctx.cquery().buildfile(owner) ctx.output.print(result)   "},{"title":"cqueryctx.deps​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxdeps","content":"def cqueryctx.deps( universe, depth: [None, int.type] = None, filter: [None, str.type] = None ) -&gt; &quot;target_set&quot;  The deps query for finding the transitive closure of dependencies. Sample usage: def _impl_deps(ctx): result = ctx.cquery().deps(&quot;root//bin:the_binary&quot;, 1) ctx.output.print(result)   "},{"title":"cqueryctx.eval​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxeval","content":"def cqueryctx.eval( query: str.type, query_args = None, target_universe: [None, [str.type]] = None )  Evaluates some general query string. query_args can be a target_set of unconfigured nodes, or a list of strings. Sample usage: def _impl_eval(ctx): result1 = ctx.cquery().eval(&quot;inputs(root//bin:the_binary)&quot;) ctx.output.print(result1) result2 = ctx.cquery().eval(&quot;inputs(%s)&quot;, query_args = [&quot;cell//path/to/file:target&quot;]) ctx.output.print(result2)   "},{"title":"cqueryctx.filter​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxfilter","content":"def cqueryctx.filter(regex: str.type, targets) -&gt; &quot;target_set&quot;  The filter query for filtering targets by name. Sample usage: def _impl_filter(ctx): result = ctx.cquery().filter(&quot;.*the_binary&quot;, &quot;root//...&quot;) ctx.output.print(result)   "},{"title":"cqueryctx.inputs​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxinputs","content":"def cqueryctx.inputs(targets) -&gt; &quot;file_set&quot;  The inputs query for finding input files. Sample usage: def _impl_inputs(ctx): result = ctx.cquery().inputs(&quot;root//bin:the_binary&quot;) ctx.output.print(result)   "},{"title":"cqueryctx.kind​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxkind","content":"def cqueryctx.kind(regex: str.type, targets) -&gt; &quot;target_set&quot;  The kind query for filtering targets by rule type. Sample usage: def _impl_kind(ctx): kind = ctx.cquery().kind(&quot;.*1&quot;, &quot;bin/kind/...&quot;) ctx.output.print(kind)   "},{"title":"cqueryctx.owner​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxowner","content":"def cqueryctx.owner(files: [&quot;file_set&quot;, str.type]) -&gt; &quot;target_set&quot;  The owner query for finding targets that own specified files. Sample usage: def _owner_impl(ctx): owner = ctx.cquery().owner(&quot;bin/TARGETS.fixture&quot;) ctx.output.print(owner)   "},{"title":"cqueryctx.rdeps​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxrdeps","content":"def cqueryctx.rdeps(universe, from, depth: int.type = _) -&gt; &quot;target_set&quot;  The rdeps query for finding the transitive closure of reverse dependencies. Sample usage: def _impl_rdeps(ctx): result = ctx.cquery().rdeps(&quot;root//bin:the_binary&quot;, &quot;//lib:file1&quot;, 100) ctx.output.print(result)   "},{"title":"cqueryctx.somepath​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxsomepath","content":"def cqueryctx.somepath(from, to) -&gt; &quot;target_set&quot;   "},{"title":"cqueryctx.testsof​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxtestsof","content":"def cqueryctx.testsof(targets) -&gt; &quot;target_set&quot;  The testsof query for listing the tests of the specified targets.  "},{"title":"cqueryctx.testsof_with_default_target_platform​","type":1,"pageTitle":"cqueryctx type","url":"/docs/api/bxl/cqueryctx/#cqueryctxtestsof_with_default_target_platform","content":"def cqueryctx.testsof_with_default_target_platform(targets) -&gt; &quot;target_set&quot;  The testsof query for listing the tests of the specified targets. Performs default target platform resolution under the hood for the tests found. "},{"title":"ensured_artifact type","type":0,"sectionRef":"#","url":"/docs/api/bxl/ensured_artifact/","content":"","keywords":""},{"title":"ensured_artifact.abs_path​","type":1,"pageTitle":"ensured_artifact type","url":"/docs/api/bxl/ensured_artifact/#ensured_artifactabs_path","content":"def ensured_artifact.abs_path()  Converts this artifact to be printed by its absolute path. Note that this will only print out the absolute path via ctx.output.print(). Starlark's print() will print out the display info for an ensured artifact. Sample usage: def _impl_abs_path(ctx): actions = ctx.bxl_actions().actions output = actions.write(&quot;my_output&quot;, &quot;my_content&quot;) ensured = ctx.output.ensure(output) # currently defaults to creating an EnsuredArtifact with a relative path ensured_with_abs_path = ensured.abs_path() # create a new EnsuredArtifact with absolute path to reuse print(ensured_with_abs_path) # should return something like &lt;ensured artifact ... &gt; ctx.output.print(ensured_with_abs_path) # should return the absolute path of the artifact   "},{"title":"ensured_artifact.rel_path​","type":1,"pageTitle":"ensured_artifact type","url":"/docs/api/bxl/ensured_artifact/#ensured_artifactrel_path","content":"def ensured_artifact.rel_path()  Converts this artifact to be printed by its path relative to the project root. Note that this will only print out the relative path via ctx.output.print(). Starlark's print() will print out the display info for an ensured artifact. Sample usage: def _impl_rel_path(ctx): actions = ctx.bxl_actions().actions output = actions.write(&quot;my_output&quot;, &quot;my_content&quot;) ensured = ctx.output.ensure(output) # currently defaults to creating an EnsuredArtifact with a relative path ensured_with_rel_path = ensured.rel_path() # create a new EnsuredArtifact with relative path to reuse print(ensured_with_rel_path) # should return something like &lt;ensured artifact ... &gt; ctx.output.print(ensured_with_rel_path) # should return the relative path of the artifact  "},{"title":"fs type","type":0,"sectionRef":"#","url":"/docs/api/bxl/fs/","content":"","keywords":""},{"title":"fs.abs_path_unsafe​","type":1,"pageTitle":"fs type","url":"/docs/api/bxl/fs/#fsabs_path_unsafe","content":"def fs.abs_path_unsafe(expr: [&quot;artifact&quot;, str.type]) -&gt; str.type  Returns the absolute path, given the file expression. Use at your own risk, as the current working directory may have been changed when this function is called. In addition, passing the absolute path into actions that are run remotely will most likely result in failures since the absolute path most likely differs locally vs remotely. Sample usage: def _impl_abs_path_unsafe(ctx): ctx.output.print(ctx.fs.abs_path_unsafe(&quot;bin&quot;))   "},{"title":"fs.exists​","type":1,"pageTitle":"fs type","url":"/docs/api/bxl/fs/#fsexists","content":"def fs.exists(expr: [&quot;artifact&quot;, str.type]) -&gt; bool.type  Check if a path exists on disk, taking advantage of Buck's cached filesystem. Takes in a literal, a source artifact (via [StarlarkArtifact]), or a [StarlarkFileNode]. Sample usage: def _impl_exists(ctx): ctx.output.print(ctx.fs.exists(&quot;bin&quot;))   "},{"title":"fs.is_dir​","type":1,"pageTitle":"fs type","url":"/docs/api/bxl/fs/#fsis_dir","content":"def fs.is_dir(expr: [&quot;artifact&quot;, str.type]) -&gt; bool.type  Returns whether the provided path is a dir. Returns false is the dir does not exist. The input is a either a literal, a source artifact (via [StarlarkArtifact]), or a [StarlarkFileNode]. Sample usage: def _impl_is_dir(ctx): ctx.output.print(ctx.fs.is_dir(&quot;bin&quot;))   "},{"title":"fs.is_file​","type":1,"pageTitle":"fs type","url":"/docs/api/bxl/fs/#fsis_file","content":"def fs.is_file(expr: [&quot;artifact&quot;, str.type]) -&gt; bool.type  Returns whether the provided path is a file. Returns false is the file does not exist. The input is a either a literal, a source artifact (via [StarlarkArtifact]), or a [StarlarkFileNode]. Sample usage: def _impl_is_file(ctx): ctx.output.print(ctx.fs.is_dir(&quot;bin&quot;))   "},{"title":"fs.list​","type":1,"pageTitle":"fs type","url":"/docs/api/bxl/fs/#fslist","content":"def fs.list( expr: [&quot;artifact&quot;, str.type], *, dirs_only: bool.type = False ) -&gt; &quot;read_dir_set&quot;  Returns all the contents of the given input that points to a directory. Errors if the given path is a file. Takes an optional boolean dirs_only to only return directories, defaults to false. The input is a either a literal, a source artifact (via [StarlarkArtifact]), or a [StarlarkFileNode]. Sample usage: def _impl_list(ctx): list_results = ctx.fs.list(&quot;bin&quot;) for result in list_results: ctx.output.print(result)   "},{"title":"fs.project_rel_path​","type":1,"pageTitle":"fs type","url":"/docs/api/bxl/fs/#fsproject_rel_path","content":"def fs.project_rel_path(expr: [&quot;artifact&quot;, str.type]) -&gt; str.type  Returns the relative path to the project root, given the file expression. Sample usage: def project_rel_path(ctx): ctx.output.print(ctx.fs.project_rel_path(&quot;bin&quot;))   "},{"title":"fs.source​","type":1,"pageTitle":"fs type","url":"/docs/api/bxl/fs/#fssource","content":"def fs.source(expr: [&quot;artifact&quot;, str.type], target_hint = None)  Returns the source artifact for a path and an optional target hint (unconfigured target label or node) which points to the owning package. If no target hint is given, the nearest package will be used to guess the desired artifact. The path should be either an absolute path, or a project relative path. "},{"title":"ensured_artifact_group type","type":0,"sectionRef":"#","url":"/docs/api/bxl/ensured_artifact_group/","content":"","keywords":""},{"title":"ensured_artifact_group.abs_path​","type":1,"pageTitle":"ensured_artifact_group type","url":"/docs/api/bxl/ensured_artifact_group/#ensured_artifact_groupabs_path","content":"def ensured_artifact_group.abs_path()  Converts each artifact in this artifact group to be printed by its absolute path. Note that this will only print out the absolute path via ctx.output.print(). Starlark's print() will print out the display info for an ensured artifact group. Sample usage: def _impl_abs_path(ctx): # some target with RunInfo outputs result = ctx.analysis(&quot;root//bin/kind:target_with_outputs&quot;) ensured = ctx.output.ensure_multiple(result.providers()[RunInfo]) # currently defaults to creating an EnsuredArtifactGroup with a relative path ensured_with_abs_path = ensured.abs_path() # create a new EnsuredArtifactGroup with absolute path to reuse print(ensured_with_abs_path) # should return something like &lt;ensured group ... &gt; ctx.output.print(ensured_with_abs_path) # should return the absolute path of the artifact   "},{"title":"ensured_artifact_group.rel_path​","type":1,"pageTitle":"ensured_artifact_group type","url":"/docs/api/bxl/ensured_artifact_group/#ensured_artifact_grouprel_path","content":"def ensured_artifact_group.rel_path()  Converts each artifact in this artifact group to be printed by its path relative to the project root. Note that this will only print out the relative path via ctx.output.print(). Starlark's print() will print out the display info for an ensured artifact group. Sample usage: def _impl_rel_path(ctx): # some target with RunInfo outputs result = ctx.analysis(&quot;root//bin/kind:target_with_outputs&quot;) ensured = ctx.output.ensure_multiple(result.providers()[RunInfo]) # currently defaults to creating an EnsuredArtifactGroup with a relative path ensured_with_rel_path = ensured.rel_path() # create a new EnsuredArtifact with relative path to reuse print(ensured_with_rel_path) # should return something like &lt;ensured group ... &gt; ctx.output.print(ensured_with_rel_path) # should return the relative path of the artifact  "},{"title":"get_paths_without_materialization type","type":0,"sectionRef":"#","url":"/docs/api/bxl/get_paths_without_materialization/","content":"","keywords":""},{"title":"get_paths_without_materialization.get_paths_without_materialization​","type":1,"pageTitle":"get_paths_without_materialization type","url":"/docs/api/bxl/get_paths_without_materialization/#get_paths_without_materializationget_paths_without_materialization","content":"def get_paths_without_materialization.get_paths_without_materialization( this, ctx: &quot;bxl_ctx&quot;, *, abs: bool.type = False )  The output paths of a cmd_args() inputs. The output paths will be returned as a list. Takes an optional boolean to print the absolute or relative path. Note that this method returns an artifact path without asking for the artifact to be materialized, (i.e. it may not actually exist on the disk yet). This is a risky function to call because you may accidentally pass this path to further BXL actions that expect the artifact to be materialized. If this happens, the BXL script will error out. If you want the path without materialization for other uses that don’t involve passing them into further actions, then it’s safe. Sample usage: def _impl_get_paths_without_materialization(ctx): node = ctx.configured_targets(&quot;root//bin:the_binary&quot;) providers = ctx.analysis(node).providers() path = get_paths_without_materialization(providers[RunInfo], abs=True) # Note this artifact is NOT ensured or materialized ctx.output.print(path)  "},{"title":"instant type","type":0,"sectionRef":"#","url":"/docs/api/bxl/instant/","content":"","keywords":""},{"title":"instant.elapsed_millis​","type":1,"pageTitle":"instant type","url":"/docs/api/bxl/instant/#instantelapsed_millis","content":"def instant.elapsed_millis()  Elapsed time in millis as a float Sample usage: def _impl_elapsed_millis(ctx): now = now() time_a = now.elapsed_millis() # do something that takes a long time time_b = now.elapsed_millis() ctx.output.print(time_a) ctx.output.print(time_b)   "},{"title":"instant.elapsed_secs​","type":1,"pageTitle":"instant type","url":"/docs/api/bxl/instant/#instantelapsed_secs","content":"def instant.elapsed_secs()  Elapsed time in secs as a float Sample usage: def _impl_elapsed_secs(ctx): now = now() time_a = now.elapsed_secs() # do something that takes a long time time_b = now.elapsed_secs() ctx.output.print(time_a) ctx.output.print(time_b)  "},{"title":"get_path_without_materialization type","type":0,"sectionRef":"#","url":"/docs/api/bxl/get_path_without_materialization/","content":"","keywords":""},{"title":"get_path_without_materialization.get_path_without_materialization​","type":1,"pageTitle":"get_path_without_materialization type","url":"/docs/api/bxl/get_path_without_materialization/#get_path_without_materializationget_path_without_materialization","content":"def get_path_without_materialization.get_path_without_materialization( this: &quot;artifact&quot;, ctx: &quot;bxl_ctx&quot;, *, abs: bool.type = False ) -&gt; str.type  The output path of a source or build artifact. Takes an optional boolean to print the absolute or relative path. Note that this method returns an artifact path without asking for the artifact to be materialized, (i.e. it may not actually exist on the disk yet). This is a risky function to call because you may accidentally pass this path to further BXL actions that expect the artifact to be materialized. If this happens, the BXL script will error out. If you want the path without materialization for other uses that don’t involve passing them into further actions, then it’s safe. Sample usage: def _impl_get_path_without_materialization(ctx): owner = ctx.cquery().owner(&quot;cell//path/to/file&quot;)[0] artifact = owner.get_source(&quot;cell//path/to/file&quot;, ctx) source_artifact_project_rel_path = get_path_without_materialization(artifact, ctx) ctx.output.print(source_artifact_project_rel_path) # Note this artifact is NOT ensured or materialized  "},{"title":"lazy_attrs type","type":0,"sectionRef":"#","url":"/docs/api/bxl/lazy_attrs/","content":"","keywords":""},{"title":"lazy_attrs.get​","type":1,"pageTitle":"lazy_attrs type","url":"/docs/api/bxl/lazy_attrs/#lazy_attrsget","content":"def lazy_attrs.get(attr: str.type) -&gt; [&quot;configured_attr_val&quot;, None]  Gets a single attribute. Returns an optional [StarlarkConfiguredValue]. def _impl_attrs_lazy(ctx): node = ctx.cquery().owner(&quot;cell//path/to/TARGETS&quot;)[0]attrs = node.attrs_lazy() # cache once ctx.output.print(attrs.get(&quot;some_attributes&quot;).value()) ctx.output.print(attrs.get(&quot;some_attribute&quot;).label)   "},{"title":"lazy_resolved_attrs type","type":0,"sectionRef":"#","url":"/docs/api/bxl/lazy_resolved_attrs/","content":"","keywords":""},{"title":"lazy_resolved_attrs.get​","type":1,"pageTitle":"lazy_resolved_attrs type","url":"/docs/api/bxl/lazy_resolved_attrs/#lazy_resolved_attrsget","content":"def lazy_resolved_attrs.get(attr: str.type)  Gets a single resolved attribute. Returns an optional configured attribute. Gets a single attribute. def _impl_resolved_attrs_lazy(ctx): node = ctx.cquery().owner(&quot;cell//path/to/TARGETS&quot;)[0]attrs = node.resolved_attrs_lazy() # cache once ctx.output.print(attrs.get(&quot;some_attribute&quot;).value()) ctx.output.print(attrs.get(&quot;some_attribute&quot;).label)   "},{"title":"target_node type","type":0,"sectionRef":"#","url":"/docs/api/bxl/target_node/","content":"","keywords":""},{"title":"target_node.attrs_eager​","type":1,"pageTitle":"target_node type","url":"/docs/api/bxl/target_node/#target_nodeattrs_eager","content":"def target_node.attrs_eager()  Returns a struct of all the attributes of this target node. The structs fields are the attributes names, and the values are [StarlarkConfiguredValue]. If you need to access many or all attrs on the same node, then this is the preferred way. Otherwise, using attrs_lazy() would be a better option for only accessing only a few attrs, although this really depends on what kind of attrs are on the node. Benchmarking performance will give you the best indication on which method to use. You should store the result of this function call for further usage in the code rather than callingattrs_eager() each time you need to access the attrs. Sample usage: def _impl_attrs_eager(ctx): node = ctx.cquery().owner(&quot;cell//path/to/TARGETS&quot;)[0] attrs = node.attrs_eager() # cache once ctx.output.print(attrs) # do more stuff with attrs   "},{"title":"target_node.attrs_lazy​","type":1,"pageTitle":"target_node type","url":"/docs/api/bxl/target_node/#target_nodeattrs_lazy","content":"def target_node.attrs_lazy() -&gt; &quot;lazy_attrs&quot;  Gets a StarlarkLazyAttrs for getting attrs lazily. Returns a StarlarkLazyAttrs object that you can call get() on that gets an attr one at a time. If you need to access only few attrs on the same node, then this is the preferred way. Otherwise, using attrs_eager() would be a better option for accessing many or all attrs, although this really depends on what kind of attrs are on the node. Benchmarking performance will give you the best indication on which method to use. You should store the result of this function call for further usage in the code rather than callingattrs_lazy() each time to get the StarlarkLazyAttrs object. Note that if the get() is NoneType, then any methods called on NoneType will result in an error. Sample usage: def _impl_attrs_lazy(ctx): node = ctx.cquery().owner(&quot;cell//path/to/TARGETS&quot;)[0] attrs = node.attrs_lazy() # cache once ctx.output.print(attrs.get(&quot;some_attributes&quot;).value()) ctx.output.print(attrs.get(&quot;some_attribute&quot;).label)   "},{"title":"target_node.get_source​","type":1,"pageTitle":"target_node type","url":"/docs/api/bxl/target_node/#target_nodeget_source","content":"def target_node.get_source(path: str.type, ctx: &quot;bxl_ctx&quot;) -&gt; [&quot;artifact&quot;, None]  Gets the SourceArtifact that corresponds to the given path given a context. The path should be the project relative path to the file, or an absolute path. Sample usage: def _impl_get_source(ctx): owner = ctx.cquery().owner(&quot;project/relative/path/to/file&quot;)[0] artifact = owner.sources()[0] ctx.output.print(artifact)   "},{"title":"target_node.label​","type":1,"pageTitle":"target_node type","url":"/docs/api/bxl/target_node/#target_nodelabel","content":"target_node.label: &quot;configured_target_label&quot;  Gets the configured target label of this target node. Note that you cannot get a non-configured label from a configured target node because the configured target node is not uniquely identified a non-configured label, only by the configured target label. Sample usage: def _impl_label(ctx): node = ctx.configured_targets(&quot;my_cell//bin:the_binary&quot;) ctx.output.print(node.label)   "},{"title":"target_node.resolved_attrs_eager​","type":1,"pageTitle":"target_node type","url":"/docs/api/bxl/target_node/#target_noderesolved_attrs_eager","content":"def target_node.resolved_attrs_eager(ctx: &quot;bxl_ctx&quot;)  Returns a struct of all the resolved attributes of this target node. The structs fields are the attributes names, and the values are Starlark [Value]. If you need to access many or all resolved attrs on the same node, then this is the preferred way. Otherwise, using resolved_attrs_lazy() would be a better option for accessing only a few resolved attrs, although this really depends on what kind of resolved attrs are on the node. Benchmarking performance will give you the best indication on which method to use. You should store the result of this function call for further usage in the code rather than callingresolved_attrs_eager() each time you need all the resolved attrs. Sample usage: def _impl_resolved_attrs_eager(ctx): node = ctx.cquery().owner(&quot;cell//path/to/TARGETS&quot;)[0] attrs = node.resolved_attrs_eager() # cache once ctx.output.print(attrs) # do more stuff with attrs   "},{"title":"target_node.resolved_attrs_lazy​","type":1,"pageTitle":"target_node type","url":"/docs/api/bxl/target_node/#target_noderesolved_attrs_lazy","content":"def target_node.resolved_attrs_lazy(ctx: &quot;bxl_ctx&quot;) -&gt; &quot;lazy_resolved_attrs&quot;  Gets a StarlarkLazyResolvedAttrs for getting resolved attrs lazily. Returns a StarlarkLazyResolvedAttrs object that you can call get() on that gets a resolved attr one at a time. If you need to access only few resolved attrs on the same node, then this is the preferred way. Otherwise, using resolved_attrs_eager() would be a better option for accessing many or all resolved attrs, although this really depends on what kind of resolved attrs are on the node. Benchmarking performance will give you the best indication on which method to use. You should store the result of this function call for further usage in the code rather than callingresolved_attrs_lazy() each time to get the StarlarkResolvedLazyAttrs object. Note that if the get() is NoneType, then any methods called on NoneType will result in an error. Sample usage: def _impl_resolved_attrs_lazy(ctx): node = ctx.cquery().owner(&quot;cell//path/to/TARGETS&quot;)[0] attrs = node.resolved_attrs_lazy() # cache once ctx.output.print(attrs.get(&quot;some_attributes&quot;).value()) ctx.output.print(attrs.get(&quot;some_attribute&quot;).label)   "},{"title":"target_node.rule_type​","type":1,"pageTitle":"target_node type","url":"/docs/api/bxl/target_node/#target_noderule_type","content":"target_node.rule_type: str.type  Gets the targets' corresponding rule's name. This is the fully qualified rule name including the import path. Sample usage: def _impl_rule_type(ctx): node = ctx.configured_targets(&quot;my_cell//bin:the_binary&quot;) ctx.output.print(node.rule_type)   "},{"title":"target_node.sources​","type":1,"pageTitle":"target_node type","url":"/docs/api/bxl/target_node/#target_nodesources","content":"def target_node.sources() -&gt; [&quot;artifact&quot;]  Returns a List of all the sources used by this node. Sample usage: def _impl_sources(ctx): node = ctx.configured_targets(&quot;my_cell//bin:the_binary&quot;) ctx.output.print(node.sources())  "},{"title":"sub_target type","type":0,"sectionRef":"#","url":"/docs/api/bxl/sub_target/","content":"","keywords":""},{"title":"sub_target.sub_target​","type":1,"pageTitle":"sub_target type","url":"/docs/api/bxl/sub_target/#sub_targetsub_target","content":"def sub_target.sub_target( target: &quot;target_label&quot;, subtarget_name = [] ) -&gt; &quot;providers_label&quot;  Converts a TargetLabel into its corresponding ProvidersLabel given the subtarget names, which is a list for each layer of subtarget Sample usage: def _impl_sub_target(ctx): owners = ctx.cquery().owner(&quot;bin/TARGETS.fixture&quot;) for owner in owners: configured_label = owner.label unconfigured_label = configured_label.raw_target() ctx.output.print(sub_target(unconfigured_label)) ctx.output.print(sub_target(unconfigured_label, &quot;subtarget1&quot;)) ctx.output.print(sub_target(unconfigured_label, [&quot;subtarget1&quot;, &quot;subtarget2&quot;))  "},{"title":"unconfigured_target_node type","type":0,"sectionRef":"#","url":"/docs/api/bxl/unconfigured_target_node/","content":"","keywords":""},{"title":"unconfigured_target_node.attrs​","type":1,"pageTitle":"unconfigured_target_node type","url":"/docs/api/bxl/unconfigured_target_node/#unconfigured_target_nodeattrs","content":"unconfigured_target_node.attrs: &quot;&quot;  Gets the coerced attributes from the unconfigured target node. Returns a struct. Sample usage: def _impl_attributes(ctx): target_node = ctx.uquery().eval(&quot;owner('path/to/file')&quot;)[0] ctx.output.print(target_node.attrs.my_attr)   "},{"title":"unconfigured_target_node.buildfile_path​","type":1,"pageTitle":"unconfigured_target_node type","url":"/docs/api/bxl/unconfigured_target_node/#unconfigured_target_nodebuildfile_path","content":"unconfigured_target_node.buildfile_path: &quot;file_node&quot;  Gets the buildfile path from the unconfigured target node. Sample usage: def _impl_label(ctx): target_node = ctx.uquery().eval(&quot;owner('path/to/file')&quot;)[0] ctx.output.print(target_node.buildfile_path)   "},{"title":"unconfigured_target_node.label​","type":1,"pageTitle":"unconfigured_target_node type","url":"/docs/api/bxl/unconfigured_target_node/#unconfigured_target_nodelabel","content":"unconfigured_target_node.label: &quot;target_label&quot;  Gets the label from the unconfigured target node. Sample usage: def _impl_label(ctx): target_node = ctx.uquery().eval(&quot;owner('path/to/file')&quot;)[0] ctx.output.print(target_node.label)   "},{"title":"unconfigured_target_node.rule_type​","type":1,"pageTitle":"unconfigured_target_node type","url":"/docs/api/bxl/unconfigured_target_node/#unconfigured_target_noderule_type","content":"unconfigured_target_node.rule_type: str.type  Gets the fully qualified name of the rule for this unconfigured target node as a string. This includes the import path as well. Sample usage: def _impl_rule_type(ctx): target_node = ctx.uquery().owner('path/to/file')[0] ctx.output.print(target_node.rule_type)  "},{"title":"uqueryctx type","type":0,"sectionRef":"#","url":"/docs/api/bxl/uqueryctx/","content":"","keywords":""},{"title":"uqueryctx.allpaths​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxallpaths","content":"def uqueryctx.allpaths(from, to) -&gt; &quot;target_set&quot;  The allpaths query for computing all dependency paths.  "},{"title":"uqueryctx.attrfilter​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxattrfilter","content":"def uqueryctx.attrfilter( attr: str.type, value: str.type, targets ) -&gt; &quot;target_set&quot;  The attrfilter query for rule attribute filtering.  "},{"title":"uqueryctx.attrregexfilter​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxattrregexfilter","content":"def uqueryctx.attrregexfilter( attribute: str.type, value: str.type, targets ) -&gt; &quot;target_set&quot;  The attrregexfilter query for rule attribute filtering with regex. Sample usage: def _impl_attrregexfilter(ctx): filtered = ctx.uquery().attrregexfilter(&quot;foo&quot;, &quot;he.lo&quot;, &quot;bin/kind/...&quot;) ctx.output.print(filtered)   "},{"title":"uqueryctx.buildfile​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxbuildfile","content":"def uqueryctx.buildfile(targets) -&gt; &quot;file_set&quot;  Find the build file(s) that defines a target or a target set. Sample usage: def _buildfile_impl(ctx): owner = ctx.uquery().owner([&quot;bin/TARGET&quot;, &quot;bin/kind&quot;]) result = ctx.uquery().buildfile(owner) ctx.output.print(result)   "},{"title":"uqueryctx.deps​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxdeps","content":"def uqueryctx.deps( universe, depth: [None, int.type] = None, filter: [None, str.type] = None ) -&gt; &quot;target_set&quot;  The deps query for finding the transitive closure of dependencies. Sample usage: def _impl_deps(ctx): result = ctx.uquery().deps(&quot;root//bin:the_binary&quot;, 1) ctx.output.print(result)   "},{"title":"uqueryctx.eval​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxeval","content":"def uqueryctx.eval(query: str.type, query_args = None)  Evaluates some general query string, query_args can be a target_set of unconfigured nodes, or a list of strings. Sample usage: def _impl_eval(ctx): result1 = ctx.uquery().eval(&quot;inputs(cell//path/to/file:target)&quot;) ctx.output.print(result1) result2 = ctx.uquery().eval(&quot;inputs(%s)&quot;, query_args = [&quot;cell//path/to/file:target&quot;]) ctx.output.print(result2)   "},{"title":"uqueryctx.filter​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxfilter","content":"def uqueryctx.filter(regex: str.type, targets) -&gt; &quot;target_set&quot;  The filter query for filtering targets by name. Sample usage: def _impl_filter(ctx): result = ctx.uquery().filter(&quot;.*the_binary&quot;, &quot;root//...&quot;) ctx.output.print(result)   "},{"title":"uqueryctx.inputs​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxinputs","content":"def uqueryctx.inputs(targets) -&gt; &quot;file_set&quot;  The inputs query for finding input files. Sample usage: def _impl_inputs(ctx): result = ctx.uquery().inputs(&quot;root//bin:the_binary&quot;) ctx.output.print(result)   "},{"title":"uqueryctx.kind​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxkind","content":"def uqueryctx.kind(regex: str.type, targets) -&gt; &quot;target_set&quot;  The kind query for filtering targets by rule type. Sample usage: def _impl_kind(ctx): kind = ctx.uquery().kind(&quot;.*1&quot;, &quot;bin/kind/...&quot;) ctx.output.print(kind)   "},{"title":"uqueryctx.owner​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxowner","content":"def uqueryctx.owner(files: [&quot;file_set&quot;, str.type]) -&gt; &quot;target_set&quot;  The owner query for finding targets that own specified files. Sample usage: def _owner_impl(ctx): owner = ctx.uquery().owner(&quot;bin/TARGETS.fixture&quot;) ctx.output.print(owner)   "},{"title":"uqueryctx.rdeps​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxrdeps","content":"def uqueryctx.rdeps(universe, from, depth: int.type = _) -&gt; &quot;target_set&quot;  The rdeps query for finding the transitive closure of reverse dependencies. Sample usage: def _impl_rdeps(ctx): result = ctx.uquery().rdeps(&quot;root//bin:the_binary&quot;, &quot;//lib:file1&quot;, 100) ctx.output.print(result)   "},{"title":"uqueryctx.somepath​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxsomepath","content":"def uqueryctx.somepath(from, to) -&gt; &quot;target_set&quot;  The somepaths query, which returns the graph of nodes on some arbitrary path from a start to destination target.  "},{"title":"uqueryctx.testsof​","type":1,"pageTitle":"uqueryctx type","url":"/docs/api/bxl/uqueryctx/#uqueryctxtestsof","content":"def uqueryctx.testsof(targets) -&gt; &quot;target_set&quot;  The testsof query for listing the tests of the specified targets. Sample usage: def _testsof_impl(ctx): result = ctx.uquery().testsof(&quot;//:foo_lib&quot;) ctx.output.print(result)  "},{"title":"dict type","type":0,"sectionRef":"#","url":"/docs/api/starlark/dict/","content":"","keywords":""},{"title":"dict.clear​","type":1,"pageTitle":"dict type","url":"/docs/api/starlark/dict/#dictclear","content":"def dict.clear() -&gt; None  dict.clear: clear a dictionary D.clear() removes all the entries of dictionary D and returns None. It fails if the dictionary is frozen or if there are active iterators. x = {&quot;one&quot;: 1, &quot;two&quot;: 2} x.clear() x == {}   "},{"title":"dict.get​","type":1,"pageTitle":"dict type","url":"/docs/api/starlark/dict/#dictget","content":"def dict.get(key, default = _, /)  dict.get: return an element from the dictionary. D.get(key[, default]) returns the dictionary value corresponding to the given key. If the dictionary contains no such value, getreturns None, or the value of the optional default parameter if present. get fails if key is unhashable. x = {&quot;one&quot;: 1, &quot;two&quot;: 2} x.get(&quot;one&quot;) == 1 x.get(&quot;three&quot;) == None x.get(&quot;three&quot;, 0) == 0   "},{"title":"dict.items​","type":1,"pageTitle":"dict type","url":"/docs/api/starlark/dict/#dictitems","content":"def dict.items() -&gt; [(&quot;&quot;, &quot;&quot;)]  dict.items: get list of (key, value) pairs. D.items() returns a new list of key/value pairs, one per element in dictionary D, in the same order as they would be returned by a forloop. x = {&quot;one&quot;: 1, &quot;two&quot;: 2} x.items() == [(&quot;one&quot;, 1), (&quot;two&quot;, 2)]   "},{"title":"dict.keys​","type":1,"pageTitle":"dict type","url":"/docs/api/starlark/dict/#dictkeys","content":"def dict.keys() -&gt; [&quot;&quot;]  dict.keys: get the list of keys of the dictionary. D.keys() returns a new list containing the keys of dictionary D, in the same order as they would be returned by a for loop. x = {&quot;one&quot;: 1, &quot;two&quot;: 2} x.keys() == [&quot;one&quot;, &quot;two&quot;]   "},{"title":"dict.pop​","type":1,"pageTitle":"dict type","url":"/docs/api/starlark/dict/#dictpop","content":"def dict.pop(key, default = _, /)  dict.pop: return an element and remove it from a dictionary. D.pop(key[, default]) returns the value corresponding to the specified key, and removes it from the dictionary. If the dictionary contains no such value, and the optional default parameter is present, popreturns that value; otherwise, it fails. pop fails if key is unhashable, or the dictionary is frozen or has active iterators. x = {&quot;one&quot;: 1, &quot;two&quot;: 2} x.pop(&quot;one&quot;) == 1 x == {&quot;two&quot;: 2} x.pop(&quot;three&quot;, 0) == 0 x.pop(&quot;three&quot;, None) == None  Failure: {'one': 1}.pop('four') # error: not found   "},{"title":"dict.popitem​","type":1,"pageTitle":"dict type","url":"/docs/api/starlark/dict/#dictpopitem","content":"def dict.popitem() -&gt; (&quot;&quot;, &quot;&quot;)  dict.popitem: returns and removes the first key/value pair of a dictionary. D.popitem() returns the first key/value pair, removing it from the dictionary. popitem fails if the dictionary is empty, frozen, or has active iterators. x = {&quot;one&quot;: 1, &quot;two&quot;: 2} x.popitem() == (&quot;one&quot;, 1) x.popitem() == (&quot;two&quot;, 2) x == {}  Failure: {}.popitem() # error: empty dict   "},{"title":"dict.setdefault​","type":1,"pageTitle":"dict type","url":"/docs/api/starlark/dict/#dictsetdefault","content":"def dict.setdefault(key, default = _, /)  dict.setdefault: get a value from a dictionary, setting it to a new value if not present. D.setdefault(key[, default]) returns the dictionary value corresponding to the given key. If the dictionary contains no such value, setdefault, like get, returns None or the value of the optional default parameter if present; setdefault additionally inserts the new key/value entry into the dictionary. setdefault fails if the key is unhashable or if the dictionary is frozen. x = {&quot;one&quot;: 1, &quot;two&quot;: 2} x.setdefault(&quot;one&quot;) == 1 x.setdefault(&quot;three&quot;, 0) == 0 x == {&quot;one&quot;: 1, &quot;two&quot;: 2, &quot;three&quot;: 0} x.setdefault(&quot;four&quot;) == None x == {&quot;one&quot;: 1, &quot;two&quot;: 2, &quot;three&quot;: 0, &quot;four&quot;: None}   "},{"title":"dict.update​","type":1,"pageTitle":"dict type","url":"/docs/api/starlark/dict/#dictupdate","content":"def dict.update(pairs = _, /, **kwargs: {&quot;&quot;: &quot;&quot;}) -&gt; None  dict.update: update values in the dictionary. D.update([pairs][, name=value[, ...]) makes a sequence of key/value insertions into dictionary D, then returns None. If the positional argument pairs is present, it must be None, another dict, or some other iterable. If it is another dict, then its key/value pairs are inserted into D. If it is an iterable, it must provide a sequence of pairs (or other iterables of length 2), each of which is treated as a key/value pair to be inserted into D. For each name=value argument present, the name is converted to a string and used as the key for an insertion into D, with its corresponding value being value. update fails if the dictionary is frozen. x = {} x.update([(&quot;a&quot;, 1), (&quot;b&quot;, 2)], c=3) x.update({&quot;d&quot;: 4}) x.update(e=5) x == {&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: 3, &quot;d&quot;: 4, &quot;e&quot;: 5}   "},{"title":"dict.values​","type":1,"pageTitle":"dict type","url":"/docs/api/starlark/dict/#dictvalues","content":"def dict.values() -&gt; [&quot;&quot;]  dict.values: get the list of values of the dictionary. D.values() returns a new list containing the dictionary's values, in the same order as they would be returned by a for loop over the dictionary. x = {&quot;one&quot;: 1, &quot;two&quot;: 2} x.values() == [1, 2]  "},{"title":"globals","type":0,"sectionRef":"#","url":"/docs/api/starlark/globals/","content":"","keywords":""},{"title":"False​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#false","content":"False: bool.type   "},{"title":"None​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#none","content":"None: None   "},{"title":"True​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#true","content":"True: bool.type   "},{"title":"abs​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#abs","content":"def abs(x: int.type, /) -&gt; int.type  Take the absolute value of an int. # starlark::assert::all_true(r#&quot; abs(0) == 0 abs(-10) == 10 abs(10) == 10 # &quot;#);  "},{"title":"all​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#all","content":"def all(x: iter(&quot;&quot;), /) -&gt; bool.type  all: returns true if all values in the iterable object have a truth value of true. all([1, True]) == True all([1, 1]) == True all([0, 1, True]) == False all([True, 1, True]) == True all([0, 0]) == False all([0, False]) == False all([True, 0]) == False all([1, False]) == False   "},{"title":"any​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#any","content":"def any(x: iter(&quot;&quot;), /) -&gt; bool.type  any: returns true if any value in the iterable object have a truth value of true. any([0, True]) == True any([0, 1]) == True any([0, 1, True]) == True any([0, 0]) == False any([0, False]) == False   "},{"title":"bool​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#bool","content":"def bool(x = _, /) -&gt; bool.type  bool: returns the truth value of any starlark value. .type attribute​ Produces &quot;bool&quot; Details​ bool() == False bool([]) == False bool([1]) == True bool(True) == True bool(False) == False bool(None) == False bool(bool) == True bool(1) == True bool(0) == False bool({}) == False bool({1:2}) == True bool(()) == False bool((1,)) == True bool(&quot;&quot;) == False bool(&quot;1&quot;) == True   "},{"title":"breakpoint​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#breakpoint","content":"def breakpoint() -&gt; None  When a debugger is available, breaks into the debugger.  "},{"title":"chr​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#chr","content":"def chr(i: int.type, /) -&gt; str.type  chr: returns a string encoding a codepoint. chr(i) returns a returns a string that encodes the single Unicode code point whose value is specified by the integer i. chr fails unless 0 ≤ i ≤ 0x10FFFF. chr(65) == 'A' chr(1049) == 'Й' chr(0x1F63F) == '😿'   "},{"title":"debug​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#debug","content":"def debug(val, /) -&gt; str.type  Print the value with full debug formatting. The result may not be stable over time. Intended for debugging purposes and guaranteed to produce verbose output not suitable for user display.  "},{"title":"dict​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#dict","content":"def dict(*args, **kwargs) -&gt; {&quot;&quot;: &quot;&quot;}  dict: creates a dictionary. .type attribute​ Produces &quot;dict&quot; Details​ dict creates a dictionary. It accepts up to one positional argument, which is interpreted as an iterable of two-element sequences (pairs), each specifying a key/value pair in the resulting dictionary. dict also accepts any number of keyword arguments, each of which specifies a key/value pair in the resulting dictionary; each keyword is treated as a string. dict() == {} dict(**{'a': 1}) == {'a': 1} dict({'a': 1}) == {'a': 1} dict([(1, 2), (3, 4)]) == {1: 2, 3: 4} dict([(1, 2), ['a', 'b']]) == {1: 2, 'a': 'b'} dict(one=1, two=2) == {'one': 1, 'two': 2} dict([(1, 2)], x=3) == {1: 2, 'x': 3} dict([('x', 2)], x=3) == {'x': 3} x = {'a': 1} y = dict([('x', 2)], **x) x == {'a': 1} and y == {'x': 2, 'a': 1}   "},{"title":"dir​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#dir","content":"def dir(x, /) -&gt; [str.type]  dir: list attributes of a value. dir(x) returns a list of the names of the attributes (fields and methods) of its operand. The attributes of a value x are the namesf such that x.f is a valid expression. &quot;capitalize&quot; in dir(&quot;abc&quot;)   "},{"title":"enum​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#enum","content":"def enum(*args)  The enum type represents one value picked from a set of values. For example: MyEnum = enum(&quot;option1&quot;, &quot;option2&quot;, True)  This statement defines an enumeration MyEnum that consists of the three values &quot;option1&quot;, &quot;option2&quot; and True. Now MyEnum is defined, it's possible to do the following: Create values of this type with MyEnum(&quot;option2&quot;). It is a runtime error if the argument is not one of the predeclared values of the enumeration.Get the type of the enum suitable for a type annotation with MyEnum.type.Given a value of the enum (for example, v = MyEnum(&quot;option2&quot;)), get the underlying value v.value == &quot;option2&quot; or the index in the enumeration v.index = 1.Get a list of the values that make up the array with MyEnum.values() == [&quot;option1&quot;, &quot;option2&quot;, True].Treat MyEnum a bit like an array, with len(MyEnum) == 3, MyEnum[1] == MyEnum(&quot;option2&quot;) and iteration over enums [x.value for x in MyEnum] == [&quot;option1&quot;, &quot;option2&quot;, True]. Enumeration types store each value once, which are then efficiently referenced by enumeration values.  "},{"title":"enumerate​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#enumerate","content":"def enumerate(it: iter(&quot;&quot;), /, start: int.type = 0) -&gt; [(int.type, &quot;&quot;)]  enumerate: return a list of (index, element) from an iterable. enumerate(x) returns a list of (index, value) pairs, each containing successive values of the iterable sequence and the index of the value within the sequence. The optional second parameter, start, specifies an integer value to add to each index. enumerate([&quot;zero&quot;, &quot;one&quot;, &quot;two&quot;]) == [(0, &quot;zero&quot;), (1, &quot;one&quot;), (2, &quot;two&quot;)] enumerate([&quot;one&quot;, &quot;two&quot;], 1) == [(1, &quot;one&quot;), (2, &quot;two&quot;)]   "},{"title":"eval_type​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#eval_type","content":"def eval_type(ty, /) -&gt; &quot;eval_type&quot;  Create a runtime type object which can be used to check if a value matches the given type.  "},{"title":"experimental_regex​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#experimental_regex","content":"def experimental_regex(regex: str.type, /) -&gt; &quot;regex&quot;  Creates a regex which can be used for matching. experimental_regex(&quot;^[a-z]*$&quot;).match(&quot;test&quot;) == True experimental_regex(&quot;^[a-z]*$&quot;).match(&quot;1234&quot;) == False   "},{"title":"fail​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#fail","content":"def fail(*args) -&gt; &quot;never&quot;  fail: fail the execution fail(&quot;this is an error&quot;) # fail: this is an error fail(&quot;oops&quot;, 1, False) # fail: oops 1 False   "},{"title":"field​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#field","content":"def field(typ, /, default = _) -&gt; &quot;field&quot;  Creates a field record. Used as an argument to the record function. rec_type = record(host=field(str.type), port=field(int.type), mask=field(int.type, default=255)) rec = rec_type(host=&quot;localhost&quot;, port=80) rec.port == 80 rec.mask == 255   "},{"title":"filter​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#filter","content":"def filter(func: [None, &quot;function&quot;], seq: iter(&quot;&quot;), /) -&gt; [&quot;&quot;]  Apply a predicate to each element of the iterable, returning those that match. As a special case if the function is None then removes all the None values. filter(bool, [0, 1, False, True]) == [1, True] filter(lambda x: x &gt; 2, [1, 2, 3, 4]) == [3, 4] filter(None, [True, None, False]) == [True, False]   "},{"title":"float​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#float","content":"def float(a: [bool.type, &quot;float&quot;, int.type, str.type] = _, /) -&gt; &quot;float&quot;  float: interprets its argument as a floating-point number. .type attribute​ Produces &quot;float&quot; Details​ If x is a float, the result is x. if x is an int, the result is the nearest floating point value to x. If x is a string, the string is interpreted as a floating-point literal. With no arguments, float() returns 0.0. float() == 0.0 float(1) == 1.0 float('1') == 1.0 float('1.0') == 1.0 float('.25') == 0.25 float('1e2') == 100.0 float(False) == 0.0 float(True) == 1.0 float(&quot;hello&quot;) # error: not a valid number float([]) # error   "},{"title":"getattr​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#getattr","content":"def getattr( a, attr: str.type, default = _, / )  getattr: returns the value of an attribute getattr(x, name) returns the value of the attribute (field or method) of x named name. It is a dynamic error if x has no such attribute. getattr(x, &quot;f&quot;) is equivalent to x.f. getattr(&quot;banana&quot;, &quot;split&quot;)(&quot;a&quot;) == [&quot;b&quot;, &quot;n&quot;, &quot;n&quot;, &quot;&quot;] # equivalent to &quot;banana&quot;.split(&quot;a&quot;)   "},{"title":"hasattr​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#hasattr","content":"def hasattr(a, attr: str.type, /) -&gt; bool.type  hasattr: test if an object has an attribute hasattr(x, name) reports whether x has an attribute (field or method) named name.  "},{"title":"hash​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#hash","content":"def hash(a: str.type, /) -&gt; int.type  hash: returns the hash number of a value. hash(x)`` returns an integer hash value for x such that x == yimplieshash(x) == hash(y)``. hash fails if x, or any value upon which its hash depends, is unhashable. hash(&quot;hello&quot;) != hash(&quot;world&quot;)   "},{"title":"int​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#int","content":"def int( a: [bool.type, &quot;float&quot;, int.type, str.type] = _, /, base: int.type = _ ) -&gt; int.type  int: convert a value to integer. .type attribute​ Produces &quot;int&quot; Details​ int(x[, base]) interprets its argument as an integer. If x is an int, the result is x. If x is a float, the result is the integer value nearest to x, truncating towards zero; it is an error if x is not finite (NaN,+Inf, -Inf). If x is a bool, the result is 0 for False or 1 for True. If x is a string, it is interpreted like a string literal; an optional base prefix (0, 0b, 0B, 0x, 0X) determines which base to use. The string may specify an arbitrarily large integer, whereas true integer literals are restricted to 64 bits. If a non-zero base argument is provided, the string is interpreted in that base and no base prefix is permitted; the base argument may specified by name. int() with no arguments returns 0. int() == 0 int(1) == 1 int(False) == 0 int(True) == 1 int('1') == 1 int('16') == 16 int('16', 10) == 16 int('16', 8) == 14 int('16', 16) == 22 int(0.0) == 0 int(3.14) == 3 int(-12345.6789) == -12345 int(2e9) == 2000000000 int(&quot;hello&quot;) # error: Cannot parse int(float(&quot;nan&quot;)) # error: cannot be represented as exact integer int(float(&quot;inf&quot;)) # error: cannot be represented as exact integer   "},{"title":"json​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#json","content":"json: struct(..)   "},{"title":"len​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#len","content":"def len(a, /) -&gt; int.type  len: get the length of a sequence len(x) returns the number of elements in its argument. It is a dynamic error if its argument is not a sequence. len(()) == 0 len({}) == 0 len([]) == 0 len([1]) == 1 len([1,2]) == 2 len({'16': 10}) == 1 len(True) # error: not supported   "},{"title":"list​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#list","content":"def list(a: iter(&quot;&quot;) = _, /) -&gt; [&quot;&quot;]  list: construct a list. .type attribute​ Produces &quot;list&quot; Details​ list(x) returns a new list containing the elements of the iterable sequence x. With no argument, list() returns a new empty list. list() == [] list((1,2,3)) == [1, 2, 3] list(&quot;strings are not iterable&quot;) # error: not supported   "},{"title":"map​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#map","content":"def map(func: &quot;function&quot;, seq: iter(&quot;&quot;), /) -&gt; [&quot;&quot;]  Apply a function to each element of the iterable, returning the results. map(abs, [7, -5, -6]) == [7, 5, 6] map(lambda x: x * 2, [1, 2, 3, 4]) == [2, 4, 6, 8]   "},{"title":"max​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#max","content":"def max(*args, key = _)  max: returns the maximum of a sequence. max(x) returns the greatest element in the iterable sequence x. It is an error if any element does not support ordered comparison, or if the sequence is empty. The optional named parameter key specifies a function to be applied to each element prior to comparison. max([3, 1, 4, 1, 5, 9]) == 9 max(&quot;two&quot;, &quot;three&quot;, &quot;four&quot;) == &quot;two&quot; # the lexicographically greatest max(&quot;two&quot;, &quot;three&quot;, &quot;four&quot;, key=len) == &quot;three&quot; # the longest   "},{"title":"min​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#min","content":"def min(*args, key = _)  min: returns the minimum of a sequence. min(x) returns the least element in the iterable sequence x. It is an error if any element does not support ordered comparison, or if the sequence is empty. min([3, 1, 4, 1, 5, 9]) == 1 min(&quot;two&quot;, &quot;three&quot;, &quot;four&quot;) == &quot;four&quot; # the lexicographically least min(&quot;two&quot;, &quot;three&quot;, &quot;four&quot;, key=len) == &quot;two&quot; # the shortest   "},{"title":"ord​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#ord","content":"def ord(a: str.type, /) -&gt; int.type  ord: returns the codepoint of a character ord(s) returns the integer value of the sole Unicode code point encoded by the string s. If s does not encode exactly one Unicode code point, ord fails. Each invalid code within the string is treated as if it encodes the Unicode replacement character, U+FFFD. Example: ord(&quot;A&quot;) == 65 ord(&quot;Й&quot;) == 1049 ord(&quot;😿&quot;) == 0x1F63F   "},{"title":"partial​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#partial","content":"def partial( func, /, *args, **kwargs: {&quot;&quot;: &quot;&quot;} ) -&gt; &quot;function&quot;  Construct a partial application. In almost all cases it is simpler to use a lamdba.  "},{"title":"pprint​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#pprint","content":"def pprint(*args) -&gt; None   "},{"title":"print​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#print","content":"def print(*args) -&gt; None  Print some values to the output.  "},{"title":"range​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#range","content":"def range( a1: int.type, a2: int.type = _, step: int.type = 1, / ) -&gt; &quot;range&quot;  range: return a range of integers .type attribute​ Produces &quot;range&quot; Details​ range returns a tuple of integers defined by the specified interval and stride. range(stop) # equivalent to range(0, stop) range(start, stop) # equivalent to range(start, stop, 1) range(start, stop, step)  range requires between one and three integer arguments. With one argument, range(stop) returns the ascending sequence of non-negative integers less than stop. With two arguments, range(start, stop) returns only integers not less than start. With three arguments, range(start, stop, step) returns integers formed by successively adding step to start until the value meets or passes stop. A call to range fails if the value of step is zero. list(range(10)) == [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] list(range(3, 10)) == [3, 4, 5, 6, 7, 8, 9] list(range(3, 10, 2)) == [3, 5, 7, 9] list(range(10, 3, -2)) == [10, 8, 6, 4]   "},{"title":"record​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#record","content":"def record(**kwargs: {str.type: &quot;&quot;}) -&gt; &quot;function&quot;  A record type represents a set of named values, each with their own type. For example: MyRecord = record(host=str.type, port=int.type)  This above statement defines a record MyRecord with 2 fields, the first named host that must be of type str.type, and the second named port that must be of type int.type. Now MyRecord is defined, it's possible to do the following: Create values of this type with MyRecord(host=&quot;localhost&quot;, port=80). It is a runtime error if any arguments are missed, of the wrong type, or if any unexpected arguments are given.Get the type of the record suitable for a type annotation with MyRecord.type.Get the fields of the record. For example, v = MyRecord(host=&quot;localhost&quot;, port=80) will provide v.host == &quot;localhost&quot; and v.port == 80. Similarly, dir(v) == [&quot;host&quot;, &quot;port&quot;]. It is also possible to specify default values for parameters using the field function. For example: MyRecord = record(host=str.type, port=field(int.type, 80))  Now the port field can be omitted, defaulting to 80 is not present (for example, MyRecord(host=&quot;localhost&quot;).port == 80). Records are stored deduplicating their field names, making them more memory efficient than dictionaries.  "},{"title":"repr​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#repr","content":"def repr(a, /) -&gt; str.type  repr: formats its argument as a string. All strings in the result are double-quoted. repr(1) == '1' repr(&quot;x&quot;) == &quot;\\&quot;x\\&quot;&quot; repr([1, &quot;x&quot;]) == &quot;[1, \\&quot;x\\&quot;]&quot; repr(&quot;test \\&quot;'&quot;) == &quot;\\&quot;test \\\\\\&quot;'\\&quot;&quot; repr(&quot;x\\&quot;y😿 \\\\'&quot;) == &quot;\\&quot;x\\\\\\&quot;y\\\\U0001f63f \\\\\\\\'\\&quot;&quot; &quot;#);   "},{"title":"reversed​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#reversed","content":"def reversed(a: iter(&quot;&quot;), /) -&gt; [&quot;&quot;]  reversed: reverse a sequence reversed(x) returns a new list containing the elements of the iterable sequence x in reverse order. reversed(['a', 'b', 'c']) == ['c', 'b', 'a'] reversed(range(5)) == [4, 3, 2, 1, 0] reversed(&quot;stressed&quot;.elems()) == [&quot;d&quot;, &quot;e&quot;, &quot;s&quot;, &quot;s&quot;, &quot;e&quot;, &quot;r&quot;, &quot;t&quot;, &quot;s&quot;] reversed({&quot;one&quot;: 1, &quot;two&quot;: 2}.keys()) == [&quot;two&quot;, &quot;one&quot;]   "},{"title":"sorted​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#sorted","content":"def sorted( x, /, *, key = _, reverse: bool.type = False ) -&gt; [&quot;&quot;]  sorted: sort a sequence sorted(x) returns a new list containing the elements of the iterable sequence x, in sorted order. The sort algorithm is stable. The optional named parameter reverse, if true, causes sorted to return results in reverse sorted order. The optional named parameter key specifies a function of one argument to apply to obtain the value's sort key. The default behavior is the identity function. sorted([3, 1, 4, 1, 5, 9]) == [1, 1, 3, 4, 5, 9] sorted([3, 1, 4, 1, 5, 9], reverse=True) == [9, 5, 4, 3, 1, 1] sorted([&quot;two&quot;, &quot;three&quot;, &quot;four&quot;], key=len) == [&quot;two&quot;, &quot;four&quot;, &quot;three&quot;] # shortest to longest sorted([&quot;two&quot;, &quot;three&quot;, &quot;four&quot;], key=len, reverse=True) == [&quot;three&quot;, &quot;four&quot;, &quot;two&quot;] # longest to shortest   "},{"title":"str​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#str","content":"def str(a, /) -&gt; str.type  str: formats its argument as a string. .type attribute​ Produces &quot;string&quot; Details​ If x is a string, the result is x (without quotation). All other strings, such as elements of a list of strings, are double-quoted. str(1) == '1' str(&quot;x&quot;) == 'x' str([1, &quot;x&quot;]) == &quot;[1, \\&quot;x\\&quot;]&quot;   "},{"title":"struct​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#struct","content":"def struct(*args, **kwargs) -&gt; struct(..)  .type attribute​ Produces &quot;struct&quot;  "},{"title":"tuple​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#tuple","content":"def tuple(a: iter(&quot;&quot;) = _, /) -&gt; &quot;tuple&quot;  tuple: returns a tuple containing the elements of the iterable x. .type attribute​ Produces &quot;tuple&quot; Details​ With no arguments, tuple() returns the empty tuple. tuple() == () tuple([1,2,3]) == (1, 2, 3)   "},{"title":"type​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#type","content":"def type(a, /) -&gt; str.type  type: returns a string describing the type of its operand. type(None) == &quot;NoneType&quot; type(0) == &quot;int&quot; type(1) == &quot;int&quot; type(()) == &quot;tuple&quot; type(&quot;hello&quot;) == &quot;string&quot;   "},{"title":"zip​","type":1,"pageTitle":"globals","url":"/docs/api/starlark/globals/#zip","content":"def zip(*args) -&gt; [&quot;&quot;]  zip: zip several iterables together zip() returns a new list of n-tuples formed from corresponding elements of each of the n iterable sequences provided as arguments tozip. That is, the first tuple contains the first element of each of the sequences, the second element contains the second element of each of the sequences, and so on. The result list is only as long as the shortest of the input sequences. zip() == [] zip(range(5)) == [(0,), (1,), (2,), (3,), (4,)] zip(range(5), &quot;abc&quot;.elems()) == [(0, &quot;a&quot;), (1, &quot;b&quot;), (2, &quot;c&quot;)]  "},{"title":"list type","type":0,"sectionRef":"#","url":"/docs/api/starlark/list/","content":"","keywords":""},{"title":"list.append​","type":1,"pageTitle":"list type","url":"/docs/api/starlark/list/#listappend","content":"def list.append(el, /) -&gt; None  list.append: append an element to a list. L.append(x) appends x to the list L, and returns None. append fails if the list is frozen or has active iterators. x = [] x.append(1) x.append(2) x.append(3) x == [1, 2, 3]   "},{"title":"list.clear​","type":1,"pageTitle":"list type","url":"/docs/api/starlark/list/#listclear","content":"def list.clear() -&gt; None  list.clear: clear a list L.clear() removes all the elements of the list L and returns None. It fails if the list is frozen or if there are active iterators. x = [1, 2, 3] x.clear() x == []   "},{"title":"list.extend​","type":1,"pageTitle":"list type","url":"/docs/api/starlark/list/#listextend","content":"def list.extend(other: iter(&quot;&quot;), /) -&gt; None  list.extend: extend a list with another iterable's content. L.extend(x) appends the elements of x, which must be iterable, to the list L, and returns None. extend fails if x is not iterable, or if the list L is frozen or has active iterators. x = [] x.extend([1, 2, 3]) x.extend([&quot;foo&quot;]) x == [1, 2, 3, &quot;foo&quot;]   "},{"title":"list.index​","type":1,"pageTitle":"list type","url":"/docs/api/starlark/list/#listindex","content":"def list.index( needle, start: [None, int.type] = None, end: [None, int.type] = None, / ) -&gt; int.type  list.index: get the index of an element in the list. L.index(x[, start[, end]]) finds x within the list L and returns its index. The optional start and end parameters restrict the portion of list L that is inspected. If provided and not None, they must be list indices of type int. If an index is negative, len(L) is effectively added to it, then if the index is outside the range [0:len(L)], the nearest value within that range is used; see Indexing. index fails if x is not found in L, or if start or endis not a valid index (int or None). x = [&quot;b&quot;, &quot;a&quot;, &quot;n&quot;, &quot;a&quot;, &quot;n&quot;, &quot;a&quot;] x.index(&quot;a&quot;) == 1 # bAnana x.index(&quot;a&quot;, 2) == 3 # banAna x.index(&quot;a&quot;, -2) == 5 # bananA   "},{"title":"list.insert​","type":1,"pageTitle":"list type","url":"/docs/api/starlark/list/#listinsert","content":"def list.insert(index: int.type, el, /) -&gt; None  list.insert: insert an element in a list. L.insert(i, x) inserts the value x in the list L at index i, moving higher-numbered elements along by one. It returns None. As usual, the index i must be an int. If its value is negative, the length of the list is added, then its value is clamped to the nearest value in the range [0:len(L)] to yield the effective index. insert fails if the list is frozen or has active iterators. x = [&quot;b&quot;, &quot;c&quot;, &quot;e&quot;] x.insert(0, &quot;a&quot;) x.insert(-1, &quot;d&quot;) x == [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;]   "},{"title":"list.pop​","type":1,"pageTitle":"list type","url":"/docs/api/starlark/list/#listpop","content":"def list.pop(index: int.type = _, /)  list.pop: removes and returns the last element of a list. L.pop([index]) removes and returns the last element of the list L, or, if the optional index is provided, at that index. pop fails if the index is negative or not less than the length of the list, of if the list is frozen or has active iterators. x = [1, 2, 3] x.pop() == 3 x.pop() == 2 x == [1]   "},{"title":"list.remove​","type":1,"pageTitle":"list type","url":"/docs/api/starlark/list/#listremove","content":"def list.remove(needle, /) -&gt; None  list.remove: remove a value from a list L.remove(x) removes the first occurrence of the value x from the list L, and returns None. remove fails if the list does not contain x, is frozen, or has active iterators. x = [1, 2, 3, 2] x.remove(2) x == [1, 3, 2] x.remove(2) x == [1, 3]  A subsequent call to x.remove(2) would yield an error because the element won't be found. x = [1, 2, 3, 2] x.remove(2) x.remove(2) x.remove(2) # error: not found  "},{"title":"regex type","type":0,"sectionRef":"#","url":"/docs/api/starlark/regex/","content":"","keywords":""},{"title":"regex.match​","type":1,"pageTitle":"regex type","url":"/docs/api/starlark/regex/#regexmatch","content":"def regex.match(str: str.type, /) -&gt; bool.type  "},{"title":"string type","type":0,"sectionRef":"#","url":"/docs/api/starlark/string/","content":"","keywords":""},{"title":"string.capitalize​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringcapitalize","content":"def string.capitalize() -&gt; str.type  string.capitalize: returns a copy of string S, where the first character (if any) is converted to uppercase; all other characters are converted to lowercase. &quot;hello, world!&quot;.capitalize() == &quot;Hello, world!&quot; &quot;Hello, World!&quot;.capitalize() == &quot;Hello, world!&quot; &quot;&quot;.capitalize() == &quot;&quot;   "},{"title":"string.codepoints​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringcodepoints","content":"def string.codepoints() -&gt; iter(str.type)  string.codepoints: returns an iterable of the unicode codepoint of a string. S.codepoints() returns an iterable value containing the sequence of integer Unicode code points encoded by the string S. Each invalid code within the string is treated as if it encodes the Unicode replacement character, U+FFFD. By returning an iterable, not a list, the cost of decoding the string is deferred until actually needed; apply list(...) to the result to materialize the entire sequence. list(&quot;Hello, 世界&quot;.codepoints()) == [72, 101, 108, 108, 111, 44, 32, 19990, 30028]   "},{"title":"string.count​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringcount","content":"def string.count( needle: str.type, start: [None, int.type] = None, end: [None, int.type] = None, / ) -&gt; int.type  string.count: count the number of occurrences of a string in another string. S.count(sub[, start[, end]]) returns the number of occcurences ofsub within the string S, or, if the optional substring indicesstart and end are provided, within the designated substring of S. They are interpreted according to Skylark's indexing conventions. This implementation does not count occurrence of sub in the string Sthat overlap other occurrence of S (which can happen if some suffix of S is a prefix of S). For instance, &quot;abababa&quot;.count(&quot;aba&quot;) returns 2 for [aba]a[aba], not counting the middle occurrence: ab[aba]ba(this is following Python behavior). &quot;hello, world!&quot;.count(&quot;o&quot;) == 2 &quot;abababa&quot;.count(&quot;aba&quot;) == 2 &quot;hello, world!&quot;.count(&quot;o&quot;, 7, 12) == 1 # in &quot;world&quot;   "},{"title":"string.elems​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringelems","content":"def string.elems() -&gt; iter(str.type)  string.elems: returns an iterable of the bytes values of a string. S.elems() returns an iterable value containing the sequence of numeric bytes values in the string S. To materialize the entire sequence of bytes, apply list(...) to the result. list(&quot;Hello, 世界&quot;.elems()) == [ &quot;H&quot;, &quot;e&quot;, &quot;l&quot;, &quot;l&quot;, &quot;o&quot;, &quot;,&quot;, &quot; &quot;, &quot;世&quot;, &quot;界&quot;]   "},{"title":"string.endswith​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringendswith","content":"def string.endswith(suffix: [str.type, &quot;tuple&quot;], /) -&gt; bool.type  string.endswith: determine if a string ends with a given suffix. S.endswith(suffix) reports whether the string S has the specified suffix. &quot;filename.sky&quot;.endswith(&quot;.sky&quot;) == True   "},{"title":"string.find​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringfind","content":"def string.find( needle: str.type, start: [None, int.type] = None, end: [None, int.type] = None, / ) -&gt; int.type  string.find: find a substring in a string. S.find(sub[, start[, end]]) returns the index of the first occurrence of the substring sub within S. If either or both of start or end are specified, they specify a subrange of S to which the search should be restricted. They are interpreted according to Skylark's indexing conventions. If no occurrence is found, found returns -1. &quot;bonbon&quot;.find(&quot;on&quot;) == 1 &quot;bonbon&quot;.find(&quot;on&quot;, 2) == 4 &quot;bonbon&quot;.find(&quot;on&quot;, 2, 5) == -1   "},{"title":"string.format​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringformat","content":"def string.format(*args, **kwargs) -&gt; str.type  string.format: format a string. S.format(*args, **kwargs) returns a version of the format string S in which bracketed portions {...} are replaced by arguments from args and kwargs. Within the format string, a pair of braces {{ or }} is treated as a literal open or close brace. Each unpaired open brace must be matched by a close brace }. The optional text between corresponding open and close braces specifies which argument to use and how to format it, and consists of three components, all optional: a field name, a conversion preceded by '!', and a format specifier preceded by ':'. {field} {field:spec} {field!conv} {field!conv:spec}  The field name may be either a decimal number or a keyword. A number is interpreted as the index of a positional argument; a keyword specifies the value of a keyword argument. If all the numeric field names form the sequence 0, 1, 2, and so on, they may be omitted and those values will be implied; however, the explicit and implicit forms may not be mixed. The conversion specifies how to convert an argument value x to a string. It may be either !r, which converts the value usingrepr(x), or !s, which converts the value using str(x) and is the default. The format specifier, after a colon, specifies field width, alignment, padding, and numeric precision. Currently it must be empty, but it is reserved for future use. &quot;a {} c&quot;.format(3) == &quot;a 3 c&quot; &quot;a{x}b{y}c{}&quot;.format(1, x=2, y=3) == &quot;a2b3c1&quot; &quot;a{}b{}c&quot;.format(1, 2) == &quot;a1b2c&quot; &quot;({1}, {0})&quot;.format(&quot;zero&quot;, &quot;one&quot;) == &quot;(one, zero)&quot; &quot;Is {0!r} {0!s}?&quot;.format(&quot;heterological&quot;) == &quot;Is \\&quot;heterological\\&quot; heterological?&quot;   "},{"title":"string.index​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringindex","content":"def string.index( needle: str.type, start: [None, int.type] = None, end: [None, int.type] = None, / ) -&gt; int.type  string.index: search a substring inside a string, failing on not found. S.index(sub[, start[, end]]) returns the index of the first occurrence of the substring sub within S, like S.find, except that if the substring is not found, the operation fails. &quot;bonbon&quot;.index(&quot;on&quot;) == 1 &quot;bonbon&quot;.index(&quot;on&quot;, 2) == 4 &quot;bonbon&quot;.index(&quot;on&quot;, 2, 5) # error: not found   "},{"title":"string.isalnum​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringisalnum","content":"def string.isalnum() -&gt; bool.type  string.isalnum: test if a string is composed only of letters and digits. S.isalnum() reports whether the string S is non-empty and consists only Unicode letters and digits. &quot;base64&quot;.isalnum() == True &quot;Catch-22&quot;.isalnum() == False   "},{"title":"string.isalpha​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringisalpha","content":"def string.isalpha() -&gt; bool.type  string.isalpha: test if a string is composed only of letters. S.isalpha() reports whether the string S is non-empty and consists only of Unicode letters. &quot;ABC&quot;.isalpha() == True &quot;Catch-22&quot;.isalpha() == False &quot;&quot;.isalpha() == False   "},{"title":"string.isdigit​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringisdigit","content":"def string.isdigit() -&gt; bool.type  string.isdigit: test if a string is composed only of digits. S.isdigit() reports whether the string S is non-empty and consists only of Unicode digits. &quot;123&quot;.isdigit() == True &quot;Catch-22&quot;.isdigit() == False &quot;&quot;.isdigit() == False   "},{"title":"string.islower​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringislower","content":"def string.islower() -&gt; bool.type  string.islower: test if all letters of a string are lowercase. S.islower() reports whether the string S contains at least one cased Unicode letter, and all such letters are lowercase. &quot;hello, world&quot;.islower() == True &quot;Catch-22&quot;.islower() == False &quot;123&quot;.islower() == False   "},{"title":"string.isspace​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringisspace","content":"def string.isspace() -&gt; bool.type  string.isspace: test if all characters of a string are whitespaces. S.isspace() reports whether the string S is non-empty and consists only of Unicode spaces. &quot; &quot;.isspace() == True &quot;\\r\\t\\n&quot;.isspace() == True &quot;&quot;.isspace() == False   "},{"title":"string.istitle​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringistitle","content":"def string.istitle() -&gt; bool.type  string.istitle: test if the string is title cased. S.istitle() reports whether the string S contains at least one cased Unicode letter, and all such letters that begin a word are in title case. &quot;Hello, World!&quot;.istitle() == True &quot;Catch-22&quot;.istitle() == True &quot;HAL-9000&quot;.istitle() == False &quot;123&quot;.istitle() == False   "},{"title":"string.isupper​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringisupper","content":"def string.isupper() -&gt; bool.type  string.isupper: test if all letters of a string are uppercase. S.isupper() reports whether the string S contains at least one cased Unicode letter, and all such letters are uppercase. &quot;HAL-9000&quot;.isupper() == True &quot;Catch-22&quot;.isupper() == False &quot;123&quot;.isupper() == False   "},{"title":"string.join​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringjoin","content":"def string.join(to_join: iter(str.type), /) -&gt; str.type  string.join: join elements with a separator. S.join(iterable) returns the string formed by concatenating each element of its argument, with a copy of the string S between successive elements. The argument must be an iterable whose elements are strings. &quot;, &quot;.join([]) == &quot;&quot; &quot;, &quot;.join((&quot;x&quot;, )) == &quot;x&quot; &quot;, &quot;.join([&quot;one&quot;, &quot;two&quot;, &quot;three&quot;]) == &quot;one, two, three&quot; &quot;a&quot;.join(&quot;ctmrn&quot;.elems()) == &quot;catamaran&quot;   "},{"title":"string.lower​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringlower","content":"def string.lower() -&gt; str.type  string.lower: test if all letters of a string are lowercased. S.lower() returns a copy of the string S with letters converted to lowercase. &quot;Hello, World!&quot;.lower() == &quot;hello, world!&quot;   "},{"title":"string.lstrip​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringlstrip","content":"def string.lstrip(chars: str.type = _, /) -&gt; str.type  string.lstrip: trim leading whitespaces. S.lstrip() returns a copy of the string S with leading whitespace removed. In most cases instead of passing an argument you should use removeprefix. &quot; hello &quot;.lstrip() == &quot;hello &quot; &quot;x!hello &quot;.lstrip(&quot;!x &quot;) == &quot;hello &quot;   "},{"title":"string.partition​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringpartition","content":"def string.partition(needle: str.type, /) -&gt; (str.type, str.type, str.type)  string.partition: partition a string in 3 components S.partition(x = &quot; &quot;) splits string S into three parts and returns them as a tuple: the portion before the first occurrence of string x,x itself, and the portion following it. If S does not contain x, partition returns (S, &quot;&quot;, &quot;&quot;). partition fails if x is not a string, or is the empty string. &quot;one/two/three&quot;.partition(&quot;/&quot;) == (&quot;one&quot;, &quot;/&quot;, &quot;two/three&quot;) &quot;one&quot;.partition(&quot;/&quot;) == (&quot;one&quot;, &quot;&quot;, &quot;&quot;)   "},{"title":"string.removeprefix​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringremoveprefix","content":"def string.removeprefix(prefix: str.type, /) -&gt; str.type  string.removeprefix: remove a prefix from a string. Not part of standard Starlark. If the string starts with the prefix string, return string[len(prefix):]. Otherwise, return a copy of the original string: &quot;Hello, World!&quot;.removeprefix(&quot;Hello&quot;) == &quot;, World!&quot; &quot;Hello, World!&quot;.removeprefix(&quot;Goodbye&quot;) == &quot;Hello, World!&quot; &quot;Hello&quot;.removeprefix(&quot;Hello&quot;) == &quot;&quot;   "},{"title":"string.removesuffix​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringremovesuffix","content":"def string.removesuffix(suffix: str.type, /) -&gt; str.type  string.removesuffix: remove a prefix from a string. Not part of standard Starlark. If the string starts with the prefix string, return string[len(prefix):]. Otherwise, return a copy of the original string: &quot;Hello, World!&quot;.removesuffix(&quot;World!&quot;) == &quot;Hello, &quot; &quot;Hello, World!&quot;.removesuffix(&quot;World&quot;) == &quot;Hello, World!&quot; &quot;Hello&quot;.removesuffix(&quot;Hello&quot;) == &quot;&quot;   "},{"title":"string.replace​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringreplace","content":"def string.replace( old: str.type, new: str.type, count: int.type = _, / ) -&gt; str.type  string.replace: replace all occurrences of a substring. S.replace(old, new[, count]) returns a copy of string S with all occurrences of substring old replaced by new. If the optional argument count, which must be an int, is non-negative, it specifies a maximum number of occurrences to replace. &quot;banana&quot;.replace(&quot;a&quot;, &quot;o&quot;) == &quot;bonono&quot; &quot;banana&quot;.replace(&quot;a&quot;, &quot;o&quot;, 2) == &quot;bonona&quot; &quot;banana&quot;.replace(&quot;z&quot;, &quot;x&quot;) == &quot;banana&quot; &quot;banana&quot;.replace(&quot;&quot;, &quot;x&quot;) == &quot;xbxaxnxaxnxax&quot; &quot;banana&quot;.replace(&quot;&quot;, &quot;x&quot;, 2) == &quot;xbxanana&quot; &quot;&quot;.replace(&quot;&quot;, &quot;x&quot;) == &quot;x&quot; &quot;# ); &quot;banana&quot;.replace(&quot;a&quot;, &quot;o&quot;, -2) # error: argument was negative &quot;#, &quot;argument was negative&quot;);   "},{"title":"string.rfind​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringrfind","content":"def string.rfind( needle: str.type, start: [None, int.type] = None, end: [None, int.type] = None, / ) -&gt; int.type  string.rfind: find the last index of a substring. S.rfind(sub[, start[, end]]) returns the index of the substring subwithin S, like S.find, except that rfind returns the index of the substring's last occurrence. &quot;bonbon&quot;.rfind(&quot;on&quot;) == 4 &quot;bonbon&quot;.rfind(&quot;on&quot;, None, 5) == 1 &quot;bonbon&quot;.rfind(&quot;on&quot;, 2, 5) == -1   "},{"title":"string.rindex​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringrindex","content":"def string.rindex( needle: str.type, start: [None, int.type] = None, end: [None, int.type] = None, / ) -&gt; int.type  string.rindex: find the last index of a substring, failing on not found. S.rindex(sub[, start[, end]]) returns the index of the substring subwithin S, like S.index, except that rindex returns the index of the substring's last occurrence. &quot;bonbon&quot;.rindex(&quot;on&quot;) == 4 &quot;bonbon&quot;.rindex(&quot;on&quot;, None, 5) == 1 # in &quot;bonbo&quot; &quot;bonbon&quot;.rindex(&quot;on&quot;, 2, 5) # error: not found   "},{"title":"string.rpartition​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringrpartition","content":"def string.rpartition(needle: str.type, /) -&gt; (str.type, str.type, str.type)  string.rpartition: partition a string in 3 elements. S.rpartition([x = ' ']) is like partition, but splits S at the last occurrence of x. &quot;one/two/three&quot;.rpartition(&quot;/&quot;) == (&quot;one/two&quot;, &quot;/&quot;, &quot;three&quot;) &quot;one&quot;.rpartition(&quot;/&quot;) == (&quot;&quot;, &quot;&quot;, &quot;one&quot;)   "},{"title":"string.rsplit​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringrsplit","content":"def string.rsplit( sep: [None, str.type] = None, maxsplit: [None, int.type] = None, / ) -&gt; [str.type]  string.rsplit: splits a string into substrings. S.rsplit([sep[, maxsplit]]) splits a string into substrings likeS.split, except that when a maximum number of splits is specified,rsplit chooses the rightmost splits. &quot;banana&quot;.rsplit(&quot;n&quot;) == [&quot;ba&quot;, &quot;a&quot;, &quot;a&quot;] &quot;banana&quot;.rsplit(&quot;n&quot;, 1) == [&quot;bana&quot;, &quot;a&quot;] &quot;one two three&quot;.rsplit(None, 1) == [&quot;one two&quot;, &quot;three&quot;]   "},{"title":"string.rstrip​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringrstrip","content":"def string.rstrip(chars: str.type = _, /) -&gt; str.type  string.rstrip: trim trailing whitespace. S.rstrip() returns a copy of the string S with trailing whitespace removed. In most cases instead of passing an argument you should use removesuffix. &quot; hello &quot;.rstrip() == &quot; hello&quot; &quot; hello!x&quot;.rstrip(&quot; x!&quot;) == &quot; hello&quot;   "},{"title":"string.split​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringsplit","content":"def string.split( sep: [None, str.type] = None, maxsplit: [None, int.type] = None, / ) -&gt; [str.type]  string.split: split a string in substrings. S.split([sep [, maxsplit]]) returns the list of substrings of S, splitting at occurrences of the delimiter string sep. Consecutive occurrences of sep are considered to delimit empty strings, so 'food'.split('o') returns ['f', '', 'd']. Splitting an empty string with a specified separator returns ['']. If sep is the empty string, split fails. If sep is not specified or is None, split uses a different algorithm: it removes all leading spaces from S (or trailing spaces in the case of rsplit), then splits the string around each consecutive non-empty sequence of Unicode white space characters. If S consists only of white space, split returns the empty list. If maxsplit is given and non-negative, it specifies a maximum number of splits. &quot;one two three&quot;.split() == [&quot;one&quot;, &quot;two&quot;, &quot;three&quot;] &quot;one two three&quot;.split(&quot; &quot;) == [&quot;one&quot;, &quot;two&quot;, &quot;&quot;, &quot;three&quot;] &quot;one two three&quot;.split(None, 1) == [&quot;one&quot;, &quot;two three&quot;] &quot;banana&quot;.split(&quot;n&quot;) == [&quot;ba&quot;, &quot;a&quot;, &quot;a&quot;] &quot;banana&quot;.split(&quot;n&quot;, 1) == [&quot;ba&quot;, &quot;ana&quot;]   "},{"title":"string.splitlines​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringsplitlines","content":"def string.splitlines(keepends: bool.type = False, /) -&gt; [str.type]  string.splitlines: return the list of lines of a string. S.splitlines([keepends]) returns a list whose elements are the successive lines of S, that is, the strings formed by splitting S at line terminators ('\\n', '\\r' or '\\r\\n'). The optional argument, keepends, is interpreted as a Boolean. If true, line terminators are preserved in the result, though the final element does not necessarily end with a line terminator. &quot;one\\n\\ntwo&quot;.splitlines() == [&quot;one&quot;, &quot;&quot;, &quot;two&quot;] &quot;one\\n\\ntwo&quot;.splitlines(True) == [&quot;one\\n&quot;, &quot;\\n&quot;, &quot;two&quot;] &quot;a\\nb&quot;.splitlines() == [&quot;a&quot;, &quot;b&quot;]   "},{"title":"string.startswith​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringstartswith","content":"def string.startswith(prefix: [str.type, &quot;tuple&quot;], /) -&gt; bool.type  string.startswith: test whether a string starts with a given prefix. S.startswith(suffix) reports whether the string S has the specified prefix. &quot;filename.sky&quot;.startswith(&quot;filename&quot;) == True &quot;filename.sky&quot;.startswith(&quot;sky&quot;) == False 'abc'.startswith(('a', 'A')) == True 'ABC'.startswith(('a', 'A')) == True 'def'.startswith(('a', 'A')) == False   "},{"title":"string.strip​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringstrip","content":"def string.strip(chars: str.type = _, /) -&gt; str.type  string.strip: trim leading and trailing whitespaces. S.strip() returns a copy of the string S with leading and trailing whitespace removed. &quot; hello &quot;.strip() == &quot;hello&quot; &quot;xxhello!!&quot;.strip(&quot;x!&quot;) == &quot;hello&quot;   "},{"title":"string.title​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringtitle","content":"def string.title() -&gt; str.type  string.title: convert a string to title case. S.lower() returns a copy of the string S with letters converted to titlecase. Letters are converted to uppercase at the start of words, lowercase elsewhere. &quot;hElLo, WoRlD!&quot;.title() == &quot;Hello, World!&quot;   "},{"title":"string.upper​","type":1,"pageTitle":"string type","url":"/docs/api/starlark/string/#stringupper","content":"def string.upper() -&gt; str.type  string.upper: convert a string to all uppercase. S.lower() returns a copy of the string S with letters converted to lowercase. &quot;Hello, World!&quot;.upper() == &quot;HELLO, WORLD!&quot;  "},{"title":"Benefits When Compared to Buck1","type":0,"sectionRef":"#","url":"/docs/benefits/","content":"","keywords":""},{"title":"Benefits for end users​","type":1,"pageTitle":"Benefits When Compared to Buck1","url":"/docs/benefits/#benefits-for-end-users","content":"&quot;buck2 build SOME_TARGET_I_ALREADY_BUILT_BEFORE is basically instantaneous and is a super delightful experience. 🙂&quot; - End user experience &quot;Buck2 is largely faster and more memory efficient than buck1, and where I’ve seen counter-examples, the buck2 team quickly optimizes and fixes that.🙂&quot; - Software Engineer feedback For people who use Buck on a daily basis (such as using Buck build as part of their development inner loop), switching to Buck2 provides the following benefits: Performance - the performance of Buck2 is better in four ways: Fast things are fast - in Buck1, simply typing buck build when there is nothing to do can be expensive (23 seconds in some benchmarks). In Buck2, the same build action takes 0.1 seconds. Actions that should be fast are fast, which enables developers to use Buck more freely, without trying to work around the build system.Slow things are faster - when there is real work to do, Buck2 is significantly closer to the critical path. Benchmarks range from 5%/10s faster for changing a header file (lots of parallel C++ computations, Buck1 already nearly at the critical path) to 42%/145s faster (changing a Thrift file in a large project).Users contribute to the shared cache - with Buck1, only trusted CI builds write to the network cache, while with Buck2 everyone writes to the cache through sandboxed remote execution. This increases the chance of cache hits, saving capacity and time.CI builds go faster - these numbers vary day by day, but most projects are 2-4x faster. This means spending less time waiting for CI and saving some capacity at the same time. Correctness - in Buck2, rules are hermetic by default. Missing dependencies are errors. These restrictions apply to both the user-written BUCK files and the language rules. During the process of migrating to Buck2, a huge number of missing dependencies have been fixed. However, during the same process, several Buck1 issues were identified that are not going to be fixed in Buck1 (such as missing headers, genrules without dependencies, and OCaml rules don’t track all deps). The end result is that Buck2 gives the right answer more often, cutting down on user surprises. Rule features - the rules in Buck2, especially for less commonly used languages (such as Haskell, OCaml, and Rust) support features above and beyond those in Buck1. Examples: dependencies can be given as arguments to prebuilt_ocaml_library, Haskell enables the use of stub headers from C++, and Rust has experimental pipelining support. Actively developed - the Meta build team is putting all its efforts behind Buck2; it's vastly easier to develop than Buck1. While Buck2 is already ahead of Buck1 in many important aspects, the difference is only going to grow with several improvements in the pipeline.Support - Meta can provide much better support to those having difficulties with Buck2 than to those using Buck1. "},{"title":"Benefits for Rule Authors​","type":1,"pageTitle":"Benefits When Compared to Buck1","url":"/docs/benefits/#benefits-for-rule-authors","content":"If you write language-specific rules, then Buck2 is in a different league to Buck1. &quot;This is all rather fun! Buck2 rules are so much more hackable than Buck1.&quot; - Software Engineer feedback There are a number of reasons why Buck2 excels for Rule Authors: Faster developer cycle - in Buck1, the time from changing a rule to seeing the impact is many minutes: you first have to compile Buck1, invalidate the dependency cache (and so on), and perhaps work between multiple OSs. With Buck2, it takes seconds, you don’t even need to restart the daemon.Simple API - Buck2 rules use a small and documented Starlark API, which is dependency-correct by construction. In Buck1, the rules must obey a lot of subtle side conditions with a much larger API.Easier deployment - for Buck2, deployment is just checking the rules in, with an atomic commit changing associated macros (when required). For Buck1, you have to make the repo work with the old and new rules and wait for a Buck version bump to ship your changes, perhaps a few days later.Low barrier to entry - writing rules in Buck2 is vastly easier than Buck1, significantly increasing the developer pool. This means that writing rules is now accessible to language experts, not just Buck experts. "},{"title":"Benefits for Integrators​","type":1,"pageTitle":"Benefits When Compared to Buck1","url":"/docs/benefits/#benefits-for-integrators","content":"For those people who integrate Buck2 into larger systems, in addition to many of the above benefits apply, Buck2 provides the following benefits: Faster queries - many integrators make extensive use of buck uquery and cquery. In Buck2, these commands are faster and use less memory. For example, on CI target determination (a bunch of targets/queries), Buck2 is 25% faster at P50 (moving to 40% faster at P95) with 25% less memory (saving over 20Gb, and crossing below the 64Gb threshold). Profiling - Buck2 already ships with five types of profiling for both loading and analysis (flame graphs, statement breakdown, heap profiles etc). With Buck2, these tools are much more easily accessible to people not on the Build Infra team. "},{"title":"The downside​","type":1,"pageTitle":"Benefits When Compared to Buck1","url":"/docs/benefits/#the-downside","content":"While there are many benefits, it would be remiss not to include a small list of temporary issues: Stability - Buck2 is under active development, which means the risk of regression is correspondingly higher. There may be issues, but they will be fixed as quickly as possible (and lessons learned) through the through Meta's SEV-review process.Corner cases - Buck1 has been battle-tested for nearly a decade, which has included attention to events such as error messages in unlikely corner cases. Only time and user feedback will enable Meta to bring Buck2 to the same level. Please share all such feedback! "},{"title":"Bootstrapping Buck2","type":0,"sectionRef":"#","url":"/docs/bootstrapping/","content":"Bootstrapping Buck2 To generate BUCK files for buck2's dependencies, we use reindeer. Note that the resulting binary will be compiled without optimisations or jemalloc, so we recommend using the Cargo-produced binary in further development. First, install reindeer with Cargo: cargo install --locked --git https://github.com/facebookincubator/reindeer reindeer Next, run the following to buckify dependencies: cd buck2/ reindeer --third-party-dir shim/third-party/rust buckify Build buck2 with buck2: buck2 build //:buck2 ","keywords":""},{"title":"Concept Map","type":0,"sectionRef":"#","url":"/docs/concepts/concept_map/","content":"Concept Map The Concept Map provides an at-a-glance overview of the relationships between widely used Buck2 concepts. It is meant to be a tool to help those onboarding to Buck2 to quickly gain an understanding of the Buck2 environment. note The Concept Map is for reference only and is not intended to be 100% accurate nor complete.","keywords":""},{"title":"Daemon (buckd)","type":0,"sectionRef":"#","url":"/docs/concepts/daemon/","content":"","keywords":""},{"title":"Killing or disabling the Buck daemon​","type":1,"pageTitle":"Daemon (buckd)","url":"/docs/concepts/daemon/#killing-or-disabling-the-buck-daemon","content":"The Buck daemon process is killed if buck2 clean or buck2 kill commands are run. Note that they won't kill the daemon associated with custom isolation dirs. To do that, run using the --isolation-dir option (buck2 --isolation-dir &lt;dir&gt; &lt;command&gt;) "},{"title":"Glossary of Terms","type":0,"sectionRef":"#","url":"/docs/concepts/glossary/","content":"Glossary of Terms .buckconfig​ The root of your project must contain a configuration file named .buckconfig. Before executing, Buck2 reads this file to incorporate specified customizations. For more information, refer to the Legacy docs. Action​ An individual, cacheable, ideally hermetic command that's run during the build. It takes artifacts as inputs and produces other artifacts as outputs. An example command could be gcc -o main main.c, which takes the artifact main.c (a source file) and produces the artifact called main (the compiled binary). Action graph​ The dependency graph of all actions belonging to a target: it can be queried with buck2 aquery. Artifact​ A single input or output of an action. These are files that participate as inputs or outputs of a build and can be source files or build outputs. For more information, see the Artifact API. Attribute​ Declared by a rule and used to express the properties of a particular instance of a rule to create a target. For example, srcs, deps and copts, which declare a target's source files, dependencies, and custom compiler options, respectively. The available attributes for a target depend on its rule type. BUCK file​ A BUCK file (the name is configurable, some projects use TARGETS) is the main configuration file that tells Buck2 what to build, what their dependencies are, and how to build them. Buck2 takes a BUCK file as input and evaluates the file to declare targets, which are then used to create a graph of dependencies and to derive the actions that must be completed to build intermediate and final software outputs. A BUCK file marks a directory and any sub-directories not containing a BUCK file as a package. BXL​ BXL (Buck eXtension Language) scripts are written in Starlark (a restricted subset of Python) and give integrators the ability to inspect and interact directly with the buck2 graph. BXL scripts can query the action graph, configured graph, and unconfigured graph. They can also create actions and trigger builds. Cell​ The directory tree of one or more Buck2 packages. A Buck2 build can involve multiple cells. The cell root always contains a .buckconfig, although the presence of a .buckconfig file doesn't in itself define a cell. Rather, the cells involved in a build are defined at the time Buck2 is invoked; they are specified in the .buckconfig for the Buck project. Configuration​ Configurations consist of a set of 'constraint values' that are used to resolve select attributes prior to evaluating rule implementations: the attribute takes the value of the first branch in the select that matches the configuration. Configurations are instantiated by rules that produce a PlatformInfo provider. Once created, targets can receive their configuration through a variety of mechanisms, such as: Inheritance - by default, when following a dependency edge A -&gt; B, B inherits A's configuration.The default_target_platform attribute and --target-platforms command line flag.Transitions (see below). Configurations allow a single target to exist in multiple variants in the configured graph (for example, to build a given binary at differing optimization levels or targeting different CPU architectures). Configured graph​ The configured target graph is generated by configuring target nodes in the unconfigured target graph. That is, selects are fully resolved and configurations applied. The configured graph includes information about the configurations and transitions involved in building targets. The same target may appear in multiple different configurations (when printed, the configuration is after the target in parentheses). Daemon​ The Daemon process lives between invocations and is designed to allow for cache reuse between Buck2 invocations, which can considerably speed up builds. For more information, see Daemon (buckd). Dependency​ A directed edge between two targets. A target A can have a dependency on target B, for example, if any dep attribute of A mentions B. A target's dependence on another target is determined by the visibility of the latter. Execution platform​ A type of rule that includes information such as what execution types a target supports, which can be remote, local, and hybrid execution. Also, whether it supports cache uploads, which allows users to get cache hits for things that executed locally. Hybrid execution​ Enables shifting work to the local host when available parallelism in the build is low. This enables users to save on remote execution roundtrips to enable faster builds. Isolation dir​ Instances of Buck2 share a daemon if and only if their isolation directory is identical. The isolation directory also influences the output paths provided by Buck2. Package​ A directory that contains a Buck2 BUCK file and all source files belonging to the same directory as the BUCK file, or any of its subdirectories that do not contain a BUCK file themselves. Prelude​ The prelude is a unique .bzl file located at prelude//prelude.bzl. Buck2 implicitly loads all the symbols defined in the prelude whenever it loads a BUCK file. Symbols defined outside the prelude can be imported via a load() statement. When you create a Buck2 project using buck2 init --git, it will contain the same prelude used internally at Meta by Buck2 users. It is viewable at https://github.com/facebook/buck2/tree/main/prelude. Project​ The Outermost directory where there is a .buckconfig: also known as the root cell. The .buckconfig for the project specifies the cells that constitute the Buck2 project. Specifically, these cells are specified in the '[repositories]' section of the .buckconfig. All command invocations are executed from the project root. Provider​ Data returned from a rule function. It's the only way that information from this rule is available to other rules that depend on it (see dependency). Every rule must return at least the DefaultInfo provider. A common case is to also return either RunInfo (because they are executable) or custom providers that the dependents rule can use. For more information, see Providers. Remote execution (RE)​ Distributed execution of actions on remote workers. It can speed up builds significantly by scaling the nodes available for parallel actions, and by caching action outputs across Buck2 users. Rule​ A rule consists of an attribute spec and an implementation, which is a Starlark function. The attribute spec declares what attributes the rule expects to receive. The rule implementation receives the attributes of a target and the providers of its dependencies. It can declare new actions and artifacts and must return providers that can be used to pass data to its dependents or to Buck2 itself. Rules are instantiated in BUCK files to declare targets and set their attributes. The rule implementation is called when Buck2 needs its providers, which can happen when the target is built, or when one of its dependents is. As an example, the cxx_binary rule could be used to create a C++ binary, but android_binary rule would be used to create an Android APK Starlark​ Starlark is a dialect of Python originally developed by Google for the Bazel build tool. It is the configuration language of the Buck2 build system and the language you use in .bzl and BUCK files to define and instantiate rules. There are many reasons why Meta has chosen Starlark, as detailed in The Rust Starlark library article. The Buck2 project maintains and uses an open source Starlark interpreter in Rust. Target​ An object that is defined in a BUCK file. Targets represent the buildable units of a build from the perspective of the end user. Declared by instantiating a rule with attributes. A target has dependencies, which are references to other targets. Target label​ The identifier for a target. Structured as cellAlias//path/to/package:target, where cellAlias// maps to a cell root path (as defined in the ./buckconfig of the cell this target belongs to), path/to/package is the package directory that contains the BUCK file declaring the target (relative to the mapped cell alias), and :target is the target's name. Target pattern​ A string that resolves to a set of targets. They can be used as arguments to commands such as buck2 build and buck2 uquery. They can also be used in the visibility argument of a rule. For more information, see Target pattern. Transition​ Allows the configuration to change across a dependency edge. That is, normally, if target A depends on target B, then if the configuration for A is X, then B is configured using X too. By using a transition, you can produce X to configure B instead. Unconfigured graph​ A graph of targets before configurations are applied. Can be queried via buck2 uquery. Visibility​ Determines whether a target can include another target as its dependency. For more information, see Visibility.","keywords":""},{"title":"Target Pattern","type":0,"sectionRef":"#","url":"/docs/concepts/target_pattern/","content":"","keywords":""},{"title":"Build target patterns are not allowed in the deps argument​","type":1,"pageTitle":"Target Pattern","url":"/docs/concepts/target_pattern/#build-target-patterns-are-not-allowed-in-the-deps-argument","content":"Build target patterns cannot be used with the deps argument of a build rule. Buck requires that you specify all dependencies explicitly as either fully-qualified or relative build targets. "},{"title":"Target aliases​","type":1,"pageTitle":"Target Pattern","url":"/docs/concepts/target_pattern/#target-aliases","content":"Buck supports the ability to define aliases for build targets; using aliases can improve brevity when specifying targets on the Buck command line. To see which aliases exist, use buck2 audit config alias. "},{"title":"Visibility","type":0,"sectionRef":"#","url":"/docs/concepts/visibility/","content":"","keywords":""},{"title":"Examples​","type":1,"pageTitle":"Visibility","url":"/docs/concepts/visibility/#examples","content":"A common library like Guava should be able to be included by any build rule: prebuilt_jar( name = 'guava', binary_jar = 'guava-14.0.1.jar', visibility = ['PUBLIC'] )  It is common to restrict the visibility of Android resources to the Java code that uses it: android_resource( name = 'ui_res', res = 'res', package = 'com.example', visibility = ['//java/com/example/ui:ui'] )  Or it may be simpler to make it visible to the entire directory in case additional build rules are added to java/com/example/ui/BUCK: android_resource( name = 'ui_res', res = 'res', package = 'com.example', visibility = ['//java/com/example/ui:'] )  Also, it is common to limit code for testing to be visible only to tests. If you define all of your Java unit tests in a folder named javatests/ in the root of your project, then you could define the following rule to ensure that only build rules under javatests/ can depend on JUnit: prebuilt_jar( name = 'junit', binary_jar = 'junit-4.11.jar', visibility = ['//javatests/...'] )  Finally, restricting the view of a target can be useful for preventing dependency creep: java_library( name = 'example', visibility = ['PUBLIC',], within_view = ['//foo:bar','//hello:world'] )  "},{"title":"BXL and Anonymous Targets","type":0,"sectionRef":"#","url":"/docs/developers/anon_targets/","content":"","keywords":""},{"title":"Anonymous targets​","type":1,"pageTitle":"BXL and Anonymous Targets","url":"/docs/developers/anon_targets/#anonymous-targets","content":"Anonymous targets are supported in BXL. Anonymous targets are keyed by the attributes, and allow you to share/cache work more effectively. You might want to use anonymous targets if there is some heavy Starlark evaluation which can be cached, or if you want to cache local actions. "},{"title":"APIs​","type":1,"pageTitle":"BXL and Anonymous Targets","url":"/docs/developers/anon_targets/#apis","content":"The actions object returned from ctx.bxl_actions().actions (equivalent of ctx.actions in normal rules) has the following functions for anonymous targets: anon_target(rule: &quot;rule&quot;, attrs: Dict[str, Any]) -&gt; &quot;promise&quot;: generates a single anonymous target. Return type is an unresolved promise.anon_targets(rules: [(&quot;rule&quot;, Dict[str, Any])]) -&gt; &quot;promise&quot;: generates a list of anonymous targets. Return type is an unresolved promise representing the list of anonymous targets.artifact_promise(promise: &quot;promise&quot;) -&gt; &quot;promise_artifact&quot;: turns an unresolved promise into a kind of artifact. See Convert promise to artifact for more info on why you might want to use this. The resulting promise also has map() and join() functions. map() applies a function to the promise's results, and join() turns multiple promises into a single promise. To resolve promises in BXL, bxl_ctx has a resolve() function, which takes in the analysis actions instance (actions object returned from ctx.bxl_actions().actions) and a single promise and returns an optional promise value, if there is one. If you intend to create multiple promises, using join() to produce a single promise will allow you to resolve them concurently with a single resolve() call. Small example: def _my_impl(ctx): bxl_actions = ctx.bxl_actions() # pass in relevant params to configure the execution platform resolution actions = ctx.bxl_actions().actions promise1 = actions.anon_target(my_anon_rule1, my_attrs1) promise2 = actions.anon_target(my_anon_rule2, my_attrs2).map(my_map_function) joined = promise1.join(promise2) resolved = ctx.resolve(actions, joined) # do some more stuff ...  "},{"title":"Complete Example​","type":1,"pageTitle":"BXL and Anonymous Targets","url":"/docs/developers/anon_targets/#complete-example","content":"## anon_bxl_rules.bzl ############ # Define an anonymous rule. MirrorInfo = provider(fields = [&quot;mirrored_attrs&quot;]) # Anonymous rule which writes some silly output, and also mirrors all attributes received def _mirror_impl(ctx: &quot;context&quot;) -&gt; [&quot;provider&quot;]: out = ctx.actions.declare_output(&quot;my_output&quot;) ctx.actions.write(out, &quot;my_content&quot;) return [DefaultInfo(default_outputs = [out]), MirrorInfo(mirrored_attrs = ctx.attrs)] my_mirror_rule = rule(impl = _mirror_impl, attrs = { &quot;false&quot;: attrs.bool(), &quot;int&quot;: attrs.int(), &quot;list_string&quot;: attrs.list(attrs.string()), &quot;string&quot;: attrs.string(), &quot;true&quot;: attrs.bool(), }) # Will be used in a map function in my_script.bxl below StringInfo = provider(fields = [&quot;my_string&quot;]) ## my_script.bxl ############ load(&quot;:anon_bxl_rules.bzl&quot;, &quot;MirrorInfo&quot;, &quot;StringInfo&quot;, &quot;my_mirror_rule&quot;) def _anon_target_example(ctx): bxl_actions = ctx.bxl_actions() actions = bxl_actions.actions # Attrs to pass into the anonymous target. An anonymous target is defined by the hash of its attributes my_attrs = { &quot;false&quot;: False, &quot;int&quot;: 42, &quot;list_string&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], &quot;string&quot;: &quot;foo-bar-string&quot;, &quot;true&quot;: True, } # A function to be applied to the promise (result of anon target), producing a promise with the resulting value. def my_function(providers): # Do something with the attrs. In this example, we are validating that the attrs are what we expect. mirrored_fields = providers[MirrorInfo].mirrored_attrs assert_eq(mirrored_fields.true, True) assert_eq(mirrored_fields.false, False) assert_eq(mirrored_fields.int, 42) assert_eq(mirrored_fields.string, &quot;foo-bar-string&quot;) assert_eq(mirrored_fields.list_string, [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]) outputs = providers[DefaultInfo].default_outputs # These are the providers this target returns return [DefaultInfo(default_outputs = outputs), StringInfo(my_string = &quot;map function succeeded!&quot;)] # Create an anonymous target by passing in &quot;my_attrs&quot; into &quot;my_mirror_rule&quot;, and returns providers. # Specifically, it returns &quot;DefaultInfo&quot; and &quot;MirrorInfo&quot;, as defined in &quot;my_mirror_rule&quot; # Then, we map the result to &quot;my_function&quot;, which does some validation promise = actions.anon_target(my_mirror_rule, my_attrs).map(my_function) # Resolving the promise returns a &quot;provider_callable&quot;, which was defined by &quot;my_function&quot; above. # `DefaultInfo` is at index 0, `StringInfo` is at index 1 promise_result = ctx.resolve(actions, promise) ensured = ctx.output.ensure(promise_result[0].default_outputs[0]) # should print out location of the output, which contains the &quot;my_content&quot; string as defined in anon_bxl_rules.bzl above ctx.output.print(ensured) # should print out &quot;map function succeeded!&quot; ctx.output.print(promise_result[1].my_string) def assert_eq(a, b): if a != b: fail(&quot;Expected {} == {}&quot;.format(a, b)) anon_target_example = bxl( impl = _anon_target_example, cli_args = { }, )  "},{"title":"Buck1 vs Buck2","type":0,"sectionRef":"#","url":"/docs/developers/architecture/buck1_vs_buck2/","content":"","keywords":""},{"title":"At a glance​","type":1,"pageTitle":"Buck1 vs Buck2","url":"/docs/developers/architecture/buck1_vs_buck2/#at-a-glance","content":"The following table provides an at-a-glance comparison of Buck1 and Buck2. Buck1\tBuck2Build files in Starlark\tBuild files in Starlark Macros in Starlark\tMacros in Starlark Rules in Java\tRules in Starlark Rules and Macros are logically similar\tRules and Macros are logically similar Rules and Core are not well abstracted\tRules and Core are strongly separated Core in Java\tCore in Rust Remote Execution (RE) not well supported\tAll rules support remote execution by default Varying degrees of incrementality / parallelism\tUnified incrementality / parallelism "},{"title":"Top-down vs Bottom-up - understanding the implications of the difference in execution models between Buck1 and Buck2​","type":1,"pageTitle":"Buck1 vs Buck2","url":"/docs/developers/architecture/buck1_vs_buck2/#top-down-vs-bottom-up---understanding-the-implications-of-the-difference-in-execution-models-between-buck1-and-buck2","content":"It is often said that Buck1 does 'top down' and Buck2 does 'bottom up' building. This results in cases where some topics that seem conceptually trivial in Buck1 are hard problems in Buck2, or vice versa. "},{"title":"What are the differences?​","type":1,"pageTitle":"Buck1 vs Buck2","url":"/docs/developers/architecture/buck1_vs_buck2/#what-are-the-differences","content":"Scenario: Imagine you are building A, which depends on both B and C, but where neither B nor C have any dependencies. For the sake of simplicity, imagine B and C are C++ compilations (that produce object files), and A is a link (that consumes them and produces a shared library). Building A with Buck1​ Following is an oversimplified view of what happens: Buck1 computes the 'rulekey' for B. This consists of mixing together the hashes of the C++ file being compiled, as well as all C++ compiler flags, and so on. Buck1 then does the same for C.Buck1 then computes the rulekey for A. This consist of mixing together the rulekeys of B and C, as well as linker flags used by A. for example. Buck1 then looks up the rulekey for A in the cache. If there's a hit, then Buck1 downloads the output and its job done.If there's a cache miss, continue. Buck1 then queries the cache for the rulekeys of B and C: If there's a hit, then the output is downloaded.If there's a miss, then Buck1 runs the commands needed to produce the object file that was missed. Regardless of whether those commands run locally or on RE, Buck1 downloads the output of B and C. Buck1 then runs the command for A to produce the shared library. At this point, Buck1 may actually do another cache lookup with a different rulekey, which is called an input based rulekey. This rulekey is derived from the inputs of the action that needs executing, which at this point of the build are known (since they were just built)! Building A with Buck2​ In contrast, if you ask Buck2 to build A, here is what happens: Buck2 produce the action to compile B and computes the hash of the action. This is the 'action digest', which consists of mixing the hashes of all the inputs (such as the C++ file), as well as the command line (so, implicitly, the compiler flags). Buck2 queries the action cache for the action digest hash. If there's a hit, Buck2 obtains the hash of the resulting object file (that is, the output of B).If there's a miss, Buck2 runs the action on RE (or potentially locally) and obtains the hash of the object file. If the action runs remotely, Buck2 will not download the output. Buck2 does the same thing for C.Buck2 produces the action to link A. This consists of mixing together all the hashes of the input files (which were retrieved earlier) and the command line to produce an action digest, then querying the cache and potentially running the action. Once Buck2 produces A (again, on RE), then, since this output was requested by the user (unlike the intermediary outputs B and C), Buck2 downloads A. "},{"title":"Some implications​","type":1,"pageTitle":"Buck1 vs Buck2","url":"/docs/developers/architecture/buck1_vs_buck2/#some-implications","content":"Rulekeys vs Action digests​ The closest thing to Buck1’s rulekey in Buck2 is the action digest, but they are very different! Since it’s a product of the (transitive) inputs of an action, the (default) rulekey can be computed without running anything or querying any caches. However, the action digest cannot: it requires the actual inputs of an action, which means you need to build all the dependencies first. This means that: In Buck1, you can ask for rulekeys for a target.In Buck2, you’d have to run the build first then ask for the action digests (this is what the buck2 log what-ran would show you). Buck2 queries many more caches​ Buck1 will not descend further down a tree of dependency when it gets a cache hit.Buck2 will always walk up all your dependencies, regardless of whether you get cache hits or not. Materialization​ When Buck1 gets a cache miss, it downloads the outputs.Buck2, by contract, does not download outputs as part of a build (this is called 'deferred materialization'). Note that Buck2 does download the outputs if the user asked for them (that is, they were the targets the user put on the command line). "},{"title":"Second-order implications​","type":1,"pageTitle":"Buck1 vs Buck2","url":"/docs/developers/architecture/buck1_vs_buck2/#second-order-implications","content":"Non-determinism​ Non-determinism in a build affects Buck2 and Buck1 differently. One scenario that often works fine in Buck1 but can work catastrophically bad in Buck2 is a codegen step, driven by a Python binary. In certain configurations/modes, Python binaries are non-deterministic, because they are XARs and that is always non-deterministic, which is bad! In Buck1, that doesn’t really matter, because you can get a cache hit on the codegen output without ever visiting the XAR (as long as the input files haven’t changed).In Buck2, you need the XAR to check the action cache for the codegen step. However, binaries are often not cached in certain configurations/modes, so your XAR isn’t cached.Therefore, since your XAR build is non-deterministic, you’ll always miss in the action cache and the codegen step will always have to run in every build. It can get worse! If the Python binary produces non-deterministic codegen, then the entire build might become uncacheable. Cache misses don’t necessarily propagate​ Say that, in Buck2, you’re trying to build a chain of actions like codegen -&gt; compile -&gt; link. Even if your codegen step isn’t cached (say, because its action inputs are non-deterministic as mentioned above), as long as the codegen output is deterministic, you can still get cache hits from compile and link steps. Hybrid execution​ If you squint, you’ll note that Buck1’s build could be viewed as 'local first', whereas Buck2’s would be better viewed as 'remote first': When Buck1 builds something remotely or gets a cache hit, the outputs are always downloaded.When Buck2 builds something remotely or gets a cache hit, the outputs are never downloaded. In turn, this has some important implications: When Buck1 builds something locally, the inputs are always already present.When Buck2 builds something locally, the inputs have to be downloaded, unless they were built locally (which if you’re doing any RE, is usually not the case), or if another command caused them to be downloaded. This means that, in Buck1, running something locally when you have spare resources is usually a no-brainer, because it’s always ready to go, and you’ll save on not having to download the output from RE (though you might have to upload the output if you need to run actions depending on it later). On the flip side, with Buck2, that’s not necessarily the case. To run an action locally, you need to download inputs that you might otherwise not have needed, which will tax your network connection. "},{"title":"Buck2 Telemetry","type":0,"sectionRef":"#","url":"/docs/developers/architecture/buck2_telemetry/","content":"Buck2 Telemetry note 🚧 THIS PAGE IS UNDER CONSTRUCTION","keywords":""},{"title":"Architectural Model","type":0,"sectionRef":"#","url":"/docs/developers/architecture/buck2/","content":"","keywords":""},{"title":"High-level Overview​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#high-level-overview","content":"Buck2 is a build system whose core is written in Rust. Starlark, which is a deterministic, immutable version of Python, is used to extend the Buck2 build system, enabling Buck2 to be language-agnostic. The high-level flow starts with a user creating a build file (a BUCK file) containing one or more targets, which is specified by the target label, its inputs (sources, attributes, configurations, and dependencies), and the type of macro or rule to use. Briefly, a macro is a wrapper around a rule, which runs necessary commands to generate what’s needed for a target (for example, for a cxx_binary target, generate the header map and run necessary clang commands). Macros can be used to reduce boilerplate code for users (such as to supply the same set of attributes for a rule for all targets). Macros and rules are both written in Starlark and are specified by input sources, attributes, and the implementation function. If the target type is a macro, then the macro will fill in some details (for example, for a cxx_binary target, these are the compilation, debug flags to use, this is the clang to use). If the target type is a rule, then the macro layer is skipped altogether. This is all orchestrated by the core, which performs operations such as executing Buck2 CLI args, generating/updating the dependency graph (which contains the configured target nodes, unconfigured target nodes, action nodes, among other types of nodes that all allow for incrementality and execution), and materializing the artifacts. The core is written in Rust. The following diagram shows the high-level overview.  The Buck2 CLI runs in a client process, which sends commands to the Buck2 daemon via gRPC. The daemon goes through several phases after receiving a request from the client: evaluation, configuration, analysis, execution, and materialization (see Execution Model, below). When using buck2 test, there is a final stage for testing. Note that these are the phases that a build goes through, but they are not always sequential. After finishing all phases, the daemon will send the response back to the client via gRPC. "},{"title":"Execution Model​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#execution-model","content":"The following diagram shows the Execution Model, which consists of 5 phases and states.  Each of the phases and states shown in the Execution Model, are detailed in the following sub-sections. "},{"title":"State 0 - Build Files​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#state-0---build-files","content":"Build files (commonly referred to as BUCK files, their default name) are the main input to Buck2 and are syntactically Python. Each build file is uniquely identified by the directory in which it's located. Since all build files have the same name, there cannot be two build files in the same directory. This is usually represented as the relative path from the root of the project (the directory where the .buckconfig file is). Each build file has a set of targets. These describe the things the user wants Buck2 to know about. Each target has a type and a set of named attributes, including at least a name (also known as the label) identifying it. Additional attributes depend on the type of the target. "},{"title":"Phase A: Evaluation​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#phase-a-evaluation","content":"First, Buck2 evaluates a build file, and then constructs an unconfigured target graph. Buck2 performs directory listings to discover packages, then evaluates the build files that were found, expands any macros detected into their underlying rules, and then will take rule attributes and convert them from Starlark to Rust types to construct a target node, and insert it into the unconfigured target graph, which is a smaller portion of Buck2’s larger dependency graph. The target node consists of a reference to rule implementation, and the set of attributes and sources. The result of evaluation is a list of targets read from the build file mapped to a target node in Buck2 unconfigured target graph. "},{"title":"State 1 - Unconfigured Target Graph is generated​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#state-1---unconfigured-target-graph-is-generated","content":"At this point, the unconfigured target graph is available for the next stage of transformation, which is to configure the target nodes within the graph. "},{"title":"Phase B: Configuration​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#phase-b-configuration","content":"At the end of evaluation, the target nodes are not yet configured. Configuration means applying a list of constraints (such as resolving selects to specify the right CPU) to make sure the target can be run where it needs to. This is also known as target platform resolution, and can be configured within the target, the buckconfig, propagated from dependencies, or passed into the CLI. After applying configurations, the target nodes are transformed into configured target nodes within the Buck2 configured target graph, which is a smaller portion of Buck2’s larger dependency graph. "},{"title":"State 2 - Configured Target Graph is generated​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#state-2---configured-target-graph-is-generated","content":"At this point, the configured target graph is available for the analysis stage to generate the action graph. "},{"title":"Phase C: Analysis​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#phase-c-analysis","content":"In the analysis phase, Buck2 constructs a context object (ctx) which contains relevant information (such as attributes pulled from the configuration stage), all converted into Starlark types and made available to the rule. For example, the target’s dependencies are turned into a ProviderCollection, source files are converted into StarlarkArtifacts, and String attributes are turned into a StarlarkString. This ctx object is backed by Buck2’s dependency graph for computation and rules use it to tell Buck2 to run actions, create dynamic actions, or create new files. The rule will return a list of providers, which is data that the rule wants to expose to its dependents (that is, can flow through the dependency graph), such as output artifact information (such as file paths and file hashes). Providers could be actions, source files, or attributes. Within the returned list, DefaultInfo always needs to be returned, which indicates what the default outputs are. Some other common built-in providers include RunInfo, TestInfo, and InstallInfo. The end result is a list of providers and actions (inserted into the action graph) that Buck2 needs to execute to produce the desired outputs, known as 'bound artifacts'. "},{"title":"State 3 - Action Graph and Providers are generated​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#state-3---action-graph-and-providers-are-generated","content":"At this point, the action graph and providers are available to be processed by the execution stage. "},{"title":"Phase D: Execute​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#phase-d-execute","content":"Execution is where Buck2 takes all the providers (input files from the targets, args from the command line), runs the actions, and then outputs the computed results. The critical path is the theoretical lower bound for the duration of a build, which are the slowest set of actions. Buck2 can be run locally or on remote execution, or in a hybrid manner. For each action, an input action digest is created from the action (hash of command line and all of the action’s inputs), uploaded, and cached within RE. This is known as the RE action cache. If there is a cache hit, then Buck2 does not need to run the command for the action, and RE returns the output action digest. This is known as remote execution. If there is not a cache hit, then local execution has to be done, where all the action’s input files are retrieved from the filesystem (most likely from EdenFS), computation is run on these source files, and then outputted to buck-out using I/O operations in the filesystem. Hybrid execution allows Buck2 to race local and remote execution and return the returns of whichever finishes first for a performance speedup. These action digests are how Buck2 communicates with RE. The action outputs, including final/build artifacts, intermediaries, file, directories, and symlinks related to the build, are then materialized (downloaded to disk), and can be found in the buck-out path. There are different configurations that a user can set to control how materialization is handled. "},{"title":"State 4 - Build outputs are generated​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#state-4---build-outputs-are-generated","content":"At this point, the build is complete. If a user ran buck2 test, then there is a final transformation for Buck2 to construct a command for TPX to execute the actual test. "},{"title":"Phase E: Execute tests​","type":1,"pageTitle":"Architectural Model","url":"/docs/developers/architecture/buck2/#phase-e-execute-tests","content":"For more detail on testing, review Test Execution. "},{"title":"FAQs","type":0,"sectionRef":"#","url":"/docs/developers/bxl_faqs/","content":"","keywords":""},{"title":"When should I use BXL over Buck2 API/CLI?​","type":1,"pageTitle":"FAQs","url":"/docs/developers/bxl_faqs/#when-should-i-use-bxl-over-buck2-apicli","content":"There are many overlaps between BXL and Buck2 (for example, both can run cquery and both can build targets). It’s possible that one use case could be handled by both BXL and Buck2. Following are some specific recommendations to help decide when to use BXL over regular Buck2: Use/inspect resolved attributes that are not exposed/accessible to users via normal Buck2 operations. This includes introspecting the Starlark object of providers, analyzing the Starlark object of a rule’s attr before and after coercing and resolution, and introspecting intermediate query results. Reduce/eliminate the need to make several Buck2 calls within your program, such as running several subprocesses to call cquery several times. With BXL, you can just call the BXL script once in a subprocess, potentially reducing the amount of code you need to write in your program. Reduce/eliminate the need to manually parse Buck2 output format within your program, and any bugs that may come with manual parsing. Some languages are more verbose than others when it comes to string parsing.BXL scripts are written in Starlark, which is basically a deterministic, immutable Python, and are able to directly introspect Starlark objects (such as rules and target nodes, and so on) and call methods on these objects instead of parsing them over Buck2’s output. "},{"title":"When is my BXL script cached?​","type":1,"pageTitle":"FAQs","url":"/docs/developers/bxl_faqs/#when-is-my-bxl-script-cached","content":"The entire BXL script is represented as a single node on the DICE graph (Buck2’s internal dependency graph). When the script’s input changes, the entire node is invalidated and needs to be recomputed. For example, if a BXL function calls uquery, then uses the result to do a cquery and then a build, if Buck2 detects that any of the recorded calls to uquery, cquery, and build changes, then the entire BXL script will be reran. The computations themselves (uquery, cquery, and build) will still be incrementally evaluated via DICE, so we are not rerunning every computation entirely within the BXL. When the BXL script creates artifacts and ensures them, those artifacts are cached separately in an action outside of the BXL execution. This means that the artifacts produced by BXL are cached separately from the BXL script itself, much like the computations within a BXL. During 2023, there is a plan to add finer grain incrementality to make better use of DICE’s existing incrementality support. "},{"title":"What’s the difference between ctx.output.print() and print()?​","type":1,"pageTitle":"FAQs","url":"/docs/developers/bxl_faqs/#whats-the-difference-between-ctxoutputprint-and-print","content":"ctx.output.print() writes items to stdout by buck2 even when the script is cached. Items written to the output stream are considered to be the results of a BXL script, which will be displayed to stdout by buck2 even when the script is cached.print() is offered by Starlark via the stdlib. This prints anything you want but won’t be provided to stdout at the end of a BXL script. These can be used to print to stderr. NOTE: print() statements don't show up if the script has been cached. "},{"title":"What do I need to know about ensured artifacts​","type":1,"pageTitle":"FAQs","url":"/docs/developers/bxl_faqs/#what-do-i-need-to-know-about-ensured-artifacts","content":"An ensured_artifact prints out the relative or absolute path via ctx.output.print(), depending on if called with abs_path() or rel_path(), but will print out &lt;ensured artifact bound to &lt;some path&gt;&gt; via print(). This is intentional because when the ensured artifact is created with BXL within BXL, it has not been materialized yet. It will be materialized after the BXL script finishes executing, and Buck2 core performs some additional actions after the BXL script. This is a safeguard to prevent people from misusing the artifact path and passing it into an action without the artifact having been materialized or passing an absolute path into RE, which can actually mess up RE and render the action not shareable across users. In addition, it makes these actions separately cacheable from the BXL execution. "},{"title":"Getting Started","type":0,"sectionRef":"#","url":"/docs/developers/bxl_getting_started/","content":"","keywords":""},{"title":"Writing a BXL​","type":1,"pageTitle":"Getting Started","url":"/docs/developers/bxl_getting_started/#writing-a-bxl","content":"To create a BXL, first, create a script somewhere in the repository ending in .bxl. (Note that you can define a single bxl per file, or multiple BXLs per file like in Starlark rules). In it, define a BXL function as follows: def _your_implementation(ctx): # ... pass your_function_name = bxl( impl = _your_implementation, cli_args = { # cli args that you want to receive from the command line &quot;bool_arg&quot;: cli_args.bool(), &quot;list_type&quot;: cli_args.list(cli_args.int()), &quot;optional&quot;: cli_args.option(cli_args.string()), &quot;target&quot;: cli_args.target_label(), }, )  This exposes your_function_name as a function, with whatever arguments you defined it, so that on the command line you can invoke: buck2 bxl //myscript.bxl:your_function_name -- --bool_arg true --list_type 1 --list_type 2 --target //foo:bar`  You can also add helpdocs to the cli args and get them to show up in cli via --help: def _your_implementation(ctx): # ... pass your_function_name = bxl( impl = _your_implementation, cli_args = { &quot;my_bool&quot;: cli_args.bool(True, &quot;this will be printed as part of `--help`&quot;) }, )  The implementation function takes a single context as parameter (see the documentation for BxlContext). Using it, you'll be able to access functions that enable you to perform queries, analysis, builds, and even create your own actions within BXL to build artifacts as part of a BXL function. The primary method to return information from BXL is to either print them, or build some artifact (for details, see the OutputStream documentation, available as part of ctx.output). At high level, ctx.output.print(..) prints results to stdout, and ctx.output.ensure(artifact) marks artifacts as to be materialized into buck-out by the end of the BXL function, returning an object that lets you print the output path via ctx.output.print(ensured). "},{"title":"Running a BXL​","type":1,"pageTitle":"Getting Started","url":"/docs/developers/bxl_getting_started/#running-a-bxl","content":"To run a BXL function, invoke the buck2 command: buck2 bxl &lt;bxl function&gt; -- &lt;function args&gt;  Where &lt;bxl function&gt; is of the form &lt;cell path to function&gt;:&lt;function name&gt;, and &lt;function args&gt; are the arguments that the function accepts from the command line. The documentation for a BXL function can be seen by running:  buck2 bxl &lt;bxl function&gt; -- --help`  Note that this is different from buck2 bxl --help, which generates the help for the buck2 command instead of the function. "},{"title":"Common How-Tos","type":0,"sectionRef":"#","url":"/docs/developers/bxl_how_tos/","content":"","keywords":""},{"title":"Passing in and using CLI args​","type":1,"pageTitle":"Common How-Tos","url":"/docs/developers/bxl_how_tos/#passing-in-and-using-cli-args","content":"A BXL function can accept a cli_args attribute where args names and types are specified to use within your script, as shown in the following example: Example: def _impl_example(ctx): # ... pass example = bxl( impl = _impl_example, cli_args = { # cli args that you want to receive from the command line &quot;bool_arg&quot;: cli_args.bool(), &quot;list_type&quot;: cli_args.list(cli_args.int()), &quot;optional&quot;: cli_args.option(cli_args.string()), &quot;target&quot;: cli_args.target_label(), }, )  On the command line, you can invoke the arguments as follows: buck2 bxl //myscript.bxl:example -- --bool_arg true --list_type 1 --list_type 2 --target //foo:bar  For BXL functions, to read the arguments, use them as attributes from the cli_args attribute on the BXL ctx object, as follows: def _impl_example(ctx): my_bool_arg = ctx.cli_args.bool_arg  "},{"title":"Running actions​","type":1,"pageTitle":"Common How-Tos","url":"/docs/developers/bxl_how_tos/#running-actions","content":"You can create actions within BXL via the actions_factory. This is called once globally then used on demand: def _impl_example(ctx): actions = ctx.bxl_actions().actions # call once, reuse wherever needed output = actions.write(&quot;my_output&quot;, &quot;out&quot;)  "},{"title":"Getting providers from an analysis​","type":1,"pageTitle":"Common How-Tos","url":"/docs/developers/bxl_how_tos/#getting-providers-from-an-analysis","content":"After calling analysis(), you can get the providers collection from providers(): def _impl_example(ctx): my_providers = ctx.analysis(my_target).providers()  "},{"title":"Get a specific provider from an analysis​","type":1,"pageTitle":"Common How-Tos","url":"/docs/developers/bxl_how_tos/#get-a-specific-provider-from-an-analysis","content":"After calling analysis(), you can also get the providers collection from providers() then grab whatever specific provider you need: def _impl_example(ctx): default_info = ctx.analysis(my_target).providers()[DefaultInfo] ctx.output.print(default_info)  "},{"title":"Build a subtarget​","type":1,"pageTitle":"Common How-Tos","url":"/docs/developers/bxl_how_tos/#build-a-subtarget","content":"Once you have a provider, you can get its subtargets by using the sub_targets attribute on the struct to get a dict of provider labels to provider collections: def _impl_example(ctx): subtarget = ctx.analysis(my_target).providers()[DefaultInfo].sub_targets[“my_subtarget”] ctx.output.print(subtarget)  "},{"title":"Getting attributes or resolved attributes efficiently​","type":1,"pageTitle":"Common How-Tos","url":"/docs/developers/bxl_how_tos/#getting-attributes-or-resolved-attributes-efficiently","content":"If you need to use all of the attrs/resolved_attrs, then initializing the eager variant once would be best. If you only need a few of the attrs, then initializing the lazy variant is better. There’s not really a hard line, it depends on the target node, and which attrs you are looking for. If performance is key to your BXL script, the best way to determine this is to use the BXL profiler. Regardless, if you use eager or lazy versions of getting attributes, you should cache the attrs object: def _impl_example(ctx): lazy = ctx.attrs_lazy() # call once and reuse wherever is necessary eager = ctx.attrs_eager() # call once and reuse wherever is necessary  "},{"title":"Inspecting a struct​","type":1,"pageTitle":"Common How-Tos","url":"/docs/developers/bxl_how_tos/#inspecting-a-struct","content":"You can use dir(my_struct) to inspect a struct. You can also use getattr(my_struct, “my_attr”) to grab individual attributes, which is equivalent to my_struct.my_attr. These are available as part of the Starlark language spec. "},{"title":"Set addition/subtraction on a target_set​","type":1,"pageTitle":"Common How-Tos","url":"/docs/developers/bxl_how_tos/#set-additionsubtraction-on-a-target_set","content":"There are a few BXL actions that return a target_set (such as a cquery eval()). The target_set supports set subtraction and addition (you can use - and + directly in Starlark). "},{"title":"Profiling, Testing, and Debugging a BXL script​","type":1,"pageTitle":"Common How-Tos","url":"/docs/developers/bxl_how_tos/#profiling-testing-and-debugging-a-bxl-script","content":"You can use buck2 bxl profiler, with various measurements, to determine where the script is least efficient. To time individual pieces of the script, you can use BXL’s timestamp methods: def _impl_example(_ctx): start = now() # call once and reuse wherever is necessary # do something time intensive here end1 = start.elapsed_millis() # do something else time intensive here end2 = start.elapsed_millis()  BXL does not have a debugger available nor a robust testing framework for mocking. Debug - the main method to debug a BXL script is with print statements (print() and ctx.output.print()).Test - the main method to test a BXL script is to actually invoke it with required inputs then verify the outputs. "},{"title":"BXL Telemetry","type":0,"sectionRef":"#","url":"/docs/developers/bxl_telemetry/","content":"","keywords":""},{"title":"Telemetry​","type":1,"pageTitle":"BXL Telemetry","url":"/docs/developers/bxl_telemetry/#telemetry","content":""},{"title":"Emitting events from your BXL script​","type":1,"pageTitle":"BXL Telemetry","url":"/docs/developers/bxl_telemetry/#emitting-events-from-your-bxl-script","content":"In BXL, you can emit custom events via ctx.instant_event(), which takes in two named parameters: id: string, identifies your event. Helpful to identify your event when looking through event logs. Ids do not have to be unique in a single BXL script.metadata: dict, where keys are strings and values are strings, bools, or ints. You can put any metadata you wish here. Example: def _impl(ctx): ctx.instant_event(id = &quot;id1&quot;, metadata = {&quot;foo&quot;: &quot;bar&quot;}) my_script = bxl( impl = _impl, cli_args = {}, )  Only instant events can be manually created within BXL at this time, which means that the event represents a single point in time. If you need something similar to spans (start and end events which encompass a range of time) for measuring the duration of a particular section (excluding actions - see below for more information), you could couple instant events with the global now() function to measure the duration yourself: def _impl(ctx): instant = now() # do something time intensive end = instant.elapsed_millis() ctx.instant_event(id = &quot;id1&quot;, metadata = {&quot;duration&quot;: end}) # do something else time intensive end = instant.elapsed_millis() ctx.instant_event(id = &quot;id2&quot;, metadata = {&quot;duration&quot;: end}) my_script = bxl( impl = _impl, cli_args = {}, )  Measuring time for actions and ensuring artifacts You cannot use now() to measure the time it takes to run actions and ensure artifacts because these processes occur asynchronously outside of the BXL script execution. For BXL user telemetry, we emit action events via the buck2 core automatically. Events around ensuring the artifacts are not emitted currently, but will be added soon. "},{"title":"User event log​","type":1,"pageTitle":"BXL Telemetry","url":"/docs/developers/bxl_telemetry/#user-event-log","content":"To write to your own event log when running BXL, you can run your BXL command with the --user-event-log flag to tell buck2 where to write the events to. Buck2 is aware of the following file extensions: .json-lines, json-lines.zst, .json-lines.gz, and will compress the files automatically for you depending on the extension. If the extension is not one of these, the logs will always be written in JSONL format, uncompressed. Example: buck2 bxl path//to/my_script/script.bxl:my_script --user-event-log my_file.json-lines.gz  When using this flag to write to a custom event log, it is up to you to clean up these log files. In addition, if the same filename is used with subsequent BXL invocations, events are always appended to the existing file contents, which is the same behavior as buck2 &lt;any command&gt; --event-log &lt;path&gt;. If you tell buck2 to write to a compressed file, you are responsible for decompressing them. "},{"title":"Getting a user event log from a normal event log​","type":1,"pageTitle":"BXL Telemetry","url":"/docs/developers/bxl_telemetry/#getting-a-user-event-log-from-a-normal-event-log","content":"buck2 log show-user can be used to convert a normal event log (regardless of encoding/compression) to a user event. Similar to buck2 log show, you can choose the most recent invocation, or the nth invocation, or provide a path to the normal user event log. Note that user event logs are not able to be passed into buck2 log show or buck2 log show-user. "},{"title":"Event log output​","type":1,"pageTitle":"BXL Telemetry","url":"/docs/developers/bxl_telemetry/#event-log-output","content":"The first line of your event log will always be the invocation record, which contains useful things like command line args used, working directory, etc. The subsequent lines are either instant events and/or action events, depending on your BXL script's contents. Instant event Sample: { &quot;StarlarkUserEvent&quot;: { &quot;id&quot;: &quot;foo&quot;, &quot;metadata&quot;: { &quot;bool_value&quot;: true, &quot;string_value&quot;: &quot;str&quot;, &quot;int_value&quot;: 123, } }, &quot;epoch_millis&quot;: 123456789 # when the event was emitted }  Action event { &quot;ActionExecutionEvent&quot;: { &quot;kind&quot;: &quot;Write&quot;, # kind of action, like write or run &quot;name&quot;: { # name of the action, for user display. Unique within the execution of a particular target &quot;category&quot;: &quot;write&quot;, # category for the action &quot;identifier&quot;: &quot;my_output&quot; # identifier for the action }, &quot;duration_millis&quot;: 0, # duration of the action in millis, excluding input materialization time &quot;output_size&quot;: 10, # size in bytes of the action's outputs &quot;input_materialization_duration_millis&quot;: 0, # how long it took to materialize any inputs to the action &quot;execution_kind&quot;: &quot;Simple&quot;, # how the action was executed &quot;owner&quot;: &quot;cell//path/to/script.bxl:function_name&quot; # owner of the action execution (target label, anon target label, bxl label) }, &quot;epoch_millis&quot;: 123456789 # when the event was emitted }  execution_kind includes: Local: action was executed locallyRemote: action was executed via a remote executorActionCache: action was served by the action cache and not executedSimple: action is simple and executed inline within buck2 (ex: write, symlink_dir)Skipped: action was not executed at allDeferred: action logically executed, but didn't do all the workLocalDepFile: action was served by the local dep file cache and not executed.LocalWorker: action was executed via a local workerNotSet: action execution kind was not set Ensure artifact event { &quot;BxlEnsureArtifactsEvent&quot;: { &quot;duration_millis&quot;: 0, # duration of ensuring the artifact }, &quot;epoch_millis&quot;: 123456789 # when the event was emitted }  "},{"title":"BXL Testimonials","type":0,"sectionRef":"#","url":"/docs/developers/bxl_testimonials/","content":"","keywords":""},{"title":"C++ LSP​","type":1,"pageTitle":"BXL Testimonials","url":"/docs/developers/bxl_testimonials/#c-lsp","content":"&quot;On top of the 2x performance improvement we already have with buck1 -&gt; buck2, BXL brought another 3x ~ 4x improvement. With those added together, generating compilation database in Buck2 will be 6x ~ 8x faster than Buck1.&quot; "},{"title":"XCode project generation​","type":1,"pageTitle":"BXL Testimonials","url":"/docs/developers/bxl_testimonials/#xcode-project-generation","content":"&quot;It’s faster and much easier to work with than the equivalent stack in Python. In Python, we’d have to issue a query, parse the output into BuildTarget objects, process them, perform additional queries or build targets/subtargets, etc. Doing the equivalent in BXL removed a lot of inefficiencies and made working with configured targets much easier.&quot; "},{"title":"Rust Analyzer:​","type":1,"pageTitle":"BXL Testimonials","url":"/docs/developers/bxl_testimonials/#rust-analyzer","content":"&quot;It was my first time using BXL, and it allowed me to get rid of about 800 lines of Rust code and replace it with about 60 lines of BXL. It's really handy.&quot; "},{"title":"Pyre​","type":1,"pageTitle":"BXL Testimonials","url":"/docs/developers/bxl_testimonials/#pyre","content":"&quot;We found that our new BXL-based Buck-invoking logic outperformed its predecessor significantly, especially on incremental checks. P95 of Buck build time during Pyre incremental check is reduced by 95.7% for FBCode overall, after the release of the new logic, going from 332 seconds down to 14.3 seconds. That is a ~23x speed improvement! As a result, P95 of the overall time it takes for Pyre to respond after each incremental file save in FBCode has dropped from 193ms to 28ms.&quot; "},{"title":"Why BXL","type":0,"sectionRef":"#","url":"/docs/developers/bxl/","content":"","keywords":""},{"title":"Buck2 Extension Language (BXL)​","type":1,"pageTitle":"Why BXL","url":"/docs/developers/bxl/#buck2-extension-language-bxl","content":"BXL is a Starlark-based script that enables integrators to inspect and interact with the Buck2 graph. Integrators are able to: Write Starlark code that queries, analyzes and builds the Buck2 graph.Interact with the Buck2 graph structures natively, via Starlark, in a safe, controlled manner. "},{"title":"Buck 2 specific options","type":0,"sectionRef":"#","url":"/docs/developers/options/","content":"Buck 2 specific options Buck 2 introduces some options that don't exist in v1 and are accessed in the root cell: project.watchman_merge_base: defines the merge base to use for SCM-aware queries to Watchman. This is read when the daemon starts and cannot be changed later without a restart.test.v2_test_executor: defines the program to invoke as the test executor in buck test. This is read every time a test command executes.","keywords":""},{"title":"Parity Testing","type":0,"sectionRef":"#","url":"/docs/developers/parity_script/","content":"","keywords":""},{"title":"Overview​","type":1,"pageTitle":"Parity Testing","url":"/docs/developers/parity_script/#overview","content":"The buck_replay script is meant to test parity between v1 and v2 implementations of commands by querying for logs of the repo and execution state (args, directory) of v2 command invocations, reproducing it locally, making the necessary conversions from v2 to v1 args, and then running both versions of the command so output can be checked/compared. When output differs/parity testing fails, the results are logged into a Scuba table for future reference/analysis. "},{"title":"Flags​","type":1,"pageTitle":"Parity Testing","url":"/docs/developers/parity_script/#flags","content":"The following is a list of arguments/flags currently supported by the list: --verbose - supplying this turns on debug logging. By default, the replay script logs updates on script progress and any errors that happen. When --verbose is given, debug logging will also provide updates on commit and directory changes while parity testing.--dry-run - toggles logging to a test Scuba table instead of the production one. Useful if you're making edits/testing the script itself.--epoch - the time after which to query Scuba for logs of commands for, as a Unix timestamp. If not supplied, it defaults to the last 24 hours.--limit - limits the number of rows queried from Scuba. The default limit is 100000 rows. "},{"title":"Running the script​","type":1,"pageTitle":"Parity Testing","url":"/docs/developers/parity_script/#running-the-script","content":"The script can be run with buck: buck run //buck2/scripts/buck_replay:buck_replay  Example with flags: buck run //buck2/scripts/buck_replay:buck_replay -- --verbose --dry-run --epoch 1626739329 --limit 100000  "},{"title":"Development​","type":1,"pageTitle":"Parity Testing","url":"/docs/developers/parity_script/#development","content":"The script does not yet support commands beyond audit config. Because of differences in flags (different names, new/dropped flags, and so on) in v1 and v2 implementations of commands, there needs to be some conversion when going from one set of arguments to the other. As such, support for a command requires the implementation of a Command class for that command, and with it, several methods: format_common_args, format_args_v1, format_args_v2 - to format the flags/arguments in common between the v1 and v2 versions of a command as well as the ones specific to v1 and v2, respectively.run_v1 and run_v2 - meant to run the v1 and v2 commands and capture the relevant output.test_parity - meant to compare the output the v1 and v2 outputs (note that the standard for what's &quot;equal&quot; may change between commands) and log whatever is necessary. You can also work on features surrounding the replay script; specifically, adding logging to more commands (since in v2 only audit config logging is supported) and Ingress tailer support (currently command logging is handled by CommandReporterProcessor). "},{"title":"Request for Comments","type":0,"sectionRef":"#","url":"/docs/developers/request_for_comments/","content":"","keywords":""},{"title":"Drafts​","type":1,"pageTitle":"Request for Comments","url":"/docs/developers/request_for_comments/#drafts","content":"@configuration syntaxbxl actions and Build APIDigest Kinds "},{"title":"Accepted​","type":1,"pageTitle":"Request for Comments","url":"/docs/developers/request_for_comments/#accepted","content":"configured_aliasBuck Extension Language (BXL)Bxl Support for performing analysis on targetsPackage-local values "},{"title":"Implemented​","type":1,"pageTitle":"Request for Comments","url":"/docs/developers/request_for_comments/#implemented","content":"ProviderCollection[] "},{"title":"Environments","type":0,"sectionRef":"#","url":"/docs/developers/starlark/environment/","content":"","keywords":""},{"title":"Global Environment​","type":1,"pageTitle":"Environments","url":"/docs/developers/starlark/environment/#global-environment","content":"The global environment is always frozen and consists of functions and type-values. All things in the global environment are accessed by name. Type-values are things like list.append, which is used when you do either list.append(xs, 1) or xs.append(1), assuming xs is of type list. The available methods for a type can be queried (for example, dir(list)). There are also global functions, such as len, range, and str. "},{"title":"Slots​","type":1,"pageTitle":"Environments","url":"/docs/developers/starlark/environment/#slots","content":"To optimise evaluation, all variables are accessed by integers, which are known as 'slots'. Many variables can be converted to slots statically during compilation, and those which can't have their slot looked up by name at runtime. The Slots data type is defined as: enum Slots { Frozen(FrozenSlots), Slots(Rc&lt;RefCell&lt;Vec&lt;Option&lt;Value&gt;&gt;&gt;&gt;), } struct FrozenSlots(Arc&lt;Vec&lt;Option&lt;FrozenValue&gt;&gt;&gt;);  As featured in the above code: A set of slots are either Frozen, which came from another module behind Arc or just normal Slots, which can be manipulated by the current scope (behind a Rc/RefCell for single-threaded use and mutation).Vec is accessed by the slot index.Option refers to whether the slot has been assigned yet (to detect variables referenced before assignment). "},{"title":"Module Environment​","type":1,"pageTitle":"Environments","url":"/docs/developers/starlark/environment/#module-environment","content":"The module environment is where the module executes, namely where x is defined above. The module environment can have values added in the following standards-conforming ways: Assignment statements (such as x = 1 or x += 1).For loops (such as the x in for x in []:).Via the load(&quot;a.bzl&quot;, &quot;foo&quot;), which imports foo frozen.Via def foo():, which defines foo in the module environment. Whether a def is frozen or not, when it's executed, its local variables are not frozen. In addition, two non-standards-conforming ways of defining variables are supported: Some modules can be injected as bindings in advance. Given a module foo that is injected, all the bindings of foo will be inserted in this module as frozen.The function load_symbols injects a dictionary of bindings into the module environment. Note that a module has a fixed set of variables (from the standards-conforming ways), a pre-execution set (from the injections) and yet more variables at runtime (via load_symbols). To support that structure, the mapping from name to slot index is tracked in a struct: enum Names { Frozen(FrozenNames), Names(Rc&lt;RefCell&lt;HashMap&lt;String, usize&gt;&gt;&gt;), } struct FrozenNames(Arc&lt;HashMap&lt;String, usize&gt;&gt;);  Each name is given an entry in the map with an increasing slot index. A name will only be assigned a slot once, reusing it thereafter. A corresponding Slots data type provides the values associated with those names. Importantly, the Slots can be extended at runtime by the load_symbols function. As with Slots, you can either share things behind an Arc or mutate them behind an Rc/RefCell. "},{"title":"Function Environment​","type":1,"pageTitle":"Environments","url":"/docs/developers/starlark/environment/#function-environment","content":"A function can have variables introduced via assignments, for loops, and parameters. No additional variables can be discovered at runtime, so all names can be erased at compile time. A function can also access variables from the functions it is statically nested within, and from the variables at the root of the module. To support this structure, at runtime we pass around the context, defined as: struct Context { names: Names, slots: Vec&lt;Slots&gt;, }  The above code contains the mapping of names for the module and the slots for the module and each function. When executed, the inner-most Slots (at the end of slots:) will never be frozen, as that represents the local variables: but any other may be. When a function value is captured in a frozen module, use FrozenContext: struct FrozenContext { names: FrozenNames, slots: Vec&lt;FrozenSlots&gt;, } ## List comprehension environments A list comprehension can be defined as: ```python [x for x in [1,2,3]]  In the above code: The statement defines a variable x that is immediately initialised and shadows any other variables x in scope.The variable x cannot be assigned to, other than in the list comprehension, as it only lives inside the comprehension and the comprehension does not permit assignment statements (only expressions). Such names are not available at the top-level, even when defined in the root of a module. List comprehensions are implemented by adding additional entries into the Slots data type. Even when added at the root of a module, such names are not added to Names. "},{"title":"Optimisations​","type":1,"pageTitle":"Environments","url":"/docs/developers/starlark/environment/#optimisations","content":"There are a number of optimisations made to the scheme: When freezing a Names or Slots structure, it's important to only freeze a particular mutable variant once, or you duplicate memory unnecessarily. Therefore, the Slots to be Rc&lt;RefCell&lt;(_, Option&lt;FrozenSlots&gt;)&gt;&gt; are augmented, and, similarly, the Names. When freeze is called, the original value is consumed, and the Some variant is added.Note: it is unsafe to ever access the slots after the freeze. Programs can only assign to the inner-most Slots, and that slots must always be mutable. Therefore, define a local Slots that is always mutable, and a separate AST node for referring to it. For modules, it is important that this mutable local Slots is also in scope since the scope is used to retrieve unknown variables. "},{"title":"A Moving Garbage Collector","type":0,"sectionRef":"#","url":"/docs/developers/starlark/gc/","content":"","keywords":""},{"title":"A worked example​","type":1,"pageTitle":"A Moving Garbage Collector","url":"/docs/developers/starlark/gc/#a-worked-example","content":"Given a heap with the following layout: X := Data(&quot;world&quot;) Y := Data(&quot;hello&quot;, X, Y) Z := Data(&quot;universe&quot;)  All of X, Y and Z are memory locations. The Y memory location has both some data of its own (&quot;hello&quot;) and two pointers (X and Y itself). The pointers from outside the heap into the heap are known as roots. Assuming, in the above example, that Y is the only root, then, since Y is used from outside, Y must be moved to the new memory block. Consequently, the data X needs to be copied, but Z can be dropped. Following are the required steps for using a garbage collector: To copy Y, allocate a value in the new heap A with a sentinel value in it (that that sentinel is called a Blackhole). Then, turn Y into a Forward(A) pointer, so that if anyone else in this cycle tries to collect Y they immediately &quot;forward&quot; to the new value and the data from Y is grabbed so its pointers can be traversed. That results in the following: X := Data(&quot;world&quot;) Y := Forward(A) Z := Data(&quot;universe&quot;) A := Blackhole With Data(&quot;hello&quot;, X, Y) as the current item being processed. Walk the pointers of the current value, performing a garbage collection on each of them. To copy Y, it can be seen that Y points at a Forward(A) node, so there's no need to do anything. To copy X, follow the process starting at step 1, but for X (which ends up at B). Performing that move leads to the following: X := Forward(B) Y := Forward(A) Z := Data(&quot;universe&quot;) A := Blackhole B := Data(&quot;world&quot;) Replace all the pointers with the forwarded value, and write it back over the Blackhole in A. This gives the following: X := Forward(B) Y := Forward(A) Z := Data(&quot;universe&quot;) A := Data(&quot;hello&quot;, B, A) B := Data(&quot;world&quot;) Adjust any roots pointing at Y to point at A and throw away the original heap, which produces the following: A := Data(&quot;hello&quot;, B, A) B := Data(&quot;world&quot;)  These above four steps successfully garbage collects a cyclic data structure, while preserving the cycles and getting rid of the unused data. "},{"title":"Heaps and Heap References","type":0,"sectionRef":"#","url":"/docs/developers/starlark/heaps/","content":"","keywords":""},{"title":"Heaps​","type":1,"pageTitle":"Heaps and Heap References","url":"/docs/developers/starlark/heaps/#heaps","content":"In Starlark, there are three interesting heap-related points of interest: A Heap has Value's allocated on it and cannot be cloned or shared.A FrozenHeap has FrozenValue's allocated on it and cannot be cloned or shared.A FrozenHeapRef is a FrozenHeap that is now read-only and can now be cloned and shared. A FrozenHeapRef keeps a heap alive. While you have a FrozenValue, it is important that you have either the FrozenHeap itself, or more usually, a FrozenHeapRef to it. A FrozenHeap may contains a set of FrozenHeapRef's to keep the FrozenHeaps it references alive. "},{"title":"Heap Containers​","type":1,"pageTitle":"Heaps and Heap References","url":"/docs/developers/starlark/heaps/#heap-containers","content":"Heaps are included in other data types: A Module contains a Heap (where normal values are allocated) and a FrozenHeap (stores references to other frozen heaps and has compilation constants allocated on it). The Heap portion is garbage collected. At the end, when you call freeze, Value's referenced by name in the Module are moved to the FrozenHeap and then then FrozenHeap is sealed to produce a FrozenHeapRef.A FrozenModule contains a FrozenHeapRef.A GlobalsBuilder contains a FrozenHeap onto which values are allocated.A Globals contains a FrozenHeapRef. "},{"title":"Heap References​","type":1,"pageTitle":"Heaps and Heap References","url":"/docs/developers/starlark/heaps/#heap-references","content":"It is important that when a FrozenValue X is referenced by a Value or FrozenValue (for example, included in a list), the heap where X originates is added as a reference to the heap where the new value is being created. As a concrete example in pseudo-code: let h1 = FrozenHeap::new(); let s = &quot;test&quot;.alloc(h1); let h1 : FrozenHeapRef = h1.into_ref(); let h2 = Heap::new(); h2.add_reference(h1); vec![s].alloc(h2);  In the above code, the following steps are taken: Create a FrozenHeap then allocate something in it.Turn the heap into a reference.Use the allocated value s from h1 when constructing a value in h2.For that to be legal, and for the heap h1 to not disappear while it is being allocated, it is important to call add_reference. Note that this API can only point at a FrozenValue from another heap, and only after that heap has been turned into a reference, so it will not be allocated in anymore. These restrictions are deliberate and mean that most programs only have one 'active heap' at a time. Following are some places where heap references are added by Starlark: Before evaluation is started, a reference is added to the Globals from the Module, so it can access the global functions.When evaluating a load statement, a reference is added to the FrozenModule that is being loaded.When freezing a module, the FrozenHeap, in the Module, is moved to the FrozenModule, preserving the references that were added. "},{"title":"OwnedFrozenValue​","type":1,"pageTitle":"Heaps and Heap References","url":"/docs/developers/starlark/heaps/#ownedfrozenvalue","content":"When you get a value from a FrozenModule, it will be a OwnedFrozenValue. This structure is a pair of a FrozenHeapRef and a FrozenValue, where the ref keeps the value alive. You can move that OwnedFrozenValue into the value of a module with code such as: fn move&lt;'v&gt;(from: &amp;FrozenModule, to: &amp;'v Module) { let x : OwnedFrozenValue = from.get(&quot;value&quot;).unwrap(); let v : Value&lt;'v&gt; = x.owned_value(&amp;to); to.set(&quot;value&quot;, v); }  In general, you can use the OwnedFrozenValue in one of three ways: Operate on it directly - with methods like unpack_int or to_str.Extract it safely - using methods like owned_frozen_value, which takes a FrozenHeap to which the heap reference is added and returns a naked FrozenValue. After that, it is then safe for the FrozenHeap you passed in to use the FrozenValue. With owned_value, there is lifetime checking that the right heap is passed, but with FrozenValue, there isn't.Be careful to pass the right heap, although given most programs only have one active heap at a time, it should mostly work out. Extract it unsafely - using methods unchecked_frozen_value, which gives you the underlying FrozenValue without adding any references. Be careful to make sure there is a good reason the FrozenValue remains valid. "},{"title":"Starlark Language Specification","type":0,"sectionRef":"#","url":"/docs/developers/starlark/spec/","content":"Starlark Language Specification The Starlark language spec can be found in the Bazel GitHub repository.","keywords":""},{"title":"Starlark Types","type":0,"sectionRef":"#","url":"/docs/developers/starlark/types/","content":"","keywords":""},{"title":"What does a type mean?​","type":1,"pageTitle":"Starlark Types","url":"/docs/developers/starlark/types/#what-does-a-type-mean","content":"A type is just an arbitrary expression that evaluates to a value; that value is then treated as a type, which is matched against values: When fib(3) is called, the value 3 is passed to fib as parameter i.When the execution of fib is started, the expression int.type is evaluated to &quot;int&quot;.A check is then made that the value 3 matches the type represented by &quot;int&quot;. If the value doesn't match, it is a runtime error. Similarly, on return statements, or the end of the function, a check is made that result type matches int.type. Types match using the following rules: The type &quot;&quot; means anything.The type &quot;foo&quot; means any value of type foo, where the type of x is computed by doing type(x). That means that &quot;int&quot;, &quot;bool&quot; and &quot;string&quot; are common types.Most constructor functions provide a .type property to obtain the type they produce, allowing int.type, bool.type and str.type etc.Any string starting with an underscore _ (for example, &quot;_a&quot; means anything) but the name is often used as a hint to say where types go in polymorphic functions.The type None means the result must be None.The singleton list [t] means a list where each element must be of type t. If you want a list of any types, use [&quot;&quot;].Multiple element lists [t1,t2] are OR types, where the value must be either type t1 OR type t2.A tuple (t1, t2, t3) matches tuples of the same length (3 in this case), where each element of the value must match the corresponding element of the tuple.A singleton dictionary {k: v} means a dictionary where all the keys have type k, and all the values have type v.It is possible to define functions that return types. For example, def StrDict(t): return {str.type: t} would mean StrDict(int.type) was a valid type. The goals of this type system are: Reuse the existing machinery of Starlark as much as possible, avoiding inventing a special class of type values. As a consequence, any optimisations for values like string/list are reused.Provide a pleasing syntax.Some degree of compatibility with Python, which allows types as expressions in the same places Buck2 allows them (but with different meaning and different checking).And finally, a non-goal is to provide a complete type system capable of representing every type invariant: it's intended to be a lossy approximation. In addition to these built-in types, records and enumerations are provided as special concepts. "},{"title":"Record types​","type":1,"pageTitle":"Starlark Types","url":"/docs/developers/starlark/types/#record-types","content":"A record type represents a set of named values, each with their own type. For example: MyRecord = record(host=str.type, port=int.type)  This above statement defines a record MyRecord with 2 fields, the first named host that must be of type str.type, and the second named port that must be of type int.type. Now MyRecord is defined, it's possible to do the following: Create values of this type with MyRecord(host=&quot;localhost&quot;, port=80). It is a runtime error if any arguments are missed, of the wrong type, or if any unexpected arguments are given.Get the type of the record suitable for a type annotation with MyRecord.type.Get the fields of the record. For example, v = MyRecord(host=&quot;localhost&quot;, port=80) will provide v.host == &quot;localhost&quot; and v.port == 80. Similarly, dir(v) == [&quot;host&quot;, &quot;port&quot;]. It is also possible to specify default values for parameters using the field function. For example: MyRecord = record(host=str.type, port=field(int.type, 80))  Now the port field can be omitted, defaulting to 80 is not present (for example, MyRecord(host=&quot;localhost&quot;).port == 80). Records are stored deduplicating their field names, making them more memory efficient than dictionaries. "},{"title":"Enum types​","type":1,"pageTitle":"Starlark Types","url":"/docs/developers/starlark/types/#enum-types","content":"The enum type represents one value picked from a set of values. For example: MyEnum = enum(&quot;option1&quot;, &quot;option2&quot;, True)  This statement defines an enumeration MyEnum that consists of the three values &quot;option1&quot;, &quot;option2&quot; and True. Now MyEnum is defined, it's possible to do the following: Create values of this type with MyEnum(&quot;option2&quot;). It is a runtime error if the argument is not one of the predeclared values of the enumeration.Get the type of the enum suitable for a type annotation with MyEnum.type.Given a value of the enum (for example, v = MyEnum(&quot;option2&quot;)), get the underlying value v.value == &quot;option2&quot; or the index in the enumeration v.index = 1.Get a list of the values that make up the array with MyEnum.values() == [&quot;option1&quot;, &quot;option2&quot;, True].Treat MyEnum a bit like an array, with len(MyEnum) == 3, MyEnum[1] == MyEnum(&quot;option2&quot;) and iteration over enums [x.value for x in MyEnum] == [&quot;option1&quot;, &quot;option2&quot;, True]. Enumeration types store each value once, which are then efficiently referenced by enumeration values. "},{"title":"Value Representation","type":0,"sectionRef":"#","url":"/docs/developers/starlark/values/","content":"","keywords":""},{"title":"Frozen vs unfrozen values​","type":1,"pageTitle":"Value Representation","url":"/docs/developers/starlark/values/#frozen-vs-unfrozen-values","content":"Values that are frozen are segregated from those that are not: Frozen values are those you import, and (assuming no GC) are to be ref-counted atomically (so they can be shared by multiple threads) and never changed.Unfrozen values are those which are local to the module, and, since modules execute single threaded, can be non-atomically ref-counted and mutated. Once a module has finished executing, it's values are frozen and can be reused freely. "},{"title":"Thaw-on-write​","type":1,"pageTitle":"Value Representation","url":"/docs/developers/starlark/values/#thaw-on-write","content":"It's not uncommon to return list literals from functions. For example: def my_list(x): return ([1,2,3], x)  This above code returns the unfrozen list [1,2,3]. But while the list is unfrozen, and could be mutated by the caller, it probably won't be. To optimise this pattern, construct a frozen list when compiling my_list and insert a shared reference to it in the result. If anyone tries to mutate the list, it's explicitly unfrozen by copying it into a mutable variant (known as thawing the value). "},{"title":"Immutable containers of mutable data​","type":1,"pageTitle":"Value Representation","url":"/docs/developers/starlark/values/#immutable-containers-of-mutable-data","content":"There are some data types (such as functions and tuples) that are themselves immutable but contain mutable data. Importantly, all types that can be invoked as functions (for example, lambda, def, and a.b()) fall into this category. These types can be non-atomically ref-counted but can't be mutated. "},{"title":"Implementation in Rust​","type":1,"pageTitle":"Value Representation","url":"/docs/developers/starlark/values/#implementation-in-rust","content":"Putting all these above concepts together results in the following: enum FrozenValue { None(NoneType), Bool(bool), Int(i64), Obj(Arc&lt;dyn StarlarkValue&gt;), } enum Value { Immutable(FrozenValue), Pseudo(Rc&lt;dyn ComplexValue&gt;) Mutable(Rc&lt;RefCell&lt;Mutable&gt;&gt;), } enum Mutable { Mutable(Box&lt;dyn ComplexValue&gt;), ThawOnWrite(Arc&lt;dyn StarlarkValue&gt;), }  In the above code, both of the traits dyn SimpleValue and dyn ComplexValue enable you to convert to the other and have shared general value-like methods. There are four types of value: ImmutablePseudo - immutable containers of mutable values.Mutable/MutableMutable/ThawOnWrite - immutable now but can be replaced with Mutable/Mutable if needed. There are two root types: FrozenValue - imported.Value - defined locally. "},{"title":"Finding Commands That Buck2 Ran","type":0,"sectionRef":"#","url":"/docs/developers/what-ran/","content":"","keywords":""},{"title":"What Ran output format​","type":1,"pageTitle":"Finding Commands That Buck2 Ran","url":"/docs/developers/what-ran/#what-ran-output-format","content":"This will output a table showing all the commands that were executed, and how they were executed. The structure is as follows: REASON &lt;TAB&gt; TARGET &lt;TAB&gt; IDENTIFIER &lt;TAB&gt; EXECUTOR &lt;TAB&gt; REPRODUCER  Which should be used as follows: REASON - value is either build (for building a thing) or test (for running a test).TARGET - the name of the build target that declared an action.IDENTIFIER - depends on the target but will usually be something like a file name or a module.EXECUTOR - value is either cache, re or local.REPRODUCER - how you can re-run this yourself. "},{"title":"Using the What Ran output​","type":1,"pageTitle":"Finding Commands That Buck2 Ran","url":"/docs/developers/what-ran/#using-the-what-ran-output","content":"Use What Ran as follows: Start by identifying the command you're looking for: You can grep the output for a given target.You can then grep by identifier if necessary. For example, if you're after C++ compilation, try grepping for the basename of your file (for example, for fbcode/my/stuff.cpp, grep for stuff.cpp). Once you found it, reproduce as follows: If the executor was local, the command is in the output, so just run it. It's expected that you'll do this from the root of your project (use buck2 root --kind project to find where that is).If the executor was re or cache, you're provided a RE digest of the form HASH:SIZE. Run frecli cas download-action HASH:SIZE to retrieve the action, then follow the instructions to run it. "},{"title":"Examples​","type":1,"pageTitle":"Finding Commands That Buck2 Ran","url":"/docs/developers/what-ran/#examples","content":"The following ran locally: build fbcode//scripts/torozco/getenv:getenv-san-conf-__generated-lib__ (archive_thin libgetenv-san-conf-__generated-lib__.pic.a) local fbcode/third-party-buck/platform010/build/llvm-fb/bin/llvm-ar qcsTD buck-out/v2/gen/fbcode/d839c731f5505c62/scripts/torozco/getenv/__getenv-san-conf-__generated-lib____/libgetenv-san-conf-__generated-lib__.pic.a buck-out/v2/gen/fbcode/d839c731f5505c62/scripts/torozco/getenv/__getenv-san-conf-__generated-lib____/__objects__/san-conf.c.pic.o  To repro, you'd run: fbcode/third-party-buck/platform010/build/llvm-fb/bin/llvm-ar qcsTD buck-out/v2/gen/fbcode/d839c731f5505c62/scripts/torozco/getenv/__getenv-san-conf-__generated-lib____/libgetenv-san-conf-__generated-lib__.pic.a buck-out/v2/gen/fbcode/d839c731f5505c62/scripts/torozco/getenv/__getenv-san-conf-__generated-lib____/__objects__/san-conf.c.pic.  The following ran on RE: build fbcode//common/init:kill (cxx_compile Kill.cpp (pic)) re 97feca9d014155a80ec55fe27e6bb17f9d2f8574:94  To repro, you'd run: frecli cas download-action 97feca9d014155a80ec55fe27e6bb17f9d2f8574:94  "},{"title":"Expired Digests​","type":1,"pageTitle":"Finding Commands That Buck2 Ran","url":"/docs/developers/what-ran/#expired-digests","content":"Note that if the action was a cache hit on RE, you might get an error when downloading it, indicating that it's not found. If that happens, it's because the cache entry is there but the inputs have expired. If this happens to you, run your build with --upload-all-actions. "},{"title":"Windows Cheat Sheet","type":0,"sectionRef":"#","url":"/docs/developers/windows_cheat_sheet/","content":"","keywords":""},{"title":"CMD, Powershell, Bash Command Comparison​","type":1,"pageTitle":"Windows Cheat Sheet","url":"/docs/developers/windows_cheat_sheet/#cmd-powershell-bash-command-comparison","content":"Bash\tPowershell\tCMD\tWhat does it docd\tcd\tcd\tChange the current directory mkdir\tmkdir\tmkdir / md\tCreate a directory ls\tls\tdir\tList contents of a directory export var=&quot;value&quot;\t$env:var=&quot;value&quot;\tset var=value\tTo set environment variables $ENV_VAR\t$env:ENV_VAR\t%ENV_VAR%\tRead environment variable echo &quot;Hello world&quot;\techo &quot;Hello world&quot;\techo Hello world\tTo print something on the screen rm\trm\tdel\tDelete a file rm -rf\trmdir\trmdir\tDelete a directory cat\tcat\ttype\tPrint file content to console "},{"title":"Symlinks​","type":1,"pageTitle":"Windows Cheat Sheet","url":"/docs/developers/windows_cheat_sheet/#symlinks","content":"In Windows, there are two types of symlinks: file and directory. You can find out which type of symlink is being created using: dir /AL /S &lt;path&gt;. The command lists all of the symbolic links in the &lt;path&gt; directory: ^&lt;SYMLINKD^&gt; is a Directory SymLink^&lt;SYMLINK^&gt; is a File SymLink "},{"title":"Target names​","type":1,"pageTitle":"Windows Cheat Sheet","url":"/docs/developers/windows_cheat_sheet/#target-names","content":"Escaping the '=' symbol on Windows is quite complicated: make sure none of the targets being built contain this symbol as it could cause build breakages. "},{"title":"Getting Started","type":0,"sectionRef":"#","url":"/docs/getting_started/","content":"","keywords":""},{"title":"Installing Buck2​","type":1,"pageTitle":"Getting Started","url":"/docs/getting_started/#installing-buck2","content":"The latest set of buck2 executables can be found under the latest release page. To get started, first install rustup, then compile the buck2 executable: rustup install nightly-2023-05-28 cargo +nightly-2023-05-28 install --git https://github.com/facebook/buck2.git buck2  The above commands install buck2 into a suitable directory, such as $HOME/.cargo/bin, which you should then add to your $PATH: Linux / macOS export PATH=$HOME/.cargo/bin:$PATH  Windows Powershell $Env:PATH += &quot;;$HOME\\.cargo\\bin&quot;  With Buck2 installed, you can build projects with buck2! "},{"title":"Windows configuration​","type":1,"pageTitle":"Getting Started","url":"/docs/getting_started/#windows-configuration","content":"Some of our rules use symlinks, which are disabled by default for non-admin Windows users. You can fix that by enabling Developer Mode. "},{"title":"Compiling your first project​","type":1,"pageTitle":"Getting Started","url":"/docs/getting_started/#compiling-your-first-project","content":"This section covers the building of a 'hello_world' example project that contains a simple C++ binary. If you are interested in seeing how other languages can be built, take a look at the prelude example project, which contains Rust, C++, Python, and OCaml targets. First, clone the buck2 repository and cd into the 'hello_world' project: git clone https://github.com/facebookincubator/buck2.git cd buck2/examples/hello_world  buck2 init --git is all the setup you need to start building. This will use git submodule to pull buck2-prelude into your project: buck2 init --git  To use another version control system, run buck2 init and manually download buck2-prelude into prelude at root. buck2 init  To build the entire project, run: Note: Requires clang and lld to be in the path buck2 build //...  Note that this uses a simple C++ toolchain that requires a recent version of clang to be installed on your system. This can be installed with any package manager (ex. apt install clang, xcode-select --install on macOS, choco install llvm). After installing any external tools or changing your PATH, run buck2 kill before running a build. To list all targets available in the project, run: buck2 targets //...  To run the main C++ binary, run: buck2 run //:main  The newly built binary can be found with the --show-output flag: buck2 build //:main --show-output  Output: Build ID: 0e890477-5b7f-4829-9ffe-662e572320a0 Jobs completed: 3. Time elapsed: 0.0s. BUILD SUCCEEDED root//:main buck-out/v2/gen/root/9f4d83578bb24895/__main__/main  "},{"title":"Creating your first hello_world project​","type":1,"pageTitle":"Getting Started","url":"/docs/getting_started/#creating-your-first-hello_world-project","content":"This section demonstrates how to create a simple C++ 'hello_world' project. To get started, make a new folder for your project and cd into it. mkdir hello_world cd hello_world  Next, run buck2 init --git to initialize the project. This command will set up your project with git and pull in buck2-prelude as a submodule. Additionally, it will generate multiple files with default values. buck2 init --git  Next, add the source code main.cpp , #include &lt;iostream&gt; int main() { std::cout &lt;&lt; &quot;Hello from a C++ Buck2 program!&quot; &lt;&lt; std::endl; }  Then, define a cxx_binary in the root BUCK file: # BUCK cxx_binary( name = &quot;main&quot;, srcs = [&quot;main.cpp&quot;], link_style = &quot;static&quot;, )  If you try to build //:main at this point, you'll see an error about buck2 not being able to find toolchains//:cxx. The final step is to define the necessary toolchain targets. For that project, you need system_cxx_toolchain and system_python_bootstrap_toolchain, which will pick up the necessary tools (clang++, python, and so on) from the system. # toolchains/BUCK load(&quot;@prelude//toolchains:cxx.bzl&quot;, &quot;system_cxx_toolchain&quot;) load(&quot;@prelude//toolchains:python.bzl&quot;, &quot;system_python_bootstrap_toolchain&quot;) system_cxx_toolchain( name = &quot;cxx&quot;, visibility = [&quot;PUBLIC&quot;], ) system_python_bootstrap_toolchain( name = &quot;python_bootstrap&quot;, visibility = [&quot;PUBLIC&quot;], )  At this point, your project should have the following files: $ tree -a -I &quot;buck-out|prelude|.git&quot; |-- .buckconfig |-- .gitmodules |-- BUCK |-- main.cpp `-- toolchains `-- BUCK  Now, you're ready to see the build in action. To build the main C++ target, run: buck2 build //:main  To run the main C++ target, run: buck2 run //:main  In summary, a buck2 project requires: A .buckconfig file in the root which has a [repositories] section listing out cellsA prelude directory, which contains a collection of rules of your choice. buck2 init will pull in the buck2-prelude as a git submodule by defaultIf using the buck2-prelude, a toolchains directory that declares relevant toolchains. We provide some basic toolchains in prelude/toolchainsBUCK files that specify targets for your project buck2 init --git will generate all of these with reasonable default values. "},{"title":"Learning More​","type":1,"pageTitle":"Getting Started","url":"/docs/getting_started/#learning-more","content":"You should now be ready to explore Buck2 for use in your own projects. You can explore the examples folder. Look out for more tutorials in the future. "},{"title":"buck 1 Documentation Import","type":0,"sectionRef":"#","url":"/docs/legacy/","content":"buck 1 Documentation Import This folder contains documentation pulled from the Buck 1 website at https://buck.build/. The folders include the following: ├── README.md ├── about │ ├── faq.md │ ├── fast.md │ ├── performance.md │ └── troubleshooting.md ├── basics │ ├── cheatsheet.md │ ├── getting-started.md │ ├── key-concepts │ └── tutorials.md ├── concepts │ ├── buck-daemon.md │ ├── build-file.md │ ├── build-rule.md │ ├── build-target-pattern.md │ ├── build-target.md │ ├── skylark.md │ └── visibility.md └── files-and-directories ├── buck-out.md └── dot-buckconfig.md Feel free to contact Brian Johnson (brianjo) with any questions for further cleanup of this documentation.","keywords":""},{"title":"FAQ","type":0,"sectionRef":"#","url":"/docs/legacy/about/faq/","content":"FAQ Q: Why is it called Buck?​ A: The word &quot;buck&quot; is similar to the word &quot;build&quot; and is quick to type. It also has awesome mascot potential.","keywords":""},{"title":"What Makes Buck so Fast?","type":0,"sectionRef":"#","url":"/docs/legacy/about/fast/","content":"","keywords":""},{"title":"Buck builds dependencies in parallel​","type":1,"pageTitle":"What Makes Buck so Fast?","url":"/docs/legacy/about/fast/#buck-builds-dependencies-in-parallel","content":"Buck is designed so that any input files required by a build target must be specified in the build rule for that target. Therefore, we can know that the directed acyclic graph (DAG) that Buck constructs from the build rule is an accurate reflection of the build's dependencies, and that once a rule's dependencies are satisfied, the target for that rule can be built. Having a DAG makes it straightforward for rules to be built in parallel, which can dramatically reduce build times. Buck starts with the leaf nodes of the graph, that is, targets that have no dependencies. Buck adds these to a queue of targets to build. When a thread is available, Buck removes a target from the front of the queue and builds it. Assuming the target builds successfully, Buck notifies all of the rules that depend on that target. When all of a rule's dependencies have been satisfied, Buck adds that rule's target to the build queue. Computation proceeds in this manner until all of the nodes in the graph have been built. This execution model means that breaking modules into finer dependencies creates opportunities for increased parallelism, which improves throughput. "},{"title":"Buck uses only first-order dependencies for Java​","type":1,"pageTitle":"What Makes Buck so Fast?","url":"/docs/legacy/about/fast/#buck-uses-only-first-order-dependencies-for-java","content":"When compiling Java, Buck uses first-order dependencies only, that is, dependencies that you specify explicitly in the deps argument of your build rule. This means that the compilation step in your build sees only explicitly-declared dependencies, not other libraries that those dependencies themselves depend on. Using only first-order dependencies dramatically shrinks the set of APIs that your Java code is exposed to, which dramatically reduces the scope of changes that will trigger a rebuild.NOTE: If your rule does, in fact, depend on a dependency of one of your explicitly-specified dependencies—such as a second-order dependency—you can make that dependency available to your rule by specifying it in an exported_deps argument in the rule of the explicitly-specified dependency. "},{"title":"Buck uses dependency files to trim over-specified inputs​","type":1,"pageTitle":"What Makes Buck so Fast?","url":"/docs/legacy/about/fast/#buck-uses-dependency-files-to-trim-over-specified-inputs","content":"Buck's low-level build rules specify all inputs—such as source files or the outputs from other build rules—that might contribute to the output when the build rule is executed. Normally, changes to any of these inputs result in a new RuleKey and therefore trigger a rebuild. However, in practice, it's not uncommon for these build rules to over-specify their inputs. A good example is Buck's C/C++ compilation rules. C/C++ compilation rules specify as inputs all headers found from the transitive closure of C/C++ library dependencies, even though in many cases only a small subset of these headers are actually used. For example, a C/C++ source file might use only one of many headers exported by a C/C++ library dependency. However, there's not enough information available before running the build to know if any given input is used, and so all inputs must be considered, which can lead to unnecessary rebuilding. In some cases, after the build completes, Buck can figure out the exact subset of the listed inputs that were actually used. In C/C++, compilers such as gcc provide a -M option which produces a dependency file. This file identifies the exact headers that were used during compilation. For supported rules, Buck uses this dependency file before the build, to try to avoid an unnecessary rebuilding: If the dependency file is available before the build, Buck reads the file and uses it to filter out unused inputs when constructing the RuleKey.If no dependency file is available before the build, Buck runs the build as normal and produces a dependency file. The dependency file is then available for subsequent builds. Note that dependency files are used only if the standard RuleKey—which considers all inputs—doesn't match. In cases where the RuleKey matches, the output from the rule can be fetched from the cache. "},{"title":"Performance Tuning","type":0,"sectionRef":"#","url":"/docs/legacy/about/performance/","content":"","keywords":""},{"title":"Performance Tuning Your Builds​","type":1,"pageTitle":"Performance Tuning","url":"/docs/legacy/about/performance/#performance-tuning-your-builds","content":"Buck does a lot of work to make builds as fast as possible, and we also give developers tools to figure out where the time is being spent inside of their builds. "},{"title":"Super Console​","type":1,"pageTitle":"Performance Tuning","url":"/docs/legacy/about/performance/#super-console","content":"When running Buck in an Ansi compliant terminal, Buck displays the break down of what each thread is doing, updated every 100ms, in what we affectionately call &quot;SuperConsole.&quot; While a build is running, this gives developers a good idea of what Buck is spending its time doing, and can often help people spot issues in their builds. If you want to see what happened after the fact or to have a trace you can send around your team, use Chrome Tracing. "},{"title":"Chrome Tracing​","type":1,"pageTitle":"Performance Tuning","url":"/docs/legacy/about/performance/#chrome-tracing","content":"The Chrome team has built an awesome framework for viewing performance traces right inside of Chrome. You can access this by going to chrome://tracing in your browser. Consult the trace viewer's project page for more information on the trace viewer and the file format. After Buck is done with each build, it will produce a Chrome Trace file that can be loaded up in chrome://tracing in the directory buck-out/log/traces/. Buck will save a file in the format build.[timestamp].trace, and then create a symlink from the most recent trace to build.trace. To load up this trace, visit chrome://tracing inside of Chrome, and hit &quot;Load&quot;. Load the trace file of interest, and look around to see where time was spent. Each row represents a different thread, and all of the steps taken for a given rule are logged underneath that rule. Additionally, we log information about how the rule was built and and the rule key for each artifact fetch. Press ? to get the help menu for the Chrome Trace Viewer. "},{"title":"Troubleshooting","type":0,"sectionRef":"#","url":"/docs/legacy/about/troubleshooting/","content":"","keywords":""},{"title":"Run buck clean​","type":1,"pageTitle":"Troubleshooting","url":"/docs/legacy/about/troubleshooting/#run-buck-clean","content":"Ideally, this solution will never work. Seriously. If Buck is working correctly, then it should know which files have been modified and which files need to be rebuilt. That said, Buck is not perfect, so it is possible that you have found a defect. In this case, give buck clean a shot and file a bug if you have found a reproducible bug. "},{"title":"Delete all generated files in your project.​","type":1,"pageTitle":"Troubleshooting","url":"/docs/legacy/about/troubleshooting/#delete-all-generated-files-in-your-project","content":"Buck is designed so that all generated files are written to the buck-out directory, which makes buck clean trivial to implement. However, you may use additional tools (such as an IDE) that generate files in other parts of the tree. Such files may inadvertently get included via glob() rules, which would interfere with Buck. For example, if you are using Git, then you can run: git clean -xfdn  to get a list of files in your project that are not under version control. The -n switch is for &quot;dry run,&quot; which means that Git will not delete any files when you run git clean. If you want to use Git to remove the generated files while preserving some non-versioned files (such as .buckconfig.local), then use it with the -e switch: git clean -xfd -e .buckconfig.local  Note that -e can be specified multiple times. "},{"title":"Buck Cheat Sheet","type":0,"sectionRef":"#","url":"/docs/legacy/basics/cheatsheet/","content":"","keywords":""},{"title":"How do I get a list of all the rules that Buck supports, *from the command line*, so that I can process them with** grep, **sed, etc?​","type":1,"pageTitle":"Buck Cheat Sheet","url":"/docs/legacy/basics/cheatsheet/#how-do-i-get-a-list-of-all-the-rules-that-buck-supports-from-the-command-line-so-that-i-can-process-them-with-grep-sed-etc","content":"Use buck audit with the ruletypes (plural) subcommand, which returns an alphabetized list of all the rules that Buck supports. The following command line uses buck audit ruletypes with the grep command to print all the build rules that have the string android in their names. buck audit ruletypes | grep android  Note that these are not all the rules that Buck provides for Android development. For example, the rules apk_genrule and ndk_library support Android development, but do not themselves contain the string android in their names. How do I see the arguments for a rule from the command line? Use buck audit with the ruletype (singular) subcommand followed by the name of the rule. The following command line uses buck audit ruletype to view the arguments supported by the remote_file rule. buck audit ruletype remote_file def remote_file ( name, sha1, url, labels = None, licenses = None, out = None, type = None, ): ...  "},{"title":"How do I find all the targets for a package?​","type":1,"pageTitle":"Buck Cheat Sheet","url":"/docs/legacy/basics/cheatsheet/#how-do-i-find-all-the-targets-for-a-package","content":"Specify a build target pattern that represents the targets in the package. buck query //path/to/dir/...  The buck query command can accept a build target pattern as a parameter. If you specify a build target pattern, Buck evaluates this pattern and shows all the build targets that match it. How do I specify more than one target to** **buck query? Use the buck query set() operator. The following command line returns the target main in the build file in the root of the Buck project and all the targets from the build file in the myclass subdirectory of the root. buck query &quot;set( '//:main' '//myclass:' )&quot;  "},{"title":"How do I get the attribute names and values for the targets returned by a query?​","type":1,"pageTitle":"Buck Cheat Sheet","url":"/docs/legacy/basics/cheatsheet/#how-do-i-get-the-attribute-names-and-values-for-the-targets-returned-by-a-query","content":"Add the --output-attributes option to the command line, followed by regular expressions that represent the attributes of interest. buck query &quot;deps(//foo:bar)&quot; --output-attributes 'name' 'exported_headers'  The --output-attributes option enables you to specify which attributes Buck should return. Instead of returning the names of the targets that match the query expression, Buck returns the names and values of the specified attributes for those targets in JSON format. Attributes are specified as regular expressions. For example, '.*' matches all attributes. See the buck query page for more details. The output for the example query above might look something like the following. {&quot;//foo/bar/lib:lib&quot; : {&quot;exported_headers&quot; : [ &quot;App/util.h&quot; ],&quot;name&quot; : &quot;lib&quot;},&quot;//foo/bar:app&quot; : {&quot;exported_headers&quot; : [ &quot;App/lib.h&quot; ],&quot;name&quot; : &quot;app&quot;}}  "},{"title":"How do I perform a query *inside* of a rule?​","type":1,"pageTitle":"Buck Cheat Sheet","url":"/docs/legacy/basics/cheatsheet/#how-do-i-perform-a-query-inside-of-a-rule","content":"Use string parameter macros, specifically, the query macros: $(query_targets &quot;queryfunction(//:foo)&quot;) $(query_outputs &quot;queryfunction(//:foo)&quot;) $(query_targets_and_outputs [SEPARATOR] &quot;queryfunction(//:foo)&quot;)  Note, however, that the query macros are supported only for genrule and apk_genrule. "},{"title":"How do I find the dependencies for a target?​","type":1,"pageTitle":"Buck Cheat Sheet","url":"/docs/legacy/basics/cheatsheet/#how-do-i-find-the-dependencies-for-a-target","content":"Use the deps() operator. buck query &quot;deps('//foo:bar')&quot; buck query &quot;deps('//foo:bar', 1, first_order_deps())&quot; buck query &quot;deps(set('//foo:bar' '//foo:lib' '//foo/baz:util'))&quot;  The deps operator finds the dependencies of the specified targets. The first argument represents the targets of interest. This can be a single build target or build target pattern, or a set of these. The optional second argument is the depth of the search for dependencies from the specified targets. For example, 1, as shown in the example above, returns only the direct dependencies. If you do not provide this argument, the output is the complete set of transitive dependencies. How do I find the reverse-dependencies for a target, that is, the targets that *depend on* a specified target? Use the buck query rdeps (reverse dependencies) operator. The following example, returns the targets in the transitive closure of //foo:bar that depend directly on //example:baz. buck query &quot;rdeps('//foo:bar', '//example:baz', 1)&quot;  "},{"title":"How do I find the buildfile that contains the target that owns a source file?​","type":1,"pageTitle":"Buck Cheat Sheet","url":"/docs/legacy/basics/cheatsheet/#how-do-i-find-the-buildfile-that-contains-the-target-that-owns-a-source-file","content":"In order to find the build file associated with a source file, combine the owner operator with buildfile. For example, buck query &quot;buildfile(owner('foo/bar/main.cpp'))&quot;  first finds the targets that own foo/bar/main.cpp and then returns the build files, such as foo/bar/BUCK, that define those targets. "},{"title":"Getting Started","type":0,"sectionRef":"#","url":"/docs/legacy/basics/getting-started/","content":"","keywords":""},{"title":"Quick Starts for various target platforms​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#quick-starts-for-various-target-platforms","content":"Platform:\tAndroidiOSJavaOtherDevelopment OS:\tmacOSLinuxWindows While not a prerequisite for installing Buck itself, to build Android applications, you will also need at least the Android SDK and the Android NDK, which can be installed via Homebrew or manually downloaded and installed. The commands in this guide are designed to be copy-pasteable, idempotent, and usable on its representative operating system (macOS, Linux, Windows). Sometimes this results in some unusual constructions (such as using echo instead of vi or Emacs to create a file). Bear in mind that this is a quick start guide, and few things are quicker than copy-and-paste! "},{"title":"Install with Homebrew​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#install-with-homebrew","content":"Buck is available as a bottle on Homebrew. "},{"title":"Prerequisites​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#prerequisites","content":"Command Line ToolsJava Runtime Environment version 11 (support for future versions is in the works) If you have multiple installations of Java on your development computer, you might get warnings from Buck that you are using an unsupported version of Java. To resolve this issue, set the JAVA_HOME environment variable to the directory for version 8 of the Java Development Kit (JDK). Note that the directory that JAVA_HOME points to should contain a bin subdirectory which in turn contains binaries for the Java compiler (javac) and Java runtime (java). # Install command line tools. NOTE: If you have Xcode installed, these may # already be installed. xcode-select --install # Download and Install Java SE 8 from: +# https://www.oracle.com/technetwork/java/javase/downloads/index.html. +# This installs the JDK 8, a superset of the JRE. +# Alternatively, install AdoptOpenJDK 8 with Homebrew: +brew tap AdoptOpenJDK/openjdk +brew install --cask adoptopenjdk8  "},{"title":"Brew install​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#brew-install","content":"You have two choices when using Homebrew. You can choose to get the latest binary release: brew tap facebook/fb brew install buck  Or, you can get the latest code and build it locally: brew update brew tap facebook/fb brew install --HEAD buck  "},{"title":"Build from Source​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#build-from-source","content":""},{"title":"Prerequisites​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#prerequisites-1","content":"To manually build Buck, download and install the following prerequisites: Command Line ToolsOracle Java Development Kit version 8 (support for future versions is in the works)Apache Ant 1.9 (or newer)Python 2.7GitWatchman We strongly recommended that you install Watchman. With watchman, Buck uses a daemon (buckd) which prevents Buck from needing to parse all of your build files every time you build—and it caches some other components of your build as well. You can use Homebrew to install many of the prerequisites on a Mac. # Install Command Line tools first. NOTE: If you have Xcode installed, these may # already be installed. xcode-select --install # Then the JDK (superset of the JRE) brew update brew tap caskroom/cask brew tap caskroom/versions brew cask install java8 # Then... brew install ant python git watchman  "},{"title":"Build​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#build","content":"Once you have the above tools installed, you can build Buck as follows: git clone https://github.com/facebook/buck.git cd buck ant ./bin/buck build --show-output buck buck-out/gen/programs/buck.pex --help  If everything worked correctly, you should see something like: buck build tool usage: buck [options] buck command --help buck command [command-options] available commands: audit lists the inputs for the specified target build builds the specified target cache makes calls to the artifact cache clean deletes any generated files fetch downloads remote resources to your local machine install builds and installs an application kill kill buckd for the current project killall kill all buckd processes project generates project configuration files for an IDE query provides facilities to query information about the configured target nodes graph root prints the absolute path to the root of the current buck project run runs a target as a command server query and control the http server targets prints the list of buildable targets test builds and runs the tests for the specified target uninstall uninstalls an APK uquery provides facilities to query information about the unconfigured target nodes graph options: --help : Shows this screen and exits. --version (-V) : Show version number.  Because you will likely be running ./bin/buck often, you should add it to your path so that you can simply run buck from the command line. "},{"title":"Set Location of Android SDK and NDK​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#set-location-of-android-sdk-and-ndk","content":"You will need to tell Buck where to find the Android SDK and NDK. To find the location of the Android SDK, Buck looks at the following values in the following order: ANDROID_SDK environment variableANDROID_HOME environment variableANDROID_SDK_ROOT environment variableThe value of the [android].sdk_path property in .buckconfig. To find the location of a specific NDK, Buck looks at the following values in the following order: ANDROID_NDK environment variable.NDK_HOME environment variable.The value of the [ndk].ndk_path property in .buckconfig. If you have multiple NDKs installed into a single enclosing directory, you can specify this directory to Buck using either of the following values: ANDROID_NDK_REPOSITORY environment variable.The [ndk].ndk_repository_path property in .buckconfig. If you specify both the environment variable and the .buckconfig setting, the environment variable takes precedence. If you specify an NDK repository, Buck selects the NDK based on the version that you specify in the [ndk].ndk_version property of .buckconfig. "},{"title":"Trying Buck​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#trying-buck","content":"Now that Buck is installed, it is time to use Buck in a sample project. "},{"title":"Clone Buck samples repo​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#clone-buck-samples-repo","content":"git clone https://github.com/fbsamples/bucksamples.git cd bucksamples/cross-platform-scale-2015-demo/  "},{"title":"Key Android Files​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#key-android-files","content":"This sample app has all the files necessary to use Buck to build an Android project. From the root directory, you will find: android/java/com/facebook/buck/demo/Hello.java: The main Java file supported by other associated resources.android/BUCK: The build file is what makes Buck work. It defines all the build rules for your source code. A build rule can also include dependencies (generally via deps), which may be from other build files, as in the case of this app..buckconfig: A .buckconfig file allows for various flag and alias settings for any project (even beyond Android) within the root directory. "},{"title":"Configure the environment​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#configure-the-environment","content":"Before building an app you need to configure environment variables to let Buck know the locations of Android SDK and Android NDK. First of all, check for existing variables: $ env | grep ANDROID_ ANDROID_HOME=&lt;path-to-sdk&gt; ANDROID_NDK_REPOSITORY=&lt;path-to-ndk&gt; ANDROID_SDK=&lt;path-to-sdk&gt; ANDROID_SDK_ROOT=&lt;path-to-sdk&gt;  Set the missing variables to the locations of Android SDK and Android NDK or set the paths in your .buckconfig file. Before building make sure you installed correct build tools and a target in Android SDK and correct version of Android NDK. You can find the required versions of these tools in .buckconfig: See [android].build_tools_version to get the version of build tools in Android SDK.[android].compile_sdk_version points to the Android SDK to build against.[ndk].ndk_version points to the version of Android NDK. Optionally: [android].sdk_path is an absolute path to the Android SDK.[ndk].ndk_path is an absolute path to the Android NDK.[ndk].ndk_repository_path is an absolute path to a directory that contains multiple Android NDKs in subdirectories. Buck selects which NDK to use based on the value of the [ndk].ndk_version property in .buckconfig. "},{"title":"Build the Android sample​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#build-the-android-sample","content":"In order to build the app, you use the buck buildcommand, specifying your app as the target. The target may be defined in the [alias] section in the .buckconfig file or it would be the name of your Android project prepended by //[the directory where your project is located]: (e.g., //android:demo-app). # From the root `cross-platform-scale-2015-demo/` directory # demo_app_android is an alias in .buckconfig for //android:demo-app. Either works. buck build demo_app_android  You should see output similar to: export ANDROID_NDK=$HOME/android-sdk buck build demo_app_android [-] PROCESSING BUCK FILES...FINISHED 0.0s [100%] [-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts) [-] BUILDING...FINISHED 0.7s [100%] (1/1 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS)  The first time you build, you will most likely see a longer time and cache misses. Subsequent builds should be much faster, with minimal cache misses. Buck outputs its results in the buck-out/ directory. "},{"title":"Run the built Android App​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#run-the-built-android-app","content":"Now that you know your app has built successfully, you can install and run the app with buck install. This command both compiles and installs the application on the Android emulator. Using the --run flag will launch the emulator as well. buck install --run demo_app_android Installing apk on emulator-5554 (android-emulator). [-] PROCESSING BUCK FILES...FINISHED 0.1s [100%] [-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts) [-] BUILDING...FINISHED 0.8s [100%] (1/1 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS) [+] INSTALLING...0.9s Successfully ran install apk //android:demo-app on 1 device(s) Starting activity com.facebook.buck.demo/.App... Successfully ran start activity on 1 device(s)  If you get an error either that you do not have certain Android add-ons (e.g., Google APIs) or that there is no emulator to run, you should launch the Android SDK Manager (e.g., android sdk) and install the appropriate packages and/or run your emulator (usually found under Tools | Manage AVDs). "},{"title":"Success!​","type":1,"pageTitle":"Getting Started","url":"/docs/legacy/basics/getting-started/#success","content":"If all goes well, you should see something similar to: "},{"title":"Key concepts","type":0,"sectionRef":"#","url":"/docs/legacy/basics/key-concepts/","content":"","keywords":""},{"title":"Buck's dependency graph​","type":1,"pageTitle":"Key concepts","url":"/docs/legacy/basics/key-concepts/#bucks-dependency-graph","content":"Every build rule can have zero or more dependencies. You can specify these dependencies using, for example, the deps argument to the build rule. For more information about specifying dependencies, consult the reference page for the build rule you are using. These dependencies form a directed graph, called the target graph. Buck requires the graph to be acyclic. When building the output of a build rule, all of the rule's transitive dependencies are built first. This means that the graph is built in a &quot;bottom-up&quot; fashion. A build rule knows only which rules it depends on, not which rules depend on it. This makes the graph easier to reason about and enables Buck to identify independent subgraphs that can be built in parallel. It also enables Buck to determine the minimal set of build targets that need to be rebuilt. For more information about how Buck leverages the graph of build dependencies, see What Makes Buck so Fast. "},{"title":"Multiple Buck projects in a single repository​","type":1,"pageTitle":"Key concepts","url":"/docs/legacy/basics/key-concepts/#multiple-buck-projects-in-a-single-repository","content":"Buck is designed to build multiple deliverables from a single repository—that is, a monorepo—rather than from multiple repositories. Support for the monorepo design motivated Buck's support for cells and projects. It is Facebook's experience that maintaining all dependencies in the same repository makes it easier to ensure that all developers have the correct version of the code and simplifies the process of making atomic commits. "},{"title":"Tutorials","type":0,"sectionRef":"#","url":"/docs/legacy/basics/tutorials/","content":"","keywords":""},{"title":"Path Setup​","type":1,"pageTitle":"Tutorials","url":"/docs/legacy/basics/tutorials/#path-setup","content":"Add Buck to your $PATH and set up buckd: sudo ln -s ${PWD}/bin/buck /usr/bin/buck sudo ln -s ${PWD}/bin/buckd /usr/bin/buckd  "},{"title":"Create Project​","type":1,"pageTitle":"Tutorials","url":"/docs/legacy/basics/tutorials/#create-project","content":"We are going to build a sample application. We should start our project in an empty directory, so create a new one and navigate to it: mkdir -p ~/my-first-buck-project/ cd ~/my-first-buck-project/  Note: the following instructions will now assume that all commands are run from your ~/my-first-buck-project directory. "},{"title":"Compile Your Code​","type":1,"pageTitle":"Tutorials","url":"/docs/legacy/basics/tutorials/#compile-your-code","content":"Android applications are typically written in Java and kotlin, so the first thing we will do is to configure Buck to compile code against the Android API. To do so, Buck needs to know where your Android SDK is. Assuming that your Android SDK is installed in ~/android-sdk, run the following command to set a ANDROID_SDK environment variable that tells Buck where to find your Android SDK: export ANDROID_SDK=$HOME/android-sdk  Now that Buck can locate your Android SDK, it is time to compile some Java code. First, we create a simple Activity at java/com/example/activity/MyFirstActivity.java: mkdir -p java/com/example/activity/ echo &quot;package com.example.activity; import android.app.Activity; import android.os.Bundle; public class MyFirstActivity extends Activity { @Override public void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); } }&quot; &gt; java/com/example/activity/MyFirstActivity.java  Now we need a build file that defines a build rule to compile this Java code, so we create an android_library() rule in java/com/example/activity/BUCK: echo &quot;android_library( name = 'activity', srcs = glob(['*.java']), visibility = [ 'PUBLIC' ], )&quot; &gt; java/com/example/activity/BUCK  Now we can compile our Java code using Buck: buck build //java/com/example/activity:activity  Buck generates its output in the buck-out directory, so this is a good time to specify buck-out as something that should be ignored by your version control system. "},{"title":"Package Resources​","type":1,"pageTitle":"Tutorials","url":"/docs/legacy/basics/tutorials/#package-resources","content":"Android applications frequently contain resources, such as strings and images. For this example, we will create a trivial Android resource bundle that contains a single string: mkdir -p res/com/example/activity/res/values/ echo &quot;&lt;?xml version='1.0' encoding='utf-8' ?&gt; &lt;resources&gt; &lt;string name='app_name'&gt;Hello World&lt;/string&gt; &lt;/resources&gt;&quot; &gt; res/com/example/activity/res/values/strings.xml  Buck needs a way to reference this collection of resources, so we need to create a build file that defines an android_resource rule: echo &quot;android_resource( name = 'res', res = subdir_glob([('res', '**')]), package = 'com.example', visibility = [ '//apps/myapp:', ], )&quot; &gt; res/com/example/activity/BUCK  "},{"title":"Create a Keystore​","type":1,"pageTitle":"Tutorials","url":"/docs/legacy/basics/tutorials/#create-a-keystore","content":"In practice, you will want to be able to test your Android app on a physical Android device, which means that it needs to be signed. We will create app-specific information, such as the key and manifest, in its own directory to keep things tidy: mkdir -p apps/myapp/  To keep things simple, we will create a self-signed certificate for debugging. Unfortunately, this is not a one-liner because there is a number of prompts from the keytool command. keytool -genkey -keystore apps/myapp/debug.keystore -alias my_alias \\ -keyalg RSA -keysize 2048 -validity 10000  When prompted for a keystore password, just use android (and then type it again to confirm it), and hit Enter to accept the default values for name, organizational unit, etc. Then create a .properties file that stores all of this information: echo &quot;key.alias=my_alias key.store.password=android key.alias.password=android&quot; &gt; apps/myapp/debug.keystore.properties  "},{"title":"Build an APK​","type":1,"pageTitle":"Tutorials","url":"/docs/legacy/basics/tutorials/#build-an-apk","content":"An Android application needs a manifest named AndroidManifest.xml, so we must create such a file: echo &quot;&lt;?xml version='1.0' encoding='utf-8'?&gt; &lt;manifest xmlns:android='http://schemas.android.com/apk/res/android' package='com.example' &gt; &lt;application android:label='@string/app_name' android:hardwareAccelerated='true'&gt; &lt;activity android:name='.activity.MyFirstActivity'&gt; &lt;intent-filter&gt; &lt;action android:name='android.intent.action.MAIN' /&gt; &lt;category android:name='android.intent.category.LAUNCHER' /&gt; &lt;/intent-filter&gt; &lt;/activity&gt; &lt;/application&gt; &lt;/manifest&gt;&quot; &gt; apps/myapp/AndroidManifest.xml  Now we define an android_binary and keystore rule in our build file: echo &quot;android_binary( name = 'app', manifest = 'AndroidManifest.xml', manifest_entries = { 'version_code': 1, 'version_name': '1.0', 'min_sdk_version': 26, 'target_sdk_version': 29 }, keystore = ':debug_keystore', deps = [ '//java/com/example/activity:activity', '//res/com/example/activity:res', ], ) keystore( name = 'debug_keystore', store = 'debug.keystore', properties = 'debug.keystore.properties', )&quot; &gt; apps/myapp/BUCK  Building an android_binary rule will produce an APK: buck build //apps/myapp:app  Alternatively, if you have an Android device connected to your computer, you can build and install the APK in one step with buck install: buck install //apps/myapp:app  "},{"title":"Create an Alias​","type":1,"pageTitle":"Tutorials","url":"/docs/legacy/basics/tutorials/#create-an-alias","content":"Typing buck build //apps/myapp:app every time you want to rebuild your APK can be tedious. Fortunately, Buck makes it possible to define an alias for a build target. An alias can always be used in place of a build target when using Buck's command-line interface. Aliases must be defined in the [alias] a config file in the root of the project: echo &quot;[alias] app = //apps/myapp:app&quot; &gt; .buckconfig  With this alias in place, the command to build and install the APK is much shorter and easier to remember: buck install app  "},{"title":"Create an IntelliJ Project​","type":1,"pageTitle":"Tutorials","url":"/docs/legacy/basics/tutorials/#create-an-intellij-project","content":"You likely want to develop your Android app using an IDE. Fortunately, Buck can generate an IntelliJ project from the build rules you defined in your build files. In order to ensure that IntelliJ recognizes where your Java folders are, you need to specify the [java].src_roots in your .buckconfig file: echo &quot;[java] src_roots = /java/&quot; &gt;&gt; .buckconfig  Now you can create the IntelliJ project by running buck project: buck project --ide intellij  Note that you will likely want to exclude these generated files from version control, so add the following to your .gitignore file (or .hgignore if you are using Mercurial) along with the files generated by buckd: echo &quot;/.buckd /buck-out *.iml /.idea/compiler.xml /.idea/libraries/*.xml /.idea/modules.xml /.idea/runConfigurations/Debug_Buck_test.xml&quot; &gt; .gitignore  Now you can build your Android application from either IntelliJ or the command line. "},{"title":"Buck Daemon (buckd)","type":0,"sectionRef":"#","url":"/docs/legacy/concepts/buck-daemon/","content":"","keywords":""},{"title":"Killing or disabling the Buck daemon​","type":1,"pageTitle":"Buck Daemon (buckd)","url":"/docs/legacy/concepts/buck-daemon/#killing-or-disabling-the-buck-daemon","content":"The Buck daemon process is killed if the buck clean command is run. You can also kill the Buck daemon explicitly by running buck kill in the directory tree for your project. Note that if—for some reason—multiple instances of the daemon are running, the buck kill command kills only one of them.If the daemon is killed, you might experience a significant delay the next time that you invoke a Buck command as the daemon restarts. "},{"title":"Build File","type":0,"sectionRef":"#","url":"/docs/legacy/concepts/build-file/","content":"Build File A build file is a file, typically named BUCK, that defines one or more build rules. Note that you can change the name that Buck uses for the build file in the buildfile section of .buckconfig. A source file in your project can only be referenced by rules in its &quot;nearest&quot; build file, where &quot;nearest&quot; means its closest direct ancestor in your project's file tree. (If a source file has a build file as a sibling, then that is its nearest ancestor.) For example, if your project had the following BUCK files: java/com/facebook/base/BUCK java/com/facebook/common/BUCK java/com/facebook/common/collect/BUCK Then your build rules would have the following constraints: Rules in java/com/facebook/base/BUCK can reference any file under java/com/facebook/base/.Rules in java/com/facebook/common/ can reference any files under that directory, except for those under java/com/facebook/common/collect/, as those &quot;belong&quot; to the BUCK file in the collect directory. The set of source files accessible to a build file is also known as its build package. The way to refer to code across build packages is to create build rules and use deps to refer to that code. Going back to the previous example, suppose code in java/com/facebook/common/concurrent/ wants to depend on code in java/com/facebook/common/collect/. Presumably java/com/facebook/common/collect/BUCK has a build rule like: java_library( name = 'collect', srcs = glob(['*.java']), deps = ['//java/com/facebook/base:base',],) Then java/com/facebook/common/BUCK could have a rule like: java_library( name = 'concurrent', srcs = glob(['concurrent/*.java']), deps = ['//java/com/facebook/base:base','//java/com/facebook/common/collect:collect',],) whereas the following would be invalid because java/com/facebook/common/collect/ has its own build file, so //java/com/facebook/common/collect:concurrent cannot list java/com/facebook/common/collect/*.java in its srcs. java_library( name = 'concurrent', srcs = glob(['collect/*.java', 'concurrent/*.java']), deps = ['//java/com/facebook/base:base',],) ","keywords":""},{"title":"Build Rule","type":0,"sectionRef":"#","url":"/docs/legacy/concepts/build-rule/","content":"","keywords":""},{"title":"Buck's collection of build rules​","type":1,"pageTitle":"Build Rule","url":"/docs/legacy/concepts/build-rule/#bucks-collection-of-build-rules","content":"Buck comes with a collection of built-in build rules for many common build procedures. For example, compiling Java code against the Android SDK is a common procedure, so Buck provides the build rule android_library to do that. Similarly, the final product of most Android development is an APK, so you can use the build rule android_binary to create an APK. This documentation organizes Buck's build rules by development language and by target platform. Examples are: C++, Java, Python (development languages) and Android, iOS, .NET (target platforms). Consult the table of contents to locate the build rules that are appropriate for your development project. You can view a list of Buck's build rules from the command line with the command: buck audit ruletypes  You can view the arguments supported by a particular rule with the command: buck audit ruletype &lt;rule&gt;  Note that the first of these commands uses the plural ruletypes, and the second uses the singular ruletype. For more information, see the buck audit documentation. "},{"title":"Source files as inputs to build rules​","type":1,"pageTitle":"Build Rule","url":"/docs/legacy/concepts/build-rule/#source-files-as-inputs-to-build-rules","content":"Most build rules specify source files as inputs. For example, a cxx_library rule would specify .cpp files as inputs. To support specifying these files, a cxx_library rule provides the srcs argument. Some languages, such as C++, use header files as well. To specify these, cxx_library provides a headers argument. In addition to srcs and headers, some rules provide variants of these arguments, such as platform_srcs and platform_headers. These arguments support groups of source files that should be used as inputs only when building for specific platforms. For more information, see the descriptions for platform_srcs and platform_headers in, for example, the cxx_library topic. "},{"title":"Package boundaries and access to source files​","type":1,"pageTitle":"Build Rule","url":"/docs/legacy/concepts/build-rule/#package-boundaries-and-access-to-source-files","content":"In Buck, a BUCK file defines a package, which corresponds roughly to the directory that contains the BUCK file and those subdirectories that do not themselves contain BUCK files. (To learn more, see the Key Concepts topic.) A rule in a BUCK file cannot specify a source file as an input unless that source file is in that BUCK file's package. An exception to this restriction exists for header files, but only if a rule in the package that contains the header file exports that header file using the exported_headers argument. For more details, see the description for exported_headers in, for example, the cxx_library topic. More commonly though, the package for a BUCK file contains all the source files required for the rules defined in that BUCK file. Functionality in source files from other packages is made available through the artifacts produced by the rules in the BUCK files for those packages. For example, a cxx_binary might use the functionality in a cxx_library that is defined in another package. To access that functionality, the cxx_binary would take that cxx_library as a dependency. Symlinks: Use with caution if at all​ We recommend that you do not use symlinks—either absolute or relative—to specify input files to build rules. Although using symlinks in this context does sometimes work, it can lead to unexpected behavior and errors. "},{"title":"Dependencies: Output from one rule as input to another rule​","type":1,"pageTitle":"Build Rule","url":"/docs/legacy/concepts/build-rule/#dependencies-output-from-one-rule-as-input-to-another-rule","content":"A build rule can use the output from another build rule as one of its inputs by specifying that rule as a dependency. Typically, a build rule specifies its dependencies as a list of build targets in its deps argument. However, the rule can also specify dependencies—as build targets—in other arguments, such as srcs.Example: The output of a java_library rule is a JAR file. If a java_library rule specifies another java_library rule as a dependency, the JAR file produced by the specified rule is added to the classpath for the java_library that depends on it.Example: If a java_binary rule specifies a java_library rule as a dependency, the JAR file for the specified java_library is available on the classpath for the java_binary. In addition, in the case of java_binary, the JAR files for any dependencies of the java_library rule are also made available to the java_binary rule—and if those dependencies have dependencies of their own, they are added as well. This exhaustive cascade of dependencies is referred to as the rule's transitive closure. "},{"title":"Required dependencies are always built first​","type":1,"pageTitle":"Build Rule","url":"/docs/legacy/concepts/build-rule/#required-dependencies-are-always-built-first","content":"Buck guarantees that any dependencies that a rule lists that are required in order to build that rule are built successfully before Buck builds the rule itself. Note though that there can be special cases—such as apple_bundle—where a rule's listed dependencies do not actually need to be built before the rule. "},{"title":"Visibility​","type":1,"pageTitle":"Build Rule","url":"/docs/legacy/concepts/build-rule/#visibility","content":"In order for a build rule to take a dependency on another build rule, the build rule on which the dependency is taken must be visible to the build rule taking the dependency. A build rule's visibility argument is a list of build target patterns that specify the rules that can take that rule as a dependency. For more information about the concept of visibility in Buck, see the Visibility topic. "},{"title":"Dependencies define a graph​","type":1,"pageTitle":"Build Rule","url":"/docs/legacy/concepts/build-rule/#dependencies-define-a-graph","content":"Build rules and their dependencies define a directed acyclic graph (DAG). Buck requires this graph to be acyclic to make it possible to build independent subgraphs in parallel. "},{"title":"How to handle special cases: genrules and macros​","type":1,"pageTitle":"Build Rule","url":"/docs/legacy/concepts/build-rule/#how-to-handle-special-cases-genrules-and-macros","content":"Although Buck provides a rich set of built-in build rules for developers, it is not able to address all possible needs. As an &quot;escape hatch,&quot; Buck provides a category of generic build rules called genrules. With genrules, you can perform arbitrary operations using shell scripts. The genrules supported by Buck are: genruleapk_genrulecxx_genrule "},{"title":"Multiple output files with genrules​","type":1,"pageTitle":"Build Rule","url":"/docs/legacy/concepts/build-rule/#multiple-output-files-with-genrules","content":"In most cases, a build rule produces exactly one output file. However, with genrules, you can specify an output directory and write arbitrary files to that directory. "},{"title":"Macros​","type":1,"pageTitle":"Build Rule","url":"/docs/legacy/concepts/build-rule/#macros","content":"Finally, note that you can define functions that generate build rules. In general, this should not be something that you need to do, but taking advantage of this option might help you add needed functionality to Buck's without editing its source code. For more details, see the Custom Macros topic. "},{"title":"Build Target Pattern","type":0,"sectionRef":"#","url":"/docs/legacy/concepts/build-target-pattern/","content":"","keywords":""},{"title":"Build target patterns are not allowed in the deps argument​","type":1,"pageTitle":"Build Target Pattern","url":"/docs/legacy/concepts/build-target-pattern/#build-target-patterns-are-not-allowed-in-the-deps-argument","content":"Build target patterns cannot be used with the deps argument of a build rule. Buck requires that you specify all dependencies explicitly as either fully-qualified or relative build targets. By making dependencies explicit, Buck prevents build rules from inadvertently adding new dependencies, which can result in non-reproducible builds. In addition, if the added dependencies are not actually required, they can unnecessarily drive up the computational cost of the build. "},{"title":"Target aliases​","type":1,"pageTitle":"Build Target Pattern","url":"/docs/legacy/concepts/build-target-pattern/#target-aliases","content":"Buck supports the ability to define aliases for build targets; using aliases can improve brevity when specifying targets on the Buck command line. For more information, see the [alias] section in the documentation for .buckconfig. "},{"title":"Build Target","type":0,"sectionRef":"#","url":"/docs/legacy/concepts/build-target/","content":"","keywords":""},{"title":"Command-line Pro Tips​","type":1,"pageTitle":"Build Target","url":"/docs/legacy/concepts/build-target/#command-line-pro-tips","content":"Here are some ways that you can reduce your typing when you specify build targets as command-line arguments to the buck build or buck run commands. Consider the following example of a fully-qualified build target used with the buck build command: buck build //java/com/facebook/share:share  Although Buck is always strict when parsing build targets in build files, Buck is flexible when parsing build targets on the command-line. Specifically, the leading // is optional on the command line, so the above could be: buck build java/com/facebook/share:share  Also, if there is a forward slash before the colon, it is ignored, so this could also be written as: buck build java/com/facebook/share/:share  which enables you to produce the red text shown below using tab-completion, which dramatically reduces how much you need to type: buck build java/com/facebook/share/:share  Finally, if the final path element matches the value specified after the colon, it can be omitted: # This is treated as //java/com/facebook/share:share. buck build java/com/facebook/share/  which makes the build target even easier to tab-complete. For this reason, the name of the build rule for the primary deliverable in a build file is often named the same as the parent directory. That way, it can be built from the command-line with less typing. "},{"title":"See also​","type":1,"pageTitle":"Build Target","url":"/docs/legacy/concepts/build-target/#see-also","content":"Buck supports the ability to define aliases for build targets; using aliases can improve brevity when specifying targets on the Buck command line. For more information, see the [alias] section in the documentation for .buckconfig. A build target pattern is a string that describes a set of one or more build targets. For example, the pattern //... is used to build an entire project. For more information, see the Build Target Pattern topic. "},{"title":"Visibility","type":0,"sectionRef":"#","url":"/docs/legacy/concepts/visibility/","content":"","keywords":""},{"title":"Examples​","type":1,"pageTitle":"Visibility","url":"/docs/legacy/concepts/visibility/#examples","content":"A common library like Guava should be able to be included by any build rule: prebuilt_jar( name = 'guava', binary_jar = 'guava-14.0.1.jar', visibility = ['PUBLIC',],)  It is common to restrict the visibility of Android resources to the Java code that uses it: android_resource( name = 'ui_res', res = 'res', package = 'com.example', visibility = ['//java/com/example/ui:ui',],)  Or it may be simpler to make it visible to the entire directory in case additional build rules are added to java/com/example/ui/BUCK: android_resource( name = 'ui_res', res = 'res', package = 'com.example', visibility = ['//java/com/example/ui:',],)  Also, it is common to limit code for testing to be visible only to tests. If you define all of your Java unit tests in a folder named javatests/ in the root of your project, then you could define the following rule to ensure that only allow build rules under javatests/ can depend on JUnit: prebuilt_jar( name = 'junit', binary_jar = 'junit-4.11.jar', visibility = ['//javatests/...',],)  Finally, restricting the view of a target can be useful for preventing dependency creep: java_library( name = 'example', visibility = ['PUBLIC',], within_view = ['//foo:bar','//hello:world',],)  "},{"title":"buck-out","type":0,"sectionRef":"#","url":"/docs/legacy/files-and-directories/buck-out/","content":"buck-out Buck stores build artifacts in a directory named buck-out in the root of your project. You should not make assumptions about where Buck places your build artifacts within the directory structure beneath buck-out as these locations depend on Buck's implementation and could potentially change over time. Instead, to obtain the location of the build artifact for a particular target, use the --show-output option with the buck build or the buck targets command. buck targets --show-output &lt;target&gt; buck build --show-output &lt;target&gt; You can also obtain the locations of your build artifacts by specifying either the --build-report or--keep-going options with buck build. Note that --show-output is going to be deprecated soon for buck build and replaced with --show-outputs. --show-outputs may print more than one build artifact per build target. buck build --build-report &lt;target&gt; buck build --keep-going &lt;target&gt; For more information about these options, see the topics for the buck build and buck targets commands.","keywords":""},{"title":".buckconfig","type":0,"sectionRef":"#","url":"/docs/legacy/files-and-directories/dot-buckconfig/","content":"","keywords":""},{"title":"Performance impact of Buck configuration changes​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#performance-impact-of-buck-configuration-changes","content":"Also, because configuration settings are sometimes included in the cache keys that Buck uses in its caching system, changes to Buck's configuration can invalidate previously-built artifacts in Buck's caches. If this occurs, Buck rebuilds those artifacts, which can impact your build time. "},{"title":"The .buckconfig file uses the INI file format​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#the-buckconfig-file-uses-the-ini-file-format","content":"The .buckconfig file uses the INI file format. That is, it is divided into sections where each section contains a collection of key names and key values. The .buckconfig implementation supports some modifications to the INI file format; these are discussed below. "},{"title":"Other INI file parsers​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#other-ini-file-parsers","content":"As mentioned previously, we have extended the INI file parser that Buck uses to parse configuration files. As a result, INI file parsers provided by other languages or libraries are often not able to parse Buck's configuration files successfully. "},{"title":"Dot character not supported in section names​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#dot-character-not-supported-in-section-names","content":"We do not support the use of the dot character (.) in section names within Buck configuration files. For example, the following is not supported—although Buck does not issue a warning or error. [foo.bar] baz=1  Note that sometimes you might need to define your own custom sections, such as for platform flavors for C++ or Python. These scenarios are examples of when you should be careful not to introduce the dot character in section names. This constraint is because Buck uses the dot character to delimit section names and key names in other contexts such as the --config command-line parameter. For information about --config, see the Common Parameters topic. "},{"title":"Character encoding​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#character-encoding","content":"To ensure that any character can be encoded in a .buckconfig key value, you can use escape sequences to encode characters that would otherwise be problematic. The following escape sequences are supported. \\\\\tbackslash\\&quot;\tdouble quote \\n\tnewline \\r\tcarriage return \\t\ttab \\x##\tUnicode character with code point ## (in hex) \\u####\tUnicode character with code point #### (in hex) \\U########\tUnicode character with code point ######## (in hex) "},{"title":"Key values as lists​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#key-values-as-lists","content":"Although the standard INI format supports only key values that represent a single item, Buck supports key values that represent a list of items. The syntax is to separate the items in the list using the space (0x20) character. For example, a key value for the list of command-line flags to be passed to a compiler could be represented as a list of the flags separated by spaces: flags = -foo -bar -baz -qux  When a key value is parsed as a list instead of a single item, the separator character is interpreted as a separator only when it occurs outside of double quotes. For example, if flags is a key value interpreted as a list of items separated by spaces, then flags = -foo &quot;-bar \\u0429&quot;  results in the two strings: foo and -bar Щ; the space character between -bar and \\u0429 is not interpreted as a separator. "},{"title":"Transclusion of values from one key to another​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#transclusion-of-values-from-one-key-to-another","content":"Values from other keys can be transcluded into the current key using the following syntax inside the current key value. $(config &lt;section&gt;.&lt;field&gt;)  For example, to use the [go].vendor_path in a custom setting: [custom_section]custom_value = $(config go.vendor_path)  "},{"title":"Comments​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#comments","content":"In addition to the semicolon (;), you can use the pound sign (#), as a comment character in .buckconfig. "},{"title":".buckconfig.local​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#buckconfiglocal","content":"The root of your project may contain a second configuration file named .buckconfig.local. Its format is the same as that of .buckconfig, but settings in .buckconfig.local override those in .buckconfig. In practice, .buckconfig is a version-controlled file that contains settings that are applicable to all team members, whereas .buckconfig.local is excluded from version control to allow users to define personal settings, such as personal aliases. "},{"title":"Other initialization files​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#other-initialization-files","content":"In addition to the .buckconfig and .buckconfig.local files in the project root, Buck reads configuration settings from the following additional locations, some of which are actually directories: Directory .buckconfig.d located in the project root directory.File .buckconfig and directory .buckconfig.d located in the current user's home directory which, on Unix-like systems, is available from the HOME environment variable or through the ~ symbol.File buckconfig and directory buckconfig.d located in system directory /etc/. Buck treats any file—irrespective of name—in a .buckconfig.d(buckconfig.d) directory (excluding files found in subdirectories) as a Buck configuration file, provided that it adheres to .buckconfig syntax. Note that a .buckconfig.d directory is distinct from the similarly-named .buckd directory which is used by the Buck Daemon (buckd) . For a description of how Buck resolves collisions between settings in these configuration files, see the section Precedence of Buck configuration specificationsbelow. "},{"title":"Command-line control of configuration​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#command-line-control-of-configuration","content":"In addition to the above configuration files, Buck supports specifying additional configuration files from the Buck command line using the --config-file parameter. You can also specify configuration settings individually on the Buck command line using the --config (-c) parameter. Furthermore, you can aggregate these settings into flag files using the --flagfile parameter. A flag file provides similar functionality to a configuration file but uses a different syntax. Flag files are sometimes called mode files or at (@) files. For more information about the --config-file and --flagfile parameters, see the Common Parameters topic. "},{"title":"Precedence of Buck configuration specifications​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#precedence-of-buck-configuration-specifications","content":"The following list shows the order of precedence for how Buck interprets its configuration specifications. Settings specified using a method closer to the top of the list have higher precedence and will override those lower on the list. For example, the .buckconfig file in the project directory overrides a .buckconfig file in the user's HOME directory. Configuration specified on the command line using --config (-c), --config-file and --flagfile. Configuration specified later on the command line overrides configuration specified earlier..buckconfig.local in the project directory..buckconfig in the project directory..buckconfig in the HOME directory.Files in a .buckconfig.d subdirectory of the project directory, irrespective of filename.Files in a .buckconfig.d subdirectory of the HOME directory, irrespective of filename.buckconfig in the /etc/ directory.Files in a buckconfig.d subdirectory of the /etc/ directory, irrespective of filename. Files in a .buckconfig.d (buckconfig.d) directory have precedence according to the lexicographical order of their file names. Files later in the lexicographical order have precedence over files earlier in that order. "},{"title":"Configuration files can include other files​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#configuration-files-can-include-other-files","content":"Any of the configuration files that we've discussed so far can also include by reference other files that contain configuration information. These included files can contain complete .buckconfig sections or they can contain a group of key name/value pairs that constitute part of a section. In this second use case, you'll need to ensure that the included file is referenced beneath the appropriate section in the including file. Because of this additional complexity, we recommend that you include only files that contain complete sections.Note: Inclusion of files is a Buck-specific extension to the INI file parser that Buck uses. Therefore, if you use this feature, your Buck configuration files will probably not be parsable by other more-generic INI file parsers. The syntax to include a file is &lt;file:*path-to-included-file*&gt;  where path-to-included-file is either a relative path from the including file (recommended) or an absolute path from the root of the file system. You can also specify that the file should be included only if it exists by prefixing with a question mark (?). &lt;?file:*path-to-included-file*&gt;  If you use this prefix, it is not an error condition if the file does not exist; Buck just silently continues to process the rest of the configuration file. In the following example, the .buckconfig file includes the file cxx-other-platform.include which exists in the subdirectory cxx-other-platform. The .buckconfig file will also include the file future-platform from the directory future-platform.include if that file exists. # # .buckconfig # [cxx] cxxppflags=&quot;-D MYMACRO=\\&quot;Buck\\&quot;&quot; &lt;file:cxx-other-platform/cxx-other-platform.include&gt; &lt;?file:future-platform/future-platform.include&gt; # # cxx-other-platform.include # [cxx#other_platform] cxxppflags=&quot;-D MYMACRO=\\&quot;Watchman\\&quot;&quot;  "},{"title":"Sections​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#sections","content":"The following sections are recognized by Buck:[adb][alias][android][apple][build][buildfile][cache][client][color][credentials][cxx][d][doctor][download][dx][export_file][go][groovy][halide][httpserver][incompatible][intellij][java][kotlin][log][lua][maven_repositories][ndk][ocaml][parser][project][python][repositories][resources][resources_per_rule][rust][sandbox][test][thrift][tools][ui][worker] "},{"title":"[adb]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#adb","content":"This section configures adb behavior. "},{"title":"adb_restart_on_failure​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#adb_restart_on_failure","content":"This specifies whether to restart adb on failure or not. [adb]adb_restart_on_failure = true  "},{"title":"multi_install_mode​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#multi_install_mode","content":"This specifies whether multi-install mode is enabled or disabled by default. [adb]multi_install_mode = false  "},{"title":"[alias]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#alias","content":"This section contains definitions of build target aliases. [alias]app = //apps/myapp:app apptest = //apps/myapp:test  These aliases can then be used from the command line: $ buck build app $ buck test apptest  You can also suffix aliases with flavors: $ buck build app#src_jar# This will expand the alias and effectively build the target returned by: $ buck targets --resolve-alias app#src_jar//apps/myapp:app#src_jar  "},{"title":"[android]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#android","content":"This section configures android-specific build behavior. "},{"title":"build_tools_version​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#build_tools_version","content":"This specifies the version of the Android SDK Build-tools that all Android code in the project should be built against. By default, Buck will select the newest version found on the system. [android]build_tools_version = 23.0.1  "},{"title":"compile_sdk_version​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#compile_sdk_version","content":"This specifies the version of the Android SDK that all Android code in the project should be built against. Even if not specified, the version that Buck chose to use will be printed to the console during the build. A list of valid values on your system can be found by running android list target --compact. [android]compile_sdk_version = Google Inc.:Google APIs:21  "},{"title":"sdk_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#sdk_path","content":"This specifies the absolute path to the Android SDK that all Android code in the project should be built against. The default is empty. Setting this property has the same effect as if you had set either of the following environment variables to the same value: ANDROID_SDKANDROID_SDK_ROOTANDROID_HOME Note that Buck gives precedence to the values of these environment variables—in the order in which they are listed above—over the value of this property in .buckconfig. [android]sdk_path = /Library/Android/sdk  "},{"title":"[apple]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#apple","content":"This section includes settings that control settings that are specific to Apple platform rules. "},{"title":"asset_catalog_validation​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#asset_catalog_validation","content":"Buck can check errors in .xcassets' contents that can later cause silent failures, like having multiple images with the same name or missing Contents.json files. To add extra validation above what Xcode does, set this option to STRICT. [apple]asset_catalog_validation = XCODE  "},{"title":"codesign​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#codesign","content":"To override a default path to codesign, set this setting to either a file path or buck target. [apple]codesign = //path/to/target/that/creates:codesign  "},{"title":"codesign_timeout​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#codesign_timeout","content":"The timeout of the code-signing step in seconds. The value is set to 300 seconds by default if not specified explicitly. [apple]codesign_timeout = 600  "},{"title":"code_sign_identities_command​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#code_sign_identities_command","content":"Specifies a command with any optional arguments that Buck will use to get the current key fingerprints available for code signing. This command should output a list of hashes and common names to standard output in the same format as security find-identity -v -p codesigning. If unspecified, Buck will use security find-identity -v -p codesigning. [apple]code_sign_identities_command = path/to/command --arg1 --arg2  "},{"title":"default_debug_info_format_for_binaries​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_debug_info_format_for_binaries","content":"default_debug_info_format_for_binaries setting controls the default debug info format that is used when building binary targets. If you don't specify it, DWARF_AND_DSYM value will be used. You can disable debug data by specifying NONE value. You can produce unstripped binary by specifyingDWARF value. [apple]default_debug_info_format_for_binaries = NONE  "},{"title":"default_debug_info_format_for_libraries​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_debug_info_format_for_libraries","content":"default_debug_info_format_for_libraries setting controls the default debug info format that is used when building dynamic library targets. If you don't specify it, DWARF value will be used. You can disable debug data by specifying NONE value. You can produce dSYM file for the library by specifyingDWARF_AND_DSYM value. [apple]default_debug_info_format_for_libraries = DWARF  "},{"title":"default_debug_info_format_for_tests​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_debug_info_format_for_tests","content":"default_debug_info_format_for_tests setting controls the default debug info format that is used when building test targets. If you don't specify it, DWARF value will be used. You can disable debug data by specifying NONE value. You can produce dSYM file by specifyingDWARF_AND_DSYM value. [apple]default_debug_info_format_for_tests = DWARF_AND_DSYM  "},{"title":"device_helper_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#device_helper_path","content":"If you want to have Buck be able to install to devices, you need to provide the path to the fbsimctl binary. [apple]device_helper_path = third-party/fbsimctl/fbsimctl  "},{"title":"ipa_compression_level​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ipa_compression_level","content":"Specify a compression level used when creating ipa. The possible values are: none: Do not compress ipa.min: Use minimum compression level.default (default): Use medium compression level.max: Use maximum compression level. If omitted, the default value will be used. [apple]ipa_compression_level = min  "},{"title":"provisioning_profile_read_command​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#provisioning_profile_read_command","content":"Specifies a command with any optional arguments that Buck will use to decode Apple's provisioning profiles for iOS builds. The full path of the provisioning profile will be appended after the command and any arguments specified here. If unspecified, Buck will use openssl smime -inform der -verify -noverify -in. [apple]provisioning_profile_read_command = path/to/command --arg1 --arg2  "},{"title":"provisioning_profile_search_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#provisioning_profile_search_path","content":"Specifies a path where Buck will look for provisioning profiles (files with extension .mobileprovision) that it can use to provision the application to be used on a device. You can specify either an absolute path or one relative to the project root. If unspecified, Buck will look in ~/Library/MobileDevice/Provisioning Profiles. [apple]provisioning_profile_search_path = path/to/provisioning/profiles  "},{"title":"target_sdk_version​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#target_sdk_version","content":"For each platform, you can specify the target SDK version to use. The format is {platform}_target_sdk_version. [apple]iphonesimulator_target_sdk_version = 7.0 iphoneos_target_sdk_version = 7.0 macosx_target_sdk_version = 10.9  "},{"title":"test_log​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#test_log","content":"When running Apple tests via xctool, Buck can set environment variables to tell the tests where to write debug logs and what log level to use. By default, Buck tells xctool to set two environment variables named FB_LOG_DIRECTORYand FB_LOG_LEVEL when running tests which you can read from your test environment:  FB_LOG_DIRECTORY=buck-out/gen/path/to/logs FB_LOG_LEVEL=debug  You can override the default names for these environment variables and the value for the debug log level via the following config settings:  [apple] test_log_directory_environment_variable=MY_LOG_DIRECTORY test_log_level_environment_variable=MY_LOG_LEVEL test_log_level=verbose  "},{"title":"use_flavored_cxx_sections​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#use_flavored_cxx_sections","content":"By default, Buck uses the C/C++ toolchain and flag settings in the cxxsection to extend Apple C/C++ platform. With this parameter set, Buck will instead use settings in cxx# sections (e.g. cxx#macosx-x86_64.cxx_flags=-foo). [apple]use_flavored_cxx_sections = true  "},{"title":"use_header_maps_in_xcode​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#use_header_maps_in_xcode","content":"Xcode projects generated by Buck by default use header maps for header search paths. This speeds up builds for large projects over using regular directory header search paths, but breaks some Xcode features, like header file name autocompletion. If that is an issue, use the following option to disable the use of header maps. [apple]use_header_maps_in_xcode = false  "},{"title":"xcode_developer_dir​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#xcode_developer_dir","content":"By default, Buck will use the output of xcode-select --print-path to determine where Xcode's developer directory is. However, you can specify a directory in the config to override whatever value that would return. [apple]xcode_developer_dir = path/to/developer/directory  "},{"title":"xcode_developer_dir_for_tests​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#xcode_developer_dir_for_tests","content":"Optionally override the Xcode developer directory for running tests, if you want them to be run with a different Xcode version than the version used for building. If absent, falls back to xcode_developer_dir and finally xcode-select --print-path. [apple]xcode_developer_dir_for_tests = path/to/developer/directory/for_tests  "},{"title":"xctool_default_destination_specifier​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#xctool_default_destination_specifier","content":"This setting is passed directly to xctool, and then toxcodebuild as the -destination argument. [apple]xctool_default_destination_specifier = platform=iOS Simulator  For more detail, see the man page for xcodebuild. To access the man page, type the following from your Terminal prompt: man xcodebuild  and then use / to search for the string Destinations. "},{"title":"xctool_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#xctool_path","content":"If you want to run tests with Buck, you will need to get xctool and tell Buck where to find it. This setting lets you specify a path to a binary. You should use either this setting or [apple].xctool_zip_target. [apple]xctool_path = path/to/binary/of/xctool  "},{"title":"xctool_zip_target​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#xctool_zip_target","content":"If you want to run tests with Buck, you will need to get xctool and tell Buck where to find it. This setting lets you specify a build target. You should use either this setting or [apple].xctool_path. [apple]xctool_zip_target = //path/to/target/that/creates:xctool-zip  "},{"title":"*_package_command​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#_package_command","content":"Specify a custom command to run for apple_package() rules. The syntax of this field is similar to the cmd field of genrule, and supports some expansions:SRCSExpands to the absolute path of the bundle argument output to theapple_package() rule.OUTExpands to the output file for the apple_package() rule. The file specified by this variable must always be written by this command.SDKROOTExpands to the SDK root directory for the requested SDK. For example,/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS9.2.sdk/. Note that since strings in the config can be quoted, literal quotes can only be written by quoting the string and use escaped quotes. If omitted, this will revert to the built-in behavior. When this option is specified, *_package_extension must also be specified. [apple]iphoneos_package_command = &quot;\\&quot;$PLATFORM_DIR/Developer/usr/bin/PackageApplication\\&quot; \\&quot;$SRCS\\&quot; \\&quot;$OUT\\&quot;&quot; iphoneos_package_extension = zip  "},{"title":"*_package_extension​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#_package_extension","content":"Specify the output extension for custom apple_package rules configured with*_package_command. This config option must be specified when *_package_command is specified, or both omitted. "},{"title":"*_replacement​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#_replacement","content":"Replace Xcode provided tools from imported SDKs and toolchains. Input path must point to a valid executable file. This takes precedence over apple.*_xcode_tool_name_override which only searches for replacement within workspace. [apple]*_replacement = /usr/bin/true  "},{"title":"*_toolchains_override​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#_toolchains_override","content":"Specify a comma-delimited custom list of toolchains to use when building with a particular SDK. This is the Buck equivalent of the TOOLCHAINS environment variable when building with Xcode. If omitted, this will revert to the built-in behavior. osx_toolchains_override = tools.stable,tools.swift40,tools.common  "},{"title":"*_version_override​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#_version_override","content":"Specify version string to use for Xcode tool. By default, Xcode tool's version value is calculated automatically from its container SDK and toolchain. But in some cases (e.g. when tools are overridden by apple.*_replacement), it needs to be manually overridden in order to prevent rule key collision. [apple]actool_replacement=/some/path/to/custom/actool actool_version_override=custom_actool_1.0  "},{"title":"*_xcode_tool_name_override​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#_xcode_tool_name_override","content":"Specify custom Xcode tool name to use in place of existing one. When set, buck will lookup Xcode search paths to locate the tool, and use it for tool invocations. This value is ignored when apple.*_replacement for the same tool is set. [apple]# Use (my_clang|my_actool) executable which exists in one of the# imported SDKs and toolchains, instead of the defaults.clang_xcode_tool_name_override=my_clang actool_xcode_tool_name_override=my_actool  "},{"title":"[build]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#build","content":"This section includes settings that control build engine behavior. "},{"title":"artifact_cache_size_limit​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#artifact_cache_size_limit","content":"Specifies the maximum size, in bytes, of a build artifact (output file) that Buck caches. # # Use a limit of 50 MB. # artifact_cache_size_limit = 52428800  This value is optional. If you do not specify a value, then it sets no limit to the size of an artifact that Buck caches—but see note below regarding distributed caches.Note: This value sets an upper bound on artifact size for all values of [cache].mode. The parameter [cache].http_max_store_size sets an artifact size limit only for distributed cache modes (http and thrift_over_http). Therefore, it is not meaningful to set a value for http_max_store_size which is larger than the value of artifact_cache_size_limit. "},{"title":"delete_temporaries​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#delete_temporaries","content":"If true, Buck deletes some temporary files immediate after executing a build rule. This is useful for conserving disk space when performing large builds. By default, temporary files are not deleted. [build]delete_temporaries = false  "},{"title":"depfiles​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#depfiles","content":"Configures the use of dependency files for rules that support them. This is an optimization that is useful when dependencies are over-specified and the rule can dynamically determine the subset of dependencies it actually needs. The possible values are: enabled: Use dependency files to avoid unnecessary rebuilds.cache (default): Use dependency files to avoid unnecessary rebuilds and to store/fetch artifacts to/from the cache.disabled: Do not use dependency files for rebuild detection. [build]depfiles = cache  "},{"title":"engine​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#engine","content":"This has two possible values that change the behavior of how Buck operates when building a build target: shallow (default): only the required transitive dependencies of a build target are materialized locally. Cache hits can result in missing transitive dependencies that are not needed for the final output.deep: ensure that all transitive dependencies of a build target are materialized locally. [build]engine = shallow  "},{"title":"max_depfile_cache_entries​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#max_depfile_cache_entries","content":"Sets the maximum size of the depfile cache for each input source file. This is only used when setting [build].depfiles to cache. An ideal setting for this should be big enough for the working set of all possible header states that a given unchanged source file uses. [build]max_depfile_cache_entries = 256  "},{"title":"network_threads​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#network_threads","content":"The number of threads to be used for network I/O. The default value is number of cores of the machine. [build]network_threads = 8  "},{"title":"rule_key_caching​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#rule_key_caching","content":"Enables caching of rule key calculations between builds when using the Buck daemon. [build]rule_key_caching = true  "},{"title":"threads​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#threads","content":"Sets the maximum number of threads to use for building. By default, Buck uses the number of available cores multiplied by 1.25. [build]threads = 4  "},{"title":"thread_core_ratio​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#thread_core_ratio","content":"Sets the maximum number of threads to use for building as a ratio of the number of available cores (e.g. 0.75 on a 4 core machine would limit building to 3 threads, or a value of 1.25 on the same machine would attempt to use 5 threads). [build]thread_core_ratio = 0.75  "},{"title":"thread_core_ratio_max_threads​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#thread_core_ratio_max_threads","content":"The maximum number of threads to use when calculating the number of build threads from thread_core_ratio. (e.g. a value of 2 on a 4 core machine would ensure that, at most, 2 threads were used, and value of 10 on a 40 core machine would ensure that, at most, 10 threads were used). [build]thread_core_ratio_max_threads = 10  "},{"title":"thread_core_ratio_min_threads​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#thread_core_ratio_min_threads","content":"The minimum number of threads to use when calculating the number of build threads from thread_core_ratio. (e.g. a value of 1 on a 4 core machine would ensure that, at least, 1 thread was used, and value of 4 on a 40 core machine would ensure that, at least, 10 threads were used). [build]thread_core_ratio_min_threads = 1  "},{"title":"thread_core_ratio_reserved_cores​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#thread_core_ratio_reserved_cores","content":"Limit the maximum number of build threads to be the number of detected cores minus this value. (e.g. a value of 1 on a 4 core machine would ensure that, at most, 3 cores were used, and a value of 2 on a 40 core machine would ensure that, at most, 38 cores were used). [build]thread_core_ratio_reserved_cores = 1  "},{"title":"type​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#type","content":"Sets the type of the build that buck has been built with. This allows buck to distinguish different kinds of builds. When you run ant locally, this will be automatically set to LOCAL_ANT. When you build buck using buck locally, e.g. buck build buck, this will be automatically set to LOCAL_PEX. If you are deploying buck through central deployment system, you may want to set build type to RELEASE_PEX: buck build buck --config build.type=RELEASE_PEX  Note: this setting does not affect how buck builds other rules. It only affects the way how buck will build buck. [build]type = RELEASE_PEX  "},{"title":"[buildfile]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#buildfile","content":"This section includes settings that control build file behavior. "},{"title":"includes​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#includes","content":"This sets a list of paths to files that will be automatically included by every build file. This is equivalent to calling include_defs() in every build file.NOTE: We recommend that you do not use this property. This property can make your builds difficult to maintain and debug, and it will be deprecated in a future release of Buck. [buildfile]includes = //core/DEFS  "},{"title":"name​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#name","content":"The name of build files within a project. This defaults to BUCK. We recommend that you use the default name. However, you could specify a different name—such as TARGETS shown below—in order to support, for example, a legacy project that used different buildfile naming conventions. [buildfile]name = TARGETS  "},{"title":"[cache]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cache","content":"This section configures build artifact caching. Caching can be configured to use the local filesystem, an SQLite database, or a remote distributed cache that can be shared among developers. Caching is disabled by default. The [cache].mode setting—described below—determines which properties are relevant to the caching configuration; other properties are ignored by Buck. "},{"title":"mode​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#mode","content":"A comma-separated list of caching policies to use. Valid values are: dir (default): Use a directory-based cache on the local filesystem.http: Use an http-based cache. See Binary HTTP Cache API.thrift_over_http: Use an http-based cache that uses thrift for object metadata. See Thrift over HTTP Cache API.sqlite: Use a SQLite-based cache that inlines small artifacts in the database and stores large artifacts on the local filesystem. [cache]mode = dir, http, sqlite  "},{"title":"dir​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#dir","content":"The path to use for directory-based caching. The path can be: An absolute path in your local file system, such as /Volumes/mySSD/cache. A path relative to your home directory, that uses tilde (~) expansion. such as ~/local/cache. A path that is relative to the root of your Buck project, such as buck-out/cache, which is the default.[cache].mode must contain dir. [cache]dir = buck-out/cache  "},{"title":"dir_cache_names​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#dir_cache_names","content":"A comma-separated list of names used to configure multiple dir caches. The caches will be used serially in the order in which their names are specified here. If an artifact is found further along in the list, an attempt to store it in the caches earlier in the list will be made. In the following example, if the artifact is found in the warm cache, it will not be stored in the local cache. Note: if [cache] dir or [cache] dir_mode are found, then Buck will fall back to single dir cache more and [cache] dir_cache_names will be completely ignored.[cache].mode must contain dir. [cache]mode = dir dir_cache_names = warm, local [cache#warm]dir = ~/prefetched_cache dir_mode = readonly [cache#local]dir = ~/buck_cache dir_mode = readwrite  "},{"title":"dir_max_size​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#dir_max_size","content":"The maximum cache size for directory-based caching. The default size is unlimited.[cache].mode must contain dir. [cache]dir_max_size = 10GB  "},{"title":"dir_mode​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#dir_mode","content":"Dictates if the cache is readonly, passthrough, or readwrite (default) when using directory-based caching.[cache].mode must contain dir. [cache]dir_mode = readwrite  "},{"title":"serve_local_cache​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#serve_local_cache","content":"Make the directory-based cache available to other hosts on the network via Buck's HTTP server (enabled under [httpserver]).[cache].mode must contain dir. [cache]serve_local_cache = false  "},{"title":"served_local_cache_mode​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#served_local_cache_mode","content":"Dictates if the cache is readonly (default) or readwrite when [cache].serve_local_cache is enabled.[cache].mode must contain dir. [cache]served_local_cache_mode = readwrite  "},{"title":"http_url​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_url","content":"The URL to use to contact the cache when using http-based caching. Buck communicates with the server using a simple API.[cache].mode must contain http. [cache]http_url = http://localhost:8080  "},{"title":"http_mode​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_mode","content":"Dictates if the cache is readonly or readwrite (default) when using http-based caching.[cache].mode must contain http or thrift_over_http. [cache]http_mode = readwrite  "},{"title":"http_read_headers​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_read_headers","content":"A semicolon-separated set of HTTP headers to use when reading from the cache when using http-based caching. The default is no headers.[cache].mode must contain http. [cache]http_read_headers = User-Agent: buck  "},{"title":"http_write_headers​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_write_headers","content":"A semicolon-separated set of HTTP headers to use when writing to the cache when using http-based caching. The default is no headers.[cache].mode must contain http. [cache]http_write_headers = Authorization: XXXXXXX; User-Agent: buck  "},{"title":"http_timeout_seconds​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_timeout_seconds","content":"Dictates the timeout per connection when using http-based caching. It will be the default value for http_connect_timeout_seconds, http_read_timeout_seconds, http_write_timeout_seconds if they're not set. The default is 3.[cache].mode must contain http. [cache]http_timeout_seconds = 3  "},{"title":"http_connect_timeout_seconds​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_connect_timeout_seconds","content":"Dictates the timeout on http connect when using http-based caching. If the value is not set, it will try to use the value set for http_timeout_seconds then use the default value 3.[cache].mode must contain http. [cache]http_connect_timeout_seconds = 3  "},{"title":"http_read_timeout_seconds​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_read_timeout_seconds","content":"Dictates the timeout on http writes when using http-based caching. If the value is not set, it will try to use the value set for http_timeout_seconds then use the default value 3.[cache].mode must contain http. [cache]http_read_timeout_seconds = 3  "},{"title":"http_write_timeout_seconds​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_write_timeout_seconds","content":"Dictates the timeout on http reads when using http-based caching. If the value is not set, it will try to use the value set for http_timeout_seconds then use the default value 3.[cache].mode must contain http. [cache]http_write_timeout_seconds = 3  "},{"title":"http_max_concurrent_writes​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_max_concurrent_writes","content":"The number of writer threads to use to upload to the http cache when using http-based caching. The default is 1. Note that when using multiple http caches (see below), the writer thread pool is shared between them all.[cache].mode must contain http. [cache]http_max_concurrent_writes = 1  "},{"title":"http_writer_shutdown_timeout_seconds​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_writer_shutdown_timeout_seconds","content":"The length of time to wait after the build completes for any remaining http cache uploads to complete before forcefully shutting down the writer thread pool when using http-based caching. The default is 1800 (30 minutes).[cache].mode must contain http. [cache]http_writer_shutdown_timeout_seconds = 1800  "},{"title":"http_error_message_format​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_error_message_format","content":"This setting allows for the customization of how http cache errors appear to the user. If the text {cache_name} is present, it will be replaced with the name of the cache. If the text {error_message}, it will be replaced with the error message.[cache].mode must contain http or thrift_over_http. [cache]http_error_message_format = The cache named {cache_name} encountered an error: {error_message}  "},{"title":"http_error_message_limit​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_error_message_limit","content":"This setting allows to set after how many errors Buck will print the http_error_message_format. Every time it prints it the counter resets to 0 to avoid spamming the console.[cache].mode must contain http or thrift_over_http. [cache]http_error_message_limit = 100  "},{"title":"http_max_store_attempts​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_max_store_attempts","content":"Maximum number of times to attempt to store item to the cache before giving up.[cache].mode must contain http or thrift_over_http. [cache]http_max_store_attempts = 1  "},{"title":"http_store_retry_interval_millis​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_store_retry_interval_millis","content":"Interval to wait if previous cache store request failed.[cache].mode must contain http or thrift_over_http. [cache]http_store_retry_interval_millis = 1000  "},{"title":"http_max_store_size​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_max_store_size","content":"The max size in bytes that an artifact can be to get pushed to an http cache.[cache].mode must contain http or thrift_over_http. [cache]http_max_store_size = 5000000  "},{"title":"http_client_tls_cert​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_client_tls_cert","content":"The path to a PEM encoded client X.509 TLS certificate that should be used for any HTTP requests to a remote cache. This operates on both read and write connections. This can be useful within a server to restrict access to a write path, log which users are writing which artifacts, and generally authenticate cache clients.Note: http_client_tls_key must be set for this setting to be used.[cache].mode must contain http or thrift_over_http. [cache]http_client_tls_cert = /etc/pki/client.crt  "},{"title":"http_client_tls_key​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#http_client_tls_key","content":"The path to a PEM encoded PKCS#8 key that should be used for any HTTP requests to a remote cache. This operates on both read and write connections. This can be useful within a server to restrict access to a write path, log which users are writing which artifacts, and generally authenticate cache clients.Note: http_client_tls_cert must be set for this setting to be used.[cache].mode must contain http or thrift_over_http. [cache]http_client_tls_key = /etc/pki/client.key  "},{"title":"hybrid_thrift_endpoint​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#hybrid_thrift_endpoint","content":"The HTTP endpoint to call if using Thrift over HTTP Cache API.[cache].mode must contain thrift_over_http. [cache]hybrid_thrift_endpoint = /hybrid_endpoint  "},{"title":"sqlite_inlined_size​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#sqlite_inlined_size","content":"The maximum size for artifacts to be inlined. The default size is 40B.[cache].mode must contain sqlite. [cache]sqlite_inlined_size = 10kB  "},{"title":"sqlite_max_size​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#sqlite_max_size","content":"The maximum cache size for SQLite-based caching. The default size is unlimited.[cache].mode must contain sqlite. [cache]sqlite_max_size = 10GB  "},{"title":"sqlite_mode​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#sqlite_mode","content":"Dictates if the cache is readonly, passthrough or readwrite (default) when using SQLite-based caching[cache].mode must contain sqlite. [cache]sqlite_mode = readwrite  "},{"title":"sqlite_cache_names​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#sqlite_cache_names","content":"A comma-separated list of names used to configure multiple SQLite caches. The caches will be used serially in the order in which their names are specified here. If an artifact is found further along in the list, an attempt to store it in the caches earlier in the list will be made. In the following example, if the artifact is found in the warm cache, it will not be stored in the local cache.[cache].mode must contain sqlite. [cache]mode = sqlite sqlite_cache_names = warm, local [cache#warm]sqlite_mode = readonly [cache#local]sqlite_mode = readwrite  "},{"title":"two_level_cache_enabled​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#two_level_cache_enabled","content":"Have the Buck client perform 2-level stores and lookups on the artifacts. Every cache operation consists of 2 steps: content hash-based and RuleKey-based. This makes it easier to reuse locally cached artifacts across different buck versions at the expense of higher latencies in the case where artifacts are not present in the local cache. [cache]two_level_cache_enabled = false  "},{"title":"two_level_cache_minimum_size​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#two_level_cache_minimum_size","content":"When performing a store artifacts smaller than this size will be stored directly, without the content hash redirection. [cache]two_level_cache_minimum_size = 1024  "},{"title":"two_level_cache_maximum_size​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#two_level_cache_maximum_size","content":"When performing a store artifacts bigger than this size will be stored directly, without the content hash redirection. [cache]two_level_cache_maximum_size = 1024  "},{"title":"action_graph_cache_check_enabled​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#action_graph_cache_check_enabled","content":"It enables an integrity checking mechanism in the action graph cache that compares the a newly generated action graph with the one already in the cache in the case of a cache hit. If the graphs do not match the build is stopped and the mismatching rules are printed and logged. [cache]action_graph_cache_check_enabled = false  "},{"title":"max_action_graph_cache_entries​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#max_action_graph_cache_entries","content":"Sets the maximum number of action graphs to cache. After this number, the least-recently-used graph will be evicted. Defaults to 1. [cache]max_action_graph_cache_entries = 3  "},{"title":"load_balancing_type​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#load_balancing_type","content":"Decides whether the distributed cache connects to a single URL or it has a pool of servers and chooses which one to use based on client side load balancing. NOTE: 'slb_*' configs only apply when CLIENT_SLB is enabled. [cache]load_balancing_type = SINGLE_SERVER, CLIENT_SLB  "},{"title":"slb_server_pool​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#slb_server_pool","content":"A comma separated list of server URLs of valid servers. The client side load balancer will try to pick the best server to connect to for every single connection. [cache]slb_server_pool = http://my.server.one/,http://my.server.two  "},{"title":"slb_ping_endpoint​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#slb_ping_endpoint","content":"The client side load balancer will use this endpoint to check whether the server is in healthy state or not. It will also be used to measure request latency. [cache]slb_ping_endpoint = /ping.php  "},{"title":"slb_health_check_internal_millis​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#slb_health_check_internal_millis","content":"The timeout in milliseconds between two consecutive client side load balancer health checks to the slb_server_pool. [cache]slb_health_check_internal_millis = 1000  "},{"title":"slb_timeout_millis​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#slb_timeout_millis","content":"The connection timeout per health request made to each of the slb_server_pool servers. Any server that fails to respond within this period will be deemed unhealthy and not be used for cache requests. [cache]slb_timeout_millis = 1000  "},{"title":"slb_error_check_time_range_millis​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#slb_error_check_time_range_millis","content":"The error rate to each individual server taking part in the slb_server_pool will be measured in the time range/window specified by this config. In different words, 'errors per second' is computed only for the last slb_error_check_time_range_millis. [cache]slb_error_check_time_range_millis = 300000  "},{"title":"slb_max_error_percentage​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#slb_max_error_percentage","content":"The max error percentage allowed within the last slb_error_check_time_range_millis that is acceptable to keep a particular server marked as healthy and usable by the load balancer. Expects a float value in the interval [0, 1]. [cache]slb_max_error_percentage = 0.1  "},{"title":"slb_latency_check_time_range_millis​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#slb_latency_check_time_range_millis","content":"The latency to each individual server taking part in the slb_server_pool will be measured in the time range/window specified by this config. In different words, 'server latency' is computed only for the last slb_latency_check_time_range_millis. [cache]slb_latency_check_time_range_millis = 300000  "},{"title":"slb_max_acceptable_latency_millis​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#slb_max_acceptable_latency_millis","content":"If the latency of a ping request to a server in slb_server_pool is higher than this, the server is deemed unhealthy and not used for cache operations. [cache]slb_max_acceptable_latency_millis = 1000  "},{"title":"[client]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#client","content":"This section includes settings that provide information about the caller. Although these can be specified in .buckconfig, in practice, they are specified exclusively on the command line: $ buck --config client.id=tool-making-this-buck-invocation build buck  "},{"title":"id​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#id","content":"It is good practice for tools that call Buck to identify themselves via --config client.id=&lt;toolname&gt;. This makes it easier for developers to audit the source of Buck invocations that they did not make directly. Note that the value of client.id is not factored into a build rule's cache key. It is purely for auditing purposes. "},{"title":"skip-action-graph-cache​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#skip-action-graph-cache","content":"When Buck is run as a daemon, it caches the last Action Graph it used for a build so that if the next build identifies the same set of targets, the [possibly expensive] Action Graph construction step can be avoided. Because only the last Action Graph is cached, it may be costly to interleave a small build job among a series of incremental builds of an expensive rule: $ buck build //big:expensive-rule # Initial Action Graph. $ buck build //big:expensive-rule # Action Graph is reused. $ buck build //library#compilation-database # Evicts costly Action Graph. $ buck build //big:expensive-rule # Action Graph is rebuilt.  Although this scenario may sound contrived, it is very common when other tools may also be running buck build in the background. Work done by IDEs and linters frequently fall into this category. In this case, the best practice is to add --config client.skip-action-graph-cache=true for any sort of &quot;one-off&quot; build for which the cost of caching the Action Graph for the new build likely outweighs the benefit of evicting the Action Graph from the previous build. As this is commonly the case for tools, this flag is frequently used in concert with --config client.id: $ buck build //big:expensive-rule # Initial Action Graph. $ buck build //big:expensive-rule # Action Graph is reused. $ buck build \\ # Cached Graph is unaffected.--config client.skip-action-graph-cache=true \\ --config client.id=nuclide \\ //library#compilation-database $ buck build //big:expensive-rule # Action Graph is reused.  "},{"title":"[color]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#color","content":"This section configures colored output of Buck. "},{"title":"ui​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ui","content":"Enables (default) or disables colorized output in the terminal. [color]ui = true  "},{"title":"[credentials]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#credentials","content":"This section configures credentials to be used when fetching from authenticated Maven repositories via HTTPS. For a repository repo appearing in [maven_repositories], Buck reads the values of repo_user and repo_pass in this section (if present), and passes them to the server using basic access authentication when fetching. Note that authenticating in this way over plain HTTP connections is disallowed and will result in an error. [maven_repositories]repo = https://example.com/repo[credentials]repo_user = joeuser repo_pass = hunter2  "},{"title":"[cxx]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cxx","content":"This section configures the paths to the C and C++ toolchains' binaries and the default flags to pass to all invocations of them. C/C++ platform flavors in .buckconfig​ Buck enables you to create additional platform flavors for C/C++ in .buckconfig. A platform flavor groups together a set of configuration parameters, which you can then reference at build time. To create a new C/C++ platform flavor, add a section with the header [cxx#**flavor**]  to .buckconfig. If you invoke Buck with the specified flavor appended to the build target, Buck uses the values in this section instead of those in [cxx]. For example, to build with the values in [cxx#my-custom-flavor] instead of [cxx], you could invoke Buck using the following command: $ buck build app#my-custom-flavor  You can also use these platform flavors, in the platform_* arguments of the cxx_binary and cxx_library rules. The Buck sample for C++ demonstrates how to use a custom platform flavor. "},{"title":"cpp​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cpp","content":"The path to the C preprocessor. [cxx]cpp = /usr/bin/gcc  "},{"title":"cc​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cc","content":"The path to the C compiler. [cxx]cc = /usr/bin/gcc  "},{"title":"ld​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ld","content":"The path to the C/C++ linker driver. [cxx]ld = /usr/bin/g++  "},{"title":"linker_platform​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#linker_platform","content":"The platform for the linker. Normally this is autodetected based on the system, but it useful to set when cross compiling. Valid values are: DARWINGNUWINDOWS [cxx]linker_platform = DARWIN  "},{"title":"cxxpp​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cxxpp","content":"The path to the C++ preprocessor. [cxx]cxxpp = /usr/bin/g++  "},{"title":"cxx​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cxx-1","content":"The path to the C++ compiler. [cxx]cxx = /usr/bin/g++  "},{"title":"aspp​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#aspp","content":"The path to the assembly preprocessor. [cxx]aspp = /usr/bin/gcc  "},{"title":"as​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#as","content":"The path to the assembler. [cxx]as = /usr/bin/as  "},{"title":"ar​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ar","content":"The path to the archiver. [cxx]ar = /usr/bin/ar  "},{"title":"archiver_platform​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#archiver_platform","content":"The platform for the archiver. Normally this is autodetected based on the system, but it useful to set when cross compiling. Valid values are: LINUXMACOSFREEBSDWINDOWS [cxx]archiver_platform = MACOS  "},{"title":"cppflags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cppflags","content":"The flags to pass to the C preprocessor. [cxx]cppflags = -Wall  "},{"title":"cflags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cflags","content":"The flags to pass to the C compiler and preprocessor. [cxx]cflags = -Wall  "},{"title":"ldflags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ldflags","content":"The flags to pass to the linker. [cxx]ldflags = --strip-all  "},{"title":"cxxppflags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cxxppflags","content":"The flags to pass to the C++ preprocessor. [cxx]cxxppflags = -Wall  "},{"title":"cxxflags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cxxflags","content":"The flags to pass to the C++ compiler and preprocessor. [cxx]cxxflags = -Wall  "},{"title":"asppflags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#asppflags","content":"The flags to pass to the assembly preprocessor. [cxx]asppflags = -W  "},{"title":"asflags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#asflags","content":"The flags to pass to the assembler and assembly preprocessor. [cxx]asflags = -W  "},{"title":"arflags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#arflags","content":"The flags to pass to the archiver. [cxx]arflags = -X32_64  "},{"title":"ranlibflags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ranlibflags","content":"The flags to pass to the archive indexer. [cxx]ranlibflags = --plugin someplugin  "},{"title":"gtest_dep​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#gtest_dep","content":"The build rule to compile the Google Test framework. [cxx]gtest_dep = //third-party/gtest:gtest  If you had your Google Test code in third-party/gtest/, the build file in that directory would look something like this: cxx_library( name = 'gtest', srcs = ['googletest/src/gtest-all.cc','googlemock/src/gmock-all.cc','googlemock/src/gmock_main.cc',], header_namespace = '', exported_headers = subdir_glob([('googletest/include', '**/*.h'),('googlemock/include', '**/*.h'),]), headers = subdir_glob([('googletest', 'src/*.cc'),('googletest', 'src/*.h'),('googlemock', 'src/*.cc'),('googlemock', 'src/*.h'),]), platform_linker_flags = [('android', []),('', ['-lpthread']),], visibility = ['//test/...',],)  "},{"title":"untracked_headers​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#untracked_headers","content":"How to handle header files that get included in a preprocessing step, but which aren't explicitly owned by any dependencies. By default, Buck sandboxes headers into symlink trees, but file relative inclusion and explicit preprocessor flags can still cause untracked headers to get pulled into the build which can break caching. ignore (default): Untracked headers are allowed in the build.warn: Print a warning to the console when an untracked header is used.error: Fail the build when an untracked header is used. [cxx]untracked_headers = error  "},{"title":"untracked_headers_whitelist​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#untracked_headers_whitelist","content":"A list of regexes which match headers to exempt from untracked header verification. [cxx]untracked_headers_whitelist = /usr/include/.*, /usr/local/include/.*  "},{"title":"should_remap_host_platform​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#should_remap_host_platform","content":"Specifies whether the default flavor should be remapped to the value of the [cxx].host_platform configuration parameter. [cxx] should_remap_host_platform = true  Default is false. Because Buck is designed for cross-platform development, Buck normally ignores the host platform when building a target. For example, Buck normally builds the same Linux target irrespective of whether Buck itself is running on, say, Linux or macOS. The should_remap_host_platform configuration parameter enables you to change Buck's behavior so that Buck's target platform is the host platform on which Buck is running. "},{"title":"host_platform​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#host_platform","content":"Specifies the host platform to use if [cxx].should_remap_host_platform is true. The value that you specify could be one of Buck's internal platform flavors, such as linux-x86_64 or macosx-x86_64: [cxx] host_platform = linux-x86_64 [cxx] host_platform = macosx-x86_64  or the value could be a custom platform flavor: [cxx] host_platform = my-custom-flavor  If [cxx].should_remap_host_platform is true, but host_platform is unspecified, then Buck infers the host platform from the local computer to be one of the following values: linux-x86_64 (Linux)macosx-x86_64 (macOS)freebsd-x86_64 (FreeBSD)windows-x86_64 (Windows) If [cxx].should_remap_host_platform is unset—or explicitly set to false—then Buck ignores the value of host_platform . "},{"title":"default_platform​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_platform","content":"Override the default platform for build rules. [cxx]default_platform = iphonesimulator-x86_64  "},{"title":"pch_enabled​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#pch_enabled","content":"Whether prefix headers used by a cxx_library or other such build rule's prefix_header parameter should be separately precompiled, and used in that rule's build. If this is disabled, the prefix header is included as-is, without precompilation. Default is true. [cxx]pch_enabled = false  "},{"title":"link_weight​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#link_weight","content":"The number of jobs that each C/C++ link rule consumes when running. By default, this is 1, but this can overridden to change how many link rules can execute in parallel for a given -j value. This is useful for builds with large I/O intensive static links where using a lower -j value is undesirable (since it reduces the parallelism for other build rule types). [cxx]link_weight = 3  "},{"title":"cache_links​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cache_links","content":"C/C++ link rules are cached by default. However, static C/C++ link jobs can take up lots of cache space and also get relatively low hit rates, so this config option provides a way to disable caching of all C/C++ link rules in the build. [cxx]cache_links = false  "},{"title":"default_reexport_all_header_dependencies​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_reexport_all_header_dependencies","content":"Default value used for reexport_all_header_dependencies, when it's undefined on the build rule. [cxx]default_reexport_all_header_dependencies = true  "},{"title":"shlib_interfaces​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#shlib_interfaces","content":"When linking a executable or shared library, any dependencies that build shared libraries are normally added to the link line. If this option is set, Buck will use shared library interfaces for these dependencies instead of full shared libraries. Shared library interfaces are a subset of the original shared library, removing parts of the shared library (e.g. the .text segment for ELF) which are typically unused used when this library is being linked against. Using shared library interfaces can allow Buck's input-based rule keys to avoid potentially unnecessary re-links (see CxxSharedLibraryInterfaceIntegrationTest for examples). [cxx]shlib_interfaces = enabled  "},{"title":"independent_shlib_interfaces​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#independent_shlib_interfaces","content":"Normally, a shared library interface for a rule is generated using it's shared library. Since linking a rule's shared library requires the shared library interfaces for all dependencies be built, this means that dynamic linking has inherent non-parallelism, due to this build dependency tree. When this option is set, Buck will build shared library interfaces independent of the rule's shared library (e.g. by linking it's own shared library without any dependency shared libraries), allowing all shared library interfaces to be built in parallel, and therefore also allowing subsequent shared libraries to be built in parallel. [cxx]independent_shlib_interfaces = true  "},{"title":"[d]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#d","content":"This section configures how code written in D is compiled. "},{"title":"base_compiler_flags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#base_compiler_flags","content":"Flags to pass to every invocation of the D compiler. This is a space-separated list. It defaults to an empty list. [d]base_compiler_flags = -I/some/path -g -O3  "},{"title":"compiler​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#compiler","content":"Path to the D compiler. If this parameter is not specified, Buck attempts to find the D compiler automatically. [d]compiler = /opt/dmd/bin/dmd  "},{"title":"library_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#library_path","content":"Directories to be searched for the D runtime libraries. This is a colon-separated list. If this parameter is not specified, Buck attempts to detect the location of the libraries automatically. [d]library_path = /usr/local/lib:/opt/dmd/lib  "},{"title":"linker_flags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#linker_flags","content":"Flags to pass to the linker when linking D code into an executable. This is a space-separated list. If omitted, this value is constructed from d.library_path. [d]linker_flags = &quot;-L/path to phobos&quot; -lphobos2  "},{"title":"[doctor]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#doctor","content":"This section defines variables that are associated with command doctor. "},{"title":"protocol​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#protocol","content":"The protocol of communication, it can be either simple or JSON. [doctor]protocol = json  "},{"title":"endpoint_url​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#endpoint_url","content":"The address of the remote endpoint that the request will go. This needs to be defined in order for the command to work. [doctor]endpoint_url = http://localhost:4545  "},{"title":"endpoint_timeout_ms​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#endpoint_timeout_ms","content":"The timeout in milliseconds before giving up contacting the analysis endpoint. [doctor]endpoint_timeout_ms = 15  "},{"title":"endpoint_extra_request_args​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#endpoint_extra_request_args","content":"This sections of keys and values is added as parameters to the POST request send to the doctor remote endpoint. [doctor]endpoint_extra_request_args = ref=&gt;1245,token=&gt;42  "},{"title":"report_upload_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#report_upload_path","content":"The address of the remote endpoint the report will be uploaded. [doctor]report_upload_path = http://localhost:4546  "},{"title":"report_max_size​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#report_max_size","content":"The maximum size that the report endpoint can handle before giving up and storing it only locally. [doctor]report_max_size = 512MB  "},{"title":"report_timeout_ms​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#report_timeout_ms","content":"The timeout in milliseconds before giving up contacting the report endpoint. [doctor]report_timeout_ms = 15  "},{"title":"report_max_upload_retries​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#report_max_upload_retries","content":"Times to try to upload to the report endpoint. [doctor]report_max_upload_retries = 2  "},{"title":"report_extra_info_command​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#report_extra_info_command","content":"An extra command that the report should and attach the information to the uploaded report. [doctor]report_extra_info_command = /custom/script/to/run.sh  "},{"title":"[download]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#download","content":"This section configures downloading from the network during buck fetch. "},{"title":"proxy​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#proxy","content":"Buck will attempt to fetch files from the network, however, if you happen to be behind a] firewall, this may not work correctly. You can supply a proxy when downloading from HTTP[S] servers with these three settings. Valid types for proxy_type are HTTP (default) and SOCKS. These values correspond to Java's Proxy.Type. [download]proxy_host=proxy.example.com proxy_port=8080 proxy_type=HTTP  "},{"title":"maven_repo​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#maven_repo","content":"If a remote file's URL starts with mvn:, that file (usually a jar) is supposed to come from a maven repo. You can specify the repo to download from here, or by setting one or more repositories in [maven_repositories]. [download]maven_repo = https://repo1.maven.org/maven2  "},{"title":"max_number_of_retries​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#max_number_of_retries","content":"In case buck is unable to download a file, it will retry specified number of times before giving up. By default it's not set, so Buck is not going to retry failed downloads. [download]max_number_of_retries = 3  "},{"title":"in_build​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#in_build","content":"If true, allow downloads to be part of the build process. If false, buck build / run / test will require the user to run 'buck fetch' first. This generally should not be changed, to avoid surprising users with unexpected build times, when the cause is mostly download times. By default this set to false. [download]in_build = true  "},{"title":"[dx]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#dx","content":"This section controls how Buck invokes the dx tool. "},{"title":"threads​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#threads-1","content":"Fixed number of threads to run dexing steps with. If not specified, the optimal number is inferred from hardware specification of running machine. [dx]threads = 4  "},{"title":"max_threads​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#max_threads","content":"The maximum number of threads allowed to run the dexing steps with. Since the dexing steps can use a lot of memory, it might be useful to set this to a lower value to avoid out-of-memory on systems that have a lot of CPU cores. This parameter is mostly useful when [dx].threads is not specified and the number of threads is obtained based on hardware. [dx]max_threads = 8  "},{"title":"max_heap_size​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#max_heap_size","content":"This option specifies how much memory is available when running dx out of process. [dx]max_heap_size = 2g  "},{"title":"[export_file]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#export_file","content":"This section configures behavior of export_file build rule. "},{"title":"input_directory_action​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#input_directory_action","content":"Defines the behavior of export_file when input of a build rule is a directory. Support for directories will be removed soon and this option provides a way to migrate a project to a state when none of the export_file rules use directories as inputs. The valid values are: allow (default): directories are allowed and no action is taken,warn: emit a warning to the console,fail: fail the build. [export_file]input_directory_action = fail  "},{"title":"[go]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#go","content":"This section defines the Go toolchain. By default Buck will try to discovery the Go compiler and linker from the go tool found in your PATH. "},{"title":"root​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#root","content":"If you have a non-standard Go install, you will need to set the Go root. The root should contain pkg and bin directories. [go]root = /opt/golang/libexec  "},{"title":"prefix​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#prefix","content":"For interoperability with the go tool, you may specify a prefix for your default package names. [go]prefix = github.com/facebook/buck  "},{"title":"tool​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#tool","content":"You can specify the path to find the go tool. This in turn will allow Buck to discover the compiler/linker by default. This defaults to ${go.root}/bin/go. [go]tool = /usr/local/bin/go  "},{"title":"compiler​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#compiler-1","content":"The full path to the Go compiler. This is normally automatically discovered. [go]compiler = /usr/local/libexec/go/pkg/tool/darwin_amd64/compile  "},{"title":"assembler​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#assembler","content":"The full path to the Go assembler. This is normally automatically discovered. [go]assembler = /usr/local/libexec/go/pkg/tool/darwin_amd64/asm  "},{"title":"packer​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#packer","content":"The full path to the Go packer. This is normally automatically discovered. [go]packer = /usr/local/libexec/go/pkg/tool/darwin_amd64/pack  "},{"title":"linker​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#linker","content":"The full path to the Go linker. This is normally automatically discovered. [go]linker = /usr/local/libexec/go/pkg/tool/darwin_amd64/link  "},{"title":"vendor_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#vendor_path","content":"A list of colon (:) separated list of directories to include for including in the importmap for Go dependencies. Packages in these directories are allowed to be imported given just the relative path to the package. This is similar to how 'vendor' directories work. e.g you can use import golang.org/x/net for a package that lives in/golang.org/x/net. [go]vendor_path = third-party/go  "},{"title":"project_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#project_path","content":"You can specify the path where buck project will store dynamically generated files (ex. genrule). This is extension to $GOPATH, particularly usefully while working with native go toolchain or IDE's. [go]project_path = third-party/go  "},{"title":"[groovy]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#groovy","content":"This section configures the Groovy toolchain. "},{"title":"groovy_home​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#groovy_home","content":"This defines the value of GROOVY_HOME that Buck should use. If it is not provided, Buck will use the system's GROOVY_HOME by default. [groovy]groovy_home = /path/to/groovy_home  "},{"title":"[halide]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#halide","content":"This section configures the Halide platform mappings and toolchain. "},{"title":"target​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#target","content":"This defines the C++ platform flavor to Halide target mapping. Each key should begin with the prefix target_, followed by the flavor name. The corresponding value should be the Halide target string to use when building for that flavor. [halide]target_iphonesimulator-x86_64 = x86-64-osx target_iphoneos-arm64 = arm-64-ios  "},{"title":"xcode_compile_script​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#xcode_compile_script","content":"The optional path to a shell script which should be used for invoking the Halide AOT &quot;compiler&quot; when building projects that include Halide targets in Xcode. [halide]xcode_compile_script = //path/to/script.sh  "},{"title":"[httpserver]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#httpserver","content":"Option to enable an experimental web server that presents a UI to explore build data. Note that Buck must be run as a daemon in order for the web server to be available. "},{"title":"port​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#port","content":"This sets the port to use for the web server. There are three possible values: n &gt; 0: For any positive integer, Buck will attempt to make the server available on that port.0: Buck will find a free port for the server to use and print it out on the command line.-1: Explicitly disables the server. [httpserver]port = 8080  "},{"title":"[incompatible]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#incompatible","content":"This section controls features of buck that are in the process of being deprecated. "},{"title":"[intellij]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#intellij","content":"This section configures a project generated for IntelliJ IDEA by buck project command. "},{"title":"default_android_manifest_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_android_manifest_path","content":"The default manifest file that should be used in Android IntelliJ modules when buck cannot detect the correct manifest to use. [intellij]default_android_manifest_path = shared/AndroidManifest.xml  "},{"title":"jdk_name​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#jdk_name","content":"IntelliJ project SDK name. [intellij]jdk_name = Java SDK 1.6  "},{"title":"jdk_type​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#jdk_type","content":"IntelliJ project SDK type. [intellij]jdk_type = Android SDK or JavaSDK  "},{"title":"android_module_sdk_type​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#android_module_sdk_type","content":"Default Android SDK type for android modules. [intellij]android_module_sdk_type = Android SDK  "},{"title":"android_module_sdk_name​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#android_module_sdk_name","content":"Default Android SDK name for android modules. [intellij]android_module_sdk_name = Android API 23 Platform  "},{"title":"java_module_sdk_type​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#java_module_sdk_type","content":"SDK type for Java modules. [intellij]java_module_sdk_type = JavaSDK  "},{"title":"java_module_sdk_name​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#java_module_sdk_name","content":"SDK name for Java modules. [intellij]java_module_sdk_name = 1.8  "},{"title":"default_min_android_sdk_version​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_min_android_sdk_version","content":"Default minimum Android SDK version supported for this project. Overwritten by min SDK version if specified in target's AndroidManifest.xml. [intellij]default_min_android_sdk_version = 9  "},{"title":"generated_sources_label_map​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#generated_sources_label_map","content":"Allows adding folders with generated source code to IntelliJ project. These folders are added when a target has a label specified in this option. In the example below, if target //app/target has label generated_code1 folder buck-out/gen/app/lib/__lib_target1__ will be added to IntelliJ project. [intellij]generated_sources_label_map = generated_code_1 =&gt; __%name%_target1__, generated_code2 =&gt; __%name%_target2__  "},{"title":"include_transitive_dependencies​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#include_transitive_dependencies","content":"Add transitive dependencies as RUNTIME library. [intellij]include_transitive_dependencies = false  "},{"title":"module_group_name​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#module_group_name","content":"Specify module group name when grouping modules. If it is set to '', modules are not grouped. [intellij]module_group_name = modules  "},{"title":"remove_unused_libraries​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#remove_unused_libraries","content":"Removes unused libraries from .idea/libraries. [intellij]remove_unused_libraries = true  "},{"title":"aggregate_android_resource_modules​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#aggregate_android_resource_modules","content":"Forces buck project to aggregate modules with Android resources. This aggregation is performed only if aggregation mode is not none.Note: using this type of aggregation disables Android layout editor provided by Android plugin. The layout files can still be edited using the XML editor. [intellij]aggregate_android_resource_modules = true  "},{"title":"android_resource_module_aggregation_limit​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#android_resource_module_aggregation_limit","content":"The maximum number of targets that can be aggregated into one module with Android resources. This limit is a workaround to avoid a problem when Android plugin cannot operate on modules with a big number of resource folders. [intellij]android_resource_module_aggregation_limit = 1000  "},{"title":"project_compiler_output_url​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#project_compiler_output_url","content":"The output directory for IntelliJ's builds. [intellij]project_compiler_output_url = intellij-out/classes  "},{"title":"extra_compiler_output_modules_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#extra_compiler_output_modules_path","content":"This option specifies the location of additional modules for code generated outside of buck graph. For example, it can be used to specify the location of R.java classes generated for Android plugin to help Layout Preview with resolving references to resources. [intellij]extra_compiler_output_modules_path = buck-out/extra-intellij-output  "},{"title":"[java]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#java","content":"This section configures the Java toolchain. "},{"title":"src_roots​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#src_roots","content":"The paths to roots of Java code (where a root contains a tree of Java folders where the folder structure mirrors the package structure). This list of paths is comma-delimited. Paths that start with a slash are relative to the root of the project, and all other paths can match a folder anywhere in the tree. In the example below, we match all folders named src, and java and javatests at the root of the project. [java]src_roots = src, /java/, /javatests/  "},{"title":"extra_arguments​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#extra_arguments","content":"A comma-delimited list of flags to pass the Java compiler. [java]extra_arguments = -g  "},{"title":"source_level​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#source_level","content":"The default version of Java for source files. Also defines the project language level in IntelliJ. [java]source_level = 7  "},{"title":"target_level​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#target_level","content":"The default version of Java for generated code. [java]target_level = 7  "},{"title":"skip_checking_missing_deps​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#skip_checking_missing_deps","content":"Buck will attempt to analyze build failures and suggest dependencies that might not be declared in order to fix the failure. On large projects, this can be slow. This setting disables the check. [java]skip_checking_missing_deps = false  "},{"title":"jar_spool_mode​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#jar_spool_mode","content":"Specifies how the compiler output to the .jar file should be spooled. The valid modes are: intermediate_to_disk (default): writes the intermediate .class files from the compiler output to disk. They are then packed into a .jar.direct_to_jar: compiler output will be directly written to a .jar file with the intermediate .class files held in memory. The compiler output will still be written to disk if there are any post-processing commands specified during the build. [java]jar_spool_mode = intermediate_to_disk  "},{"title":"abi_generation_mode​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#abi_generation_mode","content":"Specifies how Buck should create ABI jars when computing ABI rule keys. Values other than class may not be suitable for all rules; this setting may be overridden on a per-rule basis using the abi_generation_mode parameter on each rule. The valid modes are: class (default): creates an ABI jar for each library by first building the library and then stripping out any information that is not part of the interface (such as method bodies and private members). source: creates an ABI jar for each library in the process of building the library, via a plugin to the Java compiler. This improves build times by allowing each library's dependents to start building before the library is done building. Implies jar_spool_mode = direct_to_jar.source_only: creates an ABI jar for each library by referencing only the source code of the library, without considering (most of) its dependencies. This can drastically improve build times, especially in larger apps or in build environments with a large number of cores by allowing all ABI jars to be built in parallel, and then all library jars to be built in parallel (up to the available parallelism in the build environment). Additionally, in environments with network-based caches it can reduce the number of calls to the cache required for each build. Requires some changes to how Java code is written. To migrate, first do some builds in migrating_to_source_only mode, using buck fix to fix any issues encountered. Once migrated, errors will still be encountered from time to time when new code does not meet the requirements of this mode.buck fix can be used to address these. When building with source_only, using buck build --keep-going is recommended since some errors that occur when building an ABI jar will actually have their root cause in another rule that builds later. Read more about source-only ABIs here.migrating_to_source_only: used when migrating from source to source_only. Acts like source, but issues warnings (inbuck.log, not to the console) for any Java code that would cause errors undersource_only. buck fix can be used to fix most such warnings. [java]abi_generation_mode = source  "},{"title":"unused_dependencies_action​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#unused_dependencies_action","content":"Action performed when Buck detects that some dependencies are not used during Java compilation. Note that this feature is experimental and does not handle run-time dependencies. The valid values are: ignore (default): ignore unused dependencies,warn: emit a warning to the console,fail: fail the compilation. [java]unused_dependencies_action = warn  "},{"title":"duplicates_log_level​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#duplicates_log_level","content":"Verbosity of logs emitted on duplicates when building binary. The valid values are: info (default): emit an info to the console,warn: emit a warning to the console,fine: emit a fine info to the console, visible only at high verbosity levels. [java]duplicates_log_level = info  "},{"title":"[kotlin]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#kotlin","content":"This section configures various aspects of the Kotlin toolchain. "},{"title":"kotlinc​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#kotlinc","content":"The path to the kotlinc compiler executable to use when external compilation is forced. This setting has no effect by itself and must be paired with the [kotlin].external setting. [kotlin]kotlinc = /usr/local/bin/kotlinc  "},{"title":"external​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#external","content":"Forces external compilation via kotlinc. When external compilation is forced the following heuristics are used to locate the kotlinc executable: If the [kotlin].kotlinc setting is specified, the executable specified by that path will be used.If the [kotlin].kotlin_home path setting is specified, Buck will look for a bin directory under that path for an executable named kotlinc.If a KOTLIN_HOME environment variable is present, Buck will look for a bin directory under that path for an executable named kotlinc.Lastly, if none of the above are specified, Buck will look for the kotlinc executable in the paths listed in the PATH environment variable. Defaults to false. [kotlin]external = true  "},{"title":"kotlin_home​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#kotlin_home","content":"The path to the Kotlin root folder, typically the installation folder, where various Kotlin assets (executables and JAR files) can be found. This path is used in the following ways: When in-memory compilation is used, the kotlin-compiler.jar and other related Kotlin JARs required for compilation are located via this path using the following heuristics: The root of the directory specified by this path is searched.If there is a lib directory under this path, it is searched.If there is a libexec directory under this path, it is searched. If external compilation is called for (see [kotlin].external), a bin directory under this directory will be searched to locate the kotlinc executable. If this setting is not specified, the location of the Kotlin home directory can be specified via the KOTLIN_HOME environment variable. If neither the [kotlin].kotlin_home setting nor the KOTLIN_HOME environment variable is specified, Buck will attempt to locate the home directory by searching for the kotlinc executable in the paths specified by the PATH environment variable. If the kotlinc executable is found, Buck assumes that the parent directory of that executable is the Kotlin home. [kotlin]kotlin_home = /usr/local/Cellar/kotlin/1.1.1  "},{"title":"[log]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#log","content":"This section controls how Buck will log information about builds for later inspection. Settings in this section will appear as features are in the processing of being deprecated, and be removed after features are removed from Buck. "},{"title":"max_traces​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#max_traces","content":"Sets the maximum number of Chrome Traces that Buck will create. [log]max_traces = 25  "},{"title":"compress_traces​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#compress_traces","content":"true if Buck should GZIP the traces, false otherwise. [log]compress_traces = true  "},{"title":"machine_readable_logger_enabled​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#machine_readable_logger_enabled","content":"true if Buck should output to a machine readable log file under name buck-machine-log. Log entries are formatted one per line like &lt; Event type &gt;&lt; space &gt;&lt; JSON &gt;. [log]machine_readable_logger_enabled = true  "},{"title":"build_details_template​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#build_details_template","content":"If provided, Buck prints the specified string at the end of each build. The string {build_id} is replaced with the current build ID. This can be helpful to link to external systems that may have more details about the build. [log]build_details_template = &quot;Details at https://example.com/builds/{build_id}&quot;  "},{"title":"build_details_commands​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#build_details_commands","content":"If build_details_template is provided, Buck prints the specified string to the console for each of the specified list of commands. This can be useful for ensuring that users do not have too much information provided, but allows configuring log-heavy environments like CI systems to output more information for commands like 'query'. Default value is build, test, install [log]build_details_commands = build, test, install, query, targets  "},{"title":"[lua]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#lua","content":"This section defines settings relevant to lua_* rules. "},{"title":"lua​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#lua-1","content":"The path to the Lua interpreter. By default, Buck will search for the binary lua in your PATH. [lua]lua = /usr/bin/lua  "},{"title":"cxx_library​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cxx_library","content":"The build target of the Lua C library to use to link a standalone interpreter. By default, Buck will use -llua from the C/C++ linker's default library search path. [lua]cxx_library = //third-party/lua:lua  "},{"title":"starter_type​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#starter_type","content":"The method for bootstrapping Lua binaries. By default, native is chosen if the binary contains native libraries and pure is chosen otherwise. pure: The binary bootstrap process uses pure Lua code. This method cannot be used if the binary includes native code.native: The binary bootstrap process links in the Lua C library (specified in [lua].cxx_library) to form a standalone native interpreter. [lua]starter_type = pure  "},{"title":"native_starter_library​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#native_starter_library","content":"A C/C++ library to use as a custom starter for Lua binaries which use theNATIVE bootstrap method. The library is expected to define the following function: #ifdef __cplusplusextern &quot;C&quot;#endifint run_starter(int argc,const char **argv,const char *main_module,const char *modules_dir,const char *extension_suffix);  Where the arguments are as follows: argc: The number of command-line arguments.argv: The array of command-line arguments.main_module: The name of the binary's main module.modules_dir: The path, relative the binary, to the modules directory.extension_suffix: The suffix used for native libraries (e.g. .so). [lua]native_starter_library = //third-party/lua:starter  "},{"title":"extension​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#extension","content":"The extension to use for Lua binaries. Defaults to .lex. [lua]extension = .lex  "},{"title":"[maven_repositories]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#maven_repositories","content":"This section defines the set of maven repositories that Buck can use when attempting to resolve maven artifacts. It takes the form of key value pairs of a short name for the repo and the URL. The URL may either be an HTTP(S) URL, or point to a directory on your local disk. [maven_repositories]central = https://repo1.maven.org/maven2 m2 = ~/.m2/repository  Note that if you are using Buck to talk to Maven and you are using IPv6, you might need to add the following option to your .buckjavaargs file: -Djava.net.preferIPv6Addresses=true  "},{"title":"[ndk]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ndk","content":"This section defines properties to configure building native code against the Android NDK. "},{"title":"ndk_version​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ndk_version","content":"The version of the NDK that Buck should use to build native code. Buck searches for this version in the subdirectories beneath the directory specified by either the ANDROID_NDK_REPOSITORY environment variable or the value of the [ndk].ndk_repository_path property. Buck prefers an exact match, and otherwise accepts a prefix match. NDKs with a version prior to r11 store their version in the file RELEASE.TXT. For example, in version r10c this file contains r10c (64-bit). In this case, you would use r10c for the value of ndk_version. [ndk] ndk_version = r10c  NDKs with a version after r11 use a different format for their version and store their version in the Pkg.Revision property of the file source.properties. For example, this is the content of that file for version r13b: Pkg.Desc = Android NDKPkg.Revision = 13.1.3345770  In this case, you would use 13.1.3345770 for the value of ndk_version. [ndk] ndk_version = 13.1.3345770  "},{"title":"ndk_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ndk_path","content":"This specifies an absolute path to the Android NDK. The default is empty. Setting this property has the same effect as if you had set either of the following environment variables to the same value: ANDROID_NDKNDK_HOME Note that Buck gives precedence to the values of these environment variables—in the order in which they are listed above—over the value of this property in .buckconfig. [ndk]ndk_path = /Library/Android/ndk/r10c  "},{"title":"ndk_repository_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ndk_repository_path","content":"This specifies the absolute path to a directory that contains multiple versions of the Android NDK in subdirectories. The default is empty. Setting this property has the same effect as if you had set the ANDROID_NDK_REPOSITORY environment variable to the same value. However, Buck gives precedence to the value of this environment variables over the value of this property in.buckconfig. Buck selects which NDK to use based on the value of the [ndk].ndk_version property. Currently, if you do not specify a value for ndk.ndk_version, Buck selects the most-recent NDK. However, you should not rely on this behavior as it could change in a future release. [ndk]ndk_repository_path = /Library/Android/ndk  "},{"title":"app_platform​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#app_platform","content":"The android platform libraries that the code is targeting. This is equivalent to the APP_TARGET in the NDK build system. The default is android-16. [ndk]app_platform = android-21  "},{"title":"app_platform_per_cpu_abi​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#app_platform_per_cpu_abi","content":"The android platform libraries that the code is targeting, set on a per-CPU ABI basis. This is equivalent to the APP_TARGET in the NDK build system. If no value is set for a particular CPU ABI, the value from app_platform is used as a fallback. [ndk]app_platform_per_cpu_abi = arm =&gt; android-19, arm64 =&gt; android-22  "},{"title":"cpu_abis​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cpu_abis","content":"A comma separated list of the CPU ABIs that this repo supports. Buck will only build NDK code for these ABIs. [ndk]cpu_abis = armv7, x86  "},{"title":"compiler​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#compiler-2","content":"When compiling cxx_library rules, this specifies the compiler family to use from the NDK. The possible values are: gcc (default): Use the GCC family of compilation tools.clang: Use the Clang family of compilation tools. [ndk]compiler = gcc  "},{"title":"gcc_version​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#gcc_version","content":"When compiling cxx_library rules, this specifies the version of GCC to use. This will be used regardless of the value in [ndk].compiler, as other compiler families still use tools from the GCC toolchain (such as ar). The default value is 4.8. [ndk]gcc_version = 4.8  "},{"title":"clang_version​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#clang_version","content":"When compiling cxx_library rules, this specifies the version of Clang to use. The default value is 3.4. [ndk]clang_version = 3.4  "},{"title":"cxx_runtime​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cxx_runtime","content":"When compiling cxx_library rules, this specifies the variant of the C/C++ runtime to use. Possible values are: gabixxgnustl (default)libcxxstlportsystem [ndk]cxx_runtime = gnustl  "},{"title":"cxx_runtime_type​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#cxx_runtime_type","content":"When compiling cxx_library rules, this specifies how libraries are intended to be linked with the runtime. If this is static, then the C/C++ runtime library will not be packaged in the APK. Possible values are: dynamic (default)static [ndk]cxx_runtime_type = dynamic  "},{"title":"[ocaml]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ocaml","content":"This section configures the paths to the OCaml toolchain's binaries. "},{"title":"ocaml.bytecode.compiler​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ocamlbytecodecompiler","content":"The path to the OCaml bytecode compiler (ocamlc). [ocaml]ocaml.bytecode.compiler = /usr/local/bin/ocamlc.opt  "},{"title":"ocaml.compiler​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ocamlcompiler","content":"The path to the OCaml native-code compiler (ocamlopt). [ocaml]ocaml.compiler = /usr/local/bin/ocamlopt.opt  "},{"title":"dep.tool​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#deptool","content":"The path to the OCaml dependency generator (ocamldep). [ocaml]dep.tool = /usr/local/bin/ocamldep.opt  "},{"title":"lex.compiler​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#lexcompiler","content":"The path to the OCaml lexer generator (ocamllex). [ocaml]lex.compiler = /usr/local/bin/ocamllex.opt  "},{"title":"yacc.compiler​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#yacccompiler","content":"The path to the OCaml parser generator (ocamlyacc). [ocaml]yacc.compiler = /usr/local/bin/ocamlyacc  "},{"title":"debug​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#debug","content":"The path to the OCaml debugger (ocamldebug). [ocaml]debug = /usr/local/bin/ocamldebug  "},{"title":"interop.includes​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#interopincludes","content":"The path to the OCaml standard library directory (see Interfacing C with OCaml). [ocaml]interop.includes = /usr/local/lib/ocaml  "},{"title":"[parser]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#parser","content":"This section defines settings for the BUCK parser. "},{"title":"python_interpreter​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#python_interpreter","content":"The path to the python interpreter to use for parsing. If not specified, the [python].interpreter setting is used. [parser]python_interpreter = /usr/bin/python  "},{"title":"python_path​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#python_path","content":"The PYTHONPATH environment variable set for the python interpreter used by the parser to use. By default, this is unset. [parser]python_path = /path1:/path2  "},{"title":"polyglot_parsing_enabled​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#polyglot_parsing_enabled","content":"Indicates whether support for experimental polyglot parsing should be enabled. When enabled, build file can have a # BUILD FILE SYNTAX: marker followed by one of supported syntax names that include PYTHON_DSL and an experimental SKYLARK. This flag is disabled by default. [parser]polyglot_parsing_enabled = true  "},{"title":"default_build_file_syntax​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_build_file_syntax","content":"Specifies the default syntax assumed when parsing build files without explicit build syntax marker (# BUILD FILE SYNTAX: ). This flag is only applicable whenparser.polyglot_parsing_enabled configuration is set to true. By default it's value is set to PYTHON_DSL. [parser]default_build_file_syntax = SKYLARK  "},{"title":"disable_implicit_native_rules​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#disable_implicit_native_rules","content":"If set, native rules (cxx_library, android_library, etc) cannot be used in BUCK files. This can be useful if your team has a common set of macros that should be loaded, and one desires a fast-feedback way to make sure that Buck's native rules are not inadvertently used. If set, native rules can only be accessed via the 'native' object within an extension file that is evaluated with load() or include_defs(). This flag is disabled by default (native rules can be used in build files). [parser]disable_implicit_native_rules = true  "},{"title":"warn_about_deprecated_syntax​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#warn_about_deprecated_syntax","content":"If set, warnings about deprecated syntax in BUCK files will be issued. This flag is enabled by default. [parser]warn_about_deprecated_syntax = false  "},{"title":"[project]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#project","content":"This section defines project-level settings. "},{"title":"generate_android_manifest​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#generate_android_manifest","content":"Forces Buck to generate &quot;AndroidManifest.xml&quot; files for Android IntelliJ modules. The generated manifests contain package name only to allow Android IntelliJ plugin resolve references to resources correctly. Manifests are generated for modules that have information about package name and have either none or more than one targets with Android manifests. When a module has exactly one target with Android manifest this manifest is used as a manifest in the module. [project]generate_android_manifest = true  "},{"title":"ide​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ide","content":"Buck attempts to figure out the correct IDE to use based on the type of rule (e.g. for apple_library it will generate Xcode workspace), but for cross-platform libraries (like cxx_library) it is not possible. This setting lets you specify the default IDE that buck project generates. Possible values are: intellijxcode [project]ide = xcode  "},{"title":"glob_handler​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#glob_handler","content":"The glob() handler that Buck will use. The possible values are: python (default): evaluates globs in the Python interpreter while parsing build files.watchman: evaluates the globs with Watchman, which is generally much faster. [project]glob_handler = python  "},{"title":"allow_symlinks​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#allow_symlinks","content":"If set to forbid, Buck will disallow symbolic links to source and BUCK files. This allows Buck to enable a number of performance improvements. If set to allow, Buck will silently ignore symlinks. The default value is warn. [project]allow_symlinks = forbid  "},{"title":"build_file_search_method​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#build_file_search_method","content":"How Buck finds BUCK files. This is used when a build target pattern contains /... and for commands like buck project. Possible values are: filesystem_crawl (default): walk the file system recursively using APIs provided by the operating system.watchman: query Watchman with a glob query like **/BUCK. For file systems such as EdenFS, watchman can be faster than filesystem_crawl. This setting in independent of [project].glob_handler. [project]build_file_search_method = filesystem_crawl  "},{"title":"watchman_query_timeout_ms​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#watchman_query_timeout_ms","content":"When communicating with Watchman, Buck will wait this long for a response. The default is 60000 ms. [project]watchman_query_timeout_ms = 60000  "},{"title":"ide_force_kill​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ide_force_kill","content":"Configures how the buck project command responds if an instance of Apple's Xcode IDE is running. [project]ide_force_kill = never  Possible values are: always : Always terminate Xcode. Do not ask first.never : Never terminate Xcode.prompt : Ask the user whether to terminate Xcode. This is the default. To specify that Buck should respond in a way that is different than the .buckconfig setting, use the--config command-line option. buck project --config project.ide_force_kill=always  For more information about the --config option, see the Common Parameters topic. "},{"title":"initial_targets​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#initial_targets","content":"A space-separated list of build targets to run when buck project is executed. This is often a list of genrules whose outputs need to exist in order for an IDE to be able to build a project without the help of Buck. [project]initial_targets = //java/com/facebook/schema:generate_thrift_jar  "},{"title":"ignore​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ignore","content":"A comma-separated list of subtrees within the project root which are ignored in the following contexts: Buck daemon filesystem monitoring.Filesystem traversal when searching for tests and BUCK filesIntelliJ project indexing Buck automatically excludes its own output, e.g. buck-out, .buckd, and .idea, as well as the cache directory (see [cache].mode), but it makes no assumptions about source control systems. [project]ignore = .git  "},{"title":"pre_process​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#pre_process","content":"A script that should be executed before the project files are generated. This should only be used to do some project-specific actions that are reasonably fast. The environment of this script contains the following variables: BUCK_PROJECT_TARGETS - whitespace-separated list of input targets.BUCK_PROJECT_TYPE - the type of a project, can be &quot;xcode&quot; or &quot;intellij&quot;. [project]pre_process = scripts/pre_process_buck_project.py  "},{"title":"post_process​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#post_process","content":"A script that should be executed after the project files are generated. This should only be used to do some project-specific actions that are reasonably fast. The environment of this script contains the following variables: BUCK_PROJECT_TARGETS - whitespace-separated list of input targets.BUCK_PROJECT_TYPE - the type of a project, can be &quot;xcode&quot; or &quot;intellij&quot;. [project]post_process = scripts/post_process_buck_project.py  "},{"title":"parallel_parsing​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#parallel_parsing","content":"When set to true, Buck will parse your build files in parallel. [project]parallel_parsing = false  "},{"title":"parsing_threads​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#parsing_threads","content":"When [project].parallel_parsing is enabled, this specifies the number of threads Buck uses to parse. By default, this is equal to the number of threads Buck uses to build, and will be the minimum of this setting and [build].threads. [project]parsing_threads = 2  "},{"title":"build_file_import_whitelist​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#build_file_import_whitelist","content":"A comma-separated list that configures which Python modules can be imported in build files. [project]build_file_import_whitelist = math, Foo  "},{"title":"shared_libraries_in_bundles​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#shared_libraries_in_bundles","content":"When using xcode project, for projects that depend on a library, if set to 'true', if that library is the 'binary' of a bundle, the bundle will replace the library in the Xcode linking phase [project]shared_libraries_in_bundles = false  "},{"title":"motd​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#motd","content":"A plain text message that will be printed first when a user interacts with buck. This supports simple special characters like newlines (\\n). [project]motd = &quot;DO NOT BREAK THE BUILD&quot;  "},{"title":"[python]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#python","content":"This section defines settings relevant to python_* rules. Python platform flavors in .buckconfig​ Buck enables you to create additional platform flavors for Python in .buckconfig. A platform flavor groups together a set of configuration parameters, which you can then reference at build time. To create a new Python platform flavor, add a section with the header [python#**flavor**]  to .buckconfig. If you invoke Buck with the specified flavor appended to the build target, Buck uses the values in this section instead of those in [python]. For example, to build with the values in [python#py3] instead of [python], you could invoke Buck using the following command: $ buck build app#py3  This is useful if, for example, you have both Python 2 and Python 3 code in your project and need to differentiate between them by changing the value of the [python].interpreter. You can also use these platform flavors, in the platform argument of the python_binary rule, and in the platform_sources and platform_resources arguments of the python_library rule. "},{"title":"interpreter​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#interpreter","content":"The path to the python interpreter to use. By default, Buck will search for this in your PATH. [python]interpreter = /usr/bin/python  "},{"title":"inplace_interpreter_flags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#inplace_interpreter_flags","content":"Flags to pass to the python interpreter when running a .pex file that is configured to run 'inplace'. Defaults to -Es [python]inplace_interpreter_flags = -EBs  "},{"title":"library​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#library","content":"The build rule, typically a prebuilt_cxx_library, wrapping the libpython.so that cpp_python_extension rules should build against. [python]library = //third-party/python:python  "},{"title":"native_link_strategy​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#native_link_strategy","content":"The strategy used for pulling in native dependencies: merged: Native dependencies which are first-order dependencies of python_* rules are linked as full, separate, shared libraries. Transitive native dependencies are statically linked into a single monolithic shared library. This is preferred to reduce the native code size and shared library count.separate (default): Transitive native dependencies are linked as full, separate, shared libraries. This is preferred for faster build-time speed. [python]native_link_strategy = separate  "},{"title":"package_style​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#package_style","content":"The packaging style to use for python_binary and python_test. Valid values are: inplace: builds executables which are only able to run from within the repository. This style of packaging is significantly faster than standalone packages.standalone (default): builds self-contained executable packages that can be run outside of the repository. [python]package_style = standalone  "},{"title":"path_to_pex_executor​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#path_to_pex_executor","content":"The path to the tool used to run executable Python packages. For self-executing packages, this should just by the shell. [python]path_to_pex_executor = /bin/sh  "},{"title":"pex_extension​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#pex_extension","content":"The extension to use for executable Python packages. [python]pex_extension = .pex  "},{"title":"version​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#version","content":"The implementation and version of the Python interpreter. The syntax is: &lt;interpreter implementation&gt; &lt;interpreter version&gt;  The implementation and version should be separated by a space. The version should comprise only numerals and periods; it should not contain characters such as +, although some Python versions use such characters. To obtain the implementation, you can use the following command, invoked using the relevant Python interpreter: python -c &quot;import platform; print( platform.python_implementation() )&quot;  Similarly, to obtain the version, use: python -c &quot;import platform; print( platform.python_version() )&quot;  Example: [python]version = CPython 2.7  "},{"title":"[repositories]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#repositories","content":"Lists the cells that constitute the Buck project. Buck builds that are part of this project—that is, which use this .buckconfig—can access the cells specified in this section. [repositories] buck = . bazel_skylib = ./third-party/skylark/bazel-skylib  The string on the left-hand side of the equals sign is the alias for the cell. The string on the right-hand side of the equals sign is the path to the cell from the directory that contains this .buckconfig file. It is not necessary to include the current cell in this section, but we consider it a best practice to do so: buck = .  You can view the contents of this section using the buck audit cell command. Although the name of the section is repositories, the section actually lists cells. In practice, Buck cells often correspond to repositories, but this is not a requirement. For more information about the relationship between Buck projects, cells, and repositories, see the Key Concepts topic. "},{"title":"[resources]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#resources","content":"The settings to control how Buck uses resources to schedule the work. When resource-aware scheduler is enabled, Buck will create more threads in attempt to run resource-independent work in parallel. Number of build threads is still controlled by num_threads option. Buck will also create a number of additional threads that will be used for tasks that don't require CPU: network fetches, disk operations, etc. Total number of threads that Buck will operate is controlled bymanaged_thread_count option, that is, it includes build threads and additional threads. "},{"title":"resource_aware_scheduling_enabled​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#resource_aware_scheduling_enabled","content":"When set to true, Buck will attempt to use resource-aware scheduler. [resources]resource_aware_scheduling_enabled = true  "},{"title":"managed_thread_count​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#managed_thread_count","content":"Buck will use num_threads threads for CPU intensive tasks (e.g. local building) and it will use managed_thread_count - num_threadsfor other purposes. Thus, managed_thread_count value must be greater or equal to num_threads value. If you don't specify this value, Buck will create built-in number of additional threads which equals to the number of CPU cores on the machine. These additional threads will be used for non-CPU work like networking, disk I/O and etc. But if one of the num_threads threads is free then Buck will probably use it for non-CPU stuff as well. [resources]managed_thread_count = 40  "},{"title":"default_cpu_amount​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_cpu_amount","content":"Amount of CPU resource required by arbitrary job which has no specific setting for its resource amounts. By default is 1 - a single CPU is required for the job to be completed. [resources]default_cpu_amount = 1  "},{"title":"default_memory_amount​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_memory_amount","content":"Amount of memory resource required by arbitrary job which has no specific setting for its resource amounts. By default is 1 - a single memory resource is required for the job to be completed. A single memory resource is an abstract value, currently it equals to 100 Mb. [resources]default_memory_amount = 1  "},{"title":"default_disk_io_amount​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_disk_io_amount","content":"Amount of disk I/O resource required by arbitrary job which has no specific setting for its resource amounts. A single disk resource is an abstract value. Think about it as like SSD can handle 50 parallel disk jobs with weight 1, while HDD can handle only 20. Thus, if job needs to read or write a lot of data, it is better to assign a higher value for its disk I/O amount. This will reduce the risk to have several similar jobs running concurrently and performing huge disk I/O operations, slowing down build itself and system performance. [resources]default_disk_io_amount = 1  "},{"title":"default_network_io_amount​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_network_io_amount","content":"A single network resource is an abstract value. Think about it as Ethernet can handle 50 parallel network jobs with weight 1. Slower network interfaces can handle less amount of jobs. If job needs to send or receive a lot of data, it is better to assign a higher value for its network I/O amount. [resources]default_network_io_amount = 1  "},{"title":"max_memory_resource​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#max_memory_resource","content":"Maximum memory resource available to Buck. By default is size of Java heap divided by 100 Mb. A single memory resource is an abstract value, currently it equals to 100 Mb. [resources]max_memory_resource = 30  "},{"title":"max_disk_io_resource​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#max_disk_io_resource","content":"Maximum disk I/O resource available to Buck. By default the value is 50. Think about it as like SSD can handle 50 parallel disk jobs with weight 1, while HDD can handle only 20. Thus, if job needs to read or write a lot of data, it should require higher disk I/O resource. [resources]max_disk_io_resource = 30  "},{"title":"max_network_io_resource​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#max_network_io_resource","content":"Maximum disk I/O resource available to Buck. By default the value is 30. Think about it as Ethernet can handle 50 parallel network jobs with weight 1. Slower network interfaces can handle less amount of jobs. If job needs to send or receive a lot of data, it should require higher network I/O resource. [resources]max_network_io_resource = 30  "},{"title":"[resources_per_rule]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#resources_per_rule","content":"This section contains required resource amounts for various build rules. If amount for some build rule is not specified in this section, then amount of 1 (CPU), 1 (Memory), 0 (disk i/o) and 0 (network i/o) is used. Amounts are used in local building, so in most cases build rule will require 0 for network I/O unless it fetches any data from network. Rule's name is constructed by converting the camel-style class name of the BuildRulein Buck's source code (e.g. MyBuildRule) into lower underscored name (e.g. my_build_rule). [resources_per_rule]cxx_link = 1, 1, 5, 0 android_binary = 8, 30, 30, 0  Buck will use the defined resource amounts during the build process in order to attempt to use all available resources. "},{"title":"[rust]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#rust","content":"The settings to control how Buck builds rust_* rules. "},{"title":"compiler​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#compiler-3","content":"The path that Buck should use to compile Rust files. By default, it checks your PATH. [rust]compiler = /usr/local/bin/rustc  "},{"title":"rustc_flags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#rustc_flags","content":"Default command-line flags passed to all invocations of the rust compiler. [rust]rustc_flags = -g  "},{"title":"rustc_binary_flags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#rustc_binary_flags","content":"Default command-line flags passed to invocations of the rust compiler in rust_binary rules, in addition to options set in rustc_flags. [rust]rustc_binary_flags = -C lto  "},{"title":"rustc_library_flags​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#rustc_library_flags","content":"Default command-line flags passed to invocations of the rust compiler in rust_library rules, in addition to options set in rustc_flags. [rust]rustc_library_flags = --cfg=debug  "},{"title":"unflavored_binaries​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#unflavored_binaries","content":"Controls whether the output from rust_binary or rust_test rules include a flavor from the platform in the path or not. Even unflavored, the path includes #binary. [rust]unflavored_binaries = true  "},{"title":"remap_src_paths​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#remap_src_paths","content":"Controls whether rustc remaps the source paths in its output. Buck will always construct a link tree with the sources required for a given rule, which means the paths passed to rustc are not the original source paths. This option will remap those paths in compiler output, debug info, file!() and elsewhere to match the original source names. The options are &quot;no&quot; (don't remap), and &quot;yes&quot; (remap). [rust]remap_src_paths = no  "},{"title":"force_rlib​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#force_rlib","content":"When force_rlib is true, then buck will always compile static (rlib) libraries even when the final target (binary or unit test) is being linked with a shared link style. Rust code is typically always statically linked, and a lot of surrounding tooling doesn't cope well with dynamically linked Rust crates. Linking with a shared link style will still dynamically link with C/C++ shared objects. [rust]force_rlib = false  "},{"title":"prefer_static_libs​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#prefer_static_libs","content":"When prefer_static_libs is true, then buck will always prefer to link with static versions of a library when building a shared target. In practice, this only affects linking with the standard library crates. [rust]prefer_static_libs = false  "},{"title":"incremental​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#incremental","content":"When set, enable rustc's incremental build option. Rust's incremental compilation mode operates transparently to the build system - it is guaranteed to produce bit-for-bit identical output to non-incremental builds. To do this it maintains a separate incremental database to one side. The only requirement is that there is only ever one instance of rustc for a given crate at one time. Buck guarantees this by making sure there's a separate incremental database for each flavor (since builds for different flavors of the same target can be run concurrently). The value of this option is an additional path fragment used for the incremental database path. This allows the user to use separate databases for optimized, debug, etc command lines. If this is not required, then it can be any valid pathname fragment. [rust]incremental = opt  "},{"title":"default_edition​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#default_edition","content":"Set the default edition for Rust rules. The edition can be specified on a per-rule basis, but this sets the default if nothing is specified. The default is &quot;2015&quot;. [rust]default_edition = 2018  "},{"title":"[sandbox]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#sandbox","content":"This section controls sandboxing. Sandbox execution provides better guarantees about resources accessible to the processes by using system-provided capabilities to restrict certain usages (for example, restricting the set of files allowed to be read and write). "},{"title":"darwin_sandbox_enabled​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#darwin_sandbox_enabled","content":"This option specifies whether sandboxing is enabled on OS X or not. [sandbox]darwin_sandbox_enabled = true  "},{"title":"genrule_sandbox_enabled​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#genrule_sandbox_enabled","content":"Enables sandbox in genrule. [sandbox]genrule_sandbox_enabled = true  "},{"title":"[test]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#test","content":"The settings to control how Buck runs tests. "},{"title":"incl_no_location_classes​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#incl_no_location_classes","content":"This specifies whether jacoco code coverage is enabled on classes without source location. The default is false. Set to true to enable code coverage with robolectric tests. Note that setting to true will include dynamically created sources in code coverage, such as that created by mocking (e.g. jmockit) or persistence frameworks. [test]incl_no_location_classes = true  "},{"title":"timeout​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#timeout","content":"The number of milliseconds per test to allow before stopping the test and reporting a failure. The default is no timeout. Not all *_test rules utilize this value. A JUnit test can override this via the @Test annotation. [test]timeout = 300000  "},{"title":"rule_timeout​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#rule_timeout","content":"The number of milliseconds per *_test rule to allow before stopping it and reporting a failure. The default is no timeout. [test]rule_timeout = 1200000  "},{"title":"external_runner​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#external_runner","content":"This specifies an external test runner command to use instead of Buck's built-in test runner. The external test runner is invoked by Buck after it has built all the test rules. It passes the test runner the path to a file which contains a JSON-encoded list of test file infos via the --buck-test-info [path] command line option. Additionally, if buck test is invoked with -- [extra-runner-args], these will be passed to the external runner before --buck-test-info. The JSON-encoded test file contains an array of infos. Those infos have the following fields: target: The build target of the test rule.type: A string describing the type of the test.command: An array of command line arguments the test runner should invoke to run the test.env: A map of environments variables that should be defined by the test runner when running the test.labels: An array of labels that are defined on the test rule.contacts: An array of contacts that are defined on the test rule. These are typically user names or email addresses. [test]external_runner = command args...  "},{"title":"thread_utilization_ratio​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#thread_utilization_ratio","content":"Sets the maximum number of threads to use for testing as a ratio of the number of threads used for building. By default(1.0), buck uses runs tests on all threads that were used for building. [test]thread_utilization_ratio = 0.5  "},{"title":"parallel_external_test_spec_computation_enabled​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#parallel_external_test_spec_computation_enabled","content":"Whether external test spec computation is allowed to happen in parallel. Enabling this option can significantly speed up test execution when many test targets are requested. By default it is disabled. [test]parallel_external_test_spec_computation_enabled = false  "},{"title":"threads​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#threads-2","content":"Specify number of threads used when running test. [test]threads = 5  "},{"title":"[thrift]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#thrift","content":"This section provides settings to locate required thrift components. "},{"title":"compiler​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#compiler-4","content":"The path or build target that builds the thrift compiler that Buck should use. [thrift]compiler = /usr/local/bin/thrift  "},{"title":"compiler2​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#compiler2","content":"The path or build target that builds the thrift2 compiler that Buck should use. If this is unset, it defaults to the value of [thrift].compiler. [thrift]compiler2 = /usr/local/bin/thrift2  "},{"title":"[tools]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#tools","content":"This section tells Buck how to find certain tools e.g. how the Java compilation occurs and how auxiliary tools are used e.g. the ProGuard Java class file optimizer which is used as part of the Android build process. "},{"title":"javac​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#javac","content":"The javac option is a path to a program that acts like Java javac. When set, buck uses this program instead of the system Java compiler. When neither this nor [tools].javac_jar is set, Buck defaults to using the system compiler in-memory. "},{"title":"javac_jar​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#javac_jar","content":"When this option is set to a JAR file, Buck loads the referenced compiler in-memory. When neither this nor [tools].javac is set, Buck defaults to using the system compiler in-memory. "},{"title":"java_for_tests​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#java_for_tests","content":"The java_for_tests option is a path to a java binary. When set, buck uses that binary to execute Java tests—when using either the internal or external test runners—instead of the java binary used to run Buck itself. When this option is not set, Buck executes Java tests using the same binary used to run Buck. "},{"title":"compiler_class_name​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#compiler_class_name","content":"When javac_jar is set, Buck loads the referenced compiler class name from the jar. When it is not set but javac_jar is set, Buck uses the default compiler class. "},{"title":"proguard​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#proguard","content":"This option specifies the location of the JAR file to be used to invoke ProGuard. This overrides the default ProGuard JAR file that would have been picked up from the Android SDK. Here is an example setting: [tools]proguard = proguard/proguard-fork.jar  "},{"title":"proguard-max-heap-size​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#proguard-max-heap-size","content":"This option specifies how much memory is used when running proguard. Defaults to 1024M. You may want to give ProGuard more memory to try and improve performance. [tools]proguard-max-heap-size = 4096M  "},{"title":"proguard-agentpath​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#proguard-agentpath","content":"This option allows the specification of a Java profiling agent which is set with the -agentpath argument when the ProGuard jar file is executed. Typically this would be set in a .buckconfig.local configuration file for when you want to profile a build running on your local machine. Set this to the actual path of the installed agent on the machine where ProGuard will run. [tools]proguard-agentpath = /Applications/YourKit_Java_Profiler_2015_build_15084.app/Contents/Resources/bin/mac/libyjpagent.jnilib  "},{"title":"[ui]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#ui-1","content":"This section configures the appearance of Buck's command line interface. "},{"title":"always_sort_threads_by_time​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#always_sort_threads_by_time","content":"Specifies whether the lines with information about building and testing threads should always be sorted by the time spent running the rules they are currently executing. When set to false, threads are only sorted if there are more threads than available lines (see [ui].thread_line_limit for an option to configure this limit). Only effective when the super console is used. The default value is false. [ui]always_sort_threads_by_time = true  "},{"title":"error_message_augmentations​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#error_message_augmentations","content":"This setting is preliminary and is likely to change. Specifies a comma-separated list of mappings from regular expressions (regexes) to message strings. If the text of a Buck parser error matches one of the specified regexes, the corresponding message string is appended to the error. You can use the message string to provide additional helpful information to the user. If the regex contains unescaped parentheses, (), the text that the parentheses enclose is captured. You can then insert this captured text in the appended string by using $1 for the first captured text string, $2 for the second, and so on. This works exactly like Java regex replacement strings. [ui]error_message_augmentations = &quot;The rule (//S+)-cxx could not be found.&quot; =&gt; &quot;Please make sure that $1 is a cxx library.  "},{"title":"relativize_targets_to_working_directory​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#relativize_targets_to_working_directory","content":"Determines whether build target patterns provided on the command line are relativized to the current working directory. For example, if buck build bar/...is run from the foo subdirectory of the project, the pattern//foo/bar/... is built instead. If set to false, //bar/...would be built. This defaults to true. [ui]relativize_targets_to_working_directory = false  "},{"title":"enable_show_output_warning​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#enable_show_output_warning","content":"Determines whether a deprecation warning for --show-output should be shown. The warning also informs users that they should be using --show-outputs instead. This defaults to false. [ui]enable_show_output_warning = false  "},{"title":"thread_line_limit​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#thread_line_limit","content":"Specifies how many lines will be used to show the status of running threads during building and testing by default. Only effective when the super console is used. The value has to be a positive number. The default value is 10. [ui]thread_line_limit = 10  "},{"title":"thread_line_limit_on_warning​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#thread_line_limit_on_warning","content":"Specifies how many lines will be used to show the status of running threads during building and testing after a warning is reported. Only effective when the super console is used. The value has to be a positive number. Defaults to the value of [ui].thread_line_limit. [ui]thread_line_limit_on_warning = 10  "},{"title":"thread_line_limit_on_error​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#thread_line_limit_on_error","content":"Specifies how many lines will be used to show the status of running threads during building and testing after an error is reported. Only effective when the super console is used. The value has to be a positive number. Defaults to the value of [ui].thread_line_limit. [ui]thread_line_limit_on_error = 10  "},{"title":"truncate_failing_command​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#truncate_failing_command","content":"Determines whether a failing executed command is truncated in error messages. This defaults to true. [ui]truncate_failing_command = true  "},{"title":"superconsole​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#superconsole","content":"Whether the super console is enabled. If so, a more reactive UI will be shown. Valid values are ENABLED, DISABLED, and AUTO. By default, this is set to AUTO which will take OS, terminal settings and other things into account. In most interactive cases, it will be enabled. [ui]superconsole = ENABLED  "},{"title":"warn_on_config_file_overrides​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#warn_on_config_file_overrides","content":"Whether to display a warning when using configuration overrides from .buckconfig.local or any of the files mentioned in Precedence of Buck configuration specificationsThis is true by default. [ui]warn_on_config_file_overrides = false  "},{"title":"warn_on_config_file_overrides_ignored_files​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#warn_on_config_file_overrides_ignored_files","content":"A comma-separated list of names of configuration files that should be ignored. By default, Buck prints a warning if settings are in use from any of the files in Precedence of Buck configuration specificationsSometimes, however, a user should not be alerted about specific files. For example, there may be global Buck settings in /etc/buckconfig.d/system that are managed by an IT organization, not the user, and the warning would just be ignored. In this case, this setting could be set to systemso that /etc/buckconfig.d/system being present would not elicit a warning. [ui]warn_on_config_file_overrides_ignored_files = experiments,system  "},{"title":"[worker]​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#worker","content":"This section configures how Buck's workers (worker_tools and similar) work. "},{"title":"persistent​","type":1,"pageTitle":".buckconfig","url":"/docs/legacy/files-and-directories/dot-buckconfig/#persistent","content":"Specifies whether by default workers run in persistent mode (reusing the worker process across builds). The persistent option of worker_tool overrides this default. The default value is false. Be careful when switching this to true since the workers will not shut down after buck commands and will continue consuming system resources. [worker]persistent = false  "},{"title":"buck2 audit visibility command","type":0,"sectionRef":"#","url":"/docs/rfcs/audit_visibility/","content":"","keywords":""},{"title":"Context​","type":1,"pageTitle":"buck2 audit visibility command","url":"/docs/rfcs/audit_visibility/#context","content":"Buck has a concept of Visibility for every target. It allows users to define, for each target, the targets it can depend on and targets that can depend on it. Visibility is specified as an allowlist of targets/target patterns, and any target used that falls outside of the allowlist fails visibility checking. Visibility pattern can be specified on visibility and within_view attributes in buildfiles and PACKAGE files. Visibility is important to lots of codebase maintainers because it can be used to keep projects from pulling in unwanted dependencies. As some examples, App Core teams are using Buck visibility as a replacement to current supermodules for protecting app modularity. Instagram's using visibility to protect modularity and define Link Groups used for build speed optimizations. There's interest from various DevX teams in using Buck visibility on PACKAGE files to enforce repo boundaries, which will allow target determinators to migrate off of sparse profiles and onto Eden, although visibility in its current form is likely not fit for enforcing such repo boundaries. Visibility has also been used to enforce requirements that only certain targets are allowed to depend on targets in fbcode/scripts. For perf reasons, buck2 doesn't always enforce visibility. Instead, it only enforces visibility on construction of the configured target graph. Visibility checking is expensive memory-wise because it requires tracking all deps at each node. When constructing configured target graph, this cost is already paid for when buck2 checks transitive target compatibility. When constructing the unconfigured target graph, however, this is costly, so we avoid checking visibility there. (Note that buck does not allow you to specify selects in visibility attributes.) In practice, this means that commands like cquery and build can enforce visibility whereas commands like uquery and targets cannot. Having visibility checked only on the configured target graph is problematic for 2 reasons: 1) Visibility is only checked on configured deps after selects are resolved, so it's possible for a target to pass visibility checking in one configuration but fail visibility checking in another. For example, a target may pass visibility checking on a linux configuration but fail visibility checking on mac configuration if it has a bad mac-only dependency. This makes visibility enforcement more difficult because now you have to query the same graph in both linux and mac configuration before you know that visibility is always valid. 2) Uquery (querying the unconfigured target graph) has better performance than cquery (querying the configured target graph). Big-O wise, uquery scales with O(# of targets) whereas cquery scales with O((# number of configurations) x (# of targets)). Having a way to check visibility on unconfigured target graph can be much cheaper than doing so on configured target graph. "},{"title":"Proposed Solution: audit visibility command​","type":1,"pageTitle":"buck2 audit visibility command","url":"/docs/rfcs/audit_visibility/#proposed-solution-audit-visibility-command","content":"It's clear that we need a way to check visibility on the unconfigured target graph, but we don't want buck2 uquery and buck2 targets to regress in memory use. To get the best of both worlds, I propose adding a separate command to buck2, buck2 audit visibility, that will check visibility on the unconfigured target graph. Instead of checking on construction of the unconfigured target graph, this command will check after construction, which will avoid any memory regression. The tradeoff is that the visibility checking won't be cached, and rerunning audit visibility will rerun visibility checking on each invocation. "},{"title":"Usage and Invocation​","type":1,"pageTitle":"buck2 audit visibility command","url":"/docs/rfcs/audit_visibility/#usage-and-invocation","content":"buck2 audit visibility command will take in a list of target patterns as well as common build args like config flags and mode files as args. It will construct the unconfigured target graph based on the transitive deps of those targets and check that this graph has valid visibility. Checking transitive deps matches the behavior of visibility checking on cquery, but we may revisit this decision in the future if there is a need for just verifying the immediate dependencies. For example, an invocation to check visibility on the transitive closure of fbobjc can be buck2 audit visibility fbsource//fbobjc/...  It cannot be used to check that a target has a valid visibility with respect to targets outside of the transitive closure of its deps. For example, buck2 audit visibility fbcode//buck2/starlark-rust/starlark:starlark will just check that all transitive deps of starlark target (including starlark target) have valid visibility with respect to each other. It will not check that any targets that depend on starlark respect starlark target's visibility attribute. "},{"title":"Bxl support for performing analysis on targets","type":0,"sectionRef":"#","url":"/docs/rfcs/bxl-analysis/","content":"","keywords":""},{"title":"Intro​","type":1,"pageTitle":"Bxl support for performing analysis on targets","url":"/docs/rfcs/bxl-analysis/#intro","content":"As Bob and I continue to build out bxl we want users to be able to inspect the providers and actions for a given target label. In order to support this, we need to be able to provide access to AnalysisResult via starlark, obtained via a call to RuleAnalysisCalculation::get_analysis_result. "},{"title":"How to implement it?​","type":1,"pageTitle":"Bxl support for performing analysis on targets","url":"/docs/rfcs/bxl-analysis/#how-to-implement-it","content":"Our three principle options are as follows: BxlContext::analyze(targetlabel: ConfiguredTargetLabelLike), where ConfiguredTargetLabelLike accepts ConfiguredTargetLabel, ConfiguredTargetNode, or sets and lists of these things + acceptable strings. In this scenario, we attach the analysis method onto the bxl context itself, and require that users pass in the target label-ish thing when they want to construct an analysis result. It's a little awkward in some ways because the analysis is more naturally a method on the argument being passed in and the BxlContext is a context that is needed to perform the calculation. On the other hand, this allows us to construct a type analogous to TargetExpr which can parse from a wide variety of different ConfiguredTarget like things (strings, nodes, labels, sets, ...). It also is a bit nice from an implementational standpoint since we don't have to pass the context around everywhere. This isn't a huge pro though, since we can stick it in the global eval field. result = bxl.analyze(bxl.cquery.deps(&quot;foo&quot;))  ConfiguredTargetLabel::analyze(), ConfiguredTargetNode::analyze(), ... where we carry around the BxlContext in the eval global field and implement analysis on each type that is target label like. The pro of this one is that it's quite natural - you can take a ConfiguredStarlarkTargetLabel and then just ... call analyze() on it like you might expect to. The two downsides are that we have to propagate the context around behind the scenes, and we'll have to provide an implementation of analyze on everything that we'd like to have be able to be analyzable. result = &quot;root//bin:the_binary&quot;.analyze() # but we don't support &quot;root//bin:the_binary&quot;.rdeps() # instead this looks nice nodes = ctx.cquery.deps(&quot;foo&quot;) for n in nodes: # since we can now do nodes.label nodes.attrs.field # similarly access analysis nodes.analysis  BxlContext::analysis(): AnalysisContext where AnalysisContext exposes AnalysisContext::analyze(targetlabel: ConfiguredTargetLabelLike). There's not really any pros of this approach except that it's similar to the flow for cquery where we return a cqueryctx object to call cquery methods through. result = ctx.analysis().analyze(&quot;//lib:file1&quot;)  We can also restrict the API to require that users go through cquery to obtain a ConfiguredTargetNode prior to calling analysis, although we don't have to. I say that we don't have to because the get_analysis_result method mentioned above is configured to accept a label anyway. "},{"title":"Buck Extension Language (BXL)","type":0,"sectionRef":"#","url":"/docs/rfcs/bxl/","content":"","keywords":""},{"title":"Use Cases​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#use-cases","content":""},{"title":"Cpp LSP​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#cpp-lsp","content":"Lsp prefers to have a single buck command that given a file, returns the corresponding compilation database. This requires a single command, i.e a bxl, that accepts a file as input, performs owners queries, and uses the owning target plus the desired file to get the clang flags, and then writes it to disk in comp db format. It’s possible to write the same features using buck calls to cquery, and build using subtargets to generate compilation database per file. However, this requires lsp owners to maintain code in several locations and languages, and parse and reserialize data. It also does not provide the same incrementality and subscription update features of the resulting comp db that writing this in bxl would have. Furthermore, we may explore the idea of trimming the compilation command to only dependencies required per the file requested. Bxl actions provides a straightforward api for adding this when writing the actual comp db file. "},{"title":"Android LSP​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#android-lsp","content":"Android project requires traversing the target graph to find and java libraries, grouping and converting them between modules or project libraries depending on the number of references, and restructuring the graph as directory based. Android LSP is able to take advantage of subscriptions in the future when available, allowing developers to keep their IDE up-to-date automatically without needing to manually regenerate the project. With bxl, the graph traversals can be written in starlark, allowing propagation of information down the graph, accessing targets’ attributes to analyze dependencies, and access providers for artifacts and action information needed to output the project file. Project generation also performs directory listings that buck2’s dice already performs and caches (I think, need to confirm). Bxl poses the interesting possibility that we can expose a limited set of IO operations that are tracked by dice so bxl can access the same cached file operations as rest of buck2. Android project generation currently doesn’t write project files to buck-out, which prevents it from using buck2 actions. It will have to rely on an external script to process the graph information printed by buck and write the actual project files. If it moves to buck-out based, then it can take advantage of creating actions directly using the graph information processed, and potentially take advantage of incremental actions api to avoid writing the entire graph on each subsequent update. "},{"title":"iOS Project​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#ios-project","content":"iOS is currently being implemented as a series of queries that are aggregated by an external python script, that then invokes builds of subtargets. The same can be achieved in bxl, but with the entire sequence being cacheable and subscribable so that when the graph is updated, or even when generated files need updating, buck2 can automatically push the updates. However, it is uncertain whether xcode itself can make use of push updates. "},{"title":"Rust LSP​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#rust-lsp","content":"(note from dbarsky@: I’m adding this at Bob’s request. Can be removed as needed.) "},{"title":"Visual Studio Project (vsgo)​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#visual-studio-project-vsgo","content":"Vsgo is a pile of python that converts buck query/buck targets output via a variety of heuristics into inputs to a custom fork gyp which is then invoked to generate visual studio projects for a given buck target. Having direct access to the internals of buck would allow us to remove the heuristics and possibly even move project generation directly into bxl. "},{"title":"Goals​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#goals","content":"From the above use cases, BXL should offer a simple Starlark API that allows easy introspection of the buck2 graph at unconfigured, configured, providers, and actions stage, maintaining incremental behaviour of the BXL evaluation itself. Some minimal API should be offered to allow BXL to provide additional behaviour such as output artifacts, and print results. Most use cases from LSP desire to also propagate information via the command line for these operations, so BXL should support command line arguments as inputs. "},{"title":"API​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#api","content":""},{"title":"Defining a bxl function​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#defining-a-bxl-function","content":"There are multiple models possible. We can have each file be its own bxl, or have each file declare multiple bxl like rules. There are multiple advantages to allowing declaration of multiple bxls, such as grouping similar bxls in the same file, allowing them to “invoke” each other. It doesn’t necessarily add much more complexity for the author, as even with one bxl per file, the author still has to have some declaration for the bxls arguments. # sample.bxl func1 = bxl( impl = my_func1, args = { “arg1”: arg.list(arg.str()), } ) func2 = bxl( ... )  To invoke buck2 for that bxl, we can have the command line as follows. buck2 bxl sample.bxl::func1 -- --arg1 foo bar baz  For bxl functions to read the arguments, a similar api to rule attrs is used args = ctx.args.args_for_bxl  Args defined like attrs when declaring the bxl function above "},{"title":"Accessing target nodes​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#accessing-target-nodes","content":"All standard query functions will be enabled in bxl, allowing users to run query operations, storing them in variables and interacting with them. These allow introspection of the unconfigured targets, or the configured targets based on api # some.bxl targets = ctx.uquery(‘deps(&quot;//foo&quot;)’) targets = filter(targets, my_filter) # introspect a target for target in targets: ctx.print(target.attributes) # prints selects # also inspect the target like below ctx.print(target.label) target = ctx.cquery(“//foo”, “//x86”).attributes # cquery has selects resolved  "},{"title":"Inspect providers​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#inspect-providers","content":"When we have a configured target, bxl can request for the analysis of the rule target = &lt;some configured target&gt; ctx.analysis(target).providers # access the providers  "},{"title":"Actions​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#actions","content":"For IDEs, to generate compilation databases, or generate project files, writing them in bxl will entail creating actions, and executing them. As such, bxl will also be given the rules api to register actions, including dynamic outputs for the rule in the current bxl invocation to build artifacts as part of a bxl function. BXL has the ability to create actions with some constraints: Action is tied to a particular targetIt’s output location is determined in the same pattern as regular actions defined via rules targets = ctx.cquery(‘deps(“//foo:rule”)’) for t in targets: action_ctx = ctx.analysis(t).actions # the action context here is tied to the configured target `t` # actions registered by bxl will be attached with bxl prefix key action_ctx.registry.write(some_output, “foo”)  BXL can also interact with the existing actions on an action via the action_ctx, such as iterating through it, analyzing its outputs, or requesting it to be ran. targets = deps(“foo:rule”) for t in targets: action_ctx = ctx.analysis(t).actions for action in action_ctx.iter(): if “foo/path” in action.output: ctx.build(action)  "},{"title":"What is cached?​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#what-is-cached","content":"All computations requested by a bxl function will be treated as inputs. So if a bxl function calls uquery, then uses the result to do a cquery, and then a build, if buck2 detects that any of the recorded calls to uquery, cquery, and build changes, the entire bxl will be reran, with no early cutoff. The computations itself will still be cached via DICE, so no major performance issues are expected. However, in the event that a bxl function is computationally heavy, the recommendation would be to move that to an action, or split up the bxl and use inter-bxl caching described below. "},{"title":"Inter-bxl caching?​","type":1,"pageTitle":"Buck Extension Language (BXL)","url":"/docs/rfcs/bxl/#inter-bxl-caching","content":"Different bxl can be cacheable between each other if structured as “outputs”/artifacts. This is essentially the same behaviour as a bxl requesting ctx.build, which is cached. Since we have those as hashes on RE, we can track properly and not require storing the values in dice. i.e. # caching_sample.bxl func1 = bxl( impl = my_func1, args = { “arg1”: arg.list(arg.str()), } ) my_func1(ctx): … # do various stuff that might change a lot, but the final result # doesn’t change much ctx.return(some_artifact) func2 = bxl( impl = my_func2, ... ) my_func2(ctx): artifact = ctx.bxl(“:func1”) # now read artifact value # everything below will only be reran if the artifact content changes … # do some expensive stuff  "},{"title":"Buck support to implement configured_alias","type":0,"sectionRef":"#","url":"/docs/rfcs/configured-alias/","content":"","keywords":""},{"title":"Intro​","type":1,"pageTitle":"Buck support to implement configured_alias","url":"/docs/rfcs/configured-alias/#intro","content":"Currently, Buck 2 lacks configured_alias rule support. configured_alias is a builtin rule in Buck v1, and it cannot be currently implemented as user defined rule in Buck v2. This RFC proposes Buck core support for configured_alias. "},{"title":"What is configured_alias?​","type":1,"pageTitle":"Buck support to implement configured_alias","url":"/docs/rfcs/configured-alias/#what-is-configured_alias","content":"Syntax is this: configured_alias( name = &quot;foo-but-linux-release&quot;, actual = &quot;:foo&quot;, platform = &quot;config//platforms:linux-release&quot;, )  When this rule is built, it ignores &quot;current&quot; target configuration, and builds the &quot;actual&quot; target with the configuration specified as &quot;platform&quot; argument. "},{"title":"How to implement it in buck v2?​","type":1,"pageTitle":"Buck support to implement configured_alias","url":"/docs/rfcs/configured-alias/#how-to-implement-it-in-buck-v2","content":""},{"title":"New rule attribute type: configured_dep​","type":1,"pageTitle":"Buck support to implement configured_alias","url":"/docs/rfcs/configured-alias/#new-rule-attribute-type-configured_dep","content":"Currently, we have several dependency attributes: attrs.depattrs.exec_depattrs.transition_depattrs.split_transition_dep This RFC proposes adding another attribute: attrs.configured_dep configured_dep is an attribute which accepts a pair of strings: target and configuration. During analysis, configured attr deps are resolved to providers resolved using given configuration. "},{"title":"configured_alias_impl user defined rule​","type":1,"pageTitle":"Buck support to implement configured_alias","url":"/docs/rfcs/configured-alias/#configured_alias_impl-user-defined-rule","content":"The rule implementation is trivial:  def _configured_alias_impl(ctx): return ctx.attrs.actual.providers configured_alias_impl = rule( impl = _configured_alias_impl, attrs = { &quot;actual&quot;: attrs.configured_dep(), } )  "},{"title":"Finally, configured_alias macro​","type":1,"pageTitle":"Buck support to implement configured_alias","url":"/docs/rfcs/configured-alias/#finally-configured_alias-macro","content":"def configured_alias(name, actual, platform): configured_alias_impl(name, actual = (actual, platform))  "},{"title":"Alternatives​","type":1,"pageTitle":"Buck support to implement configured_alias","url":"/docs/rfcs/configured-alias/#alternatives","content":""},{"title":"No configured_alias​","type":1,"pageTitle":"Buck support to implement configured_alias","url":"/docs/rfcs/configured-alias/#no-configured_alias","content":"Each specific case where configured_alias is used, it can be done with defining custom transition, and using custom transition rule. But having configured_alias is a convenient stopgap to unblock people. "},{"title":"Use @configuration syntax from another RFC.​","type":1,"pageTitle":"Buck support to implement configured_alias","url":"/docs/rfcs/configured-alias/#use-configuration-syntax-from-another-rfc","content":"Instead of passing confiured_target_label(x, y) pass x + &quot;@&quot; + y. "},{"title":"Accept configured_target_label in dep attribute​","type":1,"pageTitle":"Buck support to implement configured_alias","url":"/docs/rfcs/configured-alias/#accept-configured_target_label-in-dep-attribute","content":"dep attribute could support all of: regular target label as stringconfigured target label (as either configured_target_label or x@y I don't know practical applications for this magic, and unless there are uses for it, better keep API simple and explicit. "},{"title":"Bxl Actions and Build API","type":0,"sectionRef":"#","url":"/docs/rfcs/drafts/bxl-actions/","content":"","keywords":""},{"title":"Actions API​","type":1,"pageTitle":"Bxl Actions and Build API","url":"/docs/rfcs/drafts/bxl-actions/#actions-api","content":"The actions API should be the same as rules' actions API. That is, it has the samectx.actions that allows registering of artifacts, creating actions, dynamic actions via the same api. "},{"title":"Creating and Building the Actions​","type":1,"pageTitle":"Bxl Actions and Build API","url":"/docs/rfcs/drafts/bxl-actions/#creating-and-building-the-actions","content":"Bxl allows users to build targets and actions. However, when creating actions, they are not bound/buildable until the artifact/action factories are finalized. As such, we will introduce the limitation that bxl cannot build artifacts that they themselves declared within the bxl. Instead, they will return a set of artifacts to expose to users, which buck2 will automatically build after finalizing the action factory. For dynamic-ness, bxl users will use the standard dynamic output api. There is an issue that during the dynamic output api's lambda, bxl functions will not be able to access the regular bxl functions for queries, etc. However, this is likely not important as most use cases should reasonably query bxl data before the dynamic outputs, and have limited power in dynamic-ness. We can also always replace the ctx of the dynamic to be the bxl context in the future, as we see fit. Sample: def my_bxl(ctx): actions_factory = ctx.bxl_actions.factory() artifact = actions_factory.write(&quot;file.txt&quot;, &quot;content&quot;) # note that existing artifacts that were declared by other rules can be built ctx.actions.build(ctx.analysis(ctx.target(&quot;foo&quot;)).providers[DefaultInfo].default_output)) return [artifact] # exposes the declared artifact to users  "},{"title":"Internal Representation (Deferred Framework)​","type":1,"pageTitle":"Bxl Actions and Build API","url":"/docs/rfcs/drafts/bxl-actions/#internal-representation-deferred-framework","content":"The existing actions framework attaches all actions to a deferred, which is based off a ConfiguredLabel, which also corresponds to the output path prefix. bxl actions should also have a unique output path prefix, and follow the same system of having a base deferred key to reuse the action implementation. We should extend the BaseKey of a DeferredKey to support beyond a ConfiguredLabel, so that we can use a BxlFunctionLabel in its place. This would allow owner of these actions to point to the correct creator. The output path would be determined by using the BxlFunctionLabel as prefix similar to a label. While this means that not all outputs are associated with an actual rule, this is arguably more correct as bxl that creates outputs that doesn't fit the target graph structure (i.e android project generation follows directory structure rather than the packages defined by targets) to not have to conform the attaching their actions to existing rules. bxl functions can examine multiple rules and create a single action, attached only to their function label. The ActionRegistry will be attached to the evaluation result of bxl. Since we do not allow bxl to explicitly request build of the actions itself declares, we can wait until the end of the bxl function to finalize the actions. Then, the action lookup can simply refer to the result of the bxl. With the above changes, the rest of the actions framework does not need changed to support the proposed API. DICE caching will work as today. "},{"title":"[RFC] Configuration Modifiers","type":0,"sectionRef":"#","url":"/docs/rfcs/drafts/cfg-modifiers/api/","content":"","keywords":""},{"title":"API​","type":1,"pageTitle":"[RFC] Configuration Modifiers","url":"/docs/rfcs/drafts/cfg-modifiers/api/#api","content":"A configuration is a collection of constraints. In this API, every top-level target starts with an empty configuration. To resolve the default target configuration, Buck will apply a list of &quot;modifiers&quot;. A modifier is a modification on the existing configuration to obtain a new configuration. A modifier can be applied on the command line, on a PACKAGE, or on a target. When resolving modifiers, Buck will collect all modifiers from command line, PACKAGE, and target and apply them in order until the target configuration is obtained. A modifier can be specified as a constraint_value, a config_setting,platform, or a cfg_override target. If the modifier applied is a constraint value, that constraint value will be added to the configuration. Config setting and platform are both collections of constraints, so if the modifier is a config setting or a platform, then we loop over every constraint value and add it to the configuration (note that since modifiers only work with configuration and not buckconfigs, using a config_setting with a non-empty set of buckconfigs as a modifier will be an error).cfg_override rule applies a transition-like function that can arbitrarily insert or delete constraints from the existing configuration. "},{"title":"1. Required Modifiers​","type":1,"pageTitle":"[RFC] Configuration Modifiers","url":"/docs/rfcs/drafts/cfg-modifiers/api/#1-required-modifiers","content":"Every top-level target starts with an empty configuration. Buck first applies &quot;required modifiers&quot;, which is a list of modifiers provided by the user via the command line. The required modifiers are specified asbuck2 build &lt;target&gt;?&lt;modifiers separated by commas&gt;, and the list of modifiers will be applied sequentially in that order. For example, If the user requests buck2 build //foo:bar, repo//foo:bar will have an empty configuration after resolving the required modifiers.If the user requestsbuck2 build repo//foo:bar?config//build_mode/constraints:nosan,repo//foo:bar will have config//build_mode/constraints:nosanin its configuration after resolving required modifiers.buck2 build repo//foo:bar?config//build_mode/constraints:nosan,config//build_mode/constraints:split-dwarfwill add nosan and split-dwarf in that order to the empty configuration.If the user requestsbuck2 build repo//foo:bar?config//build_mode/constraints:nosan,config//build_mode/constraints:asanwhere both constraint values belong to the same constraintconfig//build_mode/constraints:san, then asan will replace nosan in repo//foo:bar's configuration. To make constraints more convenient to type, you can use Buck's target alias feature to create an alias for a constraint. For example, you can add the following line to your .buckconfig [alias] asan = config//build_mode/constraints:asan nosan = config//build_mode/constraints:nosan  to use buck2 build repo//foo:bar?asan and buck2 build repo//foo:bar?nosan as shorthand. buck2 build repo//foo/...?asan and buck2 build repo//foo:?asanare both valid. To specify modifiers to a list of target patterns on the command line, you can use the --cfg=modifier flag. For example, buck2 build //foo:bar //foo:baz --cfg=asanis equivalent to buck2 build repo//foo:bar?asan //foo:baz?asan. --cfg flag can be specified multiple times to add multiple modifiers. For example, buck2 build --cfg=release --cfg=windows repo//foo:baris equivalent to buck2 build repo//foo:bar?release,windows. This behavior is consistent with how flags are interpreted in other tools, and it is the most intuitive behavior, for example, buckconfig -c flag adds to the one set of buckconfigsbuild systems like CMake have flags like -D that can be specified multiple times, and they are all added to one set of flags. It is prohibited to specify both --cfg flag and ? in target pattern.--cfg flag exists for convenience, and to specify complex configuration setups (in scripts or in CI), users can always specify ?. This restriction can be lifted in the future if there is a need. When specifying a subtarget and modifier with ?, subtarget should go before modifier, ex. buck2 build repo//foo:bar[comp-db]?asan. The configuration after all required modifiers are resolved is known as required configuration, and all constraints within that configuration are immutable entries of the target configuration. They cannot be removed or overwritten. This guarantees that the configuration a target ends up with always include the modifiers user requested. For example, if the user requests asan on the command line, the target configuration should always end up with an asan constraint value, not a nosan constraint value. If a later PACKAGE or per-target modifier specifies nosan as a constraint, nosan will not be added to the configuration because asan and nosan both belong to the same constraint config//build_mode/constraints:sanitizer, and asan is a required constraint. "},{"title":"2. (Legacy) Target platform​","type":1,"pageTitle":"[RFC] Configuration Modifiers","url":"/docs/rfcs/drafts/cfg-modifiers/api/#2-legacy-target-platform","content":"If a target platform is specified on a target (either via the default_target_platform attribute or the --target-platforms flag), then that target platform gets applied as a modifier, where Buck loops over every constraint within the platform and add it to the target configuration unless that constraint conflicts with the required configuration. When required, PACKAGE, and target modifiers are empty, the target configuration is the target platform. This is designed to making the new API interop with target platform resolution so that the migration can be gradual. "},{"title":"3. Per-PACKAGE modifiers​","type":1,"pageTitle":"[RFC] Configuration Modifiers","url":"/docs/rfcs/drafts/cfg-modifiers/api/#3-per-package-modifiers","content":"Per-PACKAGE modifiers are applied after target platform is resolved. To define a per-PACKAGE modifier, you can use theadd_default_cfg(&lt;modifier&gt;) function in a PACKAGE file. A modifier set through add_default_cfg will apply to all targets covered by that PACKAGE. The following example adds nosan and debug to the default target configurations of all targets in repo//foo/... unless the required configuration already has conflicting required constraints. # foo/PACKAGE add_default_cfg(&quot;config//build_mode/constraints:nosan&quot;) add_default_cfg(&quot;config//build_mode/constraints:debug&quot;)  In this example, debug is applied after nosan. If a sub-PACKAGE exists for a PACKAGE, that sub-PACKAGE will always inherit modifiers from its parent. This means that if there are multiple PACKAGE files in the path of a target, we apply their modifiers in order from the topmost PACKAGE. Suppose repo/PACKAGE and repo/foo/PACKAGE exist for target repo//foo:bar. In this case, modifiers in repo/PACKAGE apply first before modifiers in repo/foo/PACKAGE. PACKAGE inheritance of modifiers means that project-level modifiers can be easily set for all targets under a project without having to wire logic through the bzl wrapper of every rule type in that project. "},{"title":"4. Per-Target Modifier​","type":1,"pageTitle":"[RFC] Configuration Modifiers","url":"/docs/rfcs/drafts/cfg-modifiers/api/#4-per-target-modifier","content":"Per-target modifier are applied after all per-PACKAGE modifier are resolved. Modifiers can be set on any target through the default_cfg attribute. The modifiers are specified as a list and will be applied in sequential order. For example, # repo/foo/TARGETS python_binary( name = &quot;bar&quot;, # Some other attributes... default_cfg = [ &quot;config//build_mode/constraints:nosan&quot;, &quot;config//build_mode/constraints:debug&quot;, ], )  adds nosan and debug constraints in that order torepo//foo:bar's configuration. Once per-target modifiers are resolved, we end up with a target configuration used to configure a target. Note that that target's configuration can further change after modifiers are resolved if there are per-rule transitions applied on the target. "},{"title":"cfg_override rule​","type":1,"pageTitle":"[RFC] Configuration Modifiers","url":"/docs/rfcs/drafts/cfg-modifiers/api/#cfg_override-rule","content":"A modifier can be defined as a cfg_override rule in addition to platform and constraint value. This rule applies a function that takes in the existing configuration as input, changes it, and returns a new configuration. This allows more complex logic like adding a constraint only if an existing constraint exists. The following example shows a way to express &quot;use msvc on windows configuration but clang on other OSes&quot;. # repo/BUCK def _msvc_if_windows_else_clang_impl( # `Configuration` is an opaque object that supports methods `contains`, `get`, `insert`, and `pop` similar to a dictionary. cfg: &quot;Configuration&quot;, # `Refs` holds references to dependent constraints, platforms, and modifiers. refs, ) -&gt; &quot;Configuration&quot;: if cfg.contains(refs.windows): cfg.insert(refs.msvc) else: cfg.insert(refs.clang) return cfg cfg_override( name = &quot;msvc_if_windows_else_clang&quot;, impl = _msvc_if_windows_else_clang_impl, refs = { &quot;clang&quot;: &quot;config//compiler/constraints:clang&quot;, &quot;msvc&quot;: &quot;config//compiler/constraints:msvc&quot;, &quot;windows&quot;: &quot;config//os/constraints:windows&quot;, }, ) # repo/PACKAGE add_default_cfg(&quot;:msvc_if_windows_else_clang&quot;)  Now a target will always have the msvc constraint added when targeting windows but the clang constraint otherwise. It's possible to make cfg_override significantly less verbose via a lambda. For example, the above example can be rewritten as # repo/BUCK cfg_override( name = &quot;msvc_if_windows_else_clang&quot;, # `cfg.set` returns a `Configuration` object. impl = lambda cfg, refs: cfg.set( refs.msvc if cfg.contains(refs.windows) else refs.clang ), refs = { &quot;clang&quot;: &quot;config//compiler/constraints:clang&quot;, &quot;msvc&quot;: &quot;config//compiler/constraints:msvc&quot;, &quot;windows&quot;: &quot;config//os/constraints:windows&quot;, }, )  cfg_override target can only be specified for PACKAGE and per-target modifiers, not required modifiers (this restriction can be revisited later if needed). cfg_override is only intended for complex cases needed to selectively insert constraints based on existing constraints. For the majority of use cases, specifying constraints directly as modifiers should be sufficient. Like other types of modifiers, cfg_override cannot override required constraints. To guarantee this, insert and pop methods of Configuration object will be no-ops if it is trying to overwrite a required constraint. For example, in the previous example, if the user supplies a requested configuration of windows and clang, then the target configuration will end up containing windows and clang, not windows and msvc. To make it clear which constraints are required to the cfg_override function, the Configuration object supports a required_cfg function that returns a RequiredConfiguration object holding only the required constraints. A RequiredConfiguration is immutable and supportscontains and get methods but not insert, set, or pop. "},{"title":"Configuration Naming​","type":1,"pageTitle":"[RFC] Configuration Modifiers","url":"/docs/rfcs/drafts/cfg-modifiers/api/#configuration-naming","content":"It's important for a configuration to have a representative name to indicate what important constraints were used. This is useful for debugging because often a build error is caused by a misconfiguration. To make this easy, this API adds a naming function to derive a useful name based on the existing configuration. The name function takes in a map of constraint settings to constraint values as input and returns a string for the name of the configuration. This name function will be defined globally for a repo. An example is as follows. # Generated configuration follows the name &lt;os&gt;-&lt;sanitizer&gt;-&lt;toolchain&gt;. KEY_CONSTRAINT_SETTINGS = [ &quot;config//os/constraints:os&quot;, &quot;config//build_mode/constraints:sanitizer&quot;, &quot;config//compiler/constraints:toolchain&quot;, ] def _name( # Keys and values in `constraints_map` are fully qualified target label strings. constraint_map, # {str.type: str.type} ) -&gt; str.type: name_builder = [] for constraint_setting in KEY_CONSTRAINT_SETTINGS: constraint_value = constraint_map.get(constraint_setting) if constraint_value is not None: # Get the target name from full target label and add it to the generated name. name_builder.append(constraint_value.split(&quot;:&quot;)[-1]) return &quot;-&quot;.join(name_builder)  "},{"title":"Debugging modifiers​","type":1,"pageTitle":"[RFC] Configuration Modifiers","url":"/docs/rfcs/drafts/cfg-modifiers/api/#debugging-modifiers","content":"Because many layers of modifiers can be applied before obtaining a final configuration, it is important that modifiers are easy to debug for integrators. To show what modifiers are applied, we can add a buck.modifiers special attribute to every target that keeps track of all the required modifiers, legacy target platform, per-PACKAGE modifiers and per-target modifiers a target goes through in order. We can also add a buck2 audit cfg-modifiers &lt;TARGET&gt;command to show the configuration change after each modifier is applied as well as which PACKAGE/BUCK/TARGETS file each modifier is added. "},{"title":"How configuration modifiers differ from transitions​","type":1,"pageTitle":"[RFC] Configuration Modifiers","url":"/docs/rfcs/drafts/cfg-modifiers/api/#how-configuration-modifiers-differ-from-transitions","content":"Modifiers are largely inspired by configuration transitions, and there are a high amount of similarities in particular between the cfg_override rule and the transition rule. The major differences are: A transition can change the configuration of a target when depending on a target, but a modifier can only change the configuration of a top-level target. In other words, if you have target A that depends on target B and you request a build of A, then A's target configuration would be resolved via modifiers and propagated down to B, but dep B would not do its own modifier resolutioncfg_override functions see an opaque &quot;Configuration&quot; object, so it cannot know every single constraint used in the configuration. Transition functions can iterate and read every constraint in the configuration. Transitions can use logic like &quot;throw away the old configuration entirely and use a new configuration&quot; (which is what fat platform transition currently does) whereas an override cannot.Transitions can accept an attrs parameter from the attributes of the target if necessary whereas cfg_override does not (if necessary, this can be revisited).cfg_override is specified as a target and transition is not. Ideally, we should unify all the API differences between cfg_overrideand transition and use transition directly instead, but that's out of the scope of this RFC for now. They have different use cases. For example, Python version should be modeled as a transition and not modifier. Suppose we have python_binary A nested as a resource of another python_binary B. A should not inherit the python version from B, so a transition is needed to change A's python version when depended on by B.Library target should use modifiers and not transitions. A C++ library target should always inherit the configuration of its parent C++ binary when it is used as a dep, but a top-level C++ library target can still have its configuration changed via modifiers when requested from command line. "},{"title":"End Goal​","type":1,"pageTitle":"[RFC] Configuration Modifiers","url":"/docs/rfcs/drafts/cfg-modifiers/api/#end-goal","content":"No more default_target_platform. No more --target-platforms flag. There shouldn't be a need to define platform targets outside of exec platforms. Most use cases of read_config are killed. Buckconfigs should be reserved for buck2 core features. Most build settings should only use configurations. "},{"title":"@configuration syntax","type":0,"sectionRef":"#","url":"/docs/rfcs/drafts/configuration-at-syntax/","content":"","keywords":""},{"title":"What​","type":1,"pageTitle":"@configuration syntax","url":"/docs/rfcs/drafts/configuration-at-syntax/#what","content":"Command buck2 build //foo:bar@config//platform:linux-x86_64  should be equivalent to current syntax: buck2 build //foo:bar --target-platforms=//platform:linux-x86_64  "},{"title":"Why​","type":1,"pageTitle":"@configuration syntax","url":"/docs/rfcs/drafts/configuration-at-syntax/#why","content":"Might be convenient if we define global (or per-target, as proposed intarget configuration discovery RFC) alias. For example, if there's an alias release=//config:linux-x86_64-release  The command above can be expressed as: buck2 build //foo:bar@release  Additionally, if we haveconfiguration expression RFC implemented, we can do something like: buck2 build //foo:bar@release+gcc  "},{"title":"Possible future extensions​","type":1,"pageTitle":"@configuration syntax","url":"/docs/rfcs/drafts/configuration-at-syntax/#possible-future-extensions","content":"For now, at-syntax only applies to command line arguments of build/targets/run/test commandsprobably cquery query It would be reasonable to expect that this syntax should be allowed anywhere we need a target (e.g. in deps attribute), but this is out of scope of this proposal. "},{"title":"Digest Kinds","type":0,"sectionRef":"#","url":"/docs/rfcs/drafts/digest-kinds/","content":"","keywords":""},{"title":"Use cases:​","type":1,"pageTitle":"Digest Kinds","url":"/docs/rfcs/drafts/digest-kinds/#use-cases","content":"Buck2 needs to support more than just SHA1 for open-sourcing, since publicly available RE providers use SHA256.Internally, we want to migrate to (potentially keyed) Blake3, and there will be a transition period where we need to support both Blake3 and SHA1. "},{"title":"Proposed plan​","type":1,"pageTitle":"Digest Kinds","url":"/docs/rfcs/drafts/digest-kinds/#proposed-plan","content":"Make all the ways in which Buck2 ingests digests either configurable or explicit about the type of digest they expect. Internally, we may keep track of digest types for debugging purposes, but we will never compute more than one digest. It follows that we won't expose configuration for the digests we output (namely: to use on RE): if we only have one digest for each blob, making it configurable has no utility since you never have a choice about the hash to use. "},{"title":"Implementation​","type":1,"pageTitle":"Digest Kinds","url":"/docs/rfcs/drafts/digest-kinds/#implementation","content":""},{"title":"Hashes received from RE​","type":1,"pageTitle":"Digest Kinds","url":"/docs/rfcs/drafts/digest-kinds/#hashes-received-from-re","content":"For interactions with RE, we'll expose two configurations (this can be on the CommandExecutorConfig): Preferred hash to use when Buck2 is doing the hashing (e.g. hashing directories).Accepted hashes. We'll use the format of the digests we receive from RE (in particular their size) to infer what algorithm they used (remember: the RE API provides no way of knowing the format of a digest, it's just a string). "},{"title":"Hashes of files​","type":1,"pageTitle":"Digest Kinds","url":"/docs/rfcs/drafts/digest-kinds/#hashes-of-files","content":"We'll expose the hash to use via a buckconfig. Our things-that-produce-hashes-of-files should either use the config to choose how they hash, or fail if they cannot provide the right hash format (e.g. that'll be true of Eden I/O). "},{"title":"Hashes of directories​","type":1,"pageTitle":"Digest Kinds","url":"/docs/rfcs/drafts/digest-kinds/#hashes-of-directories","content":"This one gets a little tricky. Our directories currently have an implementation of fingerprinting that receives only the directory as input, so some refactoring is in order. We have two options: Pick the hashing algorithm based on the contents of the directory (pick one that's already used). Dealing with empty directories is a bit annoying.Refactor the directory implementation and have directories parameterized over their fingerprints, not their hasher. The first one is easier but has the downside of not working with keyed Blake3 (because you don't have a way to bring in the key), so I'm aiming for the second implementation for now. "},{"title":"RFC: TestInfo v2","type":0,"sectionRef":"#","url":"/docs/rfcs/drafts/test-info-v2/","content":"RFC: TestInfo v2 A stub RFC for TestInfo v2 to track lessons learned about TestInfo v1. The stack starting D36339960 contains the original code for the TestInfo and templated test API experiment.","keywords":""},{"title":"Return error in ProviderCollection[] on undeclared provider","type":0,"sectionRef":"#","url":"/docs/rfcs/implemented/provider-collection-at/","content":"","keywords":""},{"title":"Why​","type":1,"pageTitle":"Return error in ProviderCollection[] on undeclared provider","url":"/docs/rfcs/implemented/provider-collection-at/#why","content":"Better diagnostics when accessing unknown provider. E. g. when writing: ctx.attrs.foo[UnknownInfo].bar  Currently, the error is: Object of type `NoneType` has no attribute `bar`  Instead, the error will be something like: provider collection does not contain `UnknownInfo`, defined providers are `FooInfo`, `BarInfo`.  "},{"title":"Bazel​","type":1,"pageTitle":"Return error in ProviderCollection[] on undeclared provider","url":"/docs/rfcs/implemented/provider-collection-at/#bazel","content":"In bazel, [] on unknown provider is an error, like this: Error: &lt;target //optional_provider:n2&gt; (rule '_sum') doesn't contain declared provider 'UnknownInfo'  "},{"title":"Package-local values","type":0,"sectionRef":"#","url":"/docs/rfcs/package-local-values/","content":"","keywords":""},{"title":"Why​","type":1,"pageTitle":"Package-local values","url":"/docs/rfcs/package-local-values/#why","content":"DevX people want to have some per-directory configuration files, accessible from Starlark macros. For example, a project NNN may want to switch to building using LLVM 15 by default. End users would want to have an easy instruction how to do that, after DevX people provided instructions and infrastructure for that. "},{"title":"What we have now​","type":1,"pageTitle":"Package-local values","url":"/docs/rfcs/package-local-values/#what-we-have-now","content":"Currently, in fbcode, we have get_modes mechanism. get_modes symbol is registered in per-package implicit symbols,here. This symbol can be accessed from macros usingimplicit_package_symbol function. get_modes functions are package-local, but all BUILD_MODE.bzlfiles need to be registered in global buckconfig, which is not ideal. Proposed per-package properties can replace get_modes mechanism. "},{"title":"API​","type":1,"pageTitle":"Package-local values","url":"/docs/rfcs/package-local-values/#api","content":""},{"title":"PACKAGE files​","type":1,"pageTitle":"Package-local values","url":"/docs/rfcs/package-local-values/#package-files","content":"Before evaluating BUCK file, buck2 will evaluate all PACKAGE files in the same directory and all parent directories. Absent PACKAGE files are treated as empty files. All relevant PACKAGE files are executed sequentially from the root directory to the current directory (but unrelated PACKAGE files can be executed in parallel). Evaluating PACKAGE files sequentially provides additional guarantees, for example, attempt to override a property (unless explicitly requested) should fail with Starlark call stack. Each PACKAGE file is evaluated at most once (like bzl file). PACKAGE files may load arbitrary bzl files.BUCK-specific functions called in bzl files (like rule functions) are available, but calling functions from PACKAGE files is an error. This way, bzl files are evaluated only once regardless of whether they are loaded from PACKAGE or BUCK file. "},{"title":"API​","type":1,"pageTitle":"Package-local values","url":"/docs/rfcs/package-local-values/#api-1","content":"PACKAGE files have a global function: PACKAGE file API​ def write_package_value( name: str.type, value: &quot;&quot;, overwrite: bool.type = False, ): ...  Name is a string which must contain exactly one dot symbol (just to enforce code style). Value is an arbitrary Starlark value, for example, an integer, a list of integer, a struct or a function. When overwrite is False (default), attempt to overwrite per-package value defined in parent PACKAGE file will fail. Written values are frozen when PACKAGE file evaluation is finished. Note write_package_value symbol exists in bzl globals, and it can be called from bzl file in context of PACKAGE evaluation, but calling write_package_file is an error on context of BUCK evaluation. Modifying PACKAGE file logically invalidates the BUCK file of this package, and all PACKAGE and BUCK files of subpackages. However, BUCK file evaluation may track which package-local values were accessed and only invalidate BUCK files which were potentially affected (similarly to how we do it with buckconfigs, with individual properties being projection keys). BUCK file API​ BUCK files (and bzl files included from BUCK files) have a global function: def read_package_value( name: str.type, ): ...  This function returns the nearest value registered per package, or None is such value does not exist. This function is available in bzl files, but attempt to call this function in context of PACKAGE file evaluation results in an error. This restriction can be lifted in the future. Per-package values are not accessible as global symbols in BUCK files. We may reconsider it in the future. "},{"title":"read_config​","type":1,"pageTitle":"Package-local values","url":"/docs/rfcs/package-local-values/#read_config","content":"PACKAGE files may call read_config function. "},{"title":"Alias","type":0,"sectionRef":"#","url":"/docs/rule_authors/alias/","content":"","keywords":""},{"title":"alias​","type":1,"pageTitle":"Alias","url":"/docs/rule_authors/alias/#alias","content":"The alias rule has the following relevant attributes: name - (required) what the actual's label should be aliased as.actual - (required) a target label.default_host_platform - default host platform to use for the aliased target. Example filegroup( name = &quot;foo&quot;, srcs = [&quot;foo.txt&quot;], ) alias( name = &quot;other_foo&quot;, actual = &quot;:foo&quot;, )  "},{"title":"versioned_alias​","type":1,"pageTitle":"Alias","url":"/docs/rule_authors/alias/#versioned_alias","content":"The versioned_alias rule has the following relevant attributes: name - (required) what the actual's label should be aliased as.actual - (required) a target label.versions - (required) a map of versions to their respective versioned target labels. Under the hood, any versioned parameters from the versioned_alias's underlying actual are translated into their select-based equivalents, which rely on constraint settings added to the target platform. Example versioned_alias( name = &quot;foo&quot;, versions = { # Target labels for foo versions &quot;1.1&quot;: &quot;//path/to/lib/1.1:foo&quot;, &quot;1.2&quot;: &quot;//path/to/lib/1.2:foo&quot;, }, visibility = [ &quot;PUBLIC&quot;, ], )  "},{"title":"configured_alias​","type":1,"pageTitle":"Alias","url":"/docs/rule_authors/alias/#configured_alias","content":"The configured_alias rule has the following relevant attributes: name - (required) what the actual's label should be aliased as.configured_actual - a configured label (mapped to a configured dep under the hood so the providers can be simply forwarded).fallback_actual - if configured_actual is not set, then fallback to this value, which is an unconfigured dep. If configured_actual is not set, then fallback_actual must be set.platform - the platform to build the aliased target with. note The actual field is available for configured_alias but it is not used under the hood (to keep compatibility of output format with Buck1 queries). Outside of simply pointing at another target, this target has one other useful feature - it contains a platform argument. This makes the alias rule useful for two distinct scenarios: Configuration switching during the build. For example, there is an iOS target that needs to build a dependency for WatchOS so it can include it in the bundle. This can be represented by the iOS target having a dependency on an alias of the Watch app with platform = &quot;//the/desired/watchos:platform&quot;.Using a target to refer to another in a non-standard configuration. For example, if you want to have an experimental version of an app, you could represent that as an alias with an 'experimental' configuration pointing to the original target. Example configured_alias( name = &quot;foo-with-platform1&quot;, actual = &quot;//lib:foo&quot;, platform = &quot;//some_config:platform1&quot;, visibility = [&quot;PUBLIC&quot;], )  "},{"title":"Anonymous Targets","type":0,"sectionRef":"#","url":"/docs/rule_authors/anon_targets/","content":"","keywords":""},{"title":"Simple Example​","type":1,"pageTitle":"Anonymous Targets","url":"/docs/rule_authors/anon_targets/#simple-example","content":"# Define an anonymous rule UpperInfo = provider(fields = [&quot;message&quot;]) def _impl_upper(ctx): return [UpperInfo(message = ctx.attrs.message.upper()] upper = rule( attrs = {&quot;message&quot;, attrs.string()}, impl = _impl_upper ) # Use an anonymous target def impl(ctx): def k(providers): print(providers[UpperInfo].message) # These are the providers this target returns return [DefaultInfo()] return ctx.actions.anon_target(upper, { name: &quot;my//:greeting&quot;, message: &quot;Hello World&quot;, }).map(k)  Notes: An anonymous rule is defined using rule. These are normal rules, with the difference that they are not in a configuration, so ctx.actions.label won't show configuration information, but just unspecified.An anonymous rule is used via ctx.actions.anon_target, passing in the rule and the attributes for the rule.The return value is a promise type, which when evaluated returns the providers of the anonymous target. The promise type has a few special behaviors. It has a map function, which takes a function and applies it to the future, returning a new future.If analysis returns a promise type, the outer Rust layer invokes the future to get at the analysis result. If that future then returns another future, Rust keeps going until it has a final result. It must eventually get to a list of providers. Attribute resolution is handled differently from normal code: String/Int/Bool happen as normal.The name attribute is optional, but, if present, must be a syntactically valid target, but can refer to a cell/package that does not exist.Deps attributes do not take strings, but dependencies, already in a configuration.Exec_deps are not available.Transitions and more complex forms of attributes are banned.Default attr.deps (as used for toolchains) are not permitted, as the default can't express a dependency. They must be passed forward from the caller. The execution platform for an anon target is that of the inherited from the calling target, which is part of the hash. If that is too restrictive, you could use execution groups, where an anon target gets told which execution group to use. "},{"title":"Longer example​","type":1,"pageTitle":"Anonymous Targets","url":"/docs/rule_authors/anon_targets/#longer-example","content":"The following code represents a scenario for a compile-and-link language where, if two targets end up compiling the same file (for example, they are in the same package and both list it, or it gets export_file'd), then that file is compiled just once: ## BUCK ############## @load(&quot;:silly.bzl&quot;, &quot;silly_binary&quot;) silly_binary( name = &quot;hello&quot;, srcs = [&quot;hello.sil&quot;, &quot;world.sil&quot;], ) ## silly.bzl ############ _SillyCompilation = provider(fields = [&quot;compiled&quot;]) def _silly_compilation_impl(ctx): out = ctx.actions.declare_output(&quot;output.o&quot;) ctx.actions.run(cmd_args( ctx.attrs.toolchain.compiler, ctx.attrs.src, &quot;-o&quot;, out.as_output(), )) return [DefaultInfo(), _SillyCompilation(compiled = out)] _silly_compilation = rule( impl = _silly_compilation_impl, attrs = { &quot;src&quot;: attrs.src(), &quot;toolchain&quot;: attrs.dep(), }, ) def _silly_binary_impl(ctx): def k(providers): # Step 2: now link them all together out = ctx.actions.declare_output(&quot;out.exe&quot;) objs = [p[_SillyCompilation].compiled for p in providers] ctx.actions.run(cmd_args( ctx.attrs._silly_toolchain.linker, objs, &quot;-o&quot;, out.as_output(), )) return [ DefaultInfo(default_output = out), RunInfo(args = out), ] # Step 1: compile all my individual files return ctx.actions.anon_targets( [(_silly_compilation, { &quot;src&quot;: src, &quot;toolchain&quot;: ctx.attrs._silly_toolchain }) for src in ctx.attrs.srcs] ).map(k) silly_binary = rule( impl = _silly_binary_impl, attrs = { &quot;srcs&quot;: attr.list(attr.src()), &quot;link_flags&quot;: attr.args(), &quot;_silly_toolchain&quot;: attr.dep(default = &quot;toolchains//:silly&quot;), }, )  "},{"title":"Convert promise to artifact​","type":1,"pageTitle":"Anonymous Targets","url":"/docs/rule_authors/anon_targets/#convert-promise-to-artifact","content":"It can be challenging to pass around the promises from anon_target and structure functions to support that. If you only need an artifact (or multiple artifacts) from an anon_target, you can use ctx.actions.promise_artifact() to convert a promise to an artifact. This artifact can be passed to most things that expect artifacts, but until it is resolved (at the end of the current analysis) it can't be inspected with artifact functions like .extension, .short_path, etc. The promise must resolve to a build (not source) artifact with no associated artifacts. Example: HelloInfo = provider(fields = [&quot;hello&quot;, &quot;world&quot;]) def _anon_impl(ctx: &quot;context&quot;) -&gt; [&quot;provider&quot;]: hello = ctx.actions.write(&quot;hello.out&quot;, &quot;hello&quot;) world = ctx.actions.write(&quot;world.out&quot;, &quot;world&quot;) return [DefaultInfo(), HelloInfo(hello = hello, world = world)] _anon = rule(impl = _anon_impl, attrs = {}) def _use_impl(ctx: &quot;context&quot;) -&gt; [&quot;provider&quot;]: promise = ctx.actions.anon_target(_anon, {}) hello_promise = promise.map(lambda x: x[HelloInfo].hello) world_promise = promise.map(lambda x: x[HelloInfo].world) hello_artifact = ctx.actions.artifact_promise(hello_promise) world_artifact = ctx.actions.artifact_promise(world_promise) out = ctx.actions.declare_output(&quot;output&quot;) ctx.actions.run([ ctx.attrs.some_tool, hello_artifact, world_artifact, out.as_output() ], category = &quot;process&quot;) return [DefaultInfo(default_output = out)] use_promise_artifact = rule(impl = _use_impl, attrs = { &quot;some_tool&quot;: attr.exec_dep(), })  "},{"title":"Configuration Transitions","type":0,"sectionRef":"#","url":"/docs/rule_authors/configuration_transitions/","content":"","keywords":""},{"title":"Transition rule​","type":1,"pageTitle":"Configuration Transitions","url":"/docs/rule_authors/configuration_transitions/#transition-rule","content":"Transition rules are defined in .bzl files using the transition built-in. The transition function creates a configuration-related object. The transition object is opaque, it does not have any operations, and can only be used as an argument to rule function or attribute constructor. The transition function call must be assigned to a global variable (this is similar to user-defined provider declarations). The transition function takes three arguments: implementation - a function.refs - references to configuration rules to be resolved and passed to the implementation function.split - (optional) bool flag (default False) to indicate whether transition is a split transition (used in per attribute transitions). The implementation function takes two arguments: platform - a configuration to transition.refs - resolved references as a struct. Example transition from ios to watchos (for example, to build a watchOS bundle as part of an iOS build): def _impl(platform: PlatformInfo.type, refs: struct.type) -&gt; PlatformInfo.type: # Operating system constraint setting. os = refs.os[ConstraintSettingInfo] # Watchos constraint value. watchos = refs.watchos[ConstraintValueInfo] # Remove operating system constraint from input platform. constraints = { s: v for (s, v) in platform.configuration.constraints.items() if s != os.label } # Add watchos constraint value. constraints[watchos.setting.label] = watchos # Construct configuration structure. new_cfg = ConfigurationInfo( # Updated constraints. constraints = constraints, # Keep original config values. values = platform.configuration.values, ) # And return new configuration, # or a dict of marker to configuration in case of split transition. return PlatformInfo( # ... supplying configuration label. label = &quot;&lt;transitioned-to-watch&gt;&quot;, configuration = new_cfg, ) iphone_to_watch_transition = transition(_impl, refs = { &quot;os&quot;: &quot;//constraints:os&quot;, &quot;watchos&quot;: &quot;//constraints:watchos&quot;, })  A transition function applied twice must produce the configuration identical to the configuration produced after applying transition once. assert tr(tr(platform=platform, refs=refs), refs=refs) == tr(platform=platform, refs=refs)  If this invariant is not held, certain operations produce incorrect and possibly infinite graphs. This is not yet enforced. "},{"title":"Per rule transition​","type":1,"pageTitle":"Configuration Transitions","url":"/docs/rule_authors/configuration_transitions/#per-rule-transition","content":"The rule function has an optional cfg attribute, which takes a reference to the transition object (created with the transition function; not a string). When such a rule is called, it is instantiated, not with the requested configuration, but with the requested configuration transformed with a given rule transition. For example, the transition for watchos when the iOS target depends on watchos resource: watchos_resource = rule( cfg = iphone_to_watch_transition, ... )  "},{"title":"Per attribute transition​","type":1,"pageTitle":"Configuration Transitions","url":"/docs/rule_authors/configuration_transitions/#per-attribute-transition","content":"The attrs object has two attribute constructors: attrs.transition_dep(cfg)attrs.split_transition_dep(cfg) These attributes are similar to the dep attribute. When dependencies are resolved for the rule instance, then they are resolved not with the rule instance configuration, but with the configuration transformed with the given transition. For split transition, each dependency is resolved into a dict of marker to providers. For example: android_binary = rule( ... attrs = { &quot;deps&quot;: attrs.list(attrs.split_transition_dep(cfg = cpu_split_transition), default = []), }, )  When the above is invoked as follows: android_binary( deps = [&quot;//foo:bar&quot;, &quot;//qux:quux&quot;], )  Then the rule implementation gets something like the following in the deps attribute: { [ { # Key in this dict is the marker returned from split transition impl function. &quot;arm64&quot;: &quot;providers for //foo:bar configured for arm64&quot;, &quot;armv7&quot;: &quot;providers for //foo:bar configured for armv7&quot;, }, { &quot;arm64&quot;: &quot;providers for //qux:quux configured for arm64&quot;, &quot;armv7&quot;: &quot;providers for //qux:quux configured for armv7&quot;, }, ] }  note It is an error to pass a split transition object to attrs.transition_dep and a non-split transition to attrs.split_transition_dep. "},{"title":"Per target transition​","type":1,"pageTitle":"Configuration Transitions","url":"/docs/rule_authors/configuration_transitions/#per-target-transition","content":"The Buck2 team is considering the implementation of per target transitions (that is, transitions referenced at a rule instantiation site as opposed to rule declaration site). No specific plans or APIs exists at the moment. It could be something like the following: cxx_binary( name = &quot;foo&quot;, cfg = &quot;//transitions:opengl-es-1.0&quot;, ... )  "},{"title":"Request transition on command line​","type":1,"pageTitle":"Configuration Transitions","url":"/docs/rule_authors/configuration_transitions/#request-transition-on-command-line","content":"For information, see RFC. "},{"title":"Access rule attributes in transition function implementation​","type":1,"pageTitle":"Configuration Transitions","url":"/docs/rule_authors/configuration_transitions/#access-rule-attributes-in-transition-function-implementation","content":"It might be useful for the transition function to be able to query rule attributes (for example, to perform transition to different configurations depending on java_version attribute). Both incoming (per rule) and outgoing (per dependency) transitions can access rule attributes. For outgoing transitions, transition rule implementation accesses the attributes of the target that has dependencies with transitions, not attributes of dependency targets. def _tr(platform, refs, attrs): # NB: There are some restrictions on what attrs can be made accessible: # - Only primitive values for now (providers are not resolved) # - Only unconfigured attributes for now attrs.my_list_attribute # == [12345, 67890] tr = transition( _tr, refs = {}, attrs = { &quot;my_list_attribute&quot;: attr.list(...), }, ) my_rule = rule(..., cfg=tr) my_rule( ..., my_list_attribute = [12345, 67890], )  "},{"title":"Configurations","type":0,"sectionRef":"#","url":"/docs/rule_authors/configurations/","content":"","keywords":""},{"title":"Context​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#context","content":"Buck configurations provide an API to express the different ways in which projects and targets can be built. A configuration consists of a set of constraints and config settings (values from buckconfig). These are determined by a base platform that sets the initial values and then a series of transitions that may change them. The common way that users are exposed to configurations is in select() invocations where the resolution is based on the configuration. A build may involve many configurations. A particular target label (//:foo) may end up with multiple instances in the configured graph with different configurations. "},{"title":"Selectable attributes​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#selectable-attributes","content":"Almost all rule attributes can be set to a select() value; such an attribute is 'selectable'. These attributes' final resolved values will depend on the configuration. There are some attributes that cannot use a select(); such attributes are termed 'not selectable'. Examples include attributes that buck needs to read from the unconfigured node (such as name and default_target_platform) and attributes that are used by platform() rules and their dependencies (see below). "},{"title":"Selectable resolution​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#selectable-resolution","content":"Resolving selectable attributes is pretty straightforward, it happens when constructing the 'configured target node'. At that point, the full configuration is available so Buck can lookup whether each constraint in the select is satisfied or not. If multiple conditions of the select() match, then the select will be resolved to the 'most refined' of the conditions that match. A set of constraints (as in a config_setting) is said to 'refine' another if it is a superset of that other's constraints. The 'most refined' of a set is then the condition that refines all the others. If there is no 'most refined' condition of the matching ones, it is an error. "},{"title":"Target Platform Resolution​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#target-platform-resolution","content":"In the event that targets are provided on the command line, or when there is no indication of what configuration the target will be built in, configurations are determined by performing 'target platform resolution' on the unconfigured target labels. The target platform resolution for a target //:foo works as follows: Look up (unconfigured) target node for //:foo.If the command has a --target-platforms flag, use that.If there's a default_target_platform attribute, use that.Else, use the cell's default platform. This is performed independently for any targets that need a platform. Since this resolution is done without a configuration, it means that the default_target_platform attribute is not selectable. This target platform will form the initial configuration for the node. "},{"title":"Configuration propagation​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#configuration-propagation","content":"Once the top-level nodes have been configured via the target platform resolution, the configuration is propagated to dependencies (possibly altered by transitions). note The target platform resolution is not applied to all nodes in the graph. "},{"title":"Transitions​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#transitions","content":"A transition transforms a configuration by adding or changing constraint values and config settings or by setting an entirely new underlying target platform. For more details, see Configuration transitions. "},{"title":"ConfigurationInfo, platform() analysis, and more​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#configurationinfo-platform-analysis-and-more","content":"The definition of a platform (either execution or target) is done with a platform rule instance. The configuration is actually part of the analysis result of the platform target (the ConfigurationInfo provider instance). This is convenient from an implementation standpoint, but it leads to a situation where some nodes are analyzed with an 'unbound' Configuration. All the rule types involved in defining a platform may be analyzed with an unbound configuration (platform(), config_setting(), constraint_setting(), and so on). These are sometimes called 'configuration rules'. This means that all the attributes of these rules are not selectable. Configurations also reference a few other provider instances such as ConstraintSettingInfo. All of these end up being potentially produced in a context with an unbound configuration. Using analysis for this also means that 'configuration' and 'analysis' are not distinct phases within a build (although they are still distinct for a node and are still conceptually useful). "},{"title":"Configurations and output paths​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#configurations-and-output-paths","content":"Since a target may appear within a build in multiple different configurations, output paths cannot be derived based on just targets (as multiple actions would map to the same outputs). For this reason, the target and the configuration are encoded into output paths. The configuration is currently represented as a hash of its values (a 'hashed buck-out'). "},{"title":"Target platform compatibility​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#target-platform-compatibility","content":"All (non-configuration) rules support a target_compatible_with attribute. In addition, the rule itself can define target_compatible_with constraints that affect all instances. The target_compatible_with attribute is a list of constraints/config settings and it is selectable. Target platform compatibility is transitive, all dependents of an incompatible target are incompatible. In other words, a node is compatible if and only if the node itself and all of its transitive dependencies are compatible. In buck, this is implemented by graph configuration returning either a configured target node or an indicator that the node is incompatible with the target platform. "},{"title":"Buck v1 compatibility​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#buck-v1-compatibility","content":"Buck2 also supports the Buck v1 legacy compatible_with field on nodes but it has different behavior. In summary: compatible_with: List of constraints, where any of them must match the configuration to be compatible.target_compatible_with: List of constraints, where all of them must match the configuration to be compatible. "},{"title":"Incompatible target skipping​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#incompatible-target-skipping","content":"In a build-like command where a non-literal target pattern is provided (for example, buck build //: or buck build //foo/...), the target pattern will be resolved to a set of unconfigured targets. Those targets will then go through target platform resolution. If any of those targets resolve to a platform where they are incompatible, building them will be skipped. Users generally expect and prefer this behavior to needing to explicitly specify only the targets that can build in their current context. If an explicitly specified literal is incompatible, it is an error. The implementation checks compatibility when looking up the analysis results for configured nodes requested (in the non-ignored flow, it uses that analysis result to lookup the default outputs and build them). "},{"title":"Execution platforms​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#execution-platforms","content":"Execution platforms/configurations are used to represent the platforms where build execution happens. These are defined in a similar manner to target platforms. These may or may not be what one would logically consider different 'platforms'. For example, there could be multiple different execution platforms that all execute things similarly on the local machine. A build configures a fixed list of one or more execution platforms. "},{"title":"Execution deps​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#execution-deps","content":"Some target deps are 'execution deps'. These are the dependencies of the target that should be built for the execution platform. For example, a compiler or other build tool would be an execution dep. This includes all exe macro deps (for example, $(exe //:tool)) and includes all attrs.exec_dep() deps. "},{"title":"Toolchain deps​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#toolchain-deps","content":"In addition to attrs.exec_dep(), there are attrs.toolchain_dep(), which are similar but differ in an important way. These nodes don't select their execution platform, but instead have it forced on them by whatever includes them; hence, it must be recorded in the configured target label. The execution platform resolution sees through them. In other words, attrs.toolchain_dep() is like a mix of attrs.dep() and attrs.exec_dep(): it inherits target platform like attrs.dep() (so anyselect()s on the target of the attrs.toolchain_dep() will evaluate as if they were on the target containing the attrs.toolchain_dep() - the target platform gets inherited as normal) and any attrs.exec_dep()s of the attrs.toolchain_dep() target become attrs.exec_deps() on the dependent of target the attrs.toolchain_dep() (they get passed up the dep tree, so participate in exec platform resolution). This is illustrated in the following example: target( name = &quot;A&quot;, toolchain = attrs.toolchain_dep(default = &quot;:B&quot;), ) target( name = &quot;B&quot;, tool = attrs.exec_dep(default = &quot;:C&quot;) )  The above means that :C will be an execution dependency of :A and any select()s defined in :B would be evaluated against the same target platform as :A (as target platform gets inherited by attrs.toolchain_dep()s). "},{"title":"Running non-execution deps​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#running-non-execution-deps","content":"If you have a binary that you want to run, but it isn't a build tool, then you should use $(exe_target //:binary) rather than $(exe //:binary). That will run the same binary that you'd get from buck2 build, rather than one that is built for the execution platform. "},{"title":"Execution platform resolution​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#execution-platform-resolution","content":"During analysis, unlike target platform resolution, every configured node undergoes execution platform resolution independently (see exception below). This means that even for a specific target platform, different nodes in the graph can be built on different execution platforms. This works roughly as follows: next: for platform in execution_platforms: if exec_compatible_with(target, platform): for dep in target.execution_deps(): if !target_compatible_with(dep, platform): continue next return platform return err  One important note here is that until the execution platform has been resolved, the configuration for execution deps is not known. Only after execution platform has been resolved can the execution deps be configured (also, analysis for them can only be performed at that point). For the normal use case, a particular configured target node performs execution platform resolution a single time. The execution platform is not encoded in output paths. Regarding target compatibility, imagine the following pseudo-code for the target_compatible_with() function above: def target_compatible_with(target, cfg): for constraint in target.target_compatible_with: if not satisfied(constraint, cfg): return False if len(target.compatible_with) &gt; 0: found_satisfied_constraint = False for constraint in target.compatible_with: if satisfied(constraint, cfg): found_satisfied_constraint = True break if not found_satisfied_constraint: return False for (dep, dep_cfg) in direct_deps(target): # NB: recursive call if not target_compatible_with(dep, dep_cfg): return False return True  "},{"title":"Execution groups​","type":1,"pageTitle":"Configurations","url":"/docs/rule_authors/configurations/#execution-groups","content":"Execution groups are a future feature that will allow a rule to perform execution platform resolution multiple times and then specify in which of the resolved platforms each action runs in. "},{"title":"Dep Files","type":0,"sectionRef":"#","url":"/docs/rule_authors/dep_files/","content":"","keywords":""},{"title":"Use Cases​","type":1,"pageTitle":"Dep Files","url":"/docs/rule_authors/dep_files/#use-cases","content":"Dep files are used to make dependencies finer grained than what exists in the target graph, but they're not a substitute for avoiding unused dependencies. They're often useful when targets export many outputs (such as C++ headers) that aren't all used by all their dependents. Dep files are currently used to skip recompilation steps in C++ when an unused header changed. They're also used in Java to skip recompilation when an unused class changed. "},{"title":"Using dep files​","type":1,"pageTitle":"Dep Files","url":"/docs/rule_authors/dep_files/#using-dep-files","content":"To use dep files, you need to do the following: Declare what output is a dep file and associate it with your command.Declare which inputs are covered by the dep file (this can be a subset of your inputs).Have your command produce the dep file in a format Buck2 can use. You must also enable Deferred Materialization to use dep files. "},{"title":"Declaring the dep files and associating inputs​","type":1,"pageTitle":"Dep Files","url":"/docs/rule_authors/dep_files/#declaring-the-dep-files-and-associating-inputs","content":"To declare a dep file and associate it with your command, you need to tag your artifacts. Specifically, you'll tag the output (the dep file) and the inputs it covers, as shown in the following code: # First, create a tag headers_tag = ctx.actions.artifact_tag() # Then, tag inputs and the dep file itself in your command line. # You do this using the `tag_artifacts` method on your tag. # This method does not mutate the input, it wraps it, so you use the output. # Any command-line-arg-like can be tagged. tagged_headers = headers_tag.tag_artifacts(headers) dep_file = ctx.actions.declare_output(&quot;deps&quot;).as_output() tagged_dep_file = headers_tag.tag_artifacts(dep_file) # Finally, declare your action. # Use the tagged artifacts as you would regular command-line-arg-likes. # Pass the tag in `dep_files` and give a name (this is used for logging). ctx.actions.run( [&quot;mycc&quot;, &quot;-I&quot;, tagged_headers, &quot;-MD&quot;, &quot;-MF&quot;, tagged_dep_file, &quot;-o&quot;, ...], dep_files = { &quot;headers&quot;: headers_tag } )  "},{"title":"Producing the dep file​","type":1,"pageTitle":"Dep Files","url":"/docs/rule_authors/dep_files/#producing-the-dep-file","content":"Your command must produce dep files in the format Buck2 expects, which is simply a list of all the inputs that were used, one per line. The paths must be the paths Buck2 would use for your inputs, which means paths relative to the project root. If this is not the format your tool produces, use a wrapper to take whatever output your command produces and rewrite it in the format Buck2 expects. "},{"title":"Testing dep files​","type":1,"pageTitle":"Dep Files","url":"/docs/rule_authors/dep_files/#testing-dep-files","content":"When writing a command that produces a dep file, you should test it! At a minimum, check that the inputs you expect are tagged properly. To do so, build your target, then use buck2 audit dep-files TARGET CATEGORY IDENTIFIER, which will show you the set of inputs your command used and how they're tagged. "},{"title":"Extra notes to the implementer​","type":1,"pageTitle":"Dep Files","url":"/docs/rule_authors/dep_files/#extra-notes-to-the-implementer","content":""},{"title":"Limitations​","type":1,"pageTitle":"Dep Files","url":"/docs/rule_authors/dep_files/#limitations","content":"Dep files only work if a previous invocation of the command is known to your Buck2 daemon. Dep files are dropped when the daemon restarts or when you run buck2 debug flush-dep-files. This means that, for example, if you change an unused header, then run a build on a fresh daemon, Buck2 will still need to execute this command in order to identify that the header was in fact unused. In contrast, if you did the build (and got a remote cache hit on the command), then applied your change and re-built, Buck2 would use the dep file on the second execution, and you wouldn't need to execute anything. "},{"title":"Dep files don't need to be covering​","type":1,"pageTitle":"Dep Files","url":"/docs/rule_authors/dep_files/#dep-files-dont-need-to-be-covering","content":"It's OK for the dep file to only cover a subset of the inputs of your action. However, within that subset, the dep file must declare all the inputs that were used. If you fail to report some inputs you used, then your command will not re-run when they change, and you'll get stale output. "},{"title":"Dep files are lazy​","type":1,"pageTitle":"Dep Files","url":"/docs/rule_authors/dep_files/#dep-files-are-lazy","content":"Dep files aren't parsed by Buck2 unless the command needs to re-run. If the command ran on RE, they aren't even downloaded until then. This ensures dep files don't cause a performance hit unless they are used, at which point they stand a chance of giving a performance boost instead. This means that if you produce an invalid dep file, Buck2 will not report this until your command runs again, at which point Buck2 will report that the dep file is invalid and refuse to proceed (note: you can unblock yourself using buck2 debug flush-dep-files). To flush out issues during development, you can pass --eager-dep-files to Buck2 to force Buck2 to parse your dep files as they are produced. "},{"title":"Dep files will traverse symlinks​","type":1,"pageTitle":"Dep Files","url":"/docs/rule_authors/dep_files/#dep-files-will-traverse-symlinks","content":"If your dep file reports that a symlink was used, Buck2 will track the symlink's target as covered by this dep file. "},{"title":"Dynamic Dependencies","type":0,"sectionRef":"#","url":"/docs/rule_authors/dynamic_dependencies/","content":"","keywords":""},{"title":"Implementation​","type":1,"pageTitle":"Dynamic Dependencies","url":"/docs/rule_authors/dynamic_dependencies/#implementation","content":"Buck2 provides the following function: ctx.actions.dynamic_output(dynamic, inputs, outputs, lambda ctx: …)  The arguments are: dynamic - a list of artifacts whose values will be available in the function. These will be built before the function is run.inputs - a container of artifacts (cmd_args, list of artifacts, and so on). These inputs must include all the inputs that are referenced by the body of the function argument, apart from those listed in dynamic and outputs: extra inputs may be passed that are not used.The inputs are used for buck2 aquery functionality, but do not cause speculative building. In fact, these inputs may form a cycle with other dynamic_output actions if they were all required.In the future, it may be possible to not pass all the inputs if the repo is set to permissive mode, allowing a more powerful form of dynamic dependencies. outputs - a list of unbound artifacts (created with declare_artifact) which will be bound by the function.The function argument is given 3 arguments: ctx (context) - which is the same as that passed to the initial rule analysis.outputs - using one of the artifacts from the dynamic_output's outputs (example usage: outputs[artifact_from_dynamic_output_outputs]) gives an unbounded artifact. The function argument must use its outputs argument to bind output artifacts, rather than reusing artifacts from the outputs passed into dynamic_output directly.artifacts - using one of the artifacts from dynamic (example usage: artifacts[artifact_from_dynamic]) gives an artifact value containing the methods read_string, read_lines, and read_json to obtain the values from the disk in various formats. Anything too complex should be piped through a Python script for transformation to JSON. The function must call ctx.actions (probably ctx.actions.run) to bind all outputs. It can examine the values of the dynamic variables and depends on the inputs. The function will usually be a def, as lambda in Starlark does not allow statements, making it quite underpowered. Following is an example of using the function to determine Erlang BEAM dependencies: def erlang(ctx): beams = {} for x in ctx.attr.srcs: dep_file = ctx.actions.declare_output(x + &quot;.out&quot;) ctx.actions.run(&quot;erl&quot;, &quot;-dump-output&quot;, x, dep_file.as_output()) beam_file = ctx.actions.declare_output(x + &quot;.beam&quot;) beams[x] = beam_file def f(ctx, artifacts, outputs, x=x, dep_file=dep_file): deps = artifacts[dep_file].read_lines() ctx.actions.run( &quot;erl&quot;, &quot;-comp&quot;, x, [beams[d] for d in deps], outputs[beams[x]].as_output() ) ctx.actions.dynamic_output([dep_file], [x] + deps, [beam_file], f) return [ErlangInfo(objects = beams.values())]  The above code uses declare_output for the beam_file then binds it within the function f, after having read the dep_file with read_lines. "},{"title":"Incremental Actions","type":0,"sectionRef":"#","url":"/docs/rule_authors/incremental_actions/","content":"Incremental Actions It's possible to make certain Buck2 actions behave incrementally, that is, to produce results for a current invocation based on the result from the previous run. Incrementality could significantly improve performance of some actions such as packaging (such as Apple App Bundles) or linking (MSVC incremental linking). There are two essential requirements to make an action incremental: The result from the previous run should be accessible.An understanding of which parts of the result need to be updated; it should be easy to compare inputs from a previous run with inputs from the current run and detect those changed. The only way to run user-defined commands in Buck2 is with ctx.actions.run. Both of the above requirements are met via its metadata_env_var, metadata_path and no_outputs_cleanup parameters. When the no_outputs_cleanup flag is turned on, Buck2 won't perform any deletion of old outputs for the action. That means the result from the previous run will be accessible, but the user script has to detect which parts of it should be deleted and perform a manual cleanup. When the metadata_env_var and metadata_path parameters are present, Buck2 will create a JSON file on a disk before actually executing the command. The file will contain a list of paths and hash digests for every command action input. All paths in the file are relative to the Buck2 project root. Symlinks are not included in metadata because it is possible for the user script to resolve symlink and use a resolved path to get the destination hash digest from action metadata if it's needed, as shown in the following JSON example: { &quot;version&quot;: 1, &quot;digests&quot;: [ { &quot;path&quot;: &quot;buck-out/v2/gen/cell/configuration_hash/path/to/target/__target_name__/generated_file&quot;, &quot;digest&quot;: &quot;da39a3ee5e6b4b0d3255bfef95601890afd80709:10&quot; }, ... ] } A user script that is run as a part of an action execution is responsible for parsing the JSON file. The version field is bumped every time there is a non-backwards compatible change to the format of the file. The user script should verify that the provided data is of a supported version and should be updated accordingly when the current version is newer than the supported one. The path of the JSON file is provided to the user script via an environment variable with a key equal to metadata_env_var. The user is able to specify the part of the path relative to the result directory via metadata_path. For example, if some rule implementation has the following code: result = ctx.actions.declare_output(&quot;result&quot;) command = cmd_args([&quot;my_script.py&quot;, &quot;--output&quot;, result.as_output()]) ctx.actions.run( command, category = &quot;my_category&quot;, metadata_env_var = &quot;ACTION_METADATA&quot;, metadata_path = &quot;action_metadata.json&quot;, no_outputs_cleanup = True, ) Then my_script.py will be executed as: ACTION_METADATA=project/relative/path/to/target/action_metadata.json my_script.py --output resolved/path/to/result my_script.py is responsible for reading the ACTION_METADATA environment variable and parsing a JSON file with the action metadata. Parsed metadata provides information about inputs for the current run, but the script needs somehow to obtain similar information about inputs from the previous run. Such information could just be another output of the user script (as with the previous result, it won't be deleted when no_outputs_cleanup = True). The Format of such a file is an implementation detail of the user script, but at the very least it should contain a list of every source that was used to form the result and hash digests for such sources. The rule implementation would look something like the following: result = ctx.actions.declare_output(&quot;result&quot;) state = ctx.actions.declare_output(&quot;incremental_state.json&quot;) command = cmd_args([&quot;my_script.py&quot;, &quot;--output&quot;, result.as_output(), &quot;--incremental-state&quot;, state.as_output()]) ctx.actions.run( command, category = &quot;my_category&quot;, metadata_env_var = &quot;ACTION_METADATA&quot;, metadata_path = &quot;action_metadata.json&quot;, no_outputs_cleanup = True, ) The user script would then: Parse incremental_state.json and delete it. Deletion prior to amending the result is important so it doesn't result in a situation where an incremental state file is out of sync with the result when the user script fails while changing the result. Such a corrupted state might lead to subsequent incorrect builds reported as &quot;successful&quot;.Parse action metadata file, compute what is needed to update the result, and amend it accordingly.Calculate the new state and write it into the new incremental_state.json.","keywords":""},{"title":"Local Resources For Tests Execution","type":0,"sectionRef":"#","url":"/docs/rule_authors/local_resources/","content":"","keywords":""},{"title":"LocalResourceInfo provider​","type":1,"pageTitle":"Local Resources For Tests Execution","url":"/docs/rule_authors/local_resources/#localresourceinfo-provider","content":"This provider describes how to initialize and clean up a pool of homogeneous local resources. Management of initialized resources is done by Buck2 itself when it executes tests requiring such resources. Fields: source_target — configured target label that is providing this local resource. It is an implementation detail and used internally to uniquely identify local resource and should be set to ctx.label in an implementation of a rule which returns this provider instance.setup — command represented by cmd_args object which is executed to initialize a local resource. Running this command should write a JSON to stdout. This JSON represents a pool of local resources which are ready to be used.resource_env_vars — key-value mapping {str.type: str.type} from environment variable (appended to an execution command for test which is dependent on this local resource) to keys in JSON output of setup command. Example JSON output of setup command: { &quot;pid&quot;: 42, &quot;resources&quot;: [ {&quot;socket_address&quot;: &quot;foo:1&quot;}, {&quot;socket_address&quot;: &quot;bar:2&quot;} ] }  JSON keys: pid — an optional attribute which maps to a PID of a process that holds initialized local resources. If present, on non-Windows platforms the process will be sent SIGTERM when those resources are no longer needed. Signal should be handled to release any system resources related to local resources.resources — a list of resource instances, each is a mapping from a string alias (e.g. socket_address) to a value which represents resource. The number of concurrently running tests that require resources of the same type is limited by how many instances are in a list. String alias is mapped to an environment variable key (which will be added to a command requiring such resource) using a resource_env_vars field in LocalResourceInfo provider (see example below). "},{"title":"Test Execution​","type":1,"pageTitle":"Local Resources For Tests Execution","url":"/docs/rule_authors/local_resources/#test-execution","content":"For a general context on how tests are executed, see Test Execution. A decision whether certain local resource is required for specific test is made by a test runner. List of required resources is then passed to Buck2 in required_local_resources field of ExecuteRequest2 test API protobuf message. If resource is required for a certain test execution and test could potentially be executed locally, local_resources field in test's ExternalRunnerTestInfo provider is used to select appropriate LocalResourceInfo provider. ExternalRunnerTestInfo.local_resources is a key-value mapping {str.type: [LocalResourceInfo.type, None]}. Keys are resource types (matching values passed from test runner) and values are LocalResourceInfo providers to be used for initialization of resource of that type. If the value is None it means resource of that type will not be provided even if the test runner requests it. Before running a test, setup command from selected provider is executed and its output is used to create a pool of resource instances. This pool is shared across all tests pointing to the same configured target label in LocalResourceInfo.source_target field (normally that means pool is shared for tests requiring same resource type). A resource is acquired (with potential queuing) from that pool prior single test is executed and is returned back to the pool when test finished execution. After buck2 test command is finished, cleanup is performed when SIGTERM is sent to each process holding a pool of resources. "},{"title":"Example Usage​","type":1,"pageTitle":"Local Resources For Tests Execution","url":"/docs/rule_authors/local_resources/#example-usage","content":"Define a target which has LocalResourceInfo provider: simulator( name = &quot;my_resource&quot;, broker = &quot;:broker&quot;, )  where broker points to a runnable handling actual simulators. Implementation of simulator rule would be: def _impl(ctx: &quot;context&quot;) -&gt; [&quot;provider&quot;]: return [ DefaultInfo(), LocalResourceInfo( source_target = ctx.label, setup = cmd_args([ctx.attrs.broker[RunInfo]]), resource_env_vars = { &quot;IDB_COMPANION&quot;: &quot;socket_address&quot; }, ) ]  Running a :broker via setup command produces the following JSON: { &quot;pid&quot;: 42, &quot;resources&quot;: [ {&quot;socket_address&quot;: &quot;foo:1&quot;}, {&quot;socket_address&quot;: &quot;bar:2&quot;} ] }  When Buck2 locally executes a test which requires this particular type of local resource, it reserves one resource from the pool (e.g. {&quot;socket_address&quot;: &quot;bar:2&quot;}) and add environment variable representing this resource to execution command (e.g. IDB_COMPANION=bar:2). In our examples &quot;socket_address&quot; alias was substituted by &quot;IDB_COMPANION&quot; based on LocalResourceInfo.resource_env_vars field. The last part is to map a resource type to desired LocalResourceInfo provider. Let's assume a test runner requires a resource of type &quot;ios_simulator&quot; for every apple_test rule. Pass :my_resource target as a dependency into apple_test rule: apple_test = rule( impl = apple_test_impl, attrs = { ... &quot;_ios_simulator&quot;: attrs.default_only(attrs.dep(default = &quot;:my_resource&quot;, providers = [LocalResourceInfo])), ... }, )  Actually map &quot;ios_simulator&quot; resource type to provider: def apple_test_impl(ctx: &quot;context&quot;) -&gt; [&quot;provider&quot;]: ... return [ ... ExternalRunnerTestInfo( ... local_resources = { &quot;ios_simulator&quot;: ctx.attrs._ios_simulator[LocalResourceInfo], }, ...  "},{"title":"Optimization","type":0,"sectionRef":"#","url":"/docs/rule_authors/optimization/","content":"","keywords":""},{"title":"Starlark profiling​","type":1,"pageTitle":"Optimization","url":"/docs/rule_authors/optimization/#starlark-profiling","content":"buck2 supports profiling of the evaluation of specific BUCK files and profiling of the analysis of specific targets. There are three buck2 profiling commands: buck2 profile loadingbuck2 profile analysisbuck2 profile bxl For example: buck2 profile loading --mode=heap-summary -o heap-summary.csv //some/package: buck2 profile analysis --mode=heap-summary -o heap-summary.csv //some/package:target  "},{"title":"Summary profiling​","type":1,"pageTitle":"Optimization","url":"/docs/rule_authors/optimization/#summary-profiling","content":"The first profiling mode provides the time spent within a function and the allocations that are performed. As an example, running over a folly BUCK file, produces a CSV file whose top-left corner is: Function Time(s) TimeRec(s) Calls Allocs TOTALS 10.455 10.455 9712799 3477203 fbchain_configs 1.163 2.514 11328 33984 is_string 0.726 1.028 1514985 0 apple_library 0.725 0.725 1887 0 type 0.435 0.435 2053296 0 ...  This reveals the following: Total execution was 10.455s, which will be a bit slower than normal, because profiling is on.1.163s was spent in fbchain_configs itself and 2.514s in that function and the things it calls.A disturbing 1.5M calls and 1.028s is spent testing if things are strings, which is almost certainly responsible for half the type calls.Happily, is_string doesn't allocate, but fbchain_configs does. Scrolling to the right, on the full CSV file (not shown), reveals it allocates 1 tuple and 2 dict per call. It can also be seen that fbchain_configs is mostly called by _add_code_coverage_configs. This profiling mode is implemented by turning off garbage collection, so the heap retains everything, and pushing function entry/exit entries on to the heap with the time they happen. After execution, the heap can be scanned in order to reconstruct the call tree and allocation patterns. As a result, this profile mode may consume significantly more memory. "},{"title":"Statement profiling​","type":1,"pageTitle":"Optimization","url":"/docs/rule_authors/optimization/#statement-profiling","content":"The second profiling mode tells us which statements spent most time executing. Running it over a structured-logger BUCK file gives us a CSV file starting with: File Span Duration(s) Count TOTAL 4.03 7187761 fbcode_allowed_list.bzl 420:9-423:1 0.27 455884 cell_defs.bzl 13:5-13:60 0.17 117736 read_configs.bzl 46:5-46:55 0.08 65042 prelude.bzl 28:9-29:20 0.07 1004 ...  This profile shows how much time is spent in each statement. Looking at the relevant portion of fbode_allowed_list.bzl: for _package in _recursive_allowlist: if base_path == _package or base_path.startswith(_package + &quot;/&quot;): return True  The if statement is at location 420:9-423:1 and takes 0.27s. The if statement runs approximately 456K times. While looking at the outer statement in the profile (not shown), it can be seen that the for loop is only called 3188 times, implying an average of 143 iterations per call. It's possible that this loop could be rewritten as some clever dictionary lookup, perhaps iterating over the path components of _package. Line profiling builds on top of the before_stmt hook that is used for debugging. It records the time each statement is entered then blames that statement for all time until the next statement. That means that sometimes, due to statements making function calls, the return of the function call may be 'blamed' until the next statement executes. As a result, treat the results with slight caution. "},{"title":"Flame profiling​","type":1,"pageTitle":"Optimization","url":"/docs/rule_authors/optimization/#flame-profiling","content":"The flame profiling modes produces a .svg flamegraph showing either time spent or allocations. "},{"title":"Native profiling​","type":1,"pageTitle":"Optimization","url":"/docs/rule_authors/optimization/#native-profiling","content":"Profiling on Linux can be done with perf record -g --call-graph=dwarf,20000 ... and perf report --call-graph Don't profile the buck2 process directly unless you are interested in profiling the CLI; you likely want to profile the buck2 daemon process. You can find the pid with buck2 status and attach perf to that PID. Profiling on Mac can be done with Instruments. "},{"title":"Benchmarking​","type":1,"pageTitle":"Optimization","url":"/docs/rule_authors/optimization/#benchmarking","content":"If you want to do proper statistically relevant A/B testing, use absh -a testa -b testb (see absh in the GitHub repository).To measure the number of instructions: On Linux, use perf stat fooOn Mac, use /usr/bin/time -lp foo On Mac, to run something with the time profiler on the command line, use xcrun xctrace record --template 'Time Profiler' --launch -- foo, then open Foo.trace for the name of the trace file it spits out (or pass --output to control the output filename). "},{"title":"Rule APIs","type":0,"sectionRef":"#","url":"/docs/rule_authors/rule_api/","content":"","keywords":""},{"title":"Providers​","type":1,"pageTitle":"Rule APIs","url":"/docs/rule_authors/rule_api/#providers","content":"DefaultInfo(default_outputs : [&quot;artifact&quot;], other_outputs : [[&quot;artifact&quot;, &quot;cmd_args&quot;]] = [], sub_targets : {str.type: [&quot;provider&quot;]} = {}) - the provider that is used for: buck2 build - builds everything in default_outputs and other_outputs.$(location) - uses the default_outputs.buck2 build my_target[foo] - selects the foo value from sub_targets.Note: if you use cmd_args in other_outputs, then it will expand to all the inputs referenced by the cmd_args you provide. RunInfo(args) - used for buck2 run, where args is anything that can be converted into cmd_args, including a command line itself.ExternalRunnerTestInfo(...) - for details, see Test Execution. "},{"title":"Type context​","type":1,"pageTitle":"Rule APIs","url":"/docs/rule_authors/rule_api/#type-context","content":"The starting type, usually bound as ctx. ctx.attrs - returns the attributes of the target as a Starlark struct with a field for each attribute, which varies per rule.ctx.actions - returns actions allowing you to define actions.ctx.label - returns a label representing the target. "},{"title":"Type actions​","type":1,"pageTitle":"Rule APIs","url":"/docs/rule_authors/rule_api/#type-actions","content":"Most output filenames can either be artifacts created with declare_output or strings that are implicitly converted to output artifacts. ctx.actions.declare_output([prefix], filename, dir = False) - returns an artifact with the name filename, which when asked for its name, will return filename (which may include a directory portion). prefix (optional) - provides a silent part of the filename, which can be used to disambiguate but whose presence will not be visible to anyone using the artifact. By default, outputs are considered files; pass dir = True to indicate it is a directory.declare_output - mainly used to produce an unbound artifact for passing to ctx.actions.run. ctx.actions.write(filename, content, is_executable : bool.type = false, allow_args : bool.type = false) - returns an artifact whose contents are content. filename - can be a string or an existing artifact created with declare_output.is_executable (optional) - indicates whether the resulting file should be marked with executable permissions.allow_args (optional) - must be set to True if you want to write parameter arguments to the file (in particular, macros that write to file). If it is true, the result will be a pair of the artifact containing content and a list of artifact values that were written by macros, which should be used in hidden fields or similar. ctx.actions.write_json(filename, content, with_inputs = False) - returns an artifact whose contents are content written as a JSON value. filename - can be a string, or an existing artifact created with declare_output.content - must be composed of the basic json types (Boolean, number, string, list/tuple, dictionary) plus artifacts and command lines. An artifact will be written as a string containing the path.A command line will be written as a list of strings, unless joined=True is set, in which case it will be a string. If you pass with_inputs = True, you'll get back a cmd_args that expands to the JSON file but carries all the underlying inputs as dependencies (so you don't have to use, for example, hidden for them to be added to an action that already receives the JSON file). ctx.actions.copy_file(dest, src) - copies the source artifact to the destination (which can be a string representing a filename or an output artifact) and returns the output artifact. The copy works for files or directories. ctx.actions.symlink_file(dest, src) - creates a symlink to the source artifact at the destination (which can be a string representing a filename or an output artifact) and returns the output artifact. The symlink works for files or directories. ctx.actions.symlinked_dir(output, srcs : {str.type: &quot;artifact&quot;}) - returns an artifact that is a directory containing symlinks. The srcs must be a dictionary of path (as string, relative to the result directory) to bound artifact, which will be laid out in the directory. ctx.actions.copied_dir(output, srcs : {str.type: &quot;artifact&quot;}, copy : bool.type = false) - returns an artifact which is a directory containing copied files. The srcs must be a dictionary of path (as string, relative to the result directory) to the bound artifact, which will be laid out in the directory. ctx.actions.download_file(output, url : str.type, sha1: str.type, is_executable : bool.type = false) - downloads a URL to an output (filename as string or output artifact). The file at the URL must have the given sha1 or the command will fail. The optional parameter is_executable indicates whether the resulting file should be marked with executable permissions. ctx.actions.run(arguments, category : str.type, identifier : str.type = &quot;&quot;, env : {str.type: str.type} = {}, local_only : bool.type = false, always_print_stderr : bool.type = false, weight : int.type = 1, metadata_env_var: str.type = None, metadata_path: str.type = None, no_outputs_cleanup: bool.type = false) - runs a command. arguments - must be of type cmd_args, or a type convertible to such (such as a list of strings and artifacts) and must contain at least one .as_output() artifact.category and identifier - when used together, identify the action in Buck2's event stream, and must be unique for a given target.weight is used to note how heavy the command is and will typically be set to a higher value to indicate that less such commands should be run in parallel (if running locally).no_outputs_cleanup - if this flag is set then Buck2 won't clean the outputs of a previous build that might be present on a disk; in which case, command from arguments should be responsible for the cleanup (that is useful, for example, when an action is supporting incremental mode and its outputs are based on result from a previous build).metadata_env_var and metadata_path - both should either be set or unset. metadata_path defines a path relative to the result directory for a file with action metadata, which will be created right before the command will be run. Metadata contains the path relative to the Buck2 project root and hash digest for every action input (this excludes symlinks as they could be resolved by a user script if needed). The resolved path relative to the Buck2 project for the metadata file will be passed to command from arguments, via the environment variable, with its name set by metadata_env_var. Both metadata_env_var and metadata_path are useful when making actions behave in an incremental manner (for details, see Incremental Actions) ctx.actions.tset(type, value = None, children = None) - creates a new transitive set (for details, see Transitive Sets). ctx.actions.cas_artifact(output, digest : str.type, use_case: str.type, expires_after_timestamp: int.type, is_executable : bool.type = false) - downloads a CAS artifact to an output. digest - must look like SHA1:SIZE.use_case - your RE use case.expires_after_timestamp - must be a UNIX timestamp. Your digest's TTL must exceed this timestamp. Your build will break once the digest expires, so make sure the expiry is long enough (preferably, in years).is_executable (optional) - indicates the resulting file should be marked with executable permissions. "},{"title":"Type cmd_args​","type":1,"pageTitle":"Rule APIs","url":"/docs/rule_authors/rule_api/#type-cmd_args","content":"The cmd_args type is created by cmd_args and is consumed by ctx.actions.run. The type is a mutable collection of strings and artifact values. In general, command lines, artifacts, strings, RunInfo and lists thereof can be added to or used to construct a cmd_args value. All these methods operate mutably on cmd and return that value too. cmd_args(*args, format: str.type = &quot;&quot;, delimiter: str.type = None, prepend: str.type = None, quote: str.type = None) - creates and returns a cmd_args type. *args - a list of things to add to the command line, each of which must be coercible to a command line. Further items can be added with cmd.add.format (optional) - a string that provides a format to apply to the argument. for example, cmd_args(x, format=&quot;--args={}&quot;) would prepend --args= before x, or if x was a list, before each element in x.delimiter (optional) - added between arguments to join them together. For example, cmd_args([&quot;--args=&quot;,x], delimiter=&quot;&quot;) would produce a single argument to the underlying tool.prepend (optional) - added as a separate argument before each argument.quote (optional) - indicates whether quoting is to be applied to each argument. Note: the only current valid value is &quot;shell&quot;. cmd.add(*args) - a list of arguments to be added to the command line, as per cmd_args. cmd.hidden(*args) - things to add to the command line which do not show up but are added as dependencies. cmd.ignore_artifacts() - conceptually the opposite of hidden(). It causes none of the arguments of the command line to be added as dependencies. Use this if you need the path to an artifact but not the artifact itself.Note: if you do find yourself needing any of the inputs referenced by this command, you will hit build errors due to missing dependencies. cmd.relative_to(directory, parent : int.type = 0) - complex magic. Before using this, please contact Meta's Buck2 team. cmd.absolute_prefix(prefix : str.type)- adds a prefix to the front of every artifact. cmd.absolute_suffix(suffix : str.type) - adds a suffix to the end of every artifact. cmd.parent(count : int.type = 1) - uses the parent of all given artifacts. Often used as cmd_args(artifact, format=&quot;-L{}&quot;).parent(). cmd.replace_regex(pattern : str.type, replacement : str.type) - replaces all parts matching pattern regular expression in each argument with replacement string. Several replacements can be added by multiple replace_regex calls. cmd.copy() - returns a copy of the cmd_args such that any modifications to the original or the returned value will not impact each other. cmd.inputs - returns a list of the artifacts that are inputs to this command line. cmd.outputs - returns a list of the artifacts that are outputs of this command line. "},{"title":"Type label​","type":1,"pageTitle":"Rule APIs","url":"/docs/rule_authors/rule_api/#type-label","content":"A label represents a configured target. For example, the label fbcode//buck2/hello:world (ovr_config//platform/linux:x86_64-fbcode-46b26edb4b80a905) has the following attributes: package gives back buck2/helloname gives back worldsub_target gives back Nonepath gives back fbcode/buck2/hellocell gives back fbcoderaw_target() gives back fbcode//buck2/hello:world without the configuration "},{"title":"Type artifact​","type":1,"pageTitle":"Rule APIs","url":"/docs/rule_authors/rule_api/#type-artifact","content":"An artifact, which has a location on disk. Some of that location is considered private, and some (the suffix) is available for use. The examples below assume an artifact such as one created with ctx.actions.declare_output(&quot;hello/world.txt&quot;). It has the following attributes: basename gives back world.txtextension gives back .txtis_source - True if the artifact is a source, otherwise False.owner gives back a label representing the rule that created it (if it is a build output) or None (if it is a source).as_output() gives a value suitable for setting as an output to ctx.actions.run.short_path gives back hello/world.txt "},{"title":"Projected artifacts​","type":1,"pageTitle":"Rule APIs","url":"/docs/rule_authors/rule_api/#projected-artifacts","content":"Artifacts can be projected via the project() method. Projecting an artifact yields a path within it. For example, if artifact foo is a directory containing a file bar, then foo.project(&quot;bar&quot;) yields the file bar. It is possible for projected artifacts to hide the prefix in order to have the short name of the resulting artifact only contain the projected path, by passing hide_prefix = True to project(). "},{"title":"Test Execution","type":0,"sectionRef":"#","url":"/docs/rule_authors/test_execution/","content":"","keywords":""},{"title":"Anatomy of a test run​","type":1,"pageTitle":"Test Execution","url":"/docs/rule_authors/test_execution/#anatomy-of-a-test-run","content":"When a user runs buck2 test $targets: Buck2 identifies all matching targets that have an ExternalRunnerTestInfo.Buck2 builds all the artifacts referenced by those targets (this will likely change eventually to build them only if they are used).Buck2 then notifies the test runner that those tests exist. Currently, the test runner receives a subset of ExternalRunnerTestInfo.The test runner can request command execution from Buck2 to list and execute tests.When it receives command results from Buck2, the test runner may fire off events that the end-user will see (such as test results), upload logs externally, request further executions, and so on. note If more than one target is being built, test building and execution will proceed concurrently. "},{"title":"Information available on ExternalRunnerTestInfo​","type":1,"pageTitle":"Test Execution","url":"/docs/rule_authors/test_execution/#information-available-on-externalrunnertestinfo","content":"As noted, rules communicate their testing capabilities via ExternalRunnerTestInfo. There are a number of fields available on ExternalRunnerTestInfo to control how a given target is tested, as detailed in the following sub-sections. "},{"title":"Fields exposed to the test runner​","type":1,"pageTitle":"Test Execution","url":"/docs/rule_authors/test_execution/#fields-exposed-to-the-test-runner","content":"The following list shows what is available in ExternalRunnerTestInfo, with which the test runner can interact: type - a string key that defines the type of test this is.command and env - respectively, a list and a key-value mapping of arguments.They are not always visible to the test runner (for more details, see [Verbatim arguments and handles](#verbatim-arguments-and-handles), below).labels - a set of string labels to pass to the test runner.contacts - a list of contacts for the tests; usually oncalls.executor_overrides - a key-value mapping of executor configurations that the test runner can use when requesting execution from Buck2.local_resources - a key-value mapping from resource type to optional LocalResourceInfo provider. Provider is used for initialization of that resource type. If the value is None resource type is ignored even though test runner required it. For context see Local Resources For Tests Execution. "},{"title":"Fields pertinent for Remote Execution​","type":1,"pageTitle":"Test Execution","url":"/docs/rule_authors/test_execution/#fields-pertinent-for-remote-execution","content":"For compatibility with Remote Execution (RE), there are two fields that rules should set in their ExternalRunnerTestInfo if they should be run on RE: use_project_relative_paths - if true (the default is true), Buck2 will produce relative paths. If not, it'll produce absolute paths.run_from_project_root - if true (the default is true), tests will run from the project root (their cwd will be the project root, which is the same as all build commands). If false, it'll be the cell root. Note that passing --unstable-allow-all-tests-on-re to buck2 test will override those fields and set them to true, since they are a pre-requisite to run on RE. In contrast, passing --unstable-allow-compatible-tests-on-re will only allow tests that already set both those fields to true to execute on RE. Also note that when executor_overrides are set, if an executor override is used and results in execution on RE, it'll happen on RE unconditionally. Therefore, it's a good idea to set those fields if RE-only executor overrides are provided. "},{"title":"Verbatim arguments and handles​","type":1,"pageTitle":"Test Execution","url":"/docs/rule_authors/test_execution/#verbatim-arguments-and-handles","content":"As noted above, the test runner only interacts with a subset of arguments provided by rules in ExternalRunnerTestInfo. The reason for this is that the test runner doesn't get to access, for example, artifacts, that Buck2 knows about. Consider the following example: binary = ctx.attrs.dep[RunInfo] test_info = ExternalRunnerTestInfo(command = [binary, &quot;run-tests&quot;], ...)  When Buck2 actually runs this command, binary is expanded to a path (and possibly to more args). Buck2 would also account for any hidden arguments and make those available where the command is executed. It is important for Buck2 to retain this capability when running with the test runner. To that end, all non-trivial arguments present in command (and in the values of env), such as cmd_args or RunInfo, are exposed to the test runner as opaque handles, and simple string arguments are passed as-is to the test runner. This means that the test runner would see the command described above as: [ArgHandle(index = 0), Verbatim(&quot;foobar&quot;)]  When requesting execution from Buck2, the test runner can use the ArgHandle and Buck2 will swap it back for the underlying value that was set on the provider. This allows the test runner to introspect and modify parts of the command lines it receives, as long as it doesn't need to access the actual text value of non-verbatim arguments. Usually, this works out to be sufficient (or can be made sufficient with a bit of refactoring in the test runner). "},{"title":"Execution Configurations​","type":1,"pageTitle":"Test Execution","url":"/docs/rule_authors/test_execution/#execution-configurations","content":"By default, tests execute using the execution configuration of the associated target. This is the execution configuration that would be used for run actions (ctx.actions.run) declared in the same target. This is a default that actually makes little sense but works out as long as cross-compiling is not the norm. To support this, ExternalRunnerTestInfo allows specifying override platforms, which are given a name. The test runner can request execution on them by passing their name when it sends execution requests to Buck2, as shown in the following code: ExternalRunnerTestInfo( executor_overrides = { &quot;ios-simulator&quot;: CommandExecutorConfig( local_enabled = False, remote_enabled = True, remote_execution_properties = { &quot;platform&quot;: &quot;ios-simulator-pure-re&quot;, &quot;subplatform&quot;: &quot;iPhone 8.iOS 15.0&quot;, &quot;xcode-version&quot;: &quot;xcodestable&quot;, }, remote_execution_use_case = &quot;tpx-default&quot;, ), &quot;static-listing&quot;: CommandExecutorConfig(local_enabled = True, remote_enabled = False), }, ... )  The default execution platform can also be overridden: ExternalRunnerTestInfo( default_executor = CommandExecutorConfig( local_enabled = False, remote_enabled = True, remote_execution_properties = { &quot;platform&quot;: &quot;ios-simulator-pure-re&quot;, &quot;subplatform&quot;: &quot;iPhone 8.iOS 15.0&quot;, &quot;xcode-version&quot;: &quot;xcodestable&quot;, }, remote_execution_use_case = &quot;tpx-default&quot;, ), ... )  "},{"title":"Working Directory​","type":1,"pageTitle":"Test Execution","url":"/docs/rule_authors/test_execution/#working-directory","content":"Tests can be run from the cell root by setting `run_from_project_root = False`. To produce paths relative to the cell root for use by tests, use relative_to(ctx.label.cell_root) on cmd_args. "},{"title":"Transitive Sets","type":0,"sectionRef":"#","url":"/docs/rule_authors/transitive_sets/","content":"","keywords":""},{"title":"Rule API​","type":1,"pageTitle":"Transitive Sets","url":"/docs/rule_authors/transitive_sets/#rule-api","content":"First, you need to declare your transitive set type, then you can use it, as follows: # This is the type MySet = transitive_set() # Those are transitive sets: set1 = ctx.actions.tset(MySet, value = &quot;foo&quot;) set2 = ctx.actions.tset(MySet, value = &quot;bar&quot;, children = [set1])  Values are optional, and so are children. This means you can have a set with no value and sets with no children. "},{"title":"Projections: using transitive sets in command lines​","type":1,"pageTitle":"Transitive Sets","url":"/docs/rule_authors/transitive_sets/#projections-using-transitive-sets-in-command-lines","content":"Sets aren't useful unless you can use their contents! To use a set in a command line, you use a concept called a 'projection', which defines how to turn individual values found in the set into command line arguments. To define a projection, you write a function that takes a value of your set and returns a command-line like object (cmd_args, string, attr.arg() attributes, artifact, and so on) or a list of them in whichever way makes sense for your use case. Then, you call project_as_args to turn a set into a value suitable for inclusion in a command line. When expanded, this projection will expand like a list of all the node's individual projected values. Following is an example: # Declare the projection def project_as_define(value: str.type): return cmd_args(value, format = &quot;-D{}&quot;) # Add it to the set definition MySet = transitive_set(args_projections = { &quot;define&quot;: project_as_define }) # Create a set set1 = ctx.actions.tset(MySet, value = &quot;foo&quot;) set2 = ctx.actions.tset(MySet, value = &quot;bar&quot;, children = [set1]) # Call the projection. # Note &quot;define&quot; is the key used above in `args_projections`. args = set2.project_as_args(&quot;define&quot;)  When you use args in a command line, it will expand to -Dbar -Dfoo. Note that creating projections is very cheap. Notably, it is independent of the size of the set. "},{"title":"Projections: using transitive sets in write_json()​","type":1,"pageTitle":"Transitive Sets","url":"/docs/rule_authors/transitive_sets/#projections-using-transitive-sets-in-write_json","content":"As with command lines, sets can form json projections to be used in write_json. A json projection is defined in the same way as an arg projection. The function should return a value that write_json otherwise supports. Then, you call project_as_json to turn a set into a value that can be passed to write_json (or can appear within the value passed to it, it doesn't need to be the top-level value). When expanded, the projection will expand like a list of all the node's individual projected values. Following is an example: # Declare the projection def project_as_json(value: str.type): return struct(key = &quot;foo&quot;, value = value) # Add it to the set definition MySet = transitive_set(json_projections = { &quot;define&quot;: project_as_json }) # Create a set set1 = ctx.actions.tset(MySet, value = &quot;foo&quot;) set2 = ctx.actions.tset(MySet, value = &quot;bar&quot;, children = [set1]) # Call the projection. # Note &quot;define&quot; is the key we used above in `json_projections`. args = set2.project_as_json(&quot;define&quot;)  Note that if your projected values include (or may include) artifacts, you will likely want to use write_json(with_inputs=True) to get back a cmd_args that has all the artifacts in the json structure already in its .hidden. "},{"title":"Traversals in depth​","type":1,"pageTitle":"Transitive Sets","url":"/docs/rule_authors/transitive_sets/#traversals-in-depth","content":"Transitive sets form DAGs. Notably, this means individual nodes can exist more than once in a given transitive set. When a transitive set is traversed, nodes that have already been visited are skipped. This means their arguments will only be emitted once. For example: flowchart TD foo((foo)) bar((bar)) qux((qux)) qux --&gt; foo bar --&gt; foo qux --&gt; bar set1 = ctx.actions.tset(MySet, value = &quot;foo&quot;) set2 = ctx.actions.tset(MySet, value = &quot;bar&quot;, children = [set1]) set3 = ctx.actions.tset(MySet, value = &quot;qux&quot;, children = [set1, set2]) args = set3.project_as_args(&quot;define&quot;)  This will expand to -Dqux -Dfoo -Dbar, even though set1 (&quot;foo&quot;) shows up twice in the DAG. "},{"title":"Other APIs​","type":1,"pageTitle":"Transitive Sets","url":"/docs/rule_authors/transitive_sets/#other-apis","content":""},{"title":"Transitive set reductions​","type":1,"pageTitle":"Transitive Sets","url":"/docs/rule_authors/transitive_sets/#transitive-set-reductions","content":"You can aggregate values of a transitive set via a reduction. This can be helpful for tasks such as propagating Boolean flags up the tree. Following is a real-world example. When defining a reduction, you receive the reduced values of all your children, and an optional value for the current node (the value will be None when you create a set and you don't pass a value), and you need to merge them together to produce this node's value: def link_info_has_default_filelist(children: [&quot;bool&quot;], infos: [&quot;LinkInfos&quot;, None]): if infos: info = infos.default if info.filelist: return True return any(children) # Set of LinkInfos LinkInfosTSet = transitive_set( reductions = { &quot;has_default_filelist&quot;: link_info_has_default_filelist, }, )  "},{"title":"Transitive set iteration​","type":1,"pageTitle":"Transitive Sets","url":"/docs/rule_authors/transitive_sets/#transitive-set-iteration","content":"You can iterate over a transitive set. This will yield each value once. You can also iterate over projections. However, note that this is generally not recommended, since unlike creating and using a projection, this operation is O(set). You should use this as an escape hatch if and only if you need to implement something transitive sets don't support via projections or reductions, because in doing so you'll lose a lot of the performance benefits. For example: set1 = ctx.actions.tset(MySet, value = &quot;foo&quot;) set2 = ctx.actions.tset(MySet, value = &quot;bar&quot;, children = [set1]) set3 = ctx.actions.tset(MySet, value = &quot;qux&quot;, children = [set1, set2]) values = list(set3.traverse())  This will yield [&quot;qux&quot;, &quot;foo&quot;, &quot;bar&quot;]. "},{"title":"Ordering​","type":1,"pageTitle":"Transitive Sets","url":"/docs/rule_authors/transitive_sets/#ordering","content":"Transitive set iteration uses a left-to-right, pre-order traversal by default, and ignores nodes that have already been visited. This order is reflected in projections as well. A few different traversal orders are supported with the ordering attribute: Ordering\tDescriptionpreorder (default)\tTraverses using a depth-first-search, visiting nodes left-to-right. postorder\tTraverses children left-to-right, and then visits the current node. topological\tA Topological sort, such that nodes are listed after all nodes that have them as descendants. This is similar to a pre-order traversal, except that when nodes are shared with more than one parent it is returned in the order of its last occurrence. bfs\tBreadth-first-search (BFS) traversal, traverses nodes left-to-right before traversing children. For example: set1 = ctx.actions.tset(MySet, value = &quot;foo&quot;) set2 = ctx.actions.tset(MySet, value = &quot;bar&quot;, children = [set1]) set3 = ctx.actions.tset(MySet, value = &quot;qux&quot;, children = [set1, set2]) values = list(set3.traverse(ordering = &quot;topological&quot;)) # This also works for projections args = set3.project_as_args(&quot;project&quot;, ordering = &quot;topological&quot;))  Following is an example of how different orderings evaluate: flowchart TD foo((foo)) bar((bar)) qux((qux)) qux --&gt; foo bar --&gt; foo qux --&gt; bar Ordering\tResultpreorder\t[&quot;qux&quot;, &quot;foo&quot;, &quot;bar&quot;] postorder\t[&quot;foo&quot;, &quot;bar&quot;, &quot;qux&quot;] topological\t[&quot;qux&quot;, &quot;bar&quot;, &quot;foo&quot;] bfs\t[&quot;qux&quot;, &quot;foo&quot;, &quot;bar&quot;] "},{"title":"Implementation details​","type":1,"pageTitle":"Transitive Sets","url":"/docs/rule_authors/transitive_sets/#implementation-details","content":""},{"title":"Projection evaluation​","type":1,"pageTitle":"Transitive Sets","url":"/docs/rule_authors/transitive_sets/#projection-evaluation","content":"Projections are evaluated eagerly for each node of your transitive set. This means that if your projection throws an error, you'll find out when creating a set via ctx.actions.tset. "},{"title":"Writing Rules","type":0,"sectionRef":"#","url":"/docs/rule_authors/writing_rules/","content":"","keywords":""},{"title":"Workflow by example​","type":1,"pageTitle":"Writing Rules","url":"/docs/rule_authors/writing_rules/#workflow-by-example","content":"The built-in Buck2 rules are stored in fbsource in fbcode/buck2/prelude. To add a rule for a language, say pascal: Look at prelude/attributes.bzl to see the attributes that are supported in Buck1 and are mirrored into Buck2. If pascal was an existing rule, you would see what attributes it takes (often it will be pascal_library and pascal_binary). Create a file at prelude/pascal.bzl that will contain your rule implementations. The details are explained later, but a dummy rule looks like the following: def pascal_binary_impl(_ctx: &quot;context&quot;) -&gt; [&quot;provider&quot;]: return [DefaultInfo()] Register that rule in prelude/rules_impl.bzl, which involves adding a load(&quot;:pascal.bzl&quot;, &quot;pascal_binary_impl&quot;) at the top and an additional entry in implemented_rules section to wire up pascal_binary = pascal_binary_impl. Create a directory in fbcode/buck2/tests/targets/rules/pascal with TARGETS and whatever source files and test targets you need to test your project. Note, Apple tests are currently located at xplat/buck2/tests/apple/.... Test your code with buck2 build fbcode//buck2/tests/targets/rules/pascal:. They should succeed with no actual output produced. Now implement the rules (see the rest of this page). note Before merging a diff, it's important that all your Starlark is warning free (if you don't want to set up Buck2 for local development, test it in CI). "},{"title":"Concepts and design​","type":1,"pageTitle":"Writing Rules","url":"/docs/rule_authors/writing_rules/#concepts-and-design","content":"A rule for a target uses attributes to declare actions, which produce artifacts that get included in providers. For example, given: def pascal_binary_impl(ctx: &quot;context&quot;) -&gt; [&quot;provider&quot;]: ... binary = ctx.actions.declare_output(ctx.attrs.out) ctx.actions.run([&quot;pascalc&quot;, args, &quot;-o&quot;, binary.as_output()]) return [ DefaultInfo(default_output = binary), ] pascal_binary = rule(impl = pascal_binary_impl, attrs = { &quot;out&quot;: attrs.string(), ... })  In the above snippet: Rule is pascal_binary, which is implemented by pascal_binary_impl. The rule says how to build things.Target will be something like fbcode//buck2/tests/targets/rules/pascal:my_binary. The rule implementation pascal_binary_impl will be called once per target.Attributes are the fields on the target (for example, you might have out, which can be accessed via ctx.attrs.out).Actions are declared by the rule with things like ctx.actions.run, which takes a command line. Note that the actions are not run by the rule, but declared, so that Buck2 can run them later.Artifacts represent files on disk, which could be source or build outputs (binary in the above example). For build outputs, the artifact is produced by an action, and the existence of the artifact does not imply the build has been run: the artifact 'remembers' what should be run if it is required. Providers are returned, which is information that other rules get to use. These will often contain artifacts. The rule implementation takes in a ctx, which is the rule context. The two most important fields are ctx.attrs, which picks up the attributes declared by the rule, and ctx.actions, which lets you create new actions to actually do something. The output of any actions performed will be materialized in buck-out. However, only the defined outputs of providers are available for dependent rules to consume and only the actions necessary to produce those outputs being consumed will be run. By default, the default_output of the DefaultInfo provider is built and output during a buck build. "},{"title":"Providers​","type":1,"pageTitle":"Writing Rules","url":"/docs/rule_authors/writing_rules/#providers","content":"Providers are the data returned from a rule and are the only way that information from this rule is available to rules that depend on it. Every rule must return at least the DefaultInfo provider, but most will also return either RunInfo (because they are executable) or some custom provider (because they are incorporated into something that is ultimately executable). The DefaultInfo provider has a field default_output, which is the file that will be built when someone executes a buck2 build on this particular target, and the file that will be used when someone runs $(location target) or uses it as a source file (such as srcs = [&quot;:my_target&quot;].) The current rule of thumb is that if you can build the default_output, the rule must 'work', and, if usable, should be 'ready'. For example, for a binary, the executable and runtime libraries it depends on might be returned. For a library, because neither the static or dynamic library is the 'default', you merely have to do enough work to ensure that the static and dynamic library probably work. Similar to how DefaultInfo wraps a list of artifacts and $(location) selects from DefaultInfo, RunInfo wraps a command line and $(exe) selects from RunInfo. For more information about command lines, see Run action, below. For libraries, usually you need to pass some information about the library up to the binary. The only information that dependents on the library get are the providers, so designing the information that flows around the provider is critical to designing good rules. For a hypothetical rule, you may decide you want the name of the library and the artifact that represents the .so file, for which you could define the following provider: PascalLibraryInfo = provider(fields=[ &quot;name&quot;, # The name of the library &quot;object&quot; # An artifact, the .so file that needs linking in ] )  Often, you'll grab your dependencies from all your providers: my_deps = [x[PascalLibraryInfo] for x in ctx.attrs.deps]  In many cases, it becomes apparent you need the transitive closure of all libraries (for example, the libraries and everything they depend upon), in which case, the standard pattern is to move to a provider of a list of record (see the types.md document in GitHub) and the flatten/dedupe functions, defining it as: PascalLibraryInfo = provider(fields=[&quot;links&quot;]) # a list of LinkData LinkData = record(name = str.type, object = &quot;artifact&quot;)  And then consuming it: my_links = dedupe(flatten([x[PascalLibraryInfo].links for x in ctx.attrs.deps])) my_info = PascalLibraryInfo(links = my_links)  However, this flatten/dupe pattern can get expensive, especially when you have a deep dependency graph. To fix that it's recommended to use transitive sets. "},{"title":"Actions​","type":1,"pageTitle":"Writing Rules","url":"/docs/rule_authors/writing_rules/#actions","content":"There are several actions you can use to create symlink trees, and so on. Run action​ Of the various actions, the run action is by far the most important: it's the one that invokes a command line. A command line is both a list of string arguments and a list of artifacts they depend on; with syntactic niceties for adding artifacts to command lines in a way that ensures the dependencies are usually correct. Following are examples of command line manipulations: cmd = cmd_args([&quot;some&quot;, &quot;arguments&quot;]) cmd.add(&quot;another-arg&quot;) cmd.add(ctx.attrs.src) # An input artifact out = ctx.actions.declare_output(&quot;an output&quot;) cmd.add(out.as_output()) ctx.actions.run(cmd)  The action declare_output creates a new artifact which is not bound to anything. You can call .as_output() on it when adding it to a command line to say that this command line doesn't take the artifact as an input but produces it as an output. From now on, if out is used as a dependency (either to another command line, or in DefaultInfo) then the action will be run to produce that artifact. Typically, these outputs are declared (declare_output), bound in a ctx.actions.run call with .as_output(), then either used locally as the input to another action or returned in a provider. As another example: cmd = cmd_args([&quot;cp&quot;, input, output.as_output()]) ctx.actions.run(cmd)  A command provides both a string (what to write when used) and a list of artifacts (what must be available when used). Normally, as in the case above, the artifacts that are used correspond to those on the command line. But imagine the rule is changed to write the command to a shell script first: sh = ctx.actions.write(&quot;test.sh&quot;, [&quot;cp&quot;, input, output]) cmd = cmd_args([&quot;sh&quot;,sh]) cmd.hidden([input, output.as_output()]) ctx.actions.run(cmd)  The command has been written to a shell script, which is now run. Beforehand, all the artifacts used by the command appeared on the command line. Now they don't. However, the shell script still accesses input and output. To inform the run command, use the hidden field of the command line to declare the dependency. For more complicated actions, which perform meaningful logic beyond invoking a simple command, the tendency is to write custom Python scripts. Python scripts are used instead of shell scripts as they have better cross-platform compatibility and fewer hidden corners (especially in error paths). As an example of a Python helper, see make_comp_db.py. A further advantage of using Python is that these commands can be tested in isolation, outside of Buck2. "},{"title":"Debugging​","type":1,"pageTitle":"Writing Rules","url":"/docs/rule_authors/writing_rules/#debugging","content":"The functions fail, print and pprint are your friends. To get started, a buck2 build fbcode//buck2/tests/targets/rules/pascal: builds everything or buck2 run fbcode//buck2/tests/targets/rules/pascal:my_binary runs a specific binary that returns a RunInfo. "},{"title":"Testing Rules​","type":1,"pageTitle":"Writing Rules","url":"/docs/rule_authors/writing_rules/#testing-rules","content":"A common way to test is to use genrule to cause the produced binary to run and assert some properties from it. If your rule is in Buck1 and Buck2, use a TARGETS file so you can test with both. If your tests are incompatible with Buck1 (such as if it is a new rule), use TARGETS.v2, which will only be seen by Buck2 and won't cause errors with Buck1. "},{"title":"New rules​","type":1,"pageTitle":"Writing Rules","url":"/docs/rule_authors/writing_rules/#new-rules","content":"If your rule is not already in Buck1, then you can define it wherever you like, with a preference for it not being in fbcode/buck2/prelude. The only advantage of the prelude is that rules can be used without a corresponding load, which is generally considered a misfeature. The attributes should usually be placed adjacent to the rule itself. As an example, just below the pascal_binary_impl function, you could write: pascal_binary = rule( impl = pascal_binary_impl, attrs = { &quot;deps&quot;: attrs.list(attrs.dep()), &quot;src&quot;: attrs.source(), } )  "},{"title":"Deferred Materialization","type":0,"sectionRef":"#","url":"/docs/users/advanced/deferred_materialization/","content":"","keywords":""},{"title":"Pitfalls​","type":1,"pageTitle":"Deferred Materialization","url":"/docs/users/advanced/deferred_materialization/#pitfalls","content":"Buck2's deferred materialization makes assumptions about your Remote Execution backend. In particular, it expects that the TTL returned from action cache entries by your Remote Execution backend always exceeds the TTL of all output artifacts it references. Nonetheless, artifacts may also eventually expire from your Remote Execution backend. When that happens, builds using Deferred Materialization may fail if those artifacts are needed locally. A kill is necessary to recover from those builds. However, the Restarter can be used to mitigate this issue by restarting Buck when it encounters an expired artifact. At Meta, artifacts get periodically refreshed, but open source RE backends do not expose the TTL of artifacts, so this feature does not work outside of Meta. "},{"title":"Enabling Deferred Materialization​","type":1,"pageTitle":"Deferred Materialization","url":"/docs/users/advanced/deferred_materialization/#enabling-deferred-materialization","content":"To enable deferred materialization, add this to your Buckconfig: [buck2] materializations = deferred  "},{"title":"On-disk state​","type":1,"pageTitle":"Deferred Materialization","url":"/docs/users/advanced/deferred_materialization/#on-disk-state","content":"Buck2 can also optionally track its state on disk in a SQLite database. This allows Buck2 to remember what files are on disk across restarts. This can allow Buck2 to avoid re-downloading outputs from your Remote Execution backend if they are already on disk. To enable, add this to your Buckconfig: [buck2] sqlite_materializer_state = true  "},{"title":"Deferring Write Actions​","type":1,"pageTitle":"Deferred Materialization","url":"/docs/users/advanced/deferred_materialization/#deferring-write-actions","content":"To further speedup builds, Buck2 can also be instructed to not execute any writes on the critical path for a build. To enable, add this to your Buckconfig: [buck2] defer_write_actions = true  This mechanism is recommended if you're using the On-disk State, since it means Buck can omit writes entirely if the same content is already on disk. "},{"title":"buck2 clean --stale​","type":1,"pageTitle":"Deferred Materialization","url":"/docs/users/advanced/deferred_materialization/#buck2-clean---stale","content":"When enabling the on-disk state, Buck2 can also optionally delete only artifacts that were not used recently. This also requires enabling deferred write actions. You can use this mechanism via buck2 clean --stale. "},{"title":"In Memory Cache","type":0,"sectionRef":"#","url":"/docs/users/advanced/in_memory_cache/","content":"","keywords":""},{"title":"Enabling the in-memory cache​","type":1,"pageTitle":"In Memory Cache","url":"/docs/users/advanced/in_memory_cache/#enabling-the-in-memory-cache","content":"This feature requires enabling Deferred Materialization first. This is necessary so that Buck2 knows what's on disk. This requirement might go away once we decouple keeping track of what's on disk and deferred materialization. Once done, to enable, add this to your Buckconfig: [buck2] hash_all_commands = true  "},{"title":"Restarter","type":0,"sectionRef":"#","url":"/docs/users/advanced/restarter/","content":"","keywords":""},{"title":"Enabling the Restarter​","type":1,"pageTitle":"Restarter","url":"/docs/users/advanced/restarter/#enabling-the-restarter","content":"To enable, add this to your Buckconfig: [buck2] restarter = true  "},{"title":"Buck2 Interactive Console","type":0,"sectionRef":"#","url":"/docs/users/build_observability/interactive_console/","content":"Buck2 Interactive Console This will work as long as stdin is a TTY, which will be true most of the time if you're not piping anything into Buck2. To see what's available you can press ?. To disable to allow alternate use of stdin, or for follow up pasted commands to not get swallowed: Environment Variable: BUCK_NO_INTERACTIVE_CONSOLE or flag: --no-interactive-console Note: Not available yet for Windows","keywords":""},{"title":"Logging","type":0,"sectionRef":"#","url":"/docs/users/build_observability/logging/","content":"Logging Buck2 produces detailed event logs for each invocation. They follow a schema outlined in data.proto. Those logs can be accessed using commands under buck2 log.","keywords":""},{"title":"Commands","type":0,"sectionRef":"#","url":"/docs/users/commands/","content":"Commands To get help for a given buck2 subcommand, use buck2 $SUBCOMMAND --help, e.g. buck2 build --help.","keywords":""},{"title":"Common Issues","type":0,"sectionRef":"#","url":"/docs/users/faq/common_issues/","content":"","keywords":""},{"title":"Why is stdin being swallowed?​","type":1,"pageTitle":"Common Issues","url":"/docs/users/faq/common_issues/#why-is-stdin-being-swallowed","content":"Buck2 offers an interactive console by default. To disable either use an env var: BUCK_NO_INTERACTIVE_CONSOLE or a flag: --no-interactive-console "},{"title":"Where is my output file?​","type":1,"pageTitle":"Common Issues","url":"/docs/users/faq/common_issues/#where-is-my-output-file","content":"To find the location of output for a target, use buck2 build mytarget --show-output. The resultant path is relative to the root of the repo (such as ~/repo_root/...). Note: in Buck1, the path is relative to the enclosing cell (such as ~/repo_root/cell/...). "},{"title":"Why is Buck2 hanging?​","type":1,"pageTitle":"Common Issues","url":"/docs/users/faq/common_issues/#why-is-buck2-hanging","content":"If Buck2 seems to be doing nothing, it could be caused be a cycle in your dependencies, which may cause Buck2 to hang (Buck2 does implement a form of cycle detection, but it unfortunately has false negatives). You can confirm this by running Buck1, which will report cycles properly. "},{"title":"How do I get the commands Buck2 executed so I can reproduce them in isolation?​","type":1,"pageTitle":"Common Issues","url":"/docs/users/faq/common_issues/#how-do-i-get-the-commands-buck2-executed-so-i-can-reproduce-them-in-isolation","content":"For information, see Finding Commands that Buck2 Ran. "},{"title":"Are multiple concurrent commands supported?​","type":1,"pageTitle":"Common Issues","url":"/docs/users/faq/common_issues/#are-multiple-concurrent-commands-supported","content":"Yes, they are supported. There are 2 types of concurrent commands: 1) parallel invocations, and 2) recursive invocations. Parallel invocations: If the state of all the commands are the same, then they will run at the same time. &quot;State&quot; is referring to the same configs and source files. If the state is different amongst the commands, then buck2 will block the commands properly such that the states do not interfere with each other. Different states are caused by source file changes or config changes (ex: using a different mode). Recursive invocations: A recursive invocation is when an outer buck2 command ends up calling another buck2 command as it's running. Recursive invocations are most commonly seen with genrules and tests. For example: If you have a genrule where the command contains a buck2 cquery, and you build the genrule with buck2 build, you have a recursive invocation where the outer command is buck2 build and the inner command is buck2 cqueryIf you have a test which contains buck2 build, and you run your test with buck2 test, you have a recursive invocation where the outer command is buck2 test and the inner command is buck2 build Recursive invocations should specify an --isolation-dir, or else buck2 will return an error. "},{"title":"Why did my build OOM?​","type":1,"pageTitle":"Common Issues","url":"/docs/users/faq/common_issues/#why-did-my-build-oom","content":"If your build OOMs, you can check the last actions running by using buck2 log whatup. This will print the superconsole state at the moment the event log ended, which will indicate what actions were being run (and consuming memory) when your machine ran out of memory. You can also use the --after &lt;millis&gt; option to see all open spans at a certain point in time of the build. "},{"title":"Remote Execution","type":0,"sectionRef":"#","url":"/docs/users/remote_execution/","content":"","keywords":""},{"title":"RE configuration in .buckconfig​","type":1,"pageTitle":"Remote Execution","url":"/docs/users/remote_execution/#re-configuration-in-buckconfig","content":"Configuration for remote execution can be found under [buck2_re_client] in .buckconfig. Keys supported include: engine_address - address to your RE's engine.action_cache_address - address to your action cache endpoint.cas_address - address to your content-addressable storage (CAS) endpoint.tls_ca_certs - path to a CA certificates bundle. This must be PEM-encoded. If none is set, a default bundle will be used. This path contains environment variables using shell interpolation syntax (i.e. $VAR). They will be substituted before reading the file.tls_client_cert - path to a client certificate (and intermediate chain), as well as its associated private key. This must be PEM-encoded. This path can contain environment variables using shell interpolation syntax (i.e. $VAR). They will be substituted before reading the file.http_headers - HTTP headers to inject in all requests to RE. This is a comma-separated list of Header: Value pairs. Minimal validation of those headers is done here. This can contain environment variables using shell interpolation syntax ($VAR). They will be substituted before reading the file.instance_name - an instance name to pass on execution, action cache, and CAS requests. Buck2 uses SHA256 for all its hashing by default. If your RE engine requires something else, this can be configured in .buckconfig as follows: [buck2] # Accepts BLAKE3, SHA1, or SHA256 digest_algorithms = BLAKE3  "},{"title":"RE platform configuration​","type":1,"pageTitle":"Remote Execution","url":"/docs/users/remote_execution/#re-platform-configuration","content":"Next, your build will need an execution platform that specifies how and where actions should be executed. For a sample platform definition that sets up an execution platform to utilize RE, take a look at the EngFlow example, BuildBarn example, or the BuildBuddy example. To enable remote execution, configure the following fields in CommandExecutorConfig as follows: remote_enabled - set to True.local_enabled - set to True if you also want to run actions locally.use_limited_hybrid - set to False unless you want to exclusively run remotely when possible.remote_execution_properties - other additional properties. If the RE engine requires a container image, this can be done by setting container-image to an image URL, as is done in the example above. "},{"title":"Why Buck2","type":0,"sectionRef":"#","url":"/docs/why/","content":"","keywords":""},{"title":"Why does Buck2 exist?​","type":1,"pageTitle":"Why Buck2","url":"/docs/why/#why-does-buck2-exist","content":"Meta employs a very large monorepo, consisting of a variety of programming languages, including C++, Python, Rust, Kotlin, Swift, Objective-C, Haskell, OCaml, and more. Google employs a different but functionally similar monorepo. These large scale and multi-language repositories are generally beyond the capabilities of traditional build systems like make. To optimize the build and performance of these large systems, Facebook and Google developed their own build systems, respectively Buck and Bazel. While the internal version of Bazel was started first (also known as Blaze), Buck was open sourced first (back in March 2013), followed by Bazel a few years later (March 2015). The retroactively named Buck1 was a capable build system and is still in use today at Meta (although many users have migrated). Buck2 is a rewrite that aims to keep the best bits of Buck1 (with a high degree of target compatibility) but also borrows ideas from academic research and build systems, including Bazel, Pants, Shake, Tup, and more. Following are aspects common to Buck1 and Buck2 (and in most cases, Bazel): Targets that can be queried - the build is defined as a series of targets, specified in BUCK files, that depend on other targets. This graph of targets can be queried to understand how they relate to each other and what the potential impact of a change might be.Remote execution - the build can send actions to a set of remote servers to be executed, increasing the parallelism significantly.Multi-language composability - there can be lots of different languages in a single build, and they can be put together. For example, you could have a Python library that depends on a Rust library, which, in turn depends on a C library.File watching - at large enough scale, simply looking for changed files is prohibitively expensive. Buck can integrate with Watchman to discover which files have changed efficiently. However, for simplicity of setup, the open-source version defaults to using inotify or similar functionality.Uses Starlark - Starlark is a deterministic Python-like language used to specify the targets, enabling the definition of targets as literals and more advanced manipulation/sharing. "},{"title":"What's different about Buck2?​","type":1,"pageTitle":"Why Buck2","url":"/docs/why/#whats-different-about-buck2","content":"Buck2 has many minor differences from Buck1, but there are a number that give new efficiency or expressiveness that are of note (most of these are also differences from Bazel). Buck2 is written in Rust - Buck1 was written in Java. One of the advantages of using Rust is the absence of GC pauses, However, Java also has advantages, such as better memory profiling tools.Buck2 is remote execution first - local execution is considered a special case of remote execution, in contrast to Buck1 where it was added after. That means that things such as directory hashes can be pre-computed ready to send to remote execution, giving efficiency benefits.All Buck2 rules are written in Starlark - whereas, in Buck1, they were written in Java as part of the binary, which makes iteration on rules much faster.The Buck2 binary is entirely language agnostic - as a consequence of having all the rules external to the binary, the most important and complex rule (such as in C++), don't have access to magic internal features. As a result, features have been made available to all rules, including: Dep files - the ability to declare that a subset of the files weren't actually used, and thus not be sensitive to changes within them.Incremental actions - the ability to have the action short-circuit some subset of the work if run again. Buck2 uses a dynamic (aka monadic) graph as its underlying computation engine - while most dependencies are specified statically, there are two particular features that expose dynamic power to rule authors: Dynamic dependencies - enable rules to build a file then look at its contents before specifying the dependencies and steps in future actions. Common uses are languages where the dependency structure within a project must follow imports (e.g. Haskell, OCaml) and distributed ThinLTO (where the best optimization plan is generated from summaries).Anonymous targets - enable rules to create a graph that has more sharing than the original user graph. As a result, two unrelated binaries can compile shared code only once, despite the shared code not knowing about this commonality. This feature is useful for rules like Swift feature resolution. Transitive-sets - similar in purpose to Bazel's depset. But, instead of being just a memory optimization, are also wired into the dependency graph, providing a reduction in the size of the dependency graph.Buck2 is not phased - there are no target graph/action graph phases, just a series of dependencies in a single graph on DICE that result in whatever the user requested. That means that Buck2 can sometimes parallelise different phases and track changes very precisely.Buck2 can integrate with the virtual filesystem Eden - this provides good performance, even when the file system is backed by source control fetches. However, Eden is not required, and a normal file system will also work well.The Buck2 Starlark implementation is available as a standalone library - this provides features such as IDE integration (both LSP and DAP bindings), linters, typecheckers, and more. These features are integrated into Buck2 to give a better developer experience (which is still evolving).Buck2 supports configurations - (such as select) to provide multi-platform/architecture builds, which are heavily inspired by Bazel. Within that space, there is a number of small differences, such as toolchain_deps.Buck2 is fast - in our internal tests, we observed that Buck2 completed builds 2x as fast as Buck1. For a comprehensive list of benefits, see Benefits Compared to Buck1. "},{"title":"Why use Buck2?​","type":1,"pageTitle":"Why Buck2","url":"/docs/why/#why-use-buck2","content":"It would be delightful if you tried out Buck2! But it is early-stage software, so users may run into unexpected issues. If you encounter an issue, please report it via Github issues. Buck2 is being used internally within Meta and is available as open-source from 2023. The are several differences between the internal and open-source versions: Meta uses an internal version of remote execution with builds always hooked up to remote execution. The open-source binding, which uses Buck2 without remote execution, may be less polished.There are some configuration differences between the open source and internal versions. For example, file changes default to inotify in open-source, and to Watchman internally.The prelude (containing all the rules) is the same for open-source as internal, but toolchains are not open-sourced. The required custom toolchains may not work as well. There are also some things that aren't quite yet finished: There are not yet mechanisms to build in release mode (that should be achieved by modifying the toolchain).Windows/Mac builds are still in progress; open-source code is mostly tested on Linux. If none of that puts you off, give Buck2 a go! "},{"title":"Rules","type":0,"sectionRef":"#","url":"/docs/api/rules/","content":"","keywords":""},{"title":"android_aar​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_aar","content":"def android_aar( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, abi_generation_mode: [None, str.type] = _, annotation_processing_tool: [None, str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, build_config_values: [str.type] = _, build_config_values_file: [None, str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, enable_relinker: bool.type = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, extra_kotlinc_arguments: [str.type] = _, extra_non_source_only_abi_kotlinc_arguments: [str.type] = _, friend_paths: [str.type] = _, include_build_config_class: bool.type = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, kotlin_compiler_plugins: {str.type: {str.type: str.type}} = _, labels: [str.type] = _, language: [None, str.type] = _, licenses: [str.type] = _, manifest: [None, str.type] = _, manifest_file: [None, str.type] = _, manifest_skeleton: str.type, maven_coords: [None, str.type] = _, native_library_merge_code_generator: [None, str.type] = _, native_library_merge_glue: [None, str.type] = _, native_library_merge_localized_symbols: [None, [str.type]] = _, native_library_merge_map: [None, {str.type: [str.type]}] = _, native_library_merge_sequence: [None, [(str.type, [str.type])]] = _, native_library_merge_sequence_blocklist: [None, [str.type]] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, provided_deps_query: [None, str.type] = _, relinker_whitelist: [str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resource_union_package: [None, str.type] = _, resources: [str.type] = _, resources_root: [None, str.type] = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, srcs: [str.type] = _, target: [None, str.type] = _, use_jvm_abi_gen: [None, bool.type] = _ ) -&gt; None  An android_aar() rule is used to generate an Android AAR. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onebuild_config_values: See the documentation on the values argument for android\\_build\\_config().deps: List of build targets whose corresponding compiled Java code, Android resources, and native libraries will be included in the AAR along with their transitive dependencies. For compile time deps which should not be included in the final AAR, use provided_deps instead. android_library() Will be included in the final classes.jar android_resource() Will be included in the final R.txt, res/ and assets/ android_build_config() Will be included in the final classes.jar if include_build_config_class is True groovy_library() Will be included in the final classes.jar java_library() Will be included in the final classes.jar prebuilt_jar() Will be included in the final classes.jar ndk_library() Will be included in the final jni/ or assets/ if is_asset is True prebuilt_native_library() Will be included in the final jni/ or assets/ if is_asset is Trueinclude_build_config_class: Whether to include the BuildConfig class files in the final .aar file. Needs to be set to True if any build_config_values are specified. This is normally only needed if the build tool that is consuming the .aar file does not generate BuildConfig classes. Note: the AAR format does not specify a way to pass defaults that should be injected into the final BuildConfig class, therefore that information might need to be replicated manually in the build that's consuming the .aar file.manifest_skeleton: The skeleton manifest file used to generate the final AndroidManifest.xml . May either be a file or a android\\_manifest()target.remove_classes: List of classes to remove from the output aar. It removes classes from the target's own sources, and its dependencies. Details​ See the official Android documentation for details about the .aar format. Examples:  android_resource( name = 'res', res = 'res', assets = 'assets', package = 'com.example', ) android_library( name = 'lib', srcs = glob(['**/*.java']), ) android_aar( name = 'app', manifest_skeleton = 'AndroidManifestSkeleton.xml', deps = [ ':res', ':lib', ], )   "},{"title":"android_app_modularity​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_app_modularity","content":"def android_app_modularity( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _build_only_native_code: bool.type = _, application_module_blacklist: [None, [str.type]] = _, application_module_configs: {str.type: [str.type]} = _, application_module_dependencies: [None, {str.type: [str.type]}] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, no_dx: [str.type] = _, should_include_classes: bool.type = _, should_include_libraries: bool.type = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"android_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_binary","content":"def android_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _dex_toolchain: str.type = _, _is_building_android_binary: bool.type = _, _is_force_single_cpu: bool.type = _, _is_force_single_default_cpu: bool.type = _, _java_toolchain: str.type = _, aapt2_keep_raw_values: bool.type = _, aapt2_locale_filtering: bool.type = _, aapt_mode: str.type = _, additional_aapt_params: [str.type] = _, allow_r_dot_java_in_secondary_dex: bool.type = _, allowed_duplicate_resource_types: [str.type] = _, android_sdk_proguard_config: [None, str.type] = _, application_module_blacklist: [None, [str.type]] = _, application_module_configs: {str.type: [str.type]} = _, application_module_dependencies: [None, {str.type: [str.type]}] = _, asset_compression_algorithm: [None, str.type] = _, banned_duplicate_resource_types: [str.type] = _, build_config_values: [str.type] = _, build_config_values_file: [None, str.type] = _, build_string_source_map: bool.type = _, compress_asset_libraries: bool.type = _, constraint_overrides: [str.type] = _, contacts: [str.type] = _, cpu_filters: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, dex_compression: [None, str.type] = _, dex_group_lib_limit: int.type = _, dex_tool: str.type = _, disable_pre_dex: bool.type = _, duplicate_resource_behavior: str.type = _, duplicate_resource_whitelist: [None, str.type] = _, enable_relinker: bool.type = _, exopackage_modes: [str.type] = _, extra_filtered_resources: [str.type] = _, field_ref_count_buffer_space: int.type = _, ignore_aapt_proguard_config: bool.type = _, includes_vector_drawables: bool.type = _, is_cacheable: bool.type = _, is_voltron_language_pack_enabled: bool.type = _, keystore: str.type, labels: [str.type] = _, licenses: [str.type] = _, linear_alloc_hard_limit: int.type = _, locales: [str.type] = _, manifest: [None, str.type] = _, manifest_entries: {str.type: &quot;&quot;} = _, manifest_skeleton: [None, str.type] = _, method_ref_count_buffer_space: int.type = _, min_sdk_version: [None, int.type] = _, minimize_primary_dex_size: bool.type = _, module_manifest_skeleton: [None, str.type] = _, native_library_merge_code_generator: [None, str.type] = _, native_library_merge_glue: [None, str.type] = _, native_library_merge_localized_symbols: [None, [str.type]] = _, native_library_merge_map: [None, {str.type: [str.type]}] = _, native_library_merge_sequence: [None, [(str.type, [str.type])]] = _, native_library_merge_sequence_blocklist: [None, [str.type]] = _, no_auto_add_overlay_resources: bool.type = _, no_auto_version_resources: bool.type = _, no_dx: [str.type] = _, no_version_transitions_resources: bool.type = _, optimization_passes: int.type = _, package_asset_libraries: bool.type = _, package_type: str.type = _, packaged_locales: [str.type] = _, post_filter_resources_cmd: [None, str.type] = _, preprocess_java_classes_bash: [None, str.type] = _, preprocess_java_classes_cmd: [None, str.type] = _, preprocess_java_classes_deps: [str.type] = _, primary_dex_patterns: [str.type] = _, proguard_config: [None, str.type] = _, proguard_jvm_args: [str.type] = _, relinker_whitelist: [str.type] = _, resource_compression: str.type = _, resource_filter: [str.type] = _, resource_stable_ids: [None, str.type] = _, resource_union_package: [None, str.type] = _, secondary_dex_weight_limit: [None, int.type] = _, skip_crunch_pngs: [None, bool.type] = _, skip_proguard: bool.type = _, trim_resource_ids: bool.type = _, use_split_dex: bool.type = _, xz_compression_level: int.type = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"android_build_config​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_build_config","content":"def android_build_config( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _build_only_native_code: bool.type = _, _is_building_android_binary: bool.type = _, _java_toolchain: str.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, package: str.type = _, values: [str.type] = _, values_file: [None, str.type] = _ ) -&gt; None  An android_build_config() rule is used to generate a BuildConfig class with global configuration variables that other android\\_library()rules can compile against. Currently, the only variable exposed by BuildConfig is a global boolean named DEBUG, much like the BuildConfig.java generated by the official Android build tools based on Gradle. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onepackage: Name of the Java package to use in the generated BuildConfig.java file. Most developers set this to the application id declared in the manifest via &lt;manifest package=&quot;APP_ID&quot;&gt;. Example: com.facebook.orca.values: List of strings that defines additional fields (and values) that should be declared in the generated BuildConfig.java file. Like DEBUG, the values will be non-constant-expressions that evaluate to the value specified in the file at compilation time. To override the values in an APK, specify build_config_values or build_config_values_file in android\\_binary().values_file: Optional path to a file that defines additional fields (and values) that should be declared in the generated BuildConfig.java file. Like DEBUG, the values will be non-constant-expressions that evaluate to the value specified in the file at compilation time. To override the values in an APK, specify build_config_values or build_config_values_file in android\\_binary(). Note that values_file can be a generated file, as can build_config_values_file as demonstrated in the example below. Details​ The fields in the generated BuildConfig class will be non-constant-expressions (see JLS 15.28). However, if BuildConfig is packaged into an APK, it will be replaced with a new version where: The fields will be set to literal values (i.e., constant expressions).The boolean BuildConfig.DEBUG field will correspond to that of the package_type argument to the android\\_binary()rule that is packaging it. This transformation is done before ProGuard is applied (if applicable), so that it can propagate constants from BuildConfig and eliminate dead code. Examples: Here is an example of an android_build_config() rule that is transitively included by both debug and release versions of an android\\_binary()rule. The value of com.example.pkg.BuildConfig.DEBUG will be different in each APK even though they both transitively depend on the same :build_config rule.  android_build_config( name = 'build_config', package = 'com.example.pkg', values = [ 'String COMMIT_ID = &quot;0000000000000000000000000000000000000000&quot;', ], ) # The .java files in this library may contain references to the boolean # com.example.pkg.BuildConfig.DEBUG because :build_config is in the deps. # It could also reference BuildConfig.COMMIT_ID. android_library( name = 'mylib', srcs = glob(['src/**/*.java']), deps = [ ':build_config', ], ) android_binary( name = 'debug', package_type = 'DEBUG', keystore = '//keystores:debug', manifest = 'AndroidManifest.xml', target = 'Google Inc.:Google APIs:19', deps = [ ':mylib', ], ) # The contents of the file generated by this rule might be: # # String COMMIT_ID = &quot;7bf804bdf71fdbfc99cce3b155b3643f022c6fa4&quot; # # Note that the output of :build_config_release_values will be cached by Buck. # Assuming that generate_release_build_config.py depends on state that is not # expressed by its deps (which violates a fundamental invariant in Buck!), a # workaround is to ensure that the inputs to :build_config_release_values are # changed in some way before :release is built to ensure that the output from # :build_config_release_values is not pulled from cache. For example: # # $ buck build :release # $ uuidgen &gt; dummy_state_file.txt # $ buck build :release # # This makes sure that generate_release_build_config.py is re-run before # :release is rebuilt. This is much cheaper than deleting your build cache # before rebuilding. genrule( name = 'build_config_release_values', srcs = [ 'generate_release_build_config.py', 'dummy_state_file.txt' ], bash = 'generate_release_build_config.py $OUT', out = 'build_config_release_values.txt', ) android_binary( name = 'release', package_type = 'RELEASE', keystore = '//keystores:release', manifest = 'AndroidManifest.xml', target = 'Google Inc.:Google APIs:19', build_config_values_file = ':build_config_release_values', deps = [ ':mylib', ], )   "},{"title":"android_bundle​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_bundle","content":"def android_bundle( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _dex_toolchain: str.type = _, _is_building_android_binary: bool.type = _, _is_force_single_cpu: bool.type = _, _is_force_single_default_cpu: bool.type = _, _java_toolchain: str.type = _, aapt2_keep_raw_values: bool.type = _, aapt2_locale_filtering: bool.type = _, aapt_mode: str.type = _, additional_aapt_params: [str.type] = _, allow_r_dot_java_in_secondary_dex: bool.type = _, allowed_duplicate_resource_types: [str.type] = _, android_sdk_proguard_config: [None, str.type] = _, application_module_blacklist: [None, [str.type]] = _, application_module_configs: {str.type: [str.type]} = _, application_module_dependencies: [None, {str.type: [str.type]}] = _, asset_compression_algorithm: [None, str.type] = _, banned_duplicate_resource_types: [str.type] = _, build_config_values: [str.type] = _, build_config_values_file: [None, str.type] = _, build_string_source_map: bool.type = _, bundle_config_file: [None, str.type] = _, compress_asset_libraries: bool.type = _, contacts: [str.type] = _, cpu_filters: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, dex_compression: [None, str.type] = _, dex_group_lib_limit: int.type = _, dex_tool: str.type = _, disable_pre_dex: bool.type = _, duplicate_resource_behavior: str.type = _, duplicate_resource_whitelist: [None, str.type] = _, enable_relinker: bool.type = _, exopackage_modes: [str.type] = _, extra_filtered_resources: [str.type] = _, field_ref_count_buffer_space: int.type = _, ignore_aapt_proguard_config: bool.type = _, includes_vector_drawables: bool.type = _, is_cacheable: bool.type = _, is_voltron_language_pack_enabled: bool.type = _, keystore: str.type, labels: [str.type] = _, licenses: [str.type] = _, linear_alloc_hard_limit: int.type = _, locales: [str.type] = _, manifest: [None, str.type] = _, manifest_entries: {str.type: &quot;&quot;} = _, manifest_skeleton: [None, str.type] = _, method_ref_count_buffer_space: int.type = _, min_sdk_version: [None, int.type] = _, minimize_primary_dex_size: bool.type = _, module_manifest_skeleton: [None, str.type] = _, native_library_merge_code_generator: [None, str.type] = _, native_library_merge_glue: [None, str.type] = _, native_library_merge_localized_symbols: [None, [str.type]] = _, native_library_merge_map: [None, {str.type: [str.type]}] = _, native_library_merge_sequence: [None, [(str.type, [str.type])]] = _, native_library_merge_sequence_blocklist: [None, [str.type]] = _, no_auto_add_overlay_resources: bool.type = _, no_auto_version_resources: bool.type = _, no_dx: [str.type] = _, no_version_transitions_resources: bool.type = _, optimization_passes: int.type = _, package_asset_libraries: bool.type = _, package_type: str.type = _, packaged_locales: [str.type] = _, post_filter_resources_cmd: [None, str.type] = _, preprocess_java_classes_bash: [None, str.type] = _, preprocess_java_classes_cmd: [None, str.type] = _, preprocess_java_classes_deps: [str.type] = _, primary_dex_patterns: [str.type] = _, proguard_config: [None, str.type] = _, proguard_jvm_args: [str.type] = _, relinker_whitelist: [str.type] = _, resource_compression: str.type = _, resource_filter: [str.type] = _, resource_stable_ids: [None, str.type] = _, resource_union_package: [None, str.type] = _, secondary_dex_weight_limit: [None, int.type] = _, skip_crunch_pngs: [None, bool.type] = _, skip_proguard: bool.type = _, trim_resource_ids: bool.type = _, use_split_dex: bool.type = _, xz_compression_level: int.type = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"android_instrumentation_apk​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_instrumentation_apk","content":"def android_instrumentation_apk( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _dex_toolchain: str.type = _, _is_building_android_binary: bool.type = _, _is_force_single_cpu: bool.type = _, _is_force_single_default_cpu: bool.type = _, _java_toolchain: str.type = _, aapt_mode: str.type = _, apk: str.type, contacts: [str.type] = _, cpu_filters: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, dex_tool: str.type = _, disable_pre_dex: bool.type = _, includes_vector_drawables: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, manifest: [None, str.type] = _, manifest_skeleton: [None, str.type] = _, min_sdk_version: [None, int.type] = _, primary_dex_patterns: [str.type] = _, use_split_dex: [None, bool.type] = _ ) -&gt; None  An android_instrumentation_apk() rule is used to generate an Android Instrumentation APK. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one Details​ Android's Testing Fundamentals documentation includes a diagram that shows the relationship between an &quot;application package&quot; and a &quot;test package&quot; when running a test. This rule corresponds to a test package. Note that a test package has an interesting quirk where it is compiled against an application package, but must not include the resources or Java classes of the application package. Therefore, this class takes responsibility for making sure the appropriate bits are excluded. Failing to do so will generate mysterious runtime errors when running the test. Examples: Here is an example of an android_instrumentation_apk() rule that tests a android_binary(), and depends on a test package.  android_library( name = 'test', srcs = glob(['test/**/*.java']), ) android_binary( name = 'messenger', manifest = 'AndroidManifest.xml', keystore = '//keystores:prod', package_type = 'release', proguard_config = 'proguard.cfg', deps = [ ... ], ) # Building this rule will produce a file named messenger_test.apk android_instrumentation_apk( name = 'messenger_test', manifest = 'AndroidInstrumentationManifest.xml', apk = ':messenger', deps = [ ':test', ], )   "},{"title":"android_instrumentation_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_instrumentation_test","content":"def android_instrumentation_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _inject_test_env: str.type = _, _java_toolchain: str.type = _, apk: str.type, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, env: {str.type: str.type} = _, labels: [str.type] = _, licenses: [str.type] = _, test_rule_timeout_ms: [None, int.type] = _ ) -&gt; None  A android_instrumentation_test() rule is used to define apks that should be used to run Android instrumentation tests. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneapk: The APK containing the tests. Can be an android\\_binary(), an apk\\_genrule()or an android\\_instrumentation\\_apk().labels: A list of labels to be applied to these tests. These labels are arbitrary text strings and have no meaning within buck itself. They can, however, have meaning for you as a test author (e.g., smoke or fast). A label can be used to filter or include a specific test rule when executing buck testtest_rule_timeout_ms: If set specifies the maximum amount of time (in milliseconds) in which all of the tests in this rule should complete. This overrides the default rule_timeout if any has been specified in .buckconfig . Details​ Examples: Here is an example of an android_instrumentation_test()rule that tests an android_binary().  android_binary( name = 'messenger', manifest = 'AndroidManifest.xml', keystore = '//keystores:prod', package_type = 'release', proguard_config = 'proguard.cfg', deps = [ ... ], ) android_instrumentation_apk( name = 'messenger_test', manifest = 'AndroidInstrumentationManifest.xml', apk = ':messenger', deps = [ ... ], ) android_instrumentation_test( name = 'messenger_instrumentation_test', apk = ':messenger_test', )   "},{"title":"android_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_library","content":"def android_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _build_only_native_code: bool.type = _, _dex_min_sdk_version: [None, int.type] = _, _dex_toolchain: str.type = _, _is_building_android_binary: bool.type = _, _java_toolchain: str.type = _, _kotlin_toolchain: str.type = _, abi_generation_mode: [None, str.type] = _, annotation_processing_tool: [None, str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, extra_kotlinc_arguments: [str.type] = _, extra_non_source_only_abi_kotlinc_arguments: [str.type] = _, friend_paths: [str.type] = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, kotlin_compiler_plugins: {str.type: {str.type: str.type}} = _, labels: [str.type] = _, language: [None, str.type] = _, licenses: [str.type] = _, manifest: [None, str.type] = _, manifest_file: [None, str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, provided_deps_query: [None, str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resource_union_package: [None, str.type] = _, resources: [str.type] = _, resources_root: [None, str.type] = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, srcs: [str.type] = _, target: [None, str.type] = _, use_jvm_abi_gen: [None, bool.type] = _ ) -&gt; None  An android_library() rule is used to define a set of Java files that can be compiled together against the Android SDK. The main output of an android_library() rule is a single JAR file containing all of the compiled class files and resources. Parameters​ name: name of the target default_target_platform: specifies the default target platform, used when no platforms are specified on the command line target_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configuration compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configuration exec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platform visibility: a list of visibility patterns restricting what targets can depend on this one within_view: a list of visibility patterns restricting what this target can depend on tests: a list of targets that provide tests for this one annotation_processing_tool: Specifies the tool to use for annotation processing. Possible values: &quot;kapt&quot; or &quot;javac&quot;. &quot;kapt&quot; allows running Java annotation processors against Kotlin sources while backporting it for Java sources too. &quot;javac&quot; works only against Java sources, Kotlin sources won't have access to generated classes at compile time. deps: Rules (usually other android_library rules) that are used to generate the classpath required to compile this android_library. deps_query: Status: experimental/unstable. The deps query takes a query string that accepts the following query functions, and appends the output of the query to the declared deps: attrfilter deps except intersect filter kind set union The macro $declared_deps may be used anywhere a target literal pattern is expected in order to refer to the explicit deps of this rule as they appear in the rule's definition. For example, if your build rule declares  android_library( name = 'lib', deps = ['//foo:foo'], deps_query = '$declared_deps', )  then the macro $declared_deps would be expanded to a literal set(//foo:foo). Some example queries:  &quot;filter({name_regex}, $declared_deps)&quot;.format(name_regex='//.*') &quot;attrfilter(annotation_processors, com.foo.Processor, $declared_deps)&quot; &quot;deps('//foo:foo', 1)&quot;  Note: any targets included in this query must also be present in deps. exported_deps: Other rules that depend on this rule will also include its exported_deps in their classpaths. This is useful when the public API of a rule has return types or checked exceptions that are defined in another rule, which would otherwise require callers to add an extra dependency. It's also useful for exposing e.g. a collection of prebuilt_jar rules as a single target for callers to depend on. Targets in exported_deps are implicitly included in the deps of this rule, so they don't need to be repeated there.exported_provided_deps: This is a combination of provided_deps and exported_deps. Rules listed in this parameter will be added to classpath of rules that depend on this rule, but they will not be included in a binary if binary depends on a such target.extra_arguments: List of additional arguments to pass into the Java compiler. These arguments follow the ones specified in .buckconfig.extra_kotlinc_arguments: List of additional arguments to pass into the Kotlin compiler.javac: Specifies the Java compiler program to use for this rule. The value is a source path (e.g., //foo/bar:bar). Overrides the value in &quot;javac&quot; in the &quot;tools&quot; section of .buckconfig.manifest: An optional Android Manifest for the to declare any permissions or intents it may need or want to handle. May either be a file or a android\\_manifest()target.provided_deps: These represent dependencies that are known to be provided at run time, but are required in order for the code to compile. Examples of provided_deps include the JEE servlet APIs. When this rule is included in a , the provided_deps will not be packaged into the output.provided_deps_query: Status: experimental/unstable. The provided deps query functions in the same way as the deps query, but the referenced deps using $declared are the provided deps of the target, and the results of the query are appended to the declared provided deps.remove_classes: List of classes to remove from the output jar. It only removes classes from the target's own sources, not from any of its dependencies.required_for_source_only_abi: Indicates that this rule must be present on the classpath during source-only ABI generation of any rule that depends on it. Typically this is done when a rule contains annotations, enums, constants, or interfaces. Having rules present on the classpath during source-only ABI generation prevents Buck from completely flattening the build graph, thus reducing the performance win from source-only ABI generation. These rules should be kept small (ideally just containing annotations, constants, enums, and interfaces) and with minimal dependencies of their own. resources: Static files to include among the compiled .class files. These files can be loaded via Class.getResource(). Note: Buck uses the src_roots property in.buckconfigto help determine where resources should be placed within the generated JAR file. source: Specifies the version of Java (as a string) to interpret source files as. Overrides the value in &quot;source_level&quot; in the &quot;java&quot; section of .buckconfig.source_only_abi_deps: These are dependencies that must be present during source-only ABI generation. Typically such dependencies are added when some property of the code in this rule prevents source-only ABI generation from being correct without these dependencies being present. Having source_only_abi_deps prevents Buck from completely flattening the build graph, thus reducing the performance win from source-only ABI generation. They should be avoided when possible. Often only a small code change is needed to avoid them. For more information on such code changes, read aboutsource-only ABI generation. srcs: The set of .java files to compile for this rule.target: Specifies the version of Java (as a string) for which to generate code. Overrides the value in &quot;target_level&quot; in the &quot;java&quot; section of .buckconfig. Details​ Examples: An android_library rule used in concert with anandroid\\_resource()rule. This would be a common arrangement for a standard Android Library project as defined byhttp://developer.android.com/tools/projects/index.html  android_resource( name = 'res', res = 'res', package = 'com.example', ) android_library( name = 'my_library', srcs = glob(['src/**/*.java']), deps = [ ':res', ], )   "},{"title":"android_manifest​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_manifest","content":"def android_manifest( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, skeleton: str.type ) -&gt; None  An android_manifest() rule is used to generate an Android Manifest to be used by android\\_binary()and android\\_aar()rules. This rule takes a skeleton manifest, and merges it with manifests found in any deps. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: A collection of dependencies that includes android_library rules. The manifest files of the android\\_library()rules will be filtered out to become dependent source files for the manifest.skeleton: Either a build targetor a path to a file representing the manifest that will be merged with any manifests associated with this rule's deps. Details​ Examples: Here's an example of an android_manifest() that has no deps.  android_manifest( name = 'my-manifest', skeleton = 'AndroidManifestSkeleton.xml', )  This is what AndroidManifestSkeleton.xml looks like.  &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;manifest xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; package=&quot;com.example&quot; android:versionCode=&quot;1&quot; android:versionName=&quot;1.0&quot;&gt; &lt;uses-sdk targetSdkVersion=&quot;19&quot; minSdkVersion=&quot;17&quot;/&gt; &lt;application android:label=&quot;@string/app_name&quot; android:icon=&quot;@drawable/ic_launcher&quot;&gt; &lt;activity android:name=&quot;MyActivity&quot; android:label=&quot;@string/app_name&quot;&gt; &lt;intent-filter&gt; &lt;action android:name=&quot;android.intent.action.MAIN&quot;/&gt; &lt;category android:name=&quot;android.intent.category.LAUNCHER&quot;/&gt; &lt;/intent-filter&gt; &lt;/activity&gt; &lt;/application&gt; &lt;/manifest&gt;  You could also use a genrule()to generate the manifest file and reference thebuild targetin the skeleton argument.  "},{"title":"android_platform​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_platform","content":"def android_platform( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, base_platform: str.type, native_platforms: {str.type: str.type} = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"android_prebuilt_aar​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_prebuilt_aar","content":"def android_prebuilt_aar( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _build_only_native_code: bool.type = _, _dex_min_sdk_version: [None, int.type] = _, _dex_toolchain: str.type = _, _java_toolchain: str.type = _, aar: str.type, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, javadoc_url: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, maven_coords: [None, str.type] = _, required_for_source_only_abi: bool.type = _, source_jar: [None, str.type] = _, use_system_library_loader: bool.type = _ ) -&gt; None  An android_prebuilt_aar() rule takes an .aar file and makes it available as an Android dependency. As expected, an android\\_binary()that transitively depends on an android_prebuilt_aar() will include its contents in the generated APK. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneaar: Path to the .aar file. This may also be a build target to a rule (such as a genrule()) whose output is an .aar file.javadoc_url: URL to the Javadoc for the .class files in the aar.source_jar: Path to a JAR file that contains the .java files to create the .class in the aar. This is frequently provided for debugging purposes.use_system_library_loader: If this .aar file contains native prebuilt .so libraries and the Java code uses these libraries via a call to System.loadLibrary(), then many optimizations—such as exopackage, compression, or asset packaging—may not be compatible with these prebuilt libs. Setting this parameter to True causes all of these optimizations to skip the prebuilt .so files originating from this .aar file. The .so files will always be packaged directly into the main .apk. Details​ See the official Android documentation for details about the .aar format. Examples:  android_prebuilt_aar( name = 'play-services', aar = 'play-services-4.0.30.aar', source_jar = 'play-services-4.0.30-sources.jar', javadoc_url = 'file:///opt/android-sdk/extras/google/google_play_services/docs/reference', ) android_library( name = 'lib', # This Java code can compile against Play services and reference its resources. srcs = glob(['*.java']), deps = [ ':play-services' ], )   "},{"title":"android_resource​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#android_resource","content":"def android_resource( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _build_only_native_code: bool.type = _, allowlisted_locales: [None, [str.type]] = _, assets: [None, str.type, {str.type: str.type}] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, has_whitelisted_strings: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, manifest: [None, str.type] = _, package: [None, str.type] = _, project_assets: [None, str.type] = _, project_res: [None, str.type] = _, res: [None, str.type, {str.type: str.type}] = _, resource_union: bool.type = _ ) -&gt; None  An android_resource() rule is used to bundle Android resources that are traditionally stored in res and assets directories. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: Other android_resource rules to include via -S when running aapt.manifest: An optional Android Manifest for the to declare any permissions or intents it may need or want to handle. May either be a file or a android\\_manifest()target.package: Java package for the R.java file that will be generated for these resources. Details​ The output of an android_resource() is an R.txt file generated via aapt --output-text-symbols. Examples: Most of the time, an android_resource rule defines only name, res, and package. By convention, such simple rules are often named res:  android_resource( name = 'res', res = subdir_glob([('res', '**')]), package = 'com.example', )   "},{"title":"apk_genrule​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#apk_genrule","content":"def apk_genrule( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _genrule_toolchain: str.type = _, aab: [None, str.type] = _, apk: [None, str.type] = _, bash: [None, str.type] = _, cacheable: [None, bool.type] = _, cmd: [None, str.type] = _, cmd_exe: [None, str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, enable_sandbox: [None, bool.type] = _, environment_expansion_separator: [None, str.type] = _, is_cacheable: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, metadata_env_var: [None, str.type] = _, metadata_path: [None, str.type] = _, need_android_tools: bool.type = _, no_outputs_cleanup: bool.type = _, out: [None, str.type] = _, remote: [None, bool.type] = _, srcs: [[str.type], {str.type: str.type}] = _, type: str.type = _ ) -&gt; None  An apk_genrule() rule is used to post-process an APK. What separates an apk_genrule from a genrule is apk_genrules are known by BUCK to produce APKs, so commands like buck install or buck uninstall still work. Additionally, apk_genrule() rules can be inputs to other apk_genrule() rules. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneapk: The input android_binary() rule. The path to the APK can be accessed with the $APK shell variable.bash: A platform-specific version of the shell command parameter cmd. It runs on Linux and UNIX systems—including OSX—on which bash is installed. It has a higher priority than cmd. The bash argument is run with /usr/bin/env bash -c. It has access to the same set of macros and variables as the cmd argument.cmd: The shell command to run to generate the output file. It is the fallback for bash and cmd_exe arguments. The following environment variables are populated by Buck and available to the shell command. They are accessed using the syntax: ${&lt;variable&gt;}  Example: ${SRCS}  ${SRCS} A string expansion of the srcs argument delimited by the environment_expansion_separator argument where each element of srcs will be translated into an absolute path. ${SRCDIR} The absolute path to a directory to which sources are copied prior to running the command. ${OUT} The output file or directory for the genrule(). This variable will have whatever value is specified by the out argument if not usingÂ named outputs using named outputs, this variable will be the output directory. The value should be a valid filepath. The semantics of the shell command determine whether this filepath is treated as a file or a directory. If the filepath is a directory, then the shell command needs to create it if not using named outputs. Otherwise, it will be automatically created. The file or directory specified by this variable must always be written by this command. If not, the execution of this rule will be considered a failure, halting the build process. ${TMP} A temporary directory which can be used for intermediate results and will not be bundled into the output. String parameter macros​ It is also possible to expand references to other rules within thecmd, using builtin string parameter macros. All build rules expanded in the command are automatically considered to be dependencies of the genrule(). Note that the paths returned by these macros are absolute paths. You should convert these paths to be relative paths before embedding them in, for example, a shell script or batch file. Using relative paths ensures that your builds are hermetic, that is, they are reproducible across different machine environments. Additionally, if you embed these paths in a shell script, you should execute that script using the sh\\_binary()rule and include the targets for these paths in the resources argument of that sh_binary rule. These are the same targets that you pass to the string parameter macros. $(classpath //path/to:target) Expands to the transitive classpath of the specified build rule, provided that the rule has a Java classpath. If the rule does not have (or contribute to) a classpath, then an exception is thrown and the build breaks. $(exe //path/to:target) Expands a build rule that results in an executable to the commands necessary to run that executable. For example, a java_binary() might expand to a call to java -jar path/to/target.jar . Files that are executable (perhaps generated by a genrule()) are also expanded. If the build rule does not generate an executable output, then an exception is thrown and the build breaks. $(location //path/to:target) Expands to the location of the output of the specified build rule. This means that you can refer to the output without needing to be aware of how Buck is storing data on the disk mid-build. $(maven_coords //path/to:target) Expands to the Maven coordinates for the specified build rule. This allows you to access the Maven coordinates for Maven-aware build rules. The format of the expansion is:   cmd_exe: A platform-specific version of the shell command parameter cmd. It runs on Windows and has a higher priority than cmd. The cmd_exe argument is run with cmd.exe /v:off /c. It has access to the same set of macros and variables as the cmd argument.environment_expansion_separator: The delimiter between paths in environment variables, such as SRCS, that can contain multiple paths. It can be useful to specify this parameter if the paths could contain spaces.out: This argument only exists for historical reasons and it does not have any effect. It will be deprecated and removed in the future.srcs: Either a list or a map of the source files which Buck makes available to the shell command at the path in the SRCDIR environment variable. If you specify a list, the source files are the names in the list. If you specify a map, the source files are made available as the names in the keys of the map, where the values of the map are the original source file names. Details​ Examples: Here is an example of a couple apk_genrule() open up an APK, do some super signing, and then zipalign that APK again.  # Building this rule will produce a file named messenger.apk. android_binary( name = 'messenger', manifest = 'AndroidManifest.xml', target = 'Google Inc.:Google APIs:16', keystore = '//keystores:prod', package_type = 'release', proguard_config = 'proguard.cfg', deps = [ ':res', ':src', ], ) apk_genrule( name = 'messenger_super_sign_unalign', apk = ':messenger', bash = '$(exe //java/com/facebook/sign:super_sign) --input $APK --output $OUT', cmd_exe = '$(exe //java/com/facebook/sign:super_sign) --input %APK% --output %OUT%', out = 'messenger_super_sign_unalign.apk', ) apk_genrule( name = 'messenger_super_sign', apk = ':messenger_super_sign_unalign', bash = '$ANDROID_HOME/tools/zipalign -f 4 $APK $OUT', cmd_exe = '%ANDROID_HOME%\\tools\\zipalign -f 4 %APK% %OUT%', out = 'messenger_super_sign.apk', )   "},{"title":"apple_asset_catalog​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#apple_asset_catalog","content":"def apple_asset_catalog( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, app_icon: [None, str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, dirs: [str.type] = _, labels: [str.type] = _, launch_image: [None, str.type] = _, licenses: [str.type] = _ ) -&gt; None  An apple_asset_catalog() rule contains resources stored in Apple asset catalog directories. This rule does not have any output on its own and can be built only as a dependency (either direct or transitive) of an apple_bundle() rule, in which case all apple_asset_catalog() rules that the bundle rule depends on are merged and placed into the final output bundle together. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneapp_icon: An optional reference to a .appiconset containing a image set representing an application icon. (The extension itself should not be included.) This parameter may be specified at most once in a given apple_bundle's transitive dependencies.launch_image: An optional reference to a .launchimage containing a image set representing an application launch image. (The extension itself should not be included.) This parameter may be specified at most once in a given apple_bundle's transitive dependencies. Details​ Examples:  apple_asset_catalog( name = 'MyAssetCatalog', dirs = [ 'MyResources.xcassets', ], ) # A asset catalog with a app icon and launch image apple_asset_catalog( name = 'AssetCatalog', dirs = [ 'AssetCatalog.xcassets' ], app_icon = 'Icon', launch_image = 'LaunchImage', )   "},{"title":"apple_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#apple_binary","content":"def apple_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _apple_toolchain: str.type = _, _apple_tools: str.type = _, _apple_xctoolchain: str.type = _, _apple_xctoolchain_bundle_id: str.type = _, _omnibus_environment: [None, str.type] = _, binary_linker_flags: [str.type] = _, bridging_header: [None, str.type] = _, can_be_asset: [None, bool.type] = _, compiler_flags: [str.type] = _, configs: {str.type: {str.type: str.type}} = _, contacts: [str.type] = _, cxx_runtime_type: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, devirt_enabled: bool.type = _, diagnostics: {str.type: str.type} = _, enable_cxx_interop: bool.type = _, enable_distributed_thinlto: bool.type = _, entitlements_file: [None, str.type] = _, executable_name: [None, str.type] = _, exported_deps: [str.type] = _, exported_header_style: str.type = _, exported_headers: [[str.type], {str.type: str.type}] = _, exported_lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, exported_lang_preprocessor_flags: {str.type: [str.type]} = _, exported_linker_flags: [str.type] = _, exported_platform_deps: [(str.type, [str.type])] = _, exported_platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, exported_platform_linker_flags: [(str.type, [str.type])] = _, exported_platform_preprocessor_flags: [(str.type, [str.type])] = _, exported_post_linker_flags: [str.type] = _, exported_post_platform_linker_flags: [(str.type, [str.type])] = _, exported_preprocessor_flags: [str.type] = _, extra_xcode_files: [str.type] = _, extra_xcode_sources: [str.type] = _, fat_lto: bool.type = _, focused_list_target: [None, str.type] = _, force_static: [None, bool.type] = _, frameworks: [str.type] = _, header_namespace: [None, str.type] = _, header_path_prefix: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, info_plist: [None, str.type] = _, info_plist_substitutions: {str.type: str.type} = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, link_execution_preference: [None, str.type] = _, link_group: [None, str.type] = _, link_group_map: [None, str.type, [(str.type, [([None, str.type], str.type, [None, str.type, [str.type]], [None, str.type])], [None, {str.type: &quot;&quot;}])]] = _, link_ordering: [None, str.type] = _, link_style: [None, str.type] = _, link_whole: [None, bool.type] = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, modular: bool.type = _, module_name: [None, str.type] = _, module_requires_cxx: bool.type = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, prefer_stripped_objects: bool.type = _, preferred_linkage: str.type = _, prefix_header: [None, str.type] = _, preprocessor_flags: [str.type] = _, public_include_directories: [str.type] = _, public_system_include_directories: [str.type] = _, raw_headers: [str.type] = _, reexport_all_header_dependencies: [None, bool.type] = _, sdk_modules: [str.type] = _, serialize_debugging_options: bool.type = _, soname: [None, str.type] = _, srcs: [[str.type, (str.type, [str.type])]] = _, static_library_basename: [None, str.type] = _, stripped: bool.type = _, supported_platforms_regex: [None, str.type] = _, supports_merged_linking: [None, bool.type] = _, swift_compiler_flags: [str.type] = _, swift_version: [None, str.type] = _, target_sdk_version: [None, str.type] = _, thin_lto: bool.type = _, use_submodules: bool.type = _, uses_cxx_explicit_modules: bool.type = _, uses_explicit_modules: bool.type = _, uses_modules: bool.type = _, xcode_private_headers_symlinks: [None, bool.type] = _, xcode_public_headers_symlinks: [None, bool.type] = _ ) -&gt; None  An apple_binary() rule builds a native executableâsuch as an iOS or OSX appâfrom the supplied set of Objective-C/C++ source files and dependencies. It is similar to a cxx\\_binary()rule with which it shares many attributes. In addition to those common attributes, apple_binary() has a some additional attributes that are specific to binaries intended to be built using the Apple toolchain. Note, however, that apple_binary() and cxx_binary() differ in the way that they import header files, in order to better accommodate existing conventions. See the sections for the headers and exported_headers attributes for more details. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecompiler_flags: Flags to use when compiling any of the above sources (which require compilation).entitlements_file: An optional name of a plist file to be embedded in the binary. Some platforms like iphonesimulator require this to run properly.exported_headers: The set of header files that are made available for inclusion to the source files in this target and all targets that transitively depend on this one. These should be specified as either a list of header files or a dictionary of header names to header files. The header names can contain forward slashes (/). If a list of header files is specified, the headers can be imported with #import &quot;$HEADER_PATH_PREFIX/$HEADER_NAME&quot; or, if a header file that belongs to the same rule is being imported, with #import &quot;$HEADER_NAME&quot;, where $HEADER_PATH_PREFIX is the value of the target's header_path_prefix attribute, and $HEADER_NAME is the filename of the header file. If a dictionary is specified, each header can be imported with #import &quot;$HEADER_NAME&quot;, where $HEADER_NAME is the key corresponding to this file. In this case, the header_path_prefix attribute is ignored. In either case, quotes in the import statements can be replaced with angle brackets.exported_linker_flags: Flags to add to the linker command line when the output from this rule, or the output from any rule that transitively depends on this rule, is used in a link operation.extra_xcode_files: When the project is generated, this is the list of files that will added to the project. Those files won't be added to the build phase &quot;Compile Sources&quot;.frameworks: A list of system frameworks that the code in this target uses. Each entry should be a path starting with $SDKROOT or $PLATFORM_DIR to denote that the rest of the path is relative to the root of the SDK used for the build or to the platform toolchain directory.header_path_prefix: A path prefix when including headers of this target. For example, headers from a library defined using  apple_library( name = &quot;Library&quot;, headers = glob([&quot;**/*.h&quot;]), header_path_prefix = &quot;Lib&quot;, )  can be imported using following mapping  Library/SubDir/Header1.h -&gt; Lib/Header1.h Library/Header2.h -&gt; Lib/Header2.h  Defaults to the short name of the target. Can contain forward slashes (/), but cannot start with one. See headers for more information. headers: The set of header files that are made available for inclusion to the source files in this target. These should be specified as either a list of header files or a dictionary of header names to header files. The header names can contain forward slashes (/). If a list of header files is specified, the headers can be imported with #import &quot;$HEADER_PATH_PREFIX/$HEADER_NAME&quot; or #import &quot;$HEADER_NAME&quot;, where $HEADER_PATH_PREFIX is the value of the target's header_path_prefix attribute, and $HEADER_NAME is the filename of the header file. If a dictionary is specified, each header can be imported with #import &quot;$HEADER_NAME&quot;, where $HEADER_NAME is the key corresponding to this file. In this case, the header_path_prefix attribute is ignored. In either case, quotes in the import statements can be replaced with angle brackets.link_execution_preference: The execution preference for linking. Options are: any : No preference is set, and the link action will be performed based on buck2's executor configuration. full_hybrid : The link action will execute both locally and remotely, regardless of buck2's executor configuration (if the executor is capable of hybrid execution). The use_limited_hybrid setting of the hybrid executor is ignored. local : The link action will execute locally if compatible on current host platform. local_only : The link action will execute locally, and error if the current platform is not compatible. remote : The link action will execute remotely if a compatible remote platform exists, otherwise locally. The default is None, expressing that no preference has been set on the target itself. link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be either static, static_pic or shared.linker_extra_outputs: Declares extra outputs that the linker emits. These identifiers can be used in $(output ...) macros in linker_flags to interpolate the output path into the linker command line. Useful for custom linkers that emit extra output files.linker_flags: Flags to add to the linker command line whenever the output from this rule is used in a link operation, such as linked into an executable or a shared library.platform_compiler_flags: Platform specific compiler flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when compiling the target's sources. See compiler_flags for more information.platform_linker_flags: Platform-specific linker flags. This argument is specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched. The regex should use java.util.regex.Pattern syntax. The second element in each pair is a list of linker flags. If the regex matches the platform, these flags are added to the linker command line when the output from this rule is used in a link operation.platform_srcs: Platform specific source files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of source files or a list of tuples of source files and a list of compilation flags to be preprocessed, compiled and assembled if the platform matches the regex. See srcs for more information.preprocessor_flags: Flags to use when preprocessing any of the above sources (which require preprocessing).srcs: The set of C, C++, Objective-C, Objective-C++, or assembly source files to be preprocessed, compiled, and assembled by this rule. We determine which stages to run on each input source based on its file extension. See the GCC documentation for more detail on how file extensions are interpreted. Each element can be either a string specifying a source file (e.g. '') or a tuple of a string specifying a source file and a list of compilation flags (e.g. ('', ['-Wall', '-Werror']) ). In the latter case the specified flags will be used in addition to the rule's other flags when preprocessing and compiling that file (if applicable).target_sdk_version: The minimum OS version that the library target should support, overriding the minimum set in .buckconfig. When set, Buck will automatically add flags to both Objective-C and Swift compilation that will allow the use of the new APIs without guarding code inside availability checks. Details​ Buck enables you to override components of the Apple toolchain with alternate tools, either from the Xcode search paths or from directories that you specify. See .buckconfigand .buckconfigfor more information. Examples:  apple_binary( name = 'MyBinary', deps = [ ':MyLibrary', '//Libraries:AnotherLibrary', ], preprocessor_flags = ['-fobjc-arc'], headers = [ 'MyHeader.h', ], srcs = [ 'MySource.m', ], frameworks = [ '$SDKROOT/System/Library/Frameworks/UIKit.framework', '$SDKROOT/System/Library/Frameworks/Foundation.framework', ], )   "},{"title":"apple_bundle​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#apple_bundle","content":"def apple_bundle( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _apple_toolchain: str.type = _, _apple_tools: str.type = _, _apple_xctoolchain: str.type = _, _apple_xctoolchain_bundle_id: str.type = _, _bundling_cache_buster: [None, str.type] = _, _bundling_log_file_enabled: bool.type = _, _codesign_entitlements: [None, str.type] = _, _codesign_type: [None, str.type] = _, _compile_resources_locally_override: [None, bool.type] = _, _dry_run_code_signing: bool.type = _, _fast_adhoc_signing_enabled: bool.type = _, _incremental_bundling_enabled: bool.type = _, _profile_bundling_enabled: bool.type = _, _provisioning_profiles: str.type = _, _resource_bundle: [None, str.type] = _, _use_entitlements_when_adhoc_code_signing: [None, bool.type] = _, asset_catalogs_compilation_options: {str.type: &quot;&quot;} = _, binary: [None, str.type] = _, codesign_flags: [str.type] = _, codesign_identity: [None, str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, deps: [str.type] = _, extension: str.type, ibtool_flags: [None, [str.type]] = _, ibtool_module_flag: [None, bool.type] = _, incremental_bundling_enabled: [None, bool.type] = _, info_plist: str.type, info_plist_substitutions: {str.type: str.type} = _, labels: [str.type] = _, licenses: [str.type] = _, platform_binary: [None, [(str.type, str.type)]] = _, product_name: [None, str.type] = _, resource_group: [None, str.type] = _, resource_group_map: [None, str.type] = _, selective_debugging: [None, str.type] = _, skip_copying_swift_stdlib: [None, bool.type] = _, try_skip_code_signing: [None, bool.type] = _, use_entitlements_when_adhoc_code_signing: bool.type = _, xcode_product_type: [None, str.type] = _ ) -&gt; None  An apple_bundle() rule takes an Apple binary and all of the resources and asset catalogs in the rule's transitive dependencies and generates a bundle containing all of those files. Optionally the generated bundle can also be signed using specified provisioning profiles. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneasset_catalogs_compilation_options: A dict holding parameters for asset catalogs compiler (actool). Its options include: notices (defaults to True) warnings (defaults to True) errors (defaults to True) compress_pngs (defaults to True) optimization (defaults to 'space') output_format (defaults to 'human-readable-text') * extra_flags (defaults to [])binary: A build target identifying an apple_binary() rule or an apple_library() rule whose output will be used as the main executable binary of the generated bundle. The required rule type depends on the value in the extension attribute. For example, application bundles expect a binary (e.g. '//Apps/MyApp:MyApp'), application extension bundles expect a shared library (e.g. '//Libraries/MyLibrary:MyLibrary#shared').deps: A list of dependencies of this bundle as build targets. You can embed application extensions by specifying the extension's bundle target. To include a WatchKit app, append the flavor #watch to the target specification. Buck will automatically substitute the appropriate platform flavor (either watchsimulator or watchos) based on the parent.extension: The extension of the generated bundle. For example 'app' for an application bundle or 'appex' for an application extension bundle.ibtool_flags: List of flags to be passed to ibtool during interface builder file compilation.info_plist: A path to an Info.plist file that will be placed in the bundle. The specified file will be processed by substituting variable names with their values (see info_plist_substitutions for more information).info_plist_substitutions: A dictionary that assigns variable names to their values. It is used for variable substitution when processing the file specified in info_plist. For example if this argument is set to {'VAR': 'MyValue'}, then each occurrence of $(VAR) or ${VAR} in the file will be replaced by MyValue.product_name: The name of the resulting bundle and binary. The setting behaves like PRODUCT_NAME Xcode build setting. For example, if your rule is named &quot;MyApp&quot; and extension is &quot;app&quot;, by default buck will generate MyApp.app bundle. But if you will set product name to &quot;SuperApp&quot;, bundle will get &quot;SuperApp.app&quot; name. Details​ Code signing will embed entitlements pointed to by the entitlements_file arg in the bundle's apple_binary. This is the preferred way to specify entitlements when building with Buck. If the entitlements file is not present, it falls back to the CODE_SIGN_ENTITLEMENTS entry ininfo_plist_substitutions. If after these checks, an entitlements file is still not specified, it will be derived based on the entitlements of the selected provisioning profile. Provisioning profiles will be selected from profiles pointed to by apple.provisioning_profile_search_path, based on a non-expired profile that matches the bundle id and entitlements. Code signing will embed entitlements pointed to by the CODE_SIGN_ENTITLEMENTS entry ininfo_plist_substitutions. If an entitlements file is omitted, it will be derived based on the entitlements of the selected provisioning profile. Provisioning profiles will be selected from profiles pointed to by apple.provisioning_profile_search_path, based on a non-expired profile that matches the bundle id and entitlements. Examples:  apple_bundle( name = 'AppBundle', binary = ':MyBinary', extension = 'app', info_plist = 'Info.plist', )   # iOS app with embedded WatchOS 2.0 app/extension apple_bundle( name = 'DemoWatchAppExtension', binary = ':DemoWatchAppExtensionBinary', extension = 'appex', info_plist = 'WatchExtension/Resources/Info.plist', ) apple_bundle( name = 'DemoWatchApp', binary = ':DemoWatchAppBinary', deps = [':DemoWatchAppResources', ':DemoWatchAppExtension'], extension = 'app', info_plist = 'WatchApplication/Info.plist', ) apple_bundle( name = 'DemoApp', binary = ':DemoAppBinary', deps = [':DemoWatchApp#watch'], extension = 'app', info_plist = 'Info.plist', )   # iOS app using safeAreaInsets delivering to iOS 9.x apple_bundle( name = 'DemoIBApp', binary = ':DemoIBAppBinary', deps = [':DemoIBAppResources'], extension = 'app', ibtool_flags = [&quot;--minimum-deployment-target&quot;, &quot;9.0&quot;], info_plist = 'Info.plist', )   "},{"title":"apple_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#apple_library","content":"def apple_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _apple_toolchain: str.type = _, _apple_tools: str.type = _, _apple_xctoolchain: str.type = _, _apple_xctoolchain_bundle_id: str.type = _, _archive_objects_locally_override: [None, bool.type] = _, _omnibus_environment: [None, str.type] = _, bridging_header: [None, str.type] = _, can_be_asset: [None, bool.type] = _, compiler_flags: [str.type] = _, configs: {str.type: {str.type: str.type}} = _, contacts: [str.type] = _, cxx_runtime_type: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, devirt_enabled: bool.type = _, diagnostics: {str.type: str.type} = _, enable_cxx_interop: bool.type = _, executable_name: [None, str.type] = _, exported_deps: [str.type] = _, exported_header_style: str.type = _, exported_headers: [[str.type], {str.type: str.type}] = _, exported_lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, exported_lang_preprocessor_flags: {str.type: [str.type]} = _, exported_linker_flags: [str.type] = _, exported_platform_deps: [(str.type, [str.type])] = _, exported_platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, exported_platform_linker_flags: [(str.type, [str.type])] = _, exported_platform_preprocessor_flags: [(str.type, [str.type])] = _, exported_post_linker_flags: [str.type] = _, exported_post_platform_linker_flags: [(str.type, [str.type])] = _, exported_preprocessor_flags: [str.type] = _, extra_xcode_files: [str.type] = _, extra_xcode_sources: [str.type] = _, fat_lto: bool.type = _, focused_list_target: [None, str.type] = _, force_static: [None, bool.type] = _, frameworks: [str.type] = _, header_namespace: [None, str.type] = _, header_path_prefix: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, info_plist: [None, str.type] = _, info_plist_substitutions: {str.type: str.type} = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, link_execution_preference: [None, str.type] = _, link_group: [None, str.type] = _, link_group_map: [None, str.type, [(str.type, [([None, str.type], str.type, [None, str.type, [str.type]], [None, str.type])], [None, {str.type: &quot;&quot;}])]] = _, link_ordering: [None, str.type] = _, link_style: [None, str.type] = _, link_whole: [None, bool.type] = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, modular: bool.type = _, module_name: [None, str.type] = _, module_requires_cxx: bool.type = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, preferred_linkage: str.type = _, prefix_header: [None, str.type] = _, preprocessor_flags: [str.type] = _, public_include_directories: [str.type] = _, public_system_include_directories: [str.type] = _, raw_headers: [str.type] = _, reexport_all_header_dependencies: [None, bool.type] = _, sdk_modules: [str.type] = _, serialize_debugging_options: bool.type = _, soname: [None, str.type] = _, srcs: [[str.type, (str.type, [str.type])]] = _, static_library_basename: [None, str.type] = _, stripped: bool.type = _, supported_platforms_regex: [None, str.type] = _, supports_header_symlink_subtarget: bool.type = _, supports_merged_linking: [None, bool.type] = _, supports_shlib_interfaces: bool.type = _, swift_compiler_flags: [str.type] = _, swift_version: [None, str.type] = _, target_sdk_version: [None, str.type] = _, thin_lto: bool.type = _, use_archive: [None, bool.type] = _, use_submodules: bool.type = _, uses_cxx_explicit_modules: bool.type = _, uses_explicit_modules: bool.type = _, uses_modules: bool.type = _, xcode_private_headers_symlinks: [None, bool.type] = _, xcode_public_headers_symlinks: [None, bool.type] = _ ) -&gt; None  An apple_library() rule represents a set of Objective-C/C++/Swift source files and is similar to a cxx_library() rule with which it shares many attributes. In addition to those common attributes, apple_library() has a some additional attributes that are specific to binaries intended to be built using the Apple toolchain. Note, however, that apple_library() and cxx_library() differ in the way that they import header files, in order to better accommodate existing conventions. See the sections for the headers and exported_headers attributes for more details. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecompiler_flags: Flags to use when compiling any of the above sources (which require compilation).exported_deps: Dependencies that will also appear to belong to any rules that depend on this one. This has two effects: Exported dependencies will also be included in the link line of dependents of this rules, but normal dependencies will not. When reexport_all_header_dependencies = False, only exported headers of the rules specified here are re-exported.exported_headers: The set of header files that are made available for inclusion to the source files in this target and all targets that transitively depend on this one. These should be specified as either a list of header files or a dictionary of header names to header files. The header names can contain forward slashes (/). If a list of header files is specified, the headers can be imported with #import &quot;$HEADER_PATH_PREFIX/$HEADER_NAME&quot; or, if a header file that belongs to the same rule is being imported, with #import &quot;$HEADER_NAME&quot;, where $HEADER_PATH_PREFIX is the value of the target's header_path_prefix attribute, and $HEADER_NAME is the filename of the header file. If a dictionary is specified, each header can be imported with #import &quot;$HEADER_NAME&quot;, where $HEADER_NAME is the key corresponding to this file. In this case, the header_path_prefix attribute is ignored. In either case, quotes in the import statements can be replaced with angle brackets.exported_linker_flags: Flags to add to the linker command line when the output from this rule, or the output from any rule that transitively depends on this rule, is used in a link operation.exported_platform_linker_flags: Platform-specific linker flags for this rule and for all rules that transitively depend on this rule. This argument is specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched. The regex should use java.util.regex.Pattern syntax. The second element in each pair is a list of linker flags. If the regex matches the platform, these flags are added to the linker command line when the output from this rule, or the output from any rule that transitively depends on this rule, is used in a link operation.extra_xcode_files: When the project is generated, this is the list of files that will added to the project. Those files won't be added to the build phase &quot;Compile Sources&quot;.frameworks: A list of system frameworks that the code in this target uses. Each entry should be a path starting with $SDKROOT or $PLATFORM_DIR to denote that the rest of the path is relative to the root of the SDK used for the build or to the platform toolchain directory.header_namespace: A path prefix when including headers of this target. Defaults to the path from the root of the repository to the directory where this target is defined. Can contain forward slashes (/), but cannot start with one. See headers for more information.header_path_prefix: A path prefix when including headers of this target. For example, headers from a library defined using  apple_library( name = &quot;Library&quot;, headers = glob([&quot;**/*.h&quot;]), header_path_prefix = &quot;Lib&quot;, )  can be imported using following mapping  Library/SubDir/Header1.h -&gt; Lib/Header1.h Library/Header2.h -&gt; Lib/Header2.h  Defaults to the short name of the target. Can contain forward slashes (/), but cannot start with one. See headers for more information. headers: The set of header files that are made available for inclusion to the source files in this target. These should be specified as either a list of header files or a dictionary of header names to header files. The header names can contain forward slashes (/). If a list of header files is specified, the headers can be imported with #import &quot;$HEADER_PATH_PREFIX/$HEADER_NAME&quot; or #import &quot;$HEADER_NAME&quot;, where $HEADER_PATH_PREFIX is the value of the target's header_path_prefix attribute, and $HEADER_NAME is the filename of the header file. If a dictionary is specified, each header can be imported with #import &quot;$HEADER_NAME&quot;, where $HEADER_NAME is the key corresponding to this file. In this case, the header_path_prefix attribute is ignored. In either case, quotes in the import statements can be replaced with angle brackets.link_execution_preference: The execution preference for linking. Options are: any : No preference is set, and the link action will be performed based on buck2's executor configuration. full_hybrid : The link action will execute both locally and remotely, regardless of buck2's executor configuration (if the executor is capable of hybrid execution). The use_limited_hybrid setting of the hybrid executor is ignored. local : The link action will execute locally if compatible on current host platform. local_only : The link action will execute locally, and error if the current platform is not compatible. remote : The link action will execute remotely if a compatible remote platform exists, otherwise locally. The default is None, expressing that no preference has been set on the target itself. link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be either static, static_pic or shared.linker_extra_outputs: Declares extra outputs that the linker emits. These identifiers can be used in $(output ...) macros in linker_flags to interpolate the output path into the linker command line. Useful for custom linkers that emit extra output files.linker_flags: Flags to add to the linker command line whenever the output from this rule is used in a link operation, such as linked into an executable or a shared library.platform_compiler_flags: Platform specific compiler flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when compiling the target's sources. See compiler_flags for more information.platform_srcs: Platform specific source files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of source files or a list of tuples of source files and a list of compilation flags to be preprocessed, compiled and assembled if the platform matches the regex. See srcs for more information.preprocessor_flags: Flags to use when preprocessing any of the above sources (which require preprocessing).reexport_all_header_dependencies: Whether to automatically re-export the exported headers of all dependencies. When this is set to false, only exported headers fromexported_deps are re-exported. srcs: The set of C, C++, Objective-C, Objective-C++, or assembly source files to be preprocessed, compiled, and assembled by this rule. We determine which stages to run on each input source based on its file extension. See the GCC documentation for more detail on how file extensions are interpreted. Each element can be either a string specifying a source file (e.g. '') or a tuple of a string specifying a source file and a list of compilation flags (e.g. ('', ['-Wall', '-Werror']) ). In the latter case the specified flags will be used in addition to the rule's other flags when preprocessing and compiling that file (if applicable).target_sdk_version: The minimum OS version that the library target should support, overriding the minimum set in .buckconfig. When set, Buck will automatically add flags to both Objective-C and Swift compilation that will allow the use of the new APIs without guarding code inside availability checks. Details​ Buck enables you to override components of the Apple toolchain with alternate tools, either from the Xcode search paths or from directories that you specify. See .buckconfigand .buckconfigfor more information. Examples:  apple_library( name = 'MyLibrary', deps = [ ':OtherLibrary', '//Libraries:YetAnotherLibrary', ], preprocessor_flags = ['-fobjc-arc'], headers = [ 'MyHeader.h', ], srcs = [ 'MySource.m', 'MySource.swift', ], frameworks = [ '$SDKROOT/System/Library/Frameworks/UIKit.framework', '$SDKROOT/System/Library/Frameworks/Foundation.framework', ], )   "},{"title":"apple_package​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#apple_package","content":"def apple_package( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _apple_toolchain: str.type = _, _ipa_compression_level: str.type, bundle: str.type, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, need_android_tools: bool.type = _ ) -&gt; None  An apple_package() rule takes the output of an apple_bundle() rule and compresses it in an IPA (iOS App Store Package) file. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one Details​ This rule can be customized using the config options .buckconfigand .buckconfig. Examples:  apple_package( name = 'AppPackage', bundle = ':AppBundle', )   "},{"title":"apple_resource​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#apple_resource","content":"def apple_resource( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, codesign_on_copy: bool.type = _, contacts: [str.type] = _, content_dirs: [str.type] = _, default_host_platform: [None, str.type] = _, destination: [None, str.type] = _, dirs: [str.type] = _, files: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, named_variants: {str.type: [str.type]} = _, resources_from_deps: [str.type] = _, variants: [str.type] = _ ) -&gt; None  An apple_resource() rule contains sets of resource directories, files and file variants that can be bundled in an application bundle. This rule does not have any output on its own and can be built only as a dependency (either direct or transitive) of an apple_bundle() rule. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedestination: Specifies the destination in the final application bundle where resource will be copied. Possible values: &quot;resources&quot;, &quot;frameworks&quot;, &quot;executables&quot;, &quot;plugins&quot;, &quot;xpcservices&quot;.named_variants: Mapping from a variant name to the list of resource file paths which should be placed in an application bundle. Those files will be placed in a directory with name equal to the corresponding key in this mapping. Keys should end with .lproj suffix. (e.g. Base.lproj, en.lproj).resources_from_deps: Set of build targets whose transitive apple_resources should be considered as part of the current resource when collecting resources for bundles. Usually, an apple_bundle collects all apple_resource rules transitively reachable through apple_library rules. This field allows for resources which are not reachable using the above traversal strategy to be considered for inclusion in the bundle. variants: Set of paths of resource file variants that should be placed in an application bundle. The files mentioned here should be placed in a directory named $VARIANT_NAME.lproj, where $VARIANT_NAME is the name of the variant (e.g. Base, en). This argument makes it possible to use different resource files based on the active locale. Details​ Examples:  apple_resource( name = 'Images', files = glob([ '*.png', ]), dirs = [ 'PrettyImages', ], )   "},{"title":"apple_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#apple_test","content":"def apple_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _apple_toolchain: str.type = _, _apple_tools: str.type = _, _apple_xctoolchain: str.type = _, _apple_xctoolchain_bundle_id: str.type = _, _bundling_cache_buster: [None, str.type] = _, _bundling_log_file_enabled: bool.type = _, _codesign_type: [None, str.type] = _, _compile_resources_locally_override: [None, bool.type] = _, _dry_run_code_signing: bool.type = _, _fast_adhoc_signing_enabled: bool.type = _, _incremental_bundling_enabled: bool.type = _, _inject_test_env: str.type = _, _ios_booted_simulator: str.type = _, _macos_idb_companion: str.type = _, _omnibus_environment: [None, str.type] = _, _profile_bundling_enabled: bool.type = _, _resource_bundle: [None, str.type] = _, _use_entitlements_when_adhoc_code_signing: [None, bool.type] = _, asset_catalogs_compilation_options: {str.type: &quot;&quot;} = _, binary: [None, str.type] = _, bridging_header: [None, str.type] = _, can_be_asset: [None, bool.type] = _, codesign_flags: [str.type] = _, codesign_identity: [None, str.type] = _, compiler_flags: [str.type] = _, configs: {str.type: {str.type: str.type}} = _, contacts: [str.type] = _, cxx_runtime_type: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, destination_specifier: {str.type: str.type} = _, devirt_enabled: bool.type = _, diagnostics: {str.type: str.type} = _, enable_cxx_interop: bool.type = _, entitlements_file: [None, str.type] = _, env: [None, {str.type: str.type}] = _, executable_name: [None, str.type] = _, exported_deps: [str.type] = _, exported_header_style: str.type = _, exported_headers: [[str.type], {str.type: str.type}] = _, exported_lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, exported_lang_preprocessor_flags: {str.type: [str.type]} = _, exported_linker_flags: [str.type] = _, exported_platform_deps: [(str.type, [str.type])] = _, exported_platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, exported_platform_linker_flags: [(str.type, [str.type])] = _, exported_platform_preprocessor_flags: [(str.type, [str.type])] = _, exported_post_linker_flags: [str.type] = _, exported_post_platform_linker_flags: [(str.type, [str.type])] = _, exported_preprocessor_flags: [str.type] = _, extension: str.type, extra_xcode_files: [str.type] = _, extra_xcode_sources: [str.type] = _, fat_lto: bool.type = _, focused_list_target: [None, str.type] = _, force_static: [None, bool.type] = _, frameworks: [str.type] = _, header_namespace: [None, str.type] = _, header_path_prefix: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, incremental_bundling_enabled: [None, bool.type] = _, info_plist: str.type, info_plist_substitutions: {str.type: str.type} = _, is_ui_test: bool.type = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, link_execution_preference: [None, str.type] = _, link_group: [None, str.type] = _, link_group_map: [None, [(str.type, [(str.type, str.type, [None, str.type])])]] = _, link_ordering: [None, str.type] = _, link_style: str.type = _, link_whole: [None, bool.type] = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, modular: bool.type = _, module_name: [None, str.type] = _, module_requires_cxx: bool.type = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, preferred_linkage: str.type = _, prefix_header: [None, str.type] = _, preprocessor_flags: [str.type] = _, public_include_directories: [str.type] = _, public_system_include_directories: [str.type] = _, raw_headers: [str.type] = _, reexport_all_header_dependencies: [None, bool.type] = _, resource_group: [None, str.type] = _, resource_group_map: [None, str.type] = _, run_test_separately: bool.type = _, runner: [None, str.type] = _, sdk_modules: [str.type] = _, serialize_debugging_options: bool.type = _, skip_copying_swift_stdlib: [None, bool.type] = _, snapshot_reference_images_path: [None, str.type] = _, soname: [None, str.type] = _, specs: [None, str.type] = _, srcs: [[str.type, (str.type, [str.type])]] = _, static_library_basename: [None, str.type] = _, stripped: bool.type = _, supported_platforms_regex: [None, str.type] = _, supports_merged_linking: [None, bool.type] = _, swift_compiler_flags: [str.type] = _, swift_version: [None, str.type] = _, target_sdk_version: [None, str.type] = _, test_host_app: [None, str.type] = _, test_rule_timeout_ms: [None, int.type] = _, thin_lto: bool.type = _, try_skip_code_signing: [None, bool.type] = _, ui_test_target_app: [None, str.type] = _, use_entitlements_when_adhoc_code_signing: bool.type = _, use_submodules: bool.type = _, uses_cxx_explicit_modules: bool.type = _, uses_explicit_modules: bool.type = _, uses_modules: bool.type = _, xcode_private_headers_symlinks: [None, bool.type] = _, xcode_product_type: [None, str.type] = _, xcode_public_headers_symlinks: [None, bool.type] = _ ) -&gt; None  An apple_test() rule contains Objective-C/C++ code which can be built and used to test code contained in other rules. The tests can be executed by running buck test. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecompiler_flags: Flags to use when compiling any of the above sources (which require compilation).extra_xcode_files: When the project is generated, this is the list of files that will added to the project. Those files won't be added to the build phase &quot;Compile Sources&quot;.frameworks: A list of system frameworks that the code in this target uses. Each entry should be a path starting with $SDKROOT or $PLATFORM_DIR to denote that the rest of the path is relative to the root of the SDK used for the build or to the platform toolchain directory.header_path_prefix: A path prefix when including headers of this target. For example, headers from a library defined using  apple_library( name = &quot;Library&quot;, headers = glob([&quot;**/*.h&quot;]), header_path_prefix = &quot;Lib&quot;, )  can be imported using following mapping  Library/SubDir/Header1.h -&gt; Lib/Header1.h Library/Header2.h -&gt; Lib/Header2.h  Defaults to the short name of the target. Can contain forward slashes (/), but cannot start with one. See headers for more information. headers: The set of header files that are made available for inclusion to the source files in this target. These should be specified as either a list of header files or a dictionary of header names to header files. The header names can contain forward slashes (/). If a list of header files is specified, the headers can be imported with #import &quot;$HEADER_PATH_PREFIX/$HEADER_NAME&quot; or #import &quot;$HEADER_NAME&quot;, where $HEADER_PATH_PREFIX is the value of the target's header_path_prefix attribute, and $HEADER_NAME is the filename of the header file. If a dictionary is specified, each header can be imported with #import &quot;$HEADER_NAME&quot;, where $HEADER_NAME is the key corresponding to this file. In this case, the header_path_prefix attribute is ignored. In either case, quotes in the import statements can be replaced with angle brackets.info_plist: A path to an Info.plist file that will be placed in the bundle. The specified file will be processed by substituting variable names with their values (see info_plist_substitutions for more information).info_plist_substitutions: A dictionary that assigns variable names to their values. It is used for variable substitution when processing the file specified in info_plist. For example if this argument is set to {'VAR': 'MyValue'}, then each occurrence of $(VAR) or ${VAR} in the file will be replaced by MyValue.labels: A list of labels to be applied to these tests. These labels are arbitrary text strings and have no meaning within buck itself. They can, however, have meaning for you as a test author (e.g., smoke or fast). A label can be used to filter or include a specific test rule when executing buck testlink_execution_preference: The execution preference for linking. Options are: any : No preference is set, and the link action will be performed based on buck2's executor configuration. full_hybrid : The link action will execute both locally and remotely, regardless of buck2's executor configuration (if the executor is capable of hybrid execution). The use_limited_hybrid setting of the hybrid executor is ignored. local : The link action will execute locally if compatible on current host platform. local_only : The link action will execute locally, and error if the current platform is not compatible. remote : The link action will execute remotely if a compatible remote platform exists, otherwise locally. The default is None, expressing that no preference has been set on the target itself. linker_flags: Flags to add to the linker command line whenever the output from this rule is used in a link operation, such as linked into an executable or a shared library.platform_compiler_flags: Platform specific compiler flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when compiling the target's sources. See compiler_flags for more information.platform_srcs: Platform specific source files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of source files or a list of tuples of source files and a list of compilation flags to be preprocessed, compiled and assembled if the platform matches the regex. See srcs for more information.preprocessor_flags: Flags to use when preprocessing any of the above sources (which require preprocessing).srcs: The set of C, C++, Objective-C, Objective-C++, or assembly source files to be preprocessed, compiled, and assembled by this rule. We determine which stages to run on each input source based on its file extension. See the GCC documentation for more detail on how file extensions are interpreted. Each element can be either a string specifying a source file (e.g. '') or a tuple of a string specifying a source file and a list of compilation flags (e.g. ('', ['-Wall', '-Werror']) ). In the latter case the specified flags will be used in addition to the rule's other flags when preprocessing and compiling that file (if applicable).target_sdk_version: The minimum OS version that the library target should support, overriding the minimum set in .buckconfig. When set, Buck will automatically add flags to both Objective-C and Swift compilation that will allow the use of the new APIs without guarding code inside availability checks.test_host_app: A build target identifying an apple_bundle() rule that builds an application bundle. Output of the specified rule will be used as a test host of this test. This implies run_test_separately. Since symbols that are defined in the test host application and its dependencies will not be linked into the test binary, to make those symbols accessible to the test target they need to be specified as a dependency of this target and ['-undefined', 'dynamic_lookup'] needs to be added to this target's linker_flags (this will suppress undefined reference errors during compilation, but if the symbols do not exist, it might result in runtime crashes). Details​ Examples:  apple_test( name = 'MyTest', info_plist = 'MyTest-Info.plist', preprocessor_flags = ['-fobjc-arc'], srcs = [ 'MyTest.m', ], deps = [ ':MyLibrary', ], frameworks = [ '$SDKROOT/System/Library/Frameworks/Foundation.framework', '$SDKROOT/System/Library/Frameworks/UIKit.framework', '$PLATFORM_DIR/Developer/Library/Frameworks/XCTest.framework', ], )   "},{"title":"apple_toolchain​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#apple_toolchain","content":"def apple_toolchain( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _internal_platform_path: [None, str.type] = _, _internal_sdk_path: [None, str.type] = _, actool: str.type, architecture: str.type = _, build_version: [None, str.type] = _, codesign: str.type, codesign_allocate: str.type, codesign_identities_command: [None, str.type] = _, compile_resources_locally: bool.type = _, contacts: [str.type] = _, copy_scene_kit_assets: str.type, cxx_toolchain: str.type, default_host_platform: [None, str.type] = _, developer_path: [None, str.type] = _, dsymutil: str.type, dwarfdump: [None, str.type] = _, extra_linker_outputs: [str.type] = _, ibtool: str.type, installer: str.type = _, labels: [str.type] = _, libtool: str.type, licenses: [str.type] = _, lipo: str.type, min_version: [None, str.type] = _, momc: str.type, odrcov: [None, str.type] = _, placeholder_tool: [None, str.type] = _, platform_path: [None, str.type] = _, requires_xcode_version_match: bool.type = _, sdk_environment: [None, str.type] = _, sdk_name: str.type = _, sdk_path: [None, str.type] = _, swift_toolchain: [None, str.type] = _, version: [None, str.type] = _, watch_kit_stub_binary: [None, str.type] = _, work_around_dsymutil_lto_stack_overflow_bug: [None, bool.type] = _, xcode_build_version: [None, str.type] = _, xcode_version: [None, str.type] = _, xctest: str.type ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"apple_toolchain_set​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#apple_toolchain_set","content":"def apple_toolchain_set( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, apple_toolchains: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"cgo_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#cgo_library","content":"def cgo_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _go_toolchain: str.type = _, cgo_compiler_flags: [str.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, cxx_runtime_type: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, deps_query: [None, str.type] = _, devirt_enabled: bool.type = _, embedcfg: [None, str.type] = _, executable_name: [None, str.type] = _, exported_deps: [str.type] = _, fat_lto: bool.type = _, focused_list_target: [None, str.type] = _, frameworks: [str.type] = _, go_assembler_flags: [str.type] = _, go_compiler_flags: [str.type] = _, go_srcs: [str.type] = _, header_namespace: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, link_deps_query_whole: bool.type = _, link_group: [None, str.type] = _, link_group_map: [None, [(str.type, [(str.type, str.type, [None, str.type])])]] = _, link_style: [None, str.type] = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, package_name: [None, str.type] = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, prefer_stripped_objects: bool.type = _, prefix_header: [None, str.type] = _, preprocessor_flags: [str.type] = _, raw_headers: [str.type] = _, srcs: [[str.type, (str.type, [str.type])]] = _, thin_lto: bool.type = _, version_universe: [None, str.type] = _, weak_framework_names: [str.type] = _ ) -&gt; None  A cgo_library() rule builds an object from the supplied set of Go/C source files and dependencies. The outputs are linked into go executable in the last step (compile). Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecgo_compiler_flags: The set of additional compiler flags to pass to go tool cgo.compiler_flags: Flags to use when compiling any of the above sources (which require compilation).go_assembler_flags: The set of additional assembler flags to pass to go tool asm.go_compiler_flags: The set of additional compiler flags to pass to go tool compile.go_srcs: The set of source files to be compiled by this rule. Go (.go) files are compiled with the Go compiler. In contrast to the srcs argument, these files cannot have import &quot;C&quot; declared.headers: The set of header files that are made available for inclusion to the source files in this target. These should be specified as either a list of header files or a dictionary of header names to header files. The header name can contain forward slashes (/). The headers can be included with #include &quot;$HEADER_NAMESPACE/$HEADER_NAME&quot; or #include &lt;$HEADER_NAMESPACE/$HEADER_NAME&gt; , where $HEADER_NAMESPACE is the value of the target's header_namespace attribute, and $HEADER_NAME is the header name if specified, and the filename of the header file otherwise. See header_namespace for more information.link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be either static, static_pic or shared.linker_extra_outputs: Declares extra outputs that the linker emits. These identifiers can be used in $(output ...) macros in linker_flags to interpolate the output path into the linker command line. Useful for custom linkers that emit extra output files.linker_flags: Flags to add to the linker command line whenever the output from this rule is used in a link operation, such as linked into an executable or a shared library.package_name: Sets the full name of the package being compiled. This defaults to the path from the buck root. (e.g. given a ./.buckconfig, a rule in ./a/b/BUCK defaults to package &quot;a/b&quot;)platform_compiler_flags: Platform specific compiler flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when compiling the target's sources. See compiler_flags for more information.platform_linker_flags: Platform-specific linker flags. This argument is specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched. The regex should use java.util.regex.Pattern syntax. The second element in each pair is a list of linker flags. If the regex matches the platform, these flags are added to the linker command line when the output from this rule is used in a link operation.platform_preprocessor_flags: Platform specific preprocessor flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when preprocessing the target's sources. See preprocessor_flags for more information.preprocessor_flags: Flags to use when preprocessing any of the above sources (which require preprocessing).raw_headers: The set of header files that can be used for inclusion to the source files in the target and all targets that transitively depend on it. Buck doesn't add raw headers to the search path of a compiler/preprocessor automatically. include_directories and public_include_directories are the recommended way to add raw headers to the search path (they will be added via -I). compiler_flags, preprocessor_flags and exported_preprocessor_flags can also be used to add such raw headers to the search path if inclusion via -isystem or -iquote is needed. raw_headers cannot be used together with headers or exported_headers in the same target.srcs: The set of source files to be compiled by this rule. .go files will be compiled with the CGO compiler. Each file needs to have import &quot;C&quot; declared. Details​ The 'go build' command would collect the cgo directives from the source files, however with buck the flags needs to be passed in the cgo_library manually This rule borrows from cxx\\_binary()since C/C++ sources are being compiled. Examples:  # A rule that builds a Go native executable with linked cgo library based on # C/C++ util library. go_binary( name = &quot;bin&quot;, srcs = [&quot;main.go&quot;], deps = [&quot;:lib&quot;] ) cgo_library( name = &quot;lib&quot;, srcs = [&quot;cgo_source.go&quot;], deps = [&quot;:util&quot;], ) cxx_library( name = &quot;util&quot;, srcs = [&quot;util.c&quot;], headers = [&quot;util.h&quot;], )   "},{"title":"command_alias​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#command_alias","content":"def command_alias( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _exec_os_type: str.type = _, _target_os_type: str.type = _, args: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, env: {str.type: str.type} = _, exe: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, platform_exe: {str.type: str.type} = _, resources: [str.type] = _ ) -&gt; None  The command_alias rule enables you to wrap build rules that create binaries and to pre-apply command-line arguments and environment variables. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneargs: A string of arguments that is passed to the executable specified by exe at startup. These arguments support a subset of Buck's string parameter macros . Only the $(location ...) and $(exe ...) macros are supported currently.env: A map of environment variables that will be passed to the executable represented by exe on startup. Environment variables support the same macros as arguments.exe: A build targetfor a rule that outputs an executable, such as an sh\\_binary().platform_exe: A mapping from platforms to build target. enables you to override exe per host platform. If present, exe will be used as a fallback on host platforms that are not specified in platform_exe. It is possible to omit exe when providing platform_exe. In that case, the build will fail if the command is invoked on a platform not specified in the mapping. Valid platforms are all values of the Platform enum : FREEBSDLINUXMACOSWINDOWS Details​ Example uses include running a command written in a scripting language with a specific interpreter, and transparently wrapping sub-commands of a binary. You can reference a command_alias target in the cmd parameter of a genrule()by using the exe macro:  $(exe //path/to:target)  Examples:  # Combining an interpreter and a script cxx_binary( name = &quot;node-js&quot;, srcs = [ # ... ], headers = [ # ... ], ) export_file( name = &quot;scripts&quot; ) command_alias( name = &quot;server&quot;, exe = &quot;:node-js&quot;, args = [ &quot;$(location :scripts)/start-server.js&quot;, ], )   # Exposing sub commands export_file( name = &quot;yarn&quot;, src = &quot;yarn.sh&quot;, ) command_alias( name = &quot;add&quot;, exe = &quot;:yarn&quot;, args = [&quot;add&quot;], ) command_alias( name = &quot;install&quot;, exe = &quot;:yarn&quot;, args = [&quot;install&quot;], ) command_alias( name = &quot;run&quot;, exe = &quot;:yarn&quot;, args = [&quot;run&quot;], )   # Platform specific commands export_file( name = &quot;node-windows&quot;, src = &quot;windows/node.exe&quot;, ) export_file( name = &quot;node-linux&quot;, src = &quot;linux/node&quot;, ) export_file( name = &quot;node-macos&quot;, src = &quot;macos/node&quot;, ) command_alias( name = &quot;node&quot;, platform_exe = { &quot;windows&quot;: &quot;:node-windows&quot;, &quot;linux&quot;: &quot;:node-linux&quot;, &quot;macos&quot;: &quot;:node-macos&quot;, }, )   "},{"title":"config_setting​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#config_setting","content":"def config_setting( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, constraint_values: [str.type] = _, values: {str.type: str.type} = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"configured_alias​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#configured_alias","content":"def configured_alias( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, actual: str.type, configured_actual: [None, (str.type, str.type)] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, fallback_actual: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, platform: [None, str.type] = _, propagate_flavors: bool.type = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"constraint_setting​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#constraint_setting","content":"def constraint_setting( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"constraint_value​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#constraint_value","content":"def constraint_value( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, constraint_setting: str.type ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"core_data_model​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#core_data_model","content":"def core_data_model( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, path: str.type ) -&gt; None  An core_data_model() rule contains models for Apple's Core Data framework. This rule does not have any output on its own and can be built only as a dependency (either direct or transitive) of an apple_bundle() rule in which case all core_data_model() rules that the bundle rule depends on are merged and placed into the final output bundle together. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one Details​ Examples:  core_data_model( name = 'MyCoreDataModel', path = 'MyCoreDataModel.xcdatamodeld', )   "},{"title":"csharp_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#csharp_library","content":"def csharp_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, dll_name: str.type = _, framework_ver: str.type, labels: [str.type] = _, licenses: [str.type] = _, resources: {str.type: str.type} = _, srcs: [str.type] = _ ) -&gt; None  A csharp_library() rule builds a .Net library from the supplied set of C# source files and dependencies by invoking csc. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecompiler_flags: The set of additional compiler flags to pass to the compiler.deps: The set of targets or system-provided assemblies to rely on. Any values that are targets must be either csharp_library or prebuilt_dotnet_library instances.dll_name: The output name of the dll. This allows you to specify the name of the dll exactly. When this is not set, the dll will be named after the short name of the target.framework_ver: The version of the .Net framework that this library targets. This is one of 'net35', 'net40', 'net45' and 'net46'.resources: Resources that should be embedded within the built DLL. The format is the name of the resource once mapped into the DLL as the key, and the value being the resource that should be merged. This allows non-unique keys to be identified quickly.srcs: The collection of source files to compile. Details​ Examples: For more examples, check out our integration tests.  csharp_library( name = 'simple', dll_name = 'Cake.dll', framework_ver = 'net46', srcs = [ 'Hello.cs', ], resources = { 'greeting.txt': '//some:target', }, deps=[ ':other', 'System.dll', ], ) prebuilt_dotnet_library( name = 'other', assembly = 'other-1.0.dll', )   "},{"title":"cxx_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#cxx_binary","content":"def cxx_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_hacks: str.type = _, _cxx_toolchain: str.type = _, auto_link_groups: bool.type = _, binary_linker_flags: [str.type] = _, bolt_flags: [str.type] = _, bolt_gdb_index: [None, str.type] = _, bolt_profile: [None, str.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, cxx_runtime_type: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, deps_query: [None, str.type] = _, devirt_enabled: bool.type = _, enable_distributed_thinlto: bool.type = _, executable_name: [None, str.type] = _, fat_lto: bool.type = _, focused_list_target: [None, str.type] = _, frameworks: [str.type] = _, header_namespace: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, link_deps_query_whole: bool.type = _, link_execution_preference: [None, str.type] = _, link_group: [None, str.type] = _, link_group_map: [None, str.type, [(str.type, [([None, str.type], str.type, [None, str.type, [str.type]], [None, str.type])], [None, {str.type: &quot;&quot;}])]] = _, link_group_min_binary_node_count: [None, int.type] = _, link_ordering: [None, str.type] = _, link_style: [None, str.type] = _, link_whole: bool.type = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, prefer_stripped_objects: bool.type = _, prefix_header: [None, str.type] = _, preprocessor_flags: [str.type] = _, raw_headers: [str.type] = _, resources: [[str.type], {str.type: str.type}] = _, srcs: [[str.type, (str.type, [str.type])]] = _, thin_lto: bool.type = _, version_universe: [None, str.type] = _, weak_framework_names: [str.type] = _ ) -&gt; None  A cxx_binary() rule builds a native executable from the supplied set of C/C++ source files and dependencies. If C/C++ library dependencies are listed, the generated native executable will request and link against their static archives (which are *not* built using PIC). Parameters​ name: name of the target default_target_platform: specifies the default target platform, used when no platforms are specified on the command line target_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configuration compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configuration exec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platform visibility: a list of visibility patterns restricting what targets can depend on this one within_view: a list of visibility patterns restricting what this target can depend on tests: a list of targets that provide tests for this one compiler_flags: Flags to use when compiling any of the above sources (which require compilation). deps_query: Status: experimental/unstable. The deps query takes a query string that accepts the following query functions, and appends the output of the query to the declared deps: attrfilter deps except intersect filter kind set union The macro $declared_deps may be used anywhere a target literal pattern is expected in order to refer to the explicit deps of this rule as they appear in the rule's definition. For example, if your build rule declares  android_library( name = 'lib', deps = ['//foo:foo'], deps_query = '$declared_deps', )  then the macro $declared_deps would be expanded to a literal set(//foo:foo). Some example queries:  &quot;filter({name_regex}, $declared_deps)&quot;.format(name_regex='//.*') &quot;attrfilter(annotation_processors, com.foo.Processor, $declared_deps)&quot; &quot;deps('//foo:foo', 1)&quot;  Note: any targets included in this query must also be present in deps. header_namespace: A path prefix when including headers of this target. Defaults to the path from the root of the repository to the directory where this target is defined. Can contain forward slashes (/), but cannot start with one. See headers for more information.headers: The set of header files that are made available for inclusion to the source files in this target. These should be specified as either a list of header files or a dictionary of header names to header files. The header name can contain forward slashes (/). The headers can be included with #include &quot;$HEADER_NAMESPACE/$HEADER_NAME&quot; or #include &lt;$HEADER_NAMESPACE/$HEADER_NAME&gt; , where $HEADER_NAMESPACE is the value of the target's header_namespace attribute, and $HEADER_NAME is the header name if specified, and the filename of the header file otherwise. See header_namespace for more information.include_directories: A list of include directories (with raw_headers) to be added to the compile command for compiling this target (via -I). An include directory is relative to the current package.link_execution_preference: The execution preference for linking. Options are: any : No preference is set, and the link action will be performed based on buck2's executor configuration. full_hybrid : The link action will execute both locally and remotely, regardless of buck2's executor configuration (if the executor is capable of hybrid execution). The use_limited_hybrid setting of the hybrid executor is ignored. local : The link action will execute locally if compatible on current host platform. local_only : The link action will execute locally, and error if the current platform is not compatible. remote : The link action will execute remotely if a compatible remote platform exists, otherwise locally. The default is None, expressing that no preference has been set on the target itself. link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be either static, static_pic or shared.linker_extra_outputs: Declares extra outputs that the linker emits. These identifiers can be used in $(output ...) macros in linker_flags to interpolate the output path into the linker command line. Useful for custom linkers that emit extra output files.linker_flags: Flags to add to the linker command line whenever the output from this rule is used in a link operation, such as linked into an executable or a shared library.platform_compiler_flags: Platform specific compiler flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when compiling the target's sources. See compiler_flags for more information.platform_headers: Platform specific header files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of header files or a dictionary of header names to header files that will be made available for inclusion to the source files in the target if the platform matches the regex. See headers for more information.platform_linker_flags: Platform-specific linker flags. This argument is specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched. The regex should use java.util.regex.Pattern syntax. The second element in each pair is a list of linker flags. If the regex matches the platform, these flags are added to the linker command line when the output from this rule is used in a link operation.platform_preprocessor_flags: Platform specific preprocessor flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when preprocessing the target's sources. See preprocessor_flags for more information.platform_srcs: Platform specific source files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of source files or a list of tuples of source files and a list of compilation flags to be preprocessed, compiled and assembled if the platform matches the regex. See srcs for more information.preprocessor_flags: Flags to use when preprocessing any of the above sources (which require preprocessing).raw_headers: The set of header files that can be used for inclusion to the source files in the target and all targets that transitively depend on it. Buck doesn't add raw headers to the search path of a compiler/preprocessor automatically. include_directories and public_include_directories are the recommended way to add raw headers to the search path (they will be added via -I). compiler_flags, preprocessor_flags and exported_preprocessor_flags can also be used to add such raw headers to the search path if inclusion via -isystem or -iquote is needed. raw_headers cannot be used together with headers or exported_headers in the same target.srcs: The set of C, C++, Objective-C, Objective-C++, or assembly source files to be preprocessed, compiled, and assembled by this rule. We determine which stages to run on each input source based on its file extension. See the GCC documentation for more detail on how file extensions are interpreted. Each element can be either a string specifying a source file (e.g. '') or a tuple of a string specifying a source file and a list of compilation flags (e.g. ('', ['-Wall', '-Werror']) ). In the latter case the specified flags will be used in addition to the rule's other flags when preprocessing and compiling that file (if applicable). Details​ Examples:  # A rule that builds a C/C++ native executable from a single .cpp file # its corresponding header, and a C/C++ library dependency. cxx_binary( name = 'echo', srcs = [ 'echo.cpp', ], headers = [ 'echo.h', ], deps = [ ':util', ], ) cxx_library( name = 'util', srcs = [ 'util.cpp', ], headers = [ 'util.h', ], ) # To build without stripping: buck build :echo # To build with stripping debug symbols only: buck build :echo#strip-debug   "},{"title":"cxx_genrule​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#cxx_genrule","content":"def cxx_genrule( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _exec_os_type: str.type = _, _genrule_toolchain: str.type = _, bash: [None, str.type] = _, cacheable: [None, bool.type] = _, cmd: [None, str.type] = _, cmd_exe: [None, str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, default_outs: [None, [str.type]] = _, enable_sandbox: [None, bool.type] = _, environment_expansion_separator: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, metadata_env_var: [None, str.type] = _, metadata_path: [None, str.type] = _, need_android_tools: bool.type = _, no_outputs_cleanup: bool.type = _, out: [None, str.type] = _, outs: [None, {str.type: [str.type]}] = _, remote: [None, bool.type] = _, srcs: [[str.type], {str.type: str.type}] = _, type: [None, str.type] = _ ) -&gt; None  A cxx_genrule() enables you to run shell commands as part of the Buck build process. A cxx_genrule() exposesâthrough a set of string parameter macros and variablesâinformation about the tools and configuration options used by the Buck environment, specifically those related to the C/C++ toolchain. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onebash: A platform-specific version of the shell command parameter cmd. It runs on Linux and UNIX systems—including OSX—on which bash is installed. It has a higher priority than cmd. The bash argument is run with /usr/bin/env bash -c. It has access to the same set of macros and variables as the cmd argument.cmd: The shell command to run to generate the output file. It is the fallback of bash and cmd_exe. The shell command can access information about the buck build environment through a set of macros, parameterized macros, and variables. Macros​ The following macros are available to the shell command and are accessed using the following syntax. $(&lt;macro&gt;)  Example: $(cc)  $(cc)Path to the C compiler. $(cxx)Path to the C++ compiler. $(cflags)Flags passed to the C compiler. $(cppflags)Flags passed to the C preprocessor. $(cxxflags)Flags passed to the C++ compiler. $(cxxppflags)Flags to pass to the C++ preprocessor. $(ld)Path to the linker. $(ldflags-pic)Flags passed to the linker for binaries that use position-independent code (PIC). $(ldflags-pic-filter &lt;pattern&gt;)Flags passed to the linker for binaries that use position-independent code (PIC). Use the pattern parameter to specify a regular expression that matches the build targets that use these flags. $(ldflags-shared)Flags passed to the linker for shared libraries, such as dynamic-link libraries (DLLs). $(ldflags-shared-filter &lt;pattern&gt;)Flags passed to the linker for shared libraries, such as dynamic-link libraries (DLLs). Use the pattern parameter to specify a regular expression that matches the build targets that use these flags. $(ldflags-static)Flags passed to the linker for statically-linked libraries. $(ldflags-static-filter &lt;pattern&gt;)Flags passed to the linker for statically-linked libraries. Use the pattern parameter to specify a regular expression that matches the build targets that use these flags. $(platform-name)The platform flavor with which this cxx_genrule was specified. Parameterized Macros​ It is also possible to expand references to other rules within the shell command, using the following subset of the builtin string parameter macros. Note that all build rules expanded in the command are automatically considered to be dependencies of the genrule(). Note that the paths returned by these macros are absolute paths. You should convert these paths to be relative paths before embedding them in, for example, a shell script or batch file. Using relative paths ensures that your builds are hermetic, that is, they are reproducible across different machine environments. Additionally, if you embed these paths in a shell script, you should execute that script using the sh\\_binary()rule and include the targets for these paths in the resources argument of that sh_binary rule. These are the same targets that you pass to the string parameter macros. $(exe //path/to:target)Expands to the commands necessary to run the executable generated by the specified build rule. For a C++ executable, this will typically just be the name of the output executable itself, such as main. If the specified build rule does not generate an executable output, an exception will be thrown and the build will fail. $(location //path/to:target)Expands to the path of the output of the build rule. This means that you can refer to these without needing to be aware of how Buck is storing data on the disk mid-build. Variables​ Finally, Buck adds the following variables to the environment in which the shell command runs. They are accessed using the following syntax. Note the use of braces rather than parentheses. ${&lt;variable&gt;}  Example: ${SRCS}  ${SRCS}A string expansion of the srcs argument delimited by the environment_expansion_separator argument where each element of srcs will be translated into an absolute path. ${SRCDIR}The absolute path to the to which sources are copied prior to running the command. ${OUT}The output file for the genrule(). The file specified by this variable must always be written by this command. If not, the execution of this rule will be considered a failure, halting the build process. ${TMP}A temporary directory which can be used for intermediate results and will not be bundled into the output. cmd_exe: A platform-specific version of the shell command parameter cmd. It runs on Windows and has a higher priority than cmd. The cmd_exe argument is run with cmd.exe /v:off /c. It has access to the same set of macros and variables as the cmd argument.enable_sandbox: Whether this target should be executed in a sandbox or not.environment_expansion_separator: The delimiter between paths in environment variables, such as SRCS, that can contain multiple paths. It can be useful to specify this parameter if the paths could contain spaces.out: The name of the output file or directory. The complete path to this argument is provided to the shell command through the OUT environment variable.srcs: Either a list or a map of the source files which Buck makes available to the shell command at the path in the SRCDIR environment variable. If you specify a list, the source files are the names in the list. If you specify a map, the source files are made available as the names in the keys of the map, where the values of the map are the original source file names.type: Specifies the type of this genrule. This is used for logging and is particularly useful for grouping genrules that share an underlying logical &quot;type&quot;. For example, if you have the following cxx_genrule defined in the root directory of your Buck project  cxx_genrule( name = 'cxx_gen', type = 'epilog', cmd = 'touch finish.txt; cp finish.txt $OUT', out = 'finish.txt' )  then the following buck query command  buck query &quot;attrfilter( type, 'epilog', '//...' )&quot;  returns  //:cxx_gen  Details​ The information exposed through these tools and configuration options is a reflection of: Buck's built-in settings, the settings in .buckconfigand .buckconfig.local, and the result of various command-line overrides specified through the common\\_parameterscommand-line option. This information is available only to the shell commands specified in the cxx_genrule. The information is not available to other arguments of the rule. A cxx_genrule() can be an input to another cxx_genrule(). Note that if you specify the cxx_genrule as a command-line target to buck build, you must include a platform flavor. For example:  buck build :cxx_gr_name#iphonesimulator-x86_64  You could also just specify the default platform flavor explicitly:  buck build :cxx_gr_name#default   "},{"title":"cxx_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#cxx_library","content":"def cxx_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_hacks: str.type = _, _cxx_toolchain: str.type = _, _is_building_android_binary: bool.type = _, _omnibus_environment: [None, str.type] = _, auto_link_groups: bool.type = _, bridging_header: [None, str.type] = _, can_be_asset: [None, bool.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, cxx_runtime_type: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, deps_query: [None, str.type] = _, devirt_enabled: bool.type = _, diagnostics: {str.type: str.type} = _, executable_name: [None, str.type] = _, exported_deps: [str.type] = _, exported_header_style: str.type = _, exported_headers: [[str.type], {str.type: str.type}] = _, exported_lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, exported_lang_preprocessor_flags: {str.type: [str.type]} = _, exported_linker_flags: [str.type] = _, exported_platform_deps: [(str.type, [str.type])] = _, exported_platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, exported_platform_linker_flags: [(str.type, [str.type])] = _, exported_platform_preprocessor_flags: [(str.type, [str.type])] = _, exported_post_linker_flags: [str.type] = _, exported_post_platform_linker_flags: [(str.type, [str.type])] = _, exported_preprocessor_flags: [str.type] = _, extra_xcode_files: [str.type] = _, extra_xcode_sources: [str.type] = _, fat_lto: bool.type = _, focused_list_target: [None, str.type] = _, force_emit_omnibus_shared_root: bool.type = _, force_static: [None, bool.type] = _, frameworks: [str.type] = _, header_mode: [None, str.type] = _, header_namespace: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, include_in_android_merge_map_output: bool.type = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, link_deps_query_whole: bool.type = _, link_execution_preference: [None, str.type] = _, link_group: [None, str.type] = _, link_group_map: [None, str.type, [(str.type, [([None, str.type], str.type, [None, str.type, [str.type]], [None, str.type])], [None, {str.type: &quot;&quot;}])]] = _, link_ordering: [None, str.type] = _, link_style: [None, str.type] = _, link_whole: [None, bool.type] = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, module_name: [None, str.type] = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, prefer_stripped_objects: bool.type = _, preferred_linkage: str.type = _, prefix_header: [None, str.type] = _, preprocessor_flags: [str.type] = _, public_include_directories: [str.type] = _, public_system_include_directories: [str.type] = _, raw_headers: [str.type] = _, reexport_all_header_dependencies: [None, bool.type] = _, resources: [[str.type], {str.type: str.type}] = _, sdk_modules: [str.type] = _, soname: [None, str.type] = _, srcs: [[str.type, (str.type, [str.type])]] = _, static_library_basename: [None, str.type] = _, supported_platforms_regex: [None, str.type] = _, supports_header_symlink_subtarget: bool.type = _, supports_merged_linking: [None, bool.type] = _, supports_python_dlopen: [None, bool.type] = _, supports_shlib_interfaces: bool.type = _, thin_lto: bool.type = _, use_archive: [None, bool.type] = _, used_by_wrap_script: bool.type = _, uses_cxx_explicit_modules: bool.type = _, uses_explicit_modules: bool.type = _, version_universe: [None, str.type] = _, weak_framework_names: [str.type] = _, xcode_private_headers_symlinks: [None, bool.type] = _, xcode_public_headers_symlinks: [None, bool.type] = _ ) -&gt; None  A cxx_library() rule specifies a set of C/C++ source files and also provides flags that specify how those files should be built. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecompiler_flags: Flags to use when compiling any of the above sources (which require compilation).exported_deps: Dependencies that will also appear to belong to any rules that depend on this one. This has two effects: Exported dependencies will also be included in the link line of dependents of this rules, but normal dependencies will not. When reexport_all_header_dependencies = False, only exported headers of the rules specified here are re-exported.exported_header_style: How dependents should include exported headers from this rule. Can be either local (e.g. -I) or system (e.g. -isystem).exported_headers: The set of header files that are made available for inclusion to the source files in the target and all targets that transitively depend on it. These should be specified as either a list of header files or a dictionary of header names to header files. The headers can be included with #include &quot;$HEADER_NAMESPACE/$HEADER_NAME&quot; or #include &lt;$HEADER_NAMESPACE/$HEADER_NAME&gt;, where $HEADER_NAMESPACE is the value of the target's header_namespace attribute, and $HEADER_NAME is the header name if specified, and the filename of the header file otherwise. Note that the header name can contain forward slashes (/). See header_namespace for more information.exported_lang_platform_preprocessor_flags: Just as lang_platform_preprocessor_flags, but these flags also apply to rules that transitively depend on this rule.exported_lang_preprocessor_flags: Just as lang_preprocessor_flags, but these flags also apply to rules that transitively depend on this rule.exported_linker_flags: Flags to add to the linker command line when the output from this rule, or the output from any rule that transitively depends on this rule, is used in a link operation.exported_platform_deps: Platform specific dependencies that will also appear to belong to any rules that depend on this one. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of external dependencies (same format as exported_deps) that are exported if the platform matches the regex. See exported_deps for more information.exported_platform_headers: Platform specific header files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of header files or a dictionary of header names to header files that will be made available for inclusion to the source files in the target and all targets that transitively depend on it if the platform matches the regex. See headers for more information.exported_platform_linker_flags: Platform-specific linker flags for this rule and for all rules that transitively depend on this rule. This argument is specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched. The regex should use java.util.regex.Pattern syntax. The second element in each pair is a list of linker flags. If the regex matches the platform, these flags are added to the linker command line when the output from this rule, or the output from any rule that transitively depends on this rule, is used in a link operation.exported_platform_preprocessor_flags: Platform specific exported preprocessor flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when preprocessing the source files in the target and all targets that transitively depend on it if the platform matches the regex. See exported_preprocessor_flags for more information.exported_post_linker_flags: Flags to add to the linker command line when the output from this rule, or the output from any rule that transitively depends on this rule, is used in a link operation—with the additional feature that these flags are guaranteed to be placed after the compiled object (.o) files on the linker command line.exported_post_platform_linker_flags: Platform-specific linker flags for this rule and for all rules that transitively depend on this rule—and that are guaranteed to be placed after the compiled object (.o) files on the linker command line. In other respects, the syntax and semantics of this argument are the same as for the exported_platform_linker_flags argument.extra_xcode_files: When the project is generated, this is the list of files that will added to the project. Those files won't be added to the build phase &quot;Compile Sources&quot;.header_namespace: A path prefix when including headers of this target. Defaults to the path from the root of the repository to the directory where this target is defined. Can contain forward slashes (/), but cannot start with one. See headers for more information.headers: The set of header files that are made available for inclusion to the source files in this target. These should be specified as either a list of header files or a dictionary of header names to header files. The header name can contain forward slashes (/). The headers can be included with #include &quot;$HEADER_NAMESPACE/$HEADER_NAME&quot; or #include &lt;$HEADER_NAMESPACE/$HEADER_NAME&gt; , where $HEADER_NAMESPACE is the value of the target's header_namespace attribute, and $HEADER_NAME is the header name if specified, and the filename of the header file otherwise. See header_namespace for more information.include_directories: A list of include directories (with raw_headers) to be added to the compile command for compiling this target (via -I). An include directory is relative to the current package.lang_compiler_flags: Language-specific compiler flags. These should be specified as a map of C-family language short names to lists of flags and is used to target flags to sources files for a specific language in the C-family (C, C++, assembler, etc.). The keys in the map can be: cpp-output for C c++-cpp-output for C++ objective-c-cpp-output for Objective-C objective-c++-cpp-output for Objective-C++ cuda-cpp-output for Cuda assembler for Assembly * asm for ASMlang_platform_compiler_flags: Language- and platform-specific compiler flags. These should be specified as a map of C-family language short names, as described in lang_compiler_flags, to lists of pairs, as described in platform_compiler_flags.lang_platform_preprocessor_flags: Language- and platform-specific preprocessor flags. These should be specified as a map of C-family language short names, as described in lang_preprocessor_flags, to lists of pairs, as described in platform_preprocessor_flags.lang_preprocessor_flags: Language-specific preprocessor flags. These should be specified as a map of C-family language short names to lists of flags and is used to target flags to sources files for a specific language in the C-family (C, C++, assembler, etc.). The keys in the map can be: c for C c++ for C++ objective-c for Objective-C objective-c++ for Objective-C++ cuda for Cuda assembler-with-cpp for Assembly * asm-with-cpp for ASMlink_execution_preference: The execution preference for linking. Options are: any : No preference is set, and the link action will be performed based on buck2's executor configuration. full_hybrid : The link action will execute both locally and remotely, regardless of buck2's executor configuration (if the executor is capable of hybrid execution). The use_limited_hybrid setting of the hybrid executor is ignored. local : The link action will execute locally if compatible on current host platform. local_only : The link action will execute locally, and error if the current platform is not compatible. remote : The link action will execute remotely if a compatible remote platform exists, otherwise locally. The default is None, expressing that no preference has been set on the target itself. link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be either static, static_pic or shared.linker_extra_outputs: Declares extra outputs that the linker emits. These identifiers can be used in $(output ...) macros in linker_flags to interpolate the output path into the linker command line. Useful for custom linkers that emit extra output files.linker_flags: Flags to add to the linker command line whenever the output from this rule is used in a link operation, such as linked into an executable or a shared library.platform_compiler_flags: Platform specific compiler flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when compiling the target's sources. See compiler_flags for more information.platform_headers: Platform specific header files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of header files or a dictionary of header names to header files that will be made available for inclusion to the source files in the target if the platform matches the regex. See headers for more information.platform_linker_flags: Platform-specific linker flags. This argument is specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched. The regex should use java.util.regex.Pattern syntax. The second element in each pair is a list of linker flags. If the regex matches the platform, these flags are added to the linker command line when the output from this rule is used in a link operation.platform_preprocessor_flags: Platform specific preprocessor flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when preprocessing the target's sources. See preprocessor_flags for more information.platform_srcs: Platform specific source files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of source files or a list of tuples of source files and a list of compilation flags to be preprocessed, compiled and assembled if the platform matches the regex. See srcs for more information.preprocessor_flags: Flags to use when preprocessing any of the above sources (which require preprocessing).public_include_directories: A list of include directories (with raw_headers) to be added to the compile command for compiling this target and every target that depends on it (via -I). An include directory is relative to the current package.public_system_include_directories: A list of include directories (with raw_headers) to be added to the compile command for compiling this target and every target that depends on it (via -isystem if the compiler supports it of via -I otherwise). An include directory is relative to the current package.raw_headers: The set of header files that can be used for inclusion to the source files in the target and all targets that transitively depend on it. Buck doesn't add raw headers to the search path of a compiler/preprocessor automatically. include_directories and public_include_directories are the recommended way to add raw headers to the search path (they will be added via -I). compiler_flags, preprocessor_flags and exported_preprocessor_flags can also be used to add such raw headers to the search path if inclusion via -isystem or -iquote is needed. raw_headers cannot be used together with headers or exported_headers in the same target.reexport_all_header_dependencies: Whether to automatically re-export the exported headers of all dependencies. When this is set to false, only exported headers fromexported_deps are re-exported. soname: Sets the soname (&quot;shared object name&quot;) of any shared library produced from this rule. The default value is based on the full rule name. The macro $(ext) will be replaced with a platform-appropriate extension. An argument can be provided, which is a library version. For example soname = 'libfoo.$(ext 2.3)' will be libfoo.2.3.dylib on Mac and libfoo.so.2.3 on Linux.srcs: The set of C, C++, Objective-C, Objective-C++, or assembly source files to be preprocessed, compiled, and assembled by this rule. We determine which stages to run on each input source based on its file extension. See the GCC documentation for more detail on how file extensions are interpreted. Each element can be either a string specifying a source file (e.g. '') or a tuple of a string specifying a source file and a list of compilation flags (e.g. ('', ['-Wall', '-Werror']) ). In the latter case the specified flags will be used in addition to the rule's other flags when preprocessing and compiling that file (if applicable).supported_platforms_regex: If present, an un-anchored regex (in java.util.regex.Pattern syntax) that matches all platforms that this library supports. It will not be built for other platforms.used_by_wrap_script: When using an exopackage Android, if this parameter is set to True, then the library is included in the primary APK even if native libraries would otherwise not be placed in it. This is intended for native libraries that are used by a wrap.sh script, which must be placed in the primary APK. Only one of can_be_asset and used_by_wrap_script can be set for a rule. Details​ Building requires a specified top-level target​ Whether a Buck command builds the cxx_library is determined by the inclusion of a top-level target, such as a cxx\\_binary()or android\\_binary(), that transitively depends on the cxx_library. The set of targets specified to the Buck command (buck build, buck run, etc) must include one of these top-level targets in order for Buck to build the cxx_library. Note that you could specify the top-level target implicitly using a build target patternor you could also specify the top-level target using an buckconfig#aliasdefined in .buckconfig. How Buck builds the library also depends on the specified top-level target. For example, a C/C++ binary (cxx_binary) would require a static non-PIC build of the library, whereas an Android APK (android_binary) would require a shared PIC-enabled build. (PIC stands for position-independent code.) Dependencies of the cxx_library also require a top-level target​ Similarly, in order for Buck to build a target that the cxx_library depends on, such as a cxx\\_genrule(), you must specify in the Buck command a top-level target that depends on the cxx_library. For example, you could specify to builda cxx_binary that depends on the cxx_library. If you specify as your build target the cxx_library itself, the build targets that the cxx_library depends on might not be built. Examples:  # A rule that includes a single .cpp file and its corresponding header and # also supplies an additional flag for compilation. cxx_library( name = 'fileutil', srcs = [ 'fileutil.cpp', ], exported_headers = [ 'fileutil.h', ], compiler_flags = [ '-fno-omit-frame-pointer', ], ) # A rule that defines explicit names for its headers cxx_library( name = 'mathutils', header_namespace = 'math', srcs = [ 'trig/src/cos.cpp', 'trig/src/tan.cpp', ], exported_headers = { # These are included as &lt;math/trig/cos.h&gt; and &lt;math/trig/tan.h&gt; 'trig/cos.h': 'trig/include/cos.h', 'trig/tan.h': 'trig/include/tan.h', }, compiler_flags = [ '-fno-omit-frame-pointer', ], ) # A rule that uses different headers and sources per platform cxx_library( name = 'vector', # Because of platform_headers, this file can include &quot;config.h&quot; # and get the architecture specific header srcs = ['vector.cpp'], platform_srcs = [ ('.*armv7$', 'armv7.S'), ('.*x86_64$', 'x86_64.S'), ], exported_headers = [ 'vector.h', ], platform_headers = [ ( '.*armv7$', { 'config.h': 'config-armv7.h', } ), ( '.*x86_64$', { 'config.h': 'config-x86_64.h', } ), ], )   "},{"title":"cxx_lua_extension​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#cxx_lua_extension","content":"def cxx_lua_extension( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, base_module: [None, str.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, cxx_runtime_type: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, executable_name: [None, str.type] = _, frameworks: [str.type] = _, header_namespace: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, prefix_header: [None, str.type] = _, preprocessor_flags: [str.type] = _, raw_headers: [str.type] = _, srcs: [[str.type, (str.type, [str.type])]] = _, version_universe: [None, str.type] = _ ) -&gt; None  A cxx_lua_extension() rule is a variant of a C/C++ library which is built as a Lua module. As such, it has a module name formed by the base_module parameter and the rule name and implicitly depends on Lua C library (configured via the .buckconfig parameter. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onebase_module: The package for which the given specified sources and resources should reside in their final location in the top-level binary. If unset, the project relative directory that houses the BUCK file is used.compiler_flags: Flags to use when compiling any of the above sources (which require compilation).header_namespace: A path prefix when including headers of this target. Defaults to the path from the root of the repository to the directory where this target is defined. Can contain forward slashes (/), but cannot start with one. See headers for more information.headers: The set of header files that are made available for inclusion to the source files in this target. These should be specified as either a list of header files or a dictionary of header names to header files. The header name can contain forward slashes (/). The headers can be included with #include &quot;$HEADER_NAMESPACE/$HEADER_NAME&quot; or #include &lt;$HEADER_NAMESPACE/$HEADER_NAME&gt; , where $HEADER_NAMESPACE is the value of the target's header_namespace attribute, and $HEADER_NAME is the header name if specified, and the filename of the header file otherwise. See header_namespace for more information.linker_flags: Flags to add to the linker command line whenever the output from this rule is used in a link operation, such as linked into an executable or a shared library.platform_compiler_flags: Platform specific compiler flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when compiling the target's sources. See compiler_flags for more information.platform_headers: Platform specific header files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of header files or a dictionary of header names to header files that will be made available for inclusion to the source files in the target if the platform matches the regex. See headers for more information.platform_linker_flags: Platform-specific linker flags. This argument is specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched. The regex should use java.util.regex.Pattern syntax. The second element in each pair is a list of linker flags. If the regex matches the platform, these flags are added to the linker command line when the output from this rule is used in a link operation.platform_preprocessor_flags: Platform specific preprocessor flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when preprocessing the target's sources. See preprocessor_flags for more information.platform_srcs: Platform specific source files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of source files or a list of tuples of source files and a list of compilation flags to be preprocessed, compiled and assembled if the platform matches the regex. See srcs for more information.preprocessor_flags: Flags to use when preprocessing any of the above sources (which require preprocessing).srcs: The set of C, C++, Objective-C, Objective-C++, or assembly source files to be preprocessed, compiled, and assembled by this rule. We determine which stages to run on each input source based on its file extension. See the GCC documentation for more detail on how file extensions are interpreted. Each element can be either a string specifying a source file (e.g. '') or a tuple of a string specifying a source file and a list of compilation flags (e.g. ('', ['-Wall', '-Werror']) ). In the latter case the specified flags will be used in addition to the rule's other flags when preprocessing and compiling that file (if applicable). Details​ Examples:  # A rule that builds a Lua extension from a single .cpp file. cxx_lua_extension( name = 'mymodule', base_module = 'foo.bar', srcs = [ 'mymodule.cpp', ], compiler_flags = [ '-fno-omit-frame-pointer', ], ) # A library rule which has a single source importing the above extension. lua_library( name = 'utils', srcs = [ 'utils.lua', ], deps = [ ':mymodule', ], )   -- The `utils.lua` source, wrapped by the `utils` rule above. -- Import the C/C++ extension build above. require &quot;foo.bar.mymodule&quot; ...   "},{"title":"cxx_precompiled_header​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#cxx_precompiled_header","content":"def cxx_precompiled_header( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, src: str.type, version_universe: [None, str.type] = _ ) -&gt; None  A cxx_precompiled_header rule specifies a single header file that can be precompiled and made available for use in other build rules such as a cxx\\_library()or a cxx\\_binary(). Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: Dependency rules which export headers used by the header specified in src.src: The path to the header file that should be precompiled. Only one header file can be specified. But of course this header could include any number of other headers. The included headers could belong to -- that is, be exported_headers from -- another rule, in which case, the rule would have to be added to deps as usual. Details​ This header file is precompiled by the preprocessor on behalf of the C, C++, Objective-C, or Objective-C++ rule using it, via its precompiled_header parameter. Afterwards the precompiled header is applied during the rule's own compilation (often with an appreciable reduction in build time, the main benefit of PCH). This PCH is built once per combination of build flags which might affect the PCH's compatibility. For example, a distinct pre-compilation of the header occurs per combination of flags related to optimization, debug, architecture, and so on, used by rules which employ PCH. The flags used during the build of the dependent rule (that is, the &quot;PCH-using rule&quot;) are in effect while building the PCH itself. Similarly, to the same end, the include paths used when building the PCH are applied to the dependent rule. For example, deps in the PCH rule are propagated back to the dependent rule, and the PCH's header search paths (e.g. -I or -isystem options) are prefixed onto the list of include paths for the dependent rule. Examples: The best way to see how the cxx_precompiled_header() rule works is with an example. Let there be a header called common.h which has the following:  #pragma once /* Include common C++ files. */ #include &lt;string&gt; #include &lt;map&gt; #include &lt;set&gt; #include &lt;type_traits&gt; #include &lt;vector&gt; /* Some frequently-used headers from the Folly project. */ #include &lt;folly/Conv.h&gt; #include &lt;folly/Executor.h&gt; #include &lt;folly/io/async/EventBase.h&gt;   cxx_precompiled_header( name = 'common_pch', src = 'common.h', deps = [ # Needed for standard C++ headers: '//external/libcxx:headers', # Needed for the Folly includes: '//folly:folly', '//folly/io/async:async', ], ) cxx_binary( name = 'main', srcs = ['main.cpp'], precompiled_header = ':common_pch', deps = [ ... ], compiler_flags = ['-g', '-O2', '-fPIC'], )  The cxx_precompiled_header rule declares a precompiled header &quot;template&quot; containing the header file path, and dependencies. In this example we indicate that common.h is to be precompiled when used by another build rule. Note that, by itself, this cxx_precompiled_header rule will not result in anything being built. The usage of this rule from another rule -- an &quot;instantiation&quot; of this precompiled header template -- is what will trigger the PCH build. In the example above, the build for the binary named &quot;main&quot; will depend on the header being precompiled in a separate step, prior to compiling main.cpp, and the resulting PCH will be used in main's compilation. The dependencies specified in this precompiled header rule's deps are transitive; they will propagate to rules using this PCH, so that during link time, any libraries which are required by the code made available in the header will be included in the final binary build. The precompiled header dynamically created from the &quot;template&quot; will be built with flags which would be used in the dependent rule. In this case, main's use of specific compiler flags -g -O2 -fPIC will result in the production of a precompiled header with the same flags. This is so the precompiled code fully jives with rules using the PCH, i.e. they will have the same debug, optimization, CPU, etc. options. (The compiler is usually smart enough to reject a bad PCH, fortunately. But we want to ensure we take the appropriate steps to ensure we always have a PCH which works with any build that uses it.) Another effect of a rule using a precompiled header is that the rule's list of build flags will change; not just to employ PCH with e.g. -include-pch (if using Clang), but also, to alter the sequence of header search paths. The rule using the precompiled header will &quot;inherit&quot; the lists of paths used during the PCH build, applying them first in its own search paths. This is to ensure that an #include directive will resolve in exactly the same way in this build as it would have in the PCH, to ensure full compatibility between the PCH and other rule's builds. For example, if the PCH were to use one version of stdcxx and another rule use a different version, the version differences won't clash, thereby avoiding different versions of the &lt;cstring&gt; header used between the precompiled header and the dependent rule, and preventing confused structure definitions, ABI incompatibility, and so on (catastrophe, in other words).  "},{"title":"cxx_python_extension​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#cxx_python_extension","content":"def cxx_python_extension( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_hacks: str.type = _, _cxx_toolchain: str.type = _, _omnibus_environment: [None, str.type] = _, _python_toolchain: str.type = _, _target_os_type: str.type = _, allow_embedding: bool.type = _, allow_suffixing: bool.type = _, auto_link_groups: bool.type = _, base_module: [None, str.type] = _, bridging_header: [None, str.type] = _, can_be_asset: [None, bool.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, cxx_runtime_type: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, devirt_enabled: bool.type = _, diagnostics: {str.type: str.type} = _, executable_name: [None, str.type] = _, exported_deps: [str.type] = _, exported_header_style: str.type = _, exported_headers: [[str.type], {str.type: str.type}] = _, exported_lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, exported_lang_preprocessor_flags: {str.type: [str.type]} = _, exported_linker_flags: [str.type] = _, exported_platform_deps: [(str.type, [str.type])] = _, exported_platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, exported_platform_linker_flags: [(str.type, [str.type])] = _, exported_platform_preprocessor_flags: [(str.type, [str.type])] = _, exported_post_linker_flags: [str.type] = _, exported_post_platform_linker_flags: [(str.type, [str.type])] = _, exported_preprocessor_flags: [str.type] = _, extra_xcode_files: [str.type] = _, extra_xcode_sources: [str.type] = _, fat_lto: bool.type = _, focused_list_target: [None, str.type] = _, force_static: [None, bool.type] = _, frameworks: [str.type] = _, header_namespace: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, include_in_android_merge_map_output: bool.type = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, link_group: [None, str.type] = _, link_group_map: [None, [(str.type, [(str.type, str.type, [None, str.type])])]] = _, link_ordering: [None, str.type] = _, link_style: [None, str.type] = _, link_whole: bool.type = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, module_name: [None, str.type] = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, preferred_linkage: str.type = _, prefix_header: [None, str.type] = _, preprocessor_flags: [str.type] = _, public_include_directories: [str.type] = _, public_system_include_directories: [str.type] = _, raw_headers: [str.type] = _, reexport_all_header_dependencies: [None, bool.type] = _, resources: [[str.type], {str.type: str.type}] = _, sdk_modules: [str.type] = _, soname: [None, str.type] = _, srcs: [[str.type, (str.type, [str.type])]] = _, static_library_basename: [None, str.type] = _, suffix_all: bool.type = _, support_shlib_interfaces: bool.type = _, supported_platforms_regex: [None, str.type] = _, supports_merged_linking: [None, bool.type] = _, thin_lto: bool.type = _, type_stub: [None, str.type] = _, use_archive: [None, bool.type] = _, used_by_wrap_script: bool.type = _, uses_cxx_explicit_modules: bool.type = _, uses_explicit_modules: bool.type = _, version_universe: [None, str.type] = _, weak_framework_names: [str.type] = _, xcode_private_headers_symlinks: [None, bool.type] = _, xcode_public_headers_symlinks: [None, bool.type] = _ ) -&gt; None  A cxx_python_extension() rule is a variant of a C/C++ library which is built as a Python module. As such, it has a module name formed by the base_module parameter and the rule name. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onebase_module: The package in which the specified source files and resources should reside in their final location in the top-level binary. If unset, Buck uses the project-relative directory that contains the BUCK file.compiler_flags: Flags to use when compiling any of the above sources (which require compilation).deps: Other rules that list srcs from which this rule imports.header_namespace: A path prefix when including headers of this target. Defaults to the path from the root of the repository to the directory where this target is defined. Can contain forward slashes (/), but cannot start with one. See headers for more information.headers: The set of header files that are made available for inclusion to the source files in this target. These should be specified as either a list of header files or a dictionary of header names to header files. The header name can contain forward slashes (/). The headers can be included with #include &quot;$HEADER_NAMESPACE/$HEADER_NAME&quot; or #include &lt;$HEADER_NAMESPACE/$HEADER_NAME&gt; , where $HEADER_NAMESPACE is the value of the target's header_namespace attribute, and $HEADER_NAME is the header name if specified, and the filename of the header file otherwise. See header_namespace for more information.labels: Set of arbitrary strings which allow you to annotate a build rulewith tags that can be searched for over an entire dependency tree using buck query() .link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be either static, static_pic or shared. Note: since shared libraries re-export its dependencies, depending on multiple shared libraries which themselves have overlapping static dependencies may cause problems if they init using global state.linker_extra_outputs: Declares extra outputs that the linker emits. These identifiers can be used in $(output ...) macros in linker_flags to interpolate the output path into the linker command line. Useful for custom linkers that emit extra output files.linker_flags: Flags to add to the linker command line whenever the output from this rule is used in a link operation, such as linked into an executable or a shared library.platform_compiler_flags: Platform specific compiler flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when compiling the target's sources. See compiler_flags for more information.platform_headers: Platform specific header files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of header files or a dictionary of header names to header files that will be made available for inclusion to the source files in the target if the platform matches the regex. See headers for more information.platform_linker_flags: Platform-specific linker flags. This argument is specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched. The regex should use java.util.regex.Pattern syntax. The second element in each pair is a list of linker flags. If the regex matches the platform, these flags are added to the linker command line when the output from this rule is used in a link operation.platform_preprocessor_flags: Platform specific preprocessor flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when preprocessing the target's sources. See preprocessor_flags for more information.platform_srcs: Platform specific source files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of source files or a list of tuples of source files and a list of compilation flags to be preprocessed, compiled and assembled if the platform matches the regex. See srcs for more information.preprocessor_flags: Flags to use when preprocessing any of the above sources (which require preprocessing).srcs: The set of C, C++, Objective-C, Objective-C++, or assembly source files to be preprocessed, compiled, and assembled by this rule. We determine which stages to run on each input source based on its file extension. See the GCC documentation for more detail on how file extensions are interpreted. Each element can be either a string specifying a source file (e.g. '') or a tuple of a string specifying a source file and a list of compilation flags (e.g. ('', ['-Wall', '-Werror']) ). In the latter case the specified flags will be used in addition to the rule's other flags when preprocessing and compiling that file (if applicable). Details​ Examples:  # A rule that builds a Python extension from a single .cpp file. cxx_python_extension( name = 'mymodule', base_module = 'foo.bar', srcs = [ 'mymodule.cpp', ], ) # A library rule which has a single source importing the above extension. python_library( name = 'utils', srcs = [ 'utils.py', ], deps = [ ':mymodule', ], )   ## The `utils.py` source, wrapped by the `utils` rule above. ## Import the C/C++ extension build above. from foo.bar import mymodule ...   "},{"title":"cxx_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#cxx_test","content":"def cxx_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_hacks: str.type = _, _cxx_toolchain: str.type = _, _inject_test_env: str.type = _, additional_coverage_targets: [str.type] = _, args: [str.type] = _, auto_link_groups: bool.type = _, binary_linker_flags: [str.type] = _, bolt_flags: [str.type] = _, bolt_gdb_index: [None, str.type] = _, bolt_profile: [None, str.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, cxx_runtime_type: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, deps_query: [None, str.type] = _, devirt_enabled: bool.type = _, enable_distributed_thinlto: bool.type = _, env: {str.type: str.type} = _, executable_name: [None, str.type] = _, fat_lto: bool.type = _, focused_list_target: [None, str.type] = _, framework: [None, str.type] = _, frameworks: [str.type] = _, header_namespace: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, link_deps_query_whole: bool.type = _, link_execution_preference: [None, str.type] = _, link_group: [None, str.type] = _, link_group_map: [None, str.type, [(str.type, [([None, str.type], str.type, [None, str.type, [str.type]], [None, str.type])], [None, {str.type: &quot;&quot;}])]] = _, link_group_min_binary_node_count: [None, int.type] = _, link_ordering: [None, str.type] = _, link_style: [None, str.type] = _, link_whole: bool.type = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, prefer_stripped_objects: bool.type = _, prefix_header: [None, str.type] = _, preprocessor_flags: [str.type] = _, raw_headers: [str.type] = _, remote_execution: [None, {str.type: [None, bool.type, str.type, {str.type: str.type}]}] = _, resources: [[str.type], {str.type: str.type}] = _, run_test_separately: [None, bool.type] = _, srcs: [[str.type, (str.type, [str.type])]] = _, test_rule_timeout_ms: [None, int.type] = _, thin_lto: bool.type = _, use_default_test_main: [None, bool.type] = _, version_universe: [None, str.type] = _, weak_framework_names: [str.type] = _ ) -&gt; None  A cxx_test() rule builds a C/C++ binary against a C/C++ testing framework and runs it as part of test. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneargs: A list of additional arguments to pass to the test when it's run. It is also possible to expand references to other rules within these arguments, using builtin string parameter macros: $(location //path/to:target)Expands to the location of the output of the build rule. This means that you can refer to these without needing to be aware of how Buck is storing data on the disk mid-build. compiler_flags: Flags to use when compiling any of the above sources (which require compilation). deps_query: Status: experimental/unstable. The deps query takes a query string that accepts the following query functions, and appends the output of the query to the declared deps: attrfilter deps except intersect filter kind set union The macro $declared_deps may be used anywhere a target literal pattern is expected in order to refer to the explicit deps of this rule as they appear in the rule's definition. For example, if your build rule declares  android_library( name = 'lib', deps = ['//foo:foo'], deps_query = '$declared_deps', )  then the macro $declared_deps would be expanded to a literal set(//foo:foo). Some example queries:  &quot;filter({name_regex}, $declared_deps)&quot;.format(name_regex='//.*') &quot;attrfilter(annotation_processors, com.foo.Processor, $declared_deps)&quot; &quot;deps('//foo:foo', 1)&quot;  Note: any targets included in this query must also be present in deps. env: A map of environment names and values to set when running the test. It is also possible to expand references to other rules within the values of these environment variables, using builtin string parameter macros: $(location //path/to:target)Expands to the location of the output of the build rule. This means that you can refer to these without needing to be aware of how Buck is storing data on the disk mid-build. framework: Unused.headers: The set of header files that are made available for inclusion to the source files in this target. These should be specified as either a list of header files or a dictionary of header names to header files. The header name can contain forward slashes (/). The headers can be included with #include &quot;$HEADER_NAMESPACE/$HEADER_NAME&quot; or #include &lt;$HEADER_NAMESPACE/$HEADER_NAME&gt; , where $HEADER_NAMESPACE is the value of the target's header_namespace attribute, and $HEADER_NAME is the header name if specified, and the filename of the header file otherwise. See header_namespace for more information.include_directories: A list of include directories (with raw_headers) to be added to the compile command for compiling this target (via -I). An include directory is relative to the current package.link_execution_preference: The execution preference for linking. Options are: any : No preference is set, and the link action will be performed based on buck2's executor configuration. full_hybrid : The link action will execute both locally and remotely, regardless of buck2's executor configuration (if the executor is capable of hybrid execution). The use_limited_hybrid setting of the hybrid executor is ignored. local : The link action will execute locally if compatible on current host platform. local_only : The link action will execute locally, and error if the current platform is not compatible. remote : The link action will execute remotely if a compatible remote platform exists, otherwise locally. The default is None, expressing that no preference has been set on the target itself. linker_flags: Flags to add to the linker command line whenever the output from this rule is used in a link operation, such as linked into an executable or a shared library.preprocessor_flags: Flags to use when preprocessing any of the above sources (which require preprocessing).raw_headers: The set of header files that can be used for inclusion to the source files in the target and all targets that transitively depend on it. Buck doesn't add raw headers to the search path of a compiler/preprocessor automatically. include_directories and public_include_directories are the recommended way to add raw headers to the search path (they will be added via -I). compiler_flags, preprocessor_flags and exported_preprocessor_flags can also be used to add such raw headers to the search path if inclusion via -isystem or -iquote is needed. raw_headers cannot be used together with headers or exported_headers in the same target.srcs: The set of C, C++, Objective-C, Objective-C++, or assembly source files to be preprocessed, compiled, and assembled by this rule. We determine which stages to run on each input source based on its file extension. See the GCC documentation for more detail on how file extensions are interpreted. Each element can be either a string specifying a source file (e.g. '') or a tuple of a string specifying a source file and a list of compilation flags (e.g. ('', ['-Wall', '-Werror']) ). In the latter case the specified flags will be used in addition to the rule's other flags when preprocessing and compiling that file (if applicable).test_rule_timeout_ms: If set specifies the maximum amount of time (in milliseconds) in which all of the tests in this rule should complete. This overrides the default rule_timeout if any has been specified in .buckconfig . Details​ Examples:  # A rule that builds and runs C/C++ test using gtest. cxx_test( name = 'echo_test', srcs = [ 'echo_test.cpp', ], )   "},{"title":"cxx_toolchain​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#cxx_toolchain","content":"def cxx_toolchain( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _dep_files_processor: str.type = _, _dist_lto_tools: str.type = _, _mk_comp_db: str.type = _, _mk_hmap: str.type = _, _msvc_hermetic_exec: str.type = _, archive_contents: str.type = _, archiver: str.type, archiver_flags: [str.type] = _, archiver_supports_argfiles: bool.type = _, archiver_type: str.type, asm_compiler: [None, str.type] = _, asm_compiler_flags: [str.type] = _, asm_compiler_type: [None, str.type] = _, asm_preprocessor: [None, str.type] = _, asm_preprocessor_flags: [str.type] = _, asm_preprocessor_type: [None, str.type] = _, assembler: str.type, assembler_flags: [str.type] = _, assembler_preprocessor: [None, str.type] = _, assembler_preprocessor_flags: [str.type] = _, assembler_preprocessor_type: [None, str.type] = _, assembler_type: [None, str.type] = _, binary_extension: [None, str.type] = _, bolt_enabled: bool.type = _, c_compiler: str.type, c_compiler_flags: [str.type] = _, c_compiler_type: [None, str.type] = _, c_preprocessor_flags: [str.type] = _, cache_links: bool.type = _, clang_trace: [None, bool.type] = _, compiler_type: [None, str.type] = _, conflicting_header_basename_exemptions: [str.type] = _, contacts: [str.type] = _, cpp_dep_tracking_mode: str.type = _, cuda_compiler: [None, str.type] = _, cuda_compiler_flags: [str.type] = _, cuda_compiler_type: [None, str.type] = _, cuda_dep_tracking_mode: str.type = _, cuda_preprocessor_flags: [str.type] = _, cxx_compiler: str.type, cxx_compiler_flags: [str.type] = _, cxx_compiler_type: [None, str.type] = _, cxx_preprocessor_flags: [str.type] = _, debug_path_prefix_map_sanitizer_format: [None, str.type] = _, default_host_platform: [None, str.type] = _, detailed_untracked_header_messages: bool.type = _, filepath_length_limited: bool.type = _, generate_linker_maps: bool.type = _, headers_as_raw_headers_mode: [None, str.type] = _, headers_whitelist: [str.type] = _, hip_compiler: [None, str.type] = _, hip_compiler_flags: [str.type] = _, hip_compiler_type: [None, str.type] = _, hip_preprocessor_flags: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, link_ordering: str.type = _, link_path_normalization_args_enabled: bool.type = _, linker: str.type, linker_flags: [str.type] = _, linker_type: str.type, llvm_link: [None, str.type] = _, lto_mode: str.type = _, nm: str.type, objcopy_for_shared_library_interface: str.type, objcopy_recalculates_layout: bool.type = _, object_file_extension: str.type = _, object_format: str.type = _, pic_behavior: str.type = _, pic_type_for_shared_linking: str.type = _, placeholder_tool: [None, str.type] = _, platform_name: [None, str.type] = _, private_headers_symlinks_enabled: bool.type = _, public_headers_symlinks_enabled: bool.type = _, ranlib: [None, str.type] = _, ranlib_flags: [str.type] = _, requires_archives: bool.type = _, requires_objects: bool.type = _, shared_dep_runtime_ld_flags: [str.type] = _, shared_library_extension: str.type = _, shared_library_interface_flags: [str.type] = _, shared_library_interface_type: str.type, shared_library_versioned_extension_format: str.type = _, split_debug_mode: str.type = _, static_dep_runtime_ld_flags: [str.type] = _, static_library_extension: str.type = _, static_pic_dep_runtime_ld_flags: [str.type] = _, strip: str.type, strip_all_flags: [None, [str.type]] = _, strip_debug_flags: [None, [str.type]] = _, strip_non_global_flags: [None, [str.type]] = _, supports_distributed_thinlto: bool.type = _, use_archiver_flags: bool.type = _, use_arg_file: bool.type = _, use_dep_files: [None, bool.type] = _, use_header_map: bool.type = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"d_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#d_binary","content":"def d_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, linker_flags: [str.type] = _, srcs: [[str.type], {str.type: str.type}] = _ ) -&gt; None  A d_binary() rule builds a native executable from the supplied set of D source files and dependencies. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: The set of dependencies of this rule. Each element should be a string specifying a d_library rule defined elsewhere (e.g. ':foo' or '//foo:bar').linker_flags: The list of flags to be passed to the linker. Each element should be a string specifying a linker flag (e.g. '--as-needed').srcs: The set of D source files to be compiled by this rule. Each element should be a string specifying a source file (e.g. 'foo/bar.d'). Details​ Examples:  # A rule that builds a D native executable from a single .d file # and a library dependency. d_binary( name='greet', srcs=[ 'greet.d', ], deps=[ ':greeting', ], ) d_library( name='greeting', srcs=[ 'greeting.d', ], deps=[ ':join', ], ) d_library( name='join', srcs=[ 'join.d', ], )   "},{"title":"d_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#d_library","content":"def d_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, linker_flags: [str.type] = _, srcs: [[str.type], {str.type: str.type}] = _ ) -&gt; None  A d_library() rule represents a set of D source files. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: The set of dependencies of this rule. Each element should be a string specifying a d_library rule defined elsewhere (e.g. ':foo' or '//foo:bar').srcs: The set of D source files to be compiled by this rule. Each element should be a string specifying a source file (e.g. 'foo/bar.d'). Details​ Examples:  # A simple library with a single source file and a single dependency. d_library( name='greeting', srcs=[ 'greeting.d', ], deps=[ ':join', ], ) d_library( name='join', srcs=[ 'join.d', ], )   "},{"title":"d_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#d_test","content":"def d_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, linker_flags: [str.type] = _, srcs: [[str.type], {str.type: str.type}] = _, test_rule_timeout_ms: [None, int.type] = _ ) -&gt; None  A d_test() rule is used to define a set of D source files that contain tests to run via D's unittest support. The source code of the test must provide a main() function. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: The set of dependencies of this rule. Each element should be a string specifying a d_library rule defined elsewhere (e.g. ':foo' or '//foo:bar').labels: A list of labels to be applied to these tests. These labels are arbitrary text strings and have no meaning within buck itself. They can, however, have meaning for you as a test author (e.g., smoke or fast). A label can be used to filter or include a specific d_test() rule when executing buck testsrcs: The set of D source files to be compiled by this rule. Each element should be a string specifying a source file (e.g. 'foo/bar.d').test_rule_timeout_ms: If set specifies the maximum amount of time (in milliseconds) in which all of the tests in this rule should complete. This overrides the default rule_timeout if any has been specified in .buckconfig . Details​ Examples:  # A rule that builds and runs D test with a single source file. d_test( name = 'test', srcs = [ 'test.d', ], )   "},{"title":"erlang_app​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#erlang_app","content":"def erlang_app( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _toolchain: str.type = _, app_src: [None, str.type] = _, applications: [str.type] = _, build_edoc_chunks: bool.type = _, contacts: [str.type] = _, env: [None, {str.type: str.type}] = _, erl_opts: [None, [str.type]] = _, extra_includes: [str.type] = _, included_applications: [str.type] = _, includes: [str.type] = _, labels: [str.type] = _, metadata: [None, {str.type: [str.type, [str.type]]}] = _, mod: [None, (str.type, [str.type])] = _, os_env: [None, {str.type: str.type}] = _, resources: [str.type] = _, shell_configs: [str.type] = _, shell_libs: [str.type] = _, srcs: [str.type] = _, use_global_parse_transforms: bool.type = _, version: str.type = _ ) -&gt; None  This rule is the main rule for Erlang applications. It gets generated by using the erlang_application macro, that takes as attributes the same attributes as this rule. You should always use the erlang_application macro instead of using this rule directly. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneapp_src: The app_src field allows to optionally reference a *.app.src template file. This template file will then be used by buck2 to generate the *.app output file in the applications ebin/ directory. This is useful during the migration from rebar3 to buck2 to avoid duplicated entries, of e.g. the version. Buck2 will use or check all fields present in the template, and fill out the fields with the information provided in the target, e.g. if the version is specified in both, buck2 will check that they are identical. Otherwise, it uses the information from the template if the target doesn't specify it, and vice versa. NOTE: If you use the app_src field and the references application resource file template specifies applicationsor included_applications buck2 checks that the target definitions and information in the template are equivalent to prevent these definitions from drifting apart during migration. applications: Equivalent to the corresponding applications and included_applications fields you will find in *.app.src or *.app files and specify the application dependencies. Contrary to the fields in the *.app.src or *.app files, it is necessary to use target paths to the application where a dependency is desired. These fields will be used to construct equally named fields in the generated *.app file for the application. OTP applications are specified with the target path otp//:&lt;application&gt;. NOTE: If you use the app_src field and the references application resource file template specifiesapplications or included_applications buck2 checks that the target definitions and information in the template are equivalent to prevent these definitions from drifting apart during migration. build_edoc_chunks: This attribute controls if the output of the builds also create edoc chunks.env: The env field allows to set the application env variables. The key value pairs will materialise in tha applications .app file and can then be accessed by application:get_env/2.erl_opts: Typically compile options are managed by global config files, however, sometimes it is desirable to overwrite the pre-defined compile options. The erl_opts field allows developers to do so for individual applications. The main use-case are the applications listed in third-party/. This option should not be used by other applications without consultation. Please ask in the WhatsApp Dev Infra Q&amp;Aworkplace group for support. extra_includes: In some cases we might have the situation, where an application app_a depends through the applications and included_applications fields on application app_b and a source file in app_b includes a header file from app_a (e.g. -include_lib(&quot;app_a/include/header.hrl). This technically creates circular dependency from app_a to app_b (e.g. via applications field) and back from app_b to app_a (via -include_lib). To break the dependency developers can specify targets in the extra_includes field, whose public include files are accessible to the application target during build time. Only the includes of the specified application are available and eventual transitive dependencies need to be managed manually. NOTE: It is not possible (or even desired) to add OTP applications with this field. NOTE: This mechanism is added to circumvent unclean dependency relationships and the goal for developers should be to reduce usages of this field. DO NOT ADD ANY MORE USAGES!! included_applications: Check the documentation for applications.includes: The public header files accessible via -include_lib(&quot;appname/include/header.hrl&quot;) from other erlang files.metadata: The metadata field can be used to specify extra key-value pairs which is are not defined in application_opt(). The key-value pair will be stored in the applications .app file and can be accessed by file:consult/1.mod: The mod field specifies the equivalent field in the generated *.app files. The format is similar, with the difference, that the module name, and the individual start arguments need to be given as the string representation of the corresponding Erlang terms.os_env: This attribute allows to set additional values for the operating system environment for invocations to the Erlang toolchain.resources: The resources field specifies targets whose default output are placed in the applications priv/ directory. For regular files this field is typically combined with export_file, filegroup, or similar targets. However, it is general, and any target can be used, e.g. if you want to place a built escript in the priv/ directory, you can use an erlang_escript target.shell_configs: This attribute allows to set config files for the shell. The dependencies that are typically used here are export_file targets.shell_libs: This attribute allows to define additional dependencies for the shell. By default this is set to [&quot;prelude//erlang/shell:buck2_shell_utils&quot;] which includes a user_default module that loads and compiles modules with buck2 mechanisms.srcs: A list of *.erl, *.hrl, *.xrl, or *.yrl source inputs that are typically located in an application's src/ folder. Header files (i.e. *.hrl files) specified in this field are considered application private headers, and can only be accessed by the *.erl files of the application itself. *.xrl and *.yrl files are processed into *.erl files before all *.erl files are compiled into *.beam files.use_global_parse_transforms: This field indicates if global parse_tranforms should be applied to this application as well. It often makes sense for third-party dependencies to not be subjected to global parse_transforms, similar to OTP applications.version: The version field specifies the applications version that is materialized as vsn field in the generated *.app file. If you use the the app_src field and specify a version in the referenced template in addition to the version field, the versions need to be identical. If no version is specified in either the app_src template or the version field, a fallback version string of&quot;1.0.0&quot; is used. Details​ Erlang Applications are the basic building block of our buck2 integration and used by many other Erlang targets, e.g. erlang_escript, erlang_test, or erlang_release. The erlang_application targets build OTP applications and as such many attributes that are used have equivalent meaning to the fields in the currently (by rebar3) used *.app.src files and OTP *.appfiles. Please familiarize yourself with the semantics of these fields by consulting theOTP documentation. The target enforces uniqueness during builds, and fails to build if duplicated artifacts in the global namespaces are detected: duplicated application names in the dependenciesduplicated module names across any of the applications or dependencies modulesambiguity when resolving header files The default output of this rule is the application folder of the target application and all transitive dependencies. Examples: Minimal Erlang Application​ erlang_application( name = &quot;minimal&quot;, )  With priv/ directory​ erlang_application( name = &quot;app_a&quot;, srcs = [ &quot;src/app_a.erl&quot;, ], includes = [], applications = [ &quot;:app_b&quot;, ], app_src = &quot;src/app_a.app.src&quot;, resources = [ &quot;:readme&quot;, ], ) export_file( name = &quot;readme&quot;, src = &quot;README.md&quot;, )  Using OTP applications and mod field​ erlang_application( name = &quot;app_b&quot;, srcs = [ &quot;src/app_b.erl&quot;, &quot;src/app_b.hrl&quot;, ], includes = [], applications = [ &quot;kernel&quot;, &quot;stdlib&quot;, &quot;:app_c&quot;, ], mod = (&quot;app_b&quot;, [ &quot;some_atom&quot;, &quot;&quot;some string&quot;&quot;, &quot;{tagged_tuple, 42}&quot;, ]), )  Using Yecc and Leex​ erlang_application( name = &quot;yecc_leex&quot;, srcs = [ &quot;src/leex_stub.xrl&quot;, &quot;src/yecc_stub.yrl&quot;, ], )   "},{"title":"erlang_app_includes​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#erlang_app_includes","content":"def erlang_app_includes( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _toolchain: str.type = _, application_name: str.type, contacts: [str.type] = _, includes: [str.type] = _, labels: [str.type] = _, os_env: [None, {str.type: str.type}] = _ ) -&gt; None  This rule is a supplementary rule for Erlang applications. It gets generated by using the erlang_application macro, that takes as attributes the same attributes as this rule. You should always use the erlang_application macro instead of using this rule directly. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneos_env: This attribute allows to set additional values for the operating system environment for invocations to the Erlang toolchain.  "},{"title":"erlang_escript​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#erlang_escript","content":"def erlang_escript( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _toolchain: str.type = _, contacts: [str.type] = _, deps: [str.type], emu_args: [str.type] = _, include_priv: bool.type = _, labels: [str.type] = _, main_module: [None, str.type] = _, os_env: [None, {str.type: str.type}] = _, resources: [str.type] = _, script_name: [None, str.type] = _ ) -&gt; None  The erlang_escript target builds and runs bundled escripts. Please refer to the OTP documentation for more details about escripts. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: List of Erlang applications that are bundled in the escript. This includes all transitive dependencies as well.emu_args: This field specifies the emulator flags that the escript uses on execution. It is often desirable to specify the number of threads and schedulers the escript uses. Please refer to the OTP documentation for details.include_priv: Setting this flag, will package the applications priv directory in the escript. Similar to files added through the resources field, the priv folders files can then be accessed by escript&quot;extract/2.main_module: Overrides the default main module. Instead of defering the main module from the scripts filename, the specified module is used. That module needs to export a main/1 function that is called as entry point.os_env: This attribute allows to set additional values for the operating system environment for invocations to the Erlang toolchain.resources: This adds the targets default output to the escript archive. To access these files, you need to use escript:extract/2, which will extract the entire escript in memory. The relevant files can then be accessed through the archive section. Please refer to the escript:extract/2 for more details. script_name: Overrides the filename of the produced escript. Details​ Escripts by default always try to use the module that has the same name as the escripts basename as entry point, e.g. if the escript is called script.escript then running the escript will try to call script:main/1. Both name and main module can be overwritten though. The target name doubles as the default escript name. If the main_module attribute is not used, the escript filename will be &lt;name&gt;.escript. Examples: erlang_escript( name = &quot;script&quot;, main_module = &quot;main_module&quot;, script_name = &quot;the_script&quot;, deps = [ &quot;:escript_app&quot;, ], emu_args = [&quot;+sbtu&quot;, &quot;+A1&quot;], ) erlang_application( name = &quot;escript_app&quot;, srcs = [&quot;src/main_module.erl&quot;], applications = [ &quot;kernel&quot;, &quot;stdlib&quot;, ], )   "},{"title":"erlang_otp_binaries​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#erlang_otp_binaries","content":"def erlang_otp_binaries( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, erl: str.type, erlc: str.type, escript: str.type, labels: [str.type] = _, os_env: [None, {str.type: str.type}] = _ ) -&gt; None  This target defines the executables for the Erlang toolchains, and is required to defined a toolchain. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneerl: Reference to erl binaryerlc: Reference to erlc binaryescript: Reference to escript binaryos_env: This attribute allows to set additional values for the operating system environment for invocations to the Erlang toolchain. Details​ Examples: erlang_otp_binaries( name = &quot;local&quot;, erl = &quot;local/erl&quot;, erlc = &quot;local/erlc&quot;, escript = &quot;local/escript&quot;, )  "},{"title":"erlang_release​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#erlang_release","content":"def erlang_release( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _toolchain: str.type = _, applications: [[str.type, (str.type, str.type)]], contacts: [str.type] = _, include_erts: bool.type = _, labels: [str.type] = _, multi_toolchain: [None, [str.type]] = _, os_env: [None, {str.type: str.type}] = _, overlays: {str.type: [str.type]} = _, release_name: [None, str.type] = _, version: str.type = _ ) -&gt; None  The erlang_release target builds OTP releases. Please refer to the OTP documentation for more details about releases. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneapplications: This field specifies the list of applications that the release should start in the given order, and optionally the start type. Top-level applications without given start type are started with type permanent.include_erts: This field controls wether OTP applications and the Erlang runtime system should be included as part of the release. Please note, that at the moment the erts folder is just erts/.multi_toolchain: This field controls wether the release should be built with a single toolchain, or multiple toolchains. In the latter case, all output paths are prefixed with the toolchain name.os_env: This attribute allows to set additional values for the operating system environment for invocations to the Erlang toolchain.overlays: Overlays can be used to add files to the release. They are specified as mapping from path (from the release root) to list of targets. The targets files are places flat at the target location with their basename.release_name: The release name can explicitly be set by this field. This overwrites the default from the target name.version: The version field specifies the release version. The release version is used in the release resource file, and is part of the path for the folder containing the boot scripts. Details​ The erlang_release target does by default (without overlays) package: applications that are required to start the releaserelease resource file &lt;relname&gt;.rel (see rel(4))boot script start.script (see rel(4))binary boot script start.bootbin/release_variables The release_variables file contains release name, version, and erts version in shell syntax, e.g. ERTS_VSN=&quot;12.1.2&quot; REL_NAME=&quot;rel1&quot; REL_VSN=&quot;1.0.0&quot;  The target name doubles as the default release name. If the release_name attribute is used, the release name will be sources from there instead. Examples: erlang_release( name = &quot;world&quot;, version = &quot;1.0.0&quot;, applications = [ &quot;//apps//app_a:app_a&quot;, &quot;//apps//app_b:app_b&quot;, ], overlays = { &quot;releases/1.0.0&quot;: [ &quot;:sys.config.src&quot;, ], &quot;bin&quot;: [ &quot;:start.sh&quot;, ], }, ) export_file( name = &quot;sys.config.src&quot;, src = &quot;sys.config&quot;, ) export_file( name = &quot;start.sh&quot;, src = &quot;start.sh&quot;, )   "},{"title":"erlang_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#erlang_test","content":"def erlang_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cli_lib: str.type = _, _ct_opts: str.type = _, _providers: str.type, _test_binary: str.type = _, _test_binary_lib: str.type = _, _toolchain: str.type = _, _trampoline: [None, str.type] = _, config_files: [str.type] = _, contacts: [str.type] = _, deps: [str.type] = _, env: {str.type: str.type} = _, extra_ct_hooks: [str.type] = _, labels: [str.type] = _, os_env: [None, {str.type: str.type}] = _, preamble: str.type = _, property_tests: [str.type] = _, resources: [str.type] = _, shell_configs: [str.type] = _, shell_libs: [str.type] = _, suite: str.type ) -&gt; None  The erlang_test ruls defines a test target for a single test suite. In most cases you want to define multiple suites in one go. The erlang_tests macro allows users to generate erlang_test targets for multiple test suites. Each suite &lt;name&gt;_SUITE.erl will have a generated hidden erlang_test target whose name is &lt;name&gt;_SUITE. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneconfig_files: Will specify what config files the erlang beam machine running test with should load, for reference look at OTP documentation. These ones should consist of default_output of some targets. In general, this field is filled with target coming from then export_file rule, as in the example below.deps: The set of dependencies needed for all suites included in the target to compile and run. They could be either erlang_app(lication) or erlang_test targets, although the latter is discouraged. If some suites need to access common methods, a common helper file should be created and included in the srcs field of the erlang_tests target. If some applications are included as dependencies of this target, their private include will automatically be pulled and made available for the test. That allows tests to access the private header files from the applications under test.env: Add the given values to the environment variables with which the test is executed.extra_ct_hooks: List of additional Common Test hooks. The strings are interpreted as Erlang terms.os_env: This attribute allows to set additional values for the operating system environment for invocations to the Erlang toolchain.resources: The resources field specifies targets whose default output are placed in the test data_dir directory for all the suites present in the macro target. Additionally, if data directory are present in the directory along the suite, this one will be pulled automatically for the relevant suite. Any target can be used, e.g. if you want to place a built escript in the data_dir directory, you can use an erlang_escript target. shell_configs: This attribute allows to set config files for the shell. The dependencies that are typically used here are export_file targets.shell_libs: This attribute allows to define additional dependencies for the shell. By default this is set to [&quot;prelude//erlang/shell:buck2_shell_utils&quot;] which includes a user_default module that loads and compiles modules with buck2 mechanisms.suite: The source file for the test suite. If you are using the macro, you should use the suites attribute instead. The suites attribtue specify which erlang_test targets should be generated. For each suite &quot;path_to_suite/suite_SUITE.erl&quot; an implicit 'erlang_test' target suite_SUITE will be generated. Details​ Each erlang_test target implements tests using the Common Test libraryOTP documentation. They can, although it is not recommended, also act as dependencies of other tests. The default output of this rule is a &quot;test_folder&quot;, consisting of the compiled test suite and the data directory. For each suite &lt;name&gt;_SUITE.erl, if a data_dir &lt;name&gt;_SUITE_data is present along the suite, (as per the data_dir naming scheme for ct), it will automatically adds the coresponding resource target to the generated test target of the suite. Resources will be placed in the Data directory (data_dir)of each of the suite. It allows the writer of the rule to add global configuration files and global default dependencies (e.g meck). These ones should be specified using global variables erlang.erlang_tests_default_apps and erlang.erlang_tests_default_configrespectively. The erlang_tests macro forwards all attributes to the erlang_test. It defines some attributes that control how the targets get generated: use_default_configs (bool): Parameter that controls if the config files specified by the global config variableerlang.erlang_tests_default_config should be used, default to True.use_default_deps (bool): Parameter that controls if the dependencies specified by the global config variableerlang.erlang_tests_default_apps should be pulled, default to True.srcs ([source]): Set of files that the suites might depend on and that are not part of any specific application. A &quot;meta&quot; application having those files as sources will automatically be created, and included in the dependencies of the tests. Ene can call buck2 build //my_app:test_SUITE to compile the test files together with its depedencies.buck2 test //my_app:other_test_SUITE to run the test.buck2 run //my_app:other_test_SUITE to open an interactive test shell, where tests can be run iteratively. buck2 test will rely on tpx to run the suite. To get access to tpx commands, add -- after the target. For example: buck2 test //my_app:other_test_SUITE -- --help will print the list of tpx available command line parameters.buck2 test //my_app:other_test_SUITE -- group.mycase will only run those test cases that match the pattern group.mycase Examples: erlang_test( name = &quot;unit_test_SUITE&quot;, suite = &quot;unit_test_SUTIE.erl&quot;, deps = [&quot;:my_other_app&quot;], contacts = [&quot;author@email.com&quot;], ) erlang_tests( suites = [&quot;test_SUITE.erl&quot;, &quot;other_test_SUITE&quot;.erl], deps = [&quot;:my_app&quot;], contacts = [&quot;author@email.com&quot;], )  "},{"title":"export_file​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#export_file","content":"def export_file( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, mode: [None, str.type] = _, out: [None, str.type] = _, src: [None, str.type] = _ ) -&gt; None  Warning: this build rule is deprecated for folders. Use filegroup()instead. It is still supported for individual files. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onemode: How files are referenced internally in buck. If set to 'copy', then a full copy will be made into the new location in buck-out. If set to 'reference', the original file will be used by internal build rules in-place. However, this mode does not work across repositories or if the 'out' property is set. For read-only operations, 'reference' can be more performant.out: The name which the file will be called if another rule depends on it instead of the name it already has.src: The path to the file that should be exported. Details​ An export_file() takes a single file or folder and exposes it so other rules can use it. Examples: The best way to see how the export_file() rule works is with some examples. The common case is:  export_file( name = 'example.html', ) # This is equivalent to export_file( name = 'example.html', src = 'example.html', out = 'example.html', )  It is sometimes useful to refer to the file not by its path, but by a more logical name:  export_file( name = 'example', src = 'example.html', ) # This is equivalent to export_file( name = 'example', src = 'example.html', out = 'example.html', )  Finally, there are occasions where you want to export a file more than once but want to copy it to a different name for each output:  export_file( name = 'runner', src = 'RemoteRunner.html', ) export_file( name = 'runner_hta', src = 'RemoteRunner.html', out = 'RemoteRunner.hta', )  Using the export_file() rule is also simple:  export_file( name = 'example', src = 'example.html', ) genrule( name = 'demo', out = 'result.html' cmd = 'cp $(location :example) $OUT', )   "},{"title":"external_test_runner​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#external_test_runner","content":"def external_test_runner( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, binary: str.type, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"filegroup​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#filegroup","content":"def filegroup( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, copy: bool.type = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, srcs: [[str.type], {str.type: str.type}] = _ ) -&gt; None  This rule provides access to a set of files. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onesrcs: The set of files to include in this rule. Details​ Files are accessible to genrule()s by using their relative path after a $(location) string parameter macro. Other rules may handle filegroup() rules natively for attributes such as resources. Examples: In this example a target exports .xml files from all subdirectories in resources.  filegroup( name = 'example', srcs = glob(['resources/**/*.xml']), ) genrule( name = 'process_xml', out = 'processed.xml', cmd = '$(exe //example:tool) -in $(location :example)/resources/file.xml &gt; $OUT', )   "},{"title":"gen_aidl​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#gen_aidl","content":"def gen_aidl( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _java_toolchain: str.type = _, aidl: str.type, aidl_srcs: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, import_path: str.type = _, import_paths: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _ ) -&gt; None  A gen_aidl() rule is used to generate .java files from .aidl files. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneaidl: The path to an .aidl file to convert to a .java file.aidl_srcs: Path to .aidl files the target aidl file imports.deps: A list of rules that must be built before this rule.import_path: The search path for import statements for the aidl command. (This is the -I argument when invoking aidl from the command line. For many apps it will be the base dir where all aidl files are, with project root as its parent, e.g. app/src/main/aidl.). This is the same as the path to the aidl file relative to what would be returned from root. Details​ Examples:  android_library( name = 'lib', srcs = glob(['**/*.java']) + [':aidl'], manifest = '//res/org/opencv:manifest', deps = [ '//res/org/opencv:res', ], visibility = [ 'PUBLIC' ], ) gen_aidl( name = 'aidl', aidl = 'engine/OpenCVEngineInterface.aidl', import_path = 'java/', )   "},{"title":"genrule​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#genrule","content":"def genrule( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _exec_os_type: str.type = _, _genrule_toolchain: str.type = _, bash: [None, str.type] = _, cacheable: [None, bool.type] = _, cmd: [None, str.type] = _, cmd_exe: [None, str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, default_outs: [None, [str.type]] = _, enable_sandbox: [None, bool.type] = _, env: {str.type: str.type} = _, environment_expansion_separator: [None, str.type] = _, executable: [None, bool.type] = _, labels: [str.type] = _, licenses: [str.type] = _, metadata_env_var: [None, str.type] = _, metadata_path: [None, str.type] = _, need_android_tools: bool.type = _, no_outputs_cleanup: bool.type = _, out: [None, str.type] = _, outs: [None, {str.type: [str.type]}] = _, remote: [None, bool.type] = _, srcs: [[str.type], {str.type: str.type}] = _, type: [None, str.type] = _ ) -&gt; None  A genrule() is used to generate files from a shell command. It must produce a single output file or folder. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onebash: A platform-specific version of the shell command parameter cmd. It runs on Linux and UNIX systems—including OSX—on which bash is installed. It has a higher priority than cmd. The bash argument is run with /usr/bin/env bash -c. It has access to the same set of macros and variables as the cmd argument.cmd: The shell command to run to generate the output file. It is the fallback for bash and cmd_exe arguments. The following environment variables are populated by Buck and available to the shell command. They are accessed using the syntax: ${&lt;variable&gt;}  Example: ${SRCS}  ${SRCS} A string expansion of the srcs argument delimited by the environment_expansion_separator argument where each element of srcs will be translated into an absolute path. ${SRCDIR} The absolute path to a directory to which sources are copied prior to running the command. ${OUT} The output file or directory for the genrule(). This variable will have whatever value is specified by the out argument if not usingÂ named outputs using named outputs, this variable will be the output directory. The value should be a valid filepath. The semantics of the shell command determine whether this filepath is treated as a file or a directory. If the filepath is a directory, then the shell command needs to create it if not using named outputs. Otherwise, it will be automatically created. The file or directory specified by this variable must always be written by this command. If not, the execution of this rule will be considered a failure, halting the build process. ${TMP} A temporary directory which can be used for intermediate results and will not be bundled into the output. String parameter macros​ It is also possible to expand references to other rules within thecmd, using builtin string parameter macros. All build rules expanded in the command are automatically considered to be dependencies of the genrule(). Note that the paths returned by these macros are absolute paths. You should convert these paths to be relative paths before embedding them in, for example, a shell script or batch file. Using relative paths ensures that your builds are hermetic, that is, they are reproducible across different machine environments. Additionally, if you embed these paths in a shell script, you should execute that script using the sh\\_binary()rule and include the targets for these paths in the resources argument of that sh_binary rule. These are the same targets that you pass to the string parameter macros. $(classpath //path/to:target) Expands to the transitive classpath of the specified build rule, provided that the rule has a Java classpath. If the rule does not have (or contribute to) a classpath, then an exception is thrown and the build breaks. $(exe //path/to:target) Expands a build rule that results in an executable to the commands necessary to run that executable. For example, a java_binary() might expand to a call to java -jar path/to/target.jar . Files that are executable (perhaps generated by a genrule()) are also expanded. If the build rule does not generate an executable output, then an exception is thrown and the build breaks. $(location //path/to:target) Expands to the location of the output of the specified build rule. This means that you can refer to the output without needing to be aware of how Buck is storing data on the disk mid-build. $(maven_coords //path/to:target) Expands to the Maven coordinates for the specified build rule. This allows you to access the Maven coordinates for Maven-aware build rules. The format of the expansion is:   cmd_exe: A platform-specific version of the shell command parameter cmd. It runs on Windows and has a higher priority than cmd. The cmd_exe argument is run with cmd.exe /v:off /c. It has access to the same set of macros and variables as the cmd argument.default_outs: Default output which must be present if the outs arg is present. Otherwise does not apply. If a rule with outs is consumed without an output label, the default output is returned. The default output does not need to be present in any of the named outputs defined in outs. Note that a maximum of one value may be present in this list. For example: default_outs = [ &quot;output_one&quot;, ]  is valid, whereas default_outs = [ &quot;output_one&quot;, &quot;output_two&quot;, ]  is not. enable_sandbox: Whether this target should be executed in a sandbox or not.environment_expansion_separator: The delimiter between paths in environment variables, such as SRCS, that can contain multiple paths. It can be useful to specify this parameter if the paths could contain spaces.executable: Whether the output of the genrule is itself executable. Marking an output as executable makes buck run and $(exe ...) macro expansion work with this target.out: The name of the output file or directory. The complete path to this argument is provided to the shell command through the OUT environment variable. Only one ofout or outs may be present.outs: Mapping defining named outputs to output paths relative to the rule's output directory. Only one of out or outs may be present. Example:  genrule( name = &quot;named_outputs&quot;, outs = { &quot;output1&quot;: [ &quot;out1.txt&quot;, ], &quot;output2&quot;: [ &quot;out2.txt&quot;, ], }, default_outs = [ &quot;out1.txt&quot; ], cmd = &quot;echo something&gt; $OUT/out1.txt &amp;&amp; echo another&gt; $OUT/out2.txt&quot;, )  Note that a maximum of one value may be present in the list in this map. For example:  outs = { &quot;output1&quot;: [ &quot;out1.txt&quot;, ], },  is valid, whereas  outs = { &quot;output1&quot;: [ &quot;out1.txt&quot;, &quot;out2.txt&quot;, ], },  is not. remote: Opts this genrule in to remote execution. Note that it is only safe to execute a genrule remotely if it is completely hermetic and completely and correctly describes its dependencies. Defaults to false. This parameter is unstable. It is subject to removal, default reversal, and other arbitrary changes in the future.srcs: Either a list or a map of the source files which Buck makes available to the shell command at the path in the SRCDIR environment variable. If you specify a list, the source files are the names in the list. If you specify a map, the source files are made available as the names in the keys of the map, where the values of the map are the original source file names.type: Specifies the type of this genrule. This is used for logging and is particularly useful for grouping genrules that share an underlying logical &quot;type&quot;. For example, if you have the following cxx_genrule defined in the root directory of your Buck project  cxx_genrule( name = 'cxx_gen', type = 'epilog', cmd = 'touch finish.txt; cp finish.txt $OUT', out = 'finish.txt' )  then the following buck query command  buck query &quot;attrfilter( type, 'epilog', '//...' )&quot;  returns  //:cxx_gen  Details​ Examples: This genrule() uses a Python script to derive a newAndroidManifest.xml from anAndroidManifest.xml in the source tree. Note you don't need to prepend execution commands withpython: Buck knows how to execute different kinds of binaries using $(exe) command.  genrule( name = 'generate_manifest', srcs = [ 'AndroidManifest.xml', ], bash = '$(exe //python/android:basic_to_full) ' '$SRCDIR/AndroidManifest.xml &gt; $OUT', cmd_exe = '$(exe //python/android:basic_to_full) ' '%SRCDIR%\\AndroidManifest.xml &gt; %OUT%', out = 'AndroidManifest.xml', )   genrule( name = 'generate_manifest_with_named_outputs', srcs = [ 'AndroidManifest.xml', ], bash = '$(exe //python/android:basic_to_full) ' '$SRCDIR/AndroidManifest.xml &gt; $OUT/AndroidManifest.xml', cmd_exe = '$(exe //python/android:basic_to_full) ' '%SRCDIR%\\AndroidManifest.xml &gt; %OUT%\\AndroidManifest.xml', outs = { &quot;manifest&quot;: [ &quot;AndroidManifest.xml&quot; ], }, default_outs = [ &quot;AndroidManifest.xml&quot; ], )  For named outputs, build with any of the following:  buck build //:generate_manifest_with_named_outputs   buck build //:generate_manifest_with_named_outputs[manifest]  Consume in srcs with:  export_file( name = &quot;magic1&quot;, src = &quot;:generate_manifest_with_named_outputs&quot;, out = &quot;some_dir_to_copy_to/AndroidManifest.xml&quot;, )   export_file( name = &quot;magic2&quot;, src = &quot;:generate_manifest_with_named_outputs[manifest]&quot;, out = &quot;some_dir_to_copy_to/AndroidManifest.xml&quot;, )  Note that magic1 consumes generate_manifest_with_named_outputs's default output. magic2 consumes generate_manifest_with_named_outputs's named output &quot;manifest,&quot; which happen to be pointing to the same output as the default output in this case, but they do not have to point to the same output.  "},{"title":"git_fetch​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#git_fetch","content":"def git_fetch( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _git_fetch_tool: str.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, repo: str.type, rev: str.type ) -&gt; None  Checkout a commit from a git repository. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onerepo: Url suitable as a git remote.rev: 40-digit hex SHA-1 of the git commit. Details​ Examples: git_fetch( name = &quot;serde.git&quot;, repo = &quot;https://github.com/serde-rs/serde&quot;, rev = &quot;fccb9499bccbaca0b7eef91a3a82dfcb31e0b149&quot;, )   "},{"title":"go_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#go_binary","content":"def go_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _go_toolchain: str.type = _, assembler_flags: [str.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, embedcfg: [None, str.type] = _, external_linker_flags: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, link_mode: [None, str.type] = _, link_style: [None, str.type] = _, linker_flags: [str.type] = _, platform: [None, str.type] = _, platform_external_linker_flags: [(str.type, [str.type])] = _, resources: [str.type] = _, srcs: [str.type] = _ ) -&gt; None  A go_binary() rule builds a native executable from the supplied set of Go source files and dependencies. The files supplied are expected to be in the main package, implicitly. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneassembler_flags: The set of additional assembler flags to pass to go tool asm.compiler_flags: The set of additional compiler flags to pass to go tool compile.deps: The set of dependencies of this rule. Currently, this only supports go_library rules.external_linker_flags: Extra external linker flags passed to go link via -extld argument. If argument is non-empty or cgo_library is used, the link mode will switch to external.link_mode: Determines the link mode (equivalent of -mode). Can be one of the following values: internal, external. If no value is provided, the mode is set automatically depending on the other args.link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be one of the following values: static, static_pic or shared. This argument is relevant only if the cgo extension is enabled. Otherwise, Buck ignores this argument.linker_flags: Extra linker flags passed to go linksrcs: The set of source files to be compiled by this rule. .go files will be compiled with the Go compiler, .s files will be compiled with the assembler, and everything else is assumed to be files that may be #included by the assembler. Details​ Examples: For more examples, check out our integration tests.  go_binary( name='greet', srcs=[ 'main.go', ], deps=[ ':greeting', ], ) go_library( name='greeting', srcs=[ 'greeting.go', ], deps=[ ':join', ], ) go_library( name='join', srcs=[ 'join.go', ], )   "},{"title":"go_exported_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#go_exported_library","content":"def go_exported_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _go_toolchain: str.type = _, assembler_flags: [str.type] = _, build_mode: str.type, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, embedcfg: [None, str.type] = _, external_linker_flags: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, link_mode: [None, str.type] = _, link_style: [None, str.type] = _, linker_flags: [str.type] = _, platform: [None, str.type] = _, platform_external_linker_flags: [(str.type, [str.type])] = _, resources: [str.type] = _, srcs: [str.type] = _ ) -&gt; None  A go_exported_library() rule builds a C library from the supplied set of Go source files and dependencies. This is done via -buildmode flag and &quot;//export&quot; annotations in the code. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneassembler_flags: The set of additional assembler flags to pass to go tool asm.build_mode: Determines the build mode (equivalent of -buildmode). Can be one of the following values: c_archive, c_shared. This argument is valid only if at there is at least one cgo_library declared in deps. In addition you should make sure that -sharedflag is added tocompiler_flagsand go version undergo.gorootis compiled with that flag present in:gcflags, ldflagsandasmflags``compiler_flags: The set of additional compiler flags to pass to go tool compile.deps: The set of dependencies of this rule. Currently, this only supports go_library rules.external_linker_flags: Extra external linker flags passed to go link via -extld argument. If argument is non-empty or cgo_library is used, the link mode will switch to external.link_mode: Determines the link mode (equivalent of -mode). Can be one of the following values: internal, external. If no value is provided, the mode is set automatically depending on the other args.link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be one of the following values: static, static_pic or shared. This argument is relevant only if the cgo extension is enabled. Otherwise, Buck ignores this argument.linker_flags: Extra linker flags passed to go linkresources: Static files to be symlinked into the working directory of the test. You can access these in your by opening the files as relative paths, e.g. ioutil.ReadFile(&quot;testdata/input&quot;).srcs: The set of source files to be compiled by this rule. .go files will be compiled with the Go compiler, .s files will be compiled with the assembler, and everything else is assumed to be files that may be #included by the assembler. Details​ Examples: For more examples, check out our integration tests.  go_exported_library( name = &quot;shared&quot;, srcs = [&quot;main.go&quot;], build_mode = &quot;c_shared&quot;, compiler_flags = [&quot;-shared&quot;], deps = [&quot;:example&quot;], ) cgo_library( name = &quot;example&quot;, package_name = &quot;cgo&quot;, srcs = [ &quot;export-to-c.go&quot;, # file with //export annotations ], cgo_compiler_flags = [], compiler_flags = [], headers = [], ) cxx_genrule( name = &quot;cgo_exported_headers&quot;, out = &quot;includes&quot;, cmd = ( &quot;mkdir -p $OUT &amp;&amp; &quot; + &quot;cat `dirname $(location :shared)`/includes/*.h &gt; $OUT/_cgo_export.h&quot; ), ) prebuilt_cxx_library( name = &quot;cxx_so_with_header&quot;, header_dirs = [&quot;:cgo_exported_headers&quot;], shared_lib = &quot;:shared&quot;, )   "},{"title":"go_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#go_library","content":"def go_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _go_toolchain: str.type = _, assembler_flags: [str.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, embedcfg: [None, str.type] = _, exported_deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, package_name: [None, str.type] = _, srcs: [str.type] = _ ) -&gt; None  A go_library() rule builds a native library from the supplied set of Go source files and dependencies. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneassembler_flags: The set of additional assembler flags to pass to go tool asm.compiler_flags: The set of additional compiler flags to pass to go tool compile.deps: The set of dependencies of this rule. Currently, this only supports go_library rules.package_name: Sets the full name of the package being compiled. This defaults to the path from the buck root. (e.g. given a ./.buckconfig, a rule in ./a/b/BUCK defaults to package &quot;a/b&quot;)srcs: The set of source files to be compiled by this rule. .go files will be compiled with the Go compiler, .s files will be compiled with the assembler, and everything else is assumed to be files that may be #included by the assembler. Details​ Examples: For more examples, check out our integration tests.  go_library( name='greeting', srcs=[ 'greeting.go', ], deps=[ ':join', ], )   "},{"title":"go_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#go_test","content":"def go_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _go_toolchain: str.type = _, _inject_test_env: str.type = _, _testmaingen: str.type = _, assembler_flags: [str.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, coverage_mode: [None, str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, embedcfg: [None, str.type] = _, env: {str.type: str.type} = _, external_linker_flags: [str.type] = _, labels: [str.type] = _, library: [None, str.type] = _, licenses: [str.type] = _, link_mode: [None, str.type] = _, link_style: [None, str.type] = _, linker_flags: [str.type] = _, package_name: [None, str.type] = _, platform: [None, str.type] = _, resources: [str.type] = _, run_test_separately: bool.type = _, runner: [None, str.type] = _, specs: [None, str.type] = _, srcs: [str.type] = _, test_rule_timeout_ms: [None, int.type] = _ ) -&gt; None  A go_test() rule builds a native binary from the specified Go source and resource files—and a generated main file. It's similar to the go test command. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneassembler_flags: The set of additional assembler flags to pass to go tool asm.compiler_flags: The set of additional compiler flags to pass to go tool compile.deps: The set of dependencies of this rule. Currently, this only supports go_library rules.env: A map of environment variables and values to set when running the test.external_linker_flags: Extra external linker flags passed to go link via -extld argument. If argument is non-empty or cgo_library is used, the link mode will switch to external.labels: A list of labels to be applied to these tests. These labels are arbitrary text strings and have no meaning within buck itself. They can, however, have meaning for you as a test author (e.g., smoke or fast). A label can be used to filter or include a specific test rule when executing buck testlibrary: Specify the library that this internal test is testing. This will copy the srcs, package_name and deps from the target specified so you don't have to duplicate them.link_mode: Determines the link mode (equivalent of -mode). Can be one of the following values: internal, external. If no value is provided, the mode is set automatically depending on the other args.link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be one of the following values: static, static_pic or shared. This argument is relevant only if the cgo extension is enabled. Otherwise, Buck ignores this argument.linker_flags: Extra linker flags passed to go linkpackage_name: Sets the full name of the test package being compiled. This defaults to the path from the buck root with &quot;_test&quot; appended. (e.g. given a ./.buckconfig, a rule in ./a/b/BUCK defaults to package &quot;a/b_test&quot;) Note: if you want to test packages internally (i.e. same package name), use the libraryparameter instead of setting package_name to include the tested source files. srcs: The set of source files to be compiled by this rule. .go files will be compiled with the Go compiler, .s files will be compiled with the assembler, and everything else is assumed to be files that may be #included by the assembler.test_rule_timeout_ms: If set specifies the maximum amount of time (in milliseconds) in which all of the tests in this rule should complete. This overrides the default rule_timeout if any has been specified in .buckconfig . Details​ If your test requires static files you should specify these in the resources argument. If you do not specify these files, they won't be available when your test runs. Examples: For more examples, check out our integration tests.  go_library( name='greeting', srcs=[ 'greeting.go', ], deps=[ ':join', ], ) go_test( name='greeting-test', srcs=[ 'greeting_ext_test.go', ], deps=[ ':greeting' ], ) go_test( name='greeting-internal-test', package_name='greeting', srcs=[ 'greeting.go', 'greeting_test.go', ], deps=[ ':join', ], ) # Or go_test( name='greeting-better-internal-test', srcs=['greeting_test.go'], library=':greeting', )   "},{"title":"go_test_runner​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#go_test_runner","content":"def go_test_runner( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, test_runner_generator: str.type ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"groovy_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#groovy_library","content":"def groovy_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, extra_groovyc_arguments: [str.type] = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, manifest_file: [None, str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resources: [str.type] = _, resources_root: [None, str.type] = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, srcs: [str.type] = _, target: [None, str.type] = _ ) -&gt; None  A groovy_library() rule is used to define a set of Groovy files that can be compiled together. It can also be used to cross compile a set of Groovy and Java files. The main output of a groovy_library() rule is a single JAR file containing all of the compiled class files and resources. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: Rules (usually other groovy_library or java_library() rules) that are used to generate the classpath required to compile this groovy_library. This is the same as in java\\_library(). exported_deps: Other groovy_library and java_library() rules that depend on this rule will also include its exported_deps in their classpaths. This is the same as in java\\_library(). extra_arguments: Only used during cross compilation. This is the same as in java\\_library(). extra_groovyc_arguments: List of additional arguments to pass into the Groovy compiler.java_version: Only used during cross compilation. This is the same as in java\\_library(). provided_deps: This is the same as in java\\_library().resources: This is the same as in java\\_library().source: Only used during cross compilation. This is the same as in java\\_library(). srcs: The set of files to compile for this rule. Usually these will all end in .groovy, but if any of the files end in .java, cross compilation using the jdk found in JAVA_HOME will occur.target: Only used during cross compilation. This is the same as in java\\_library(). Details​ Examples:  # A rule that compiles a single .groovy file. groovy_library( name = 'example', srcs = ['MySourceFile.groovy'], )   # A rule that compiles all of the .groovy files under the directory in # which the rule is defined using glob() groovy_library( name = 'groovy-only', srcs = glob(['**/*.groovy']), )   # A rule that cross compiles all of the .groovy and .java files under # the directory in which the rule is defined, failing if compiling the # java files generates any compiler warnings groovy_library( name = 'cross-compilation', srcs = glob(['**/*.groovy', '**/*.java']), java_version = 8, extra_arguments = [ '-Werror', ], )   "},{"title":"groovy_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#groovy_test","content":"def groovy_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, contacts: [str.type] = _, cxx_library_whitelist: [str.type] = _, default_cxx_platform: [None, str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, env: {str.type: str.type} = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, extra_groovyc_arguments: [str.type] = _, fork_mode: str.type = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, manifest_file: [None, str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resources: [str.type] = _, resources_root: [None, str.type] = _, run_test_separately: bool.type = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, srcs: [str.type] = _, std_err_log_level: [None, int.type, str.type] = _, std_out_log_level: [None, int.type, str.type] = _, target: [None, str.type] = _, test_case_timeout_ms: [None, int.type] = _, test_rule_timeout_ms: [None, int.type] = _, test_type: [None, str.type] = _, use_cxx_libraries: [None, bool.type] = _, use_dependency_order_classpath: [None, bool.type] = _, vm_args: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"gwt_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#gwt_binary","content":"def gwt_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, draft_compile: [None, bool.type] = _, experimental_args: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, local_workers: [None, int.type] = _, module_deps: [str.type] = _, modules: [str.type] = _, optimize: [None, int.type] = _, strict: [None, bool.type] = _, style: [None, str.type] = _, vm_args: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"halide_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#halide_library","content":"def halide_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, compiler_deps: [str.type] = _, compiler_flags: [str.type] = _, compiler_invocation_flags: [str.type] = _, configs: {str.type: {str.type: str.type}} = _, contacts: [str.type] = _, cxx_runtime_type: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, deps_query: [None, str.type] = _, devirt_enabled: bool.type = _, executable_name: [None, str.type] = _, fat_lto: bool.type = _, focused_list_target: [None, str.type] = _, frameworks: [str.type] = _, function_name: [None, str.type] = _, header_namespace: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, link_deps_query_whole: bool.type = _, link_group: [None, str.type] = _, link_group_map: [None, [(str.type, [(str.type, str.type, [None, str.type])])]] = _, link_style: [None, str.type] = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, prefer_stripped_objects: bool.type = _, prefix_header: [None, str.type] = _, preprocessor_flags: [str.type] = _, raw_headers: [str.type] = _, srcs: [[str.type, (str.type, [str.type])]] = _, supported_platforms_regex: [None, str.type] = _, thin_lto: bool.type = _, version_universe: [None, str.type] = _, weak_framework_names: [str.type] = _ ) -&gt; None  A halide_library() rule represents a set of Halide sources, along with the &quot;compiler&quot; code needed to compile them into object format (see the Halide site for information about Halide and about static compilation of Halide pipelines). The object code will be generated for the target architecture. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecompiler_deps: The dependencies of the halide compiler itself. Targets that depend on the halide_library rule will not include or link the outputs of these targets.compiler_flags: Flags to use when compiling any of the above sources (which require compilation).deps: The dependencies of the generated halide pipeline code. This is useful if, for example, your pipeline calls an external function using Halide::Func::define_extern.linker_flags: Flags to add to the linker command line whenever the output from this rule is used in a link operation, such as linked into an executable or a shared library.platform_compiler_flags: Platform specific compiler flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when compiling the target's sources. See compiler_flags for more information.platform_linker_flags: Platform-specific linker flags. This argument is specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched. The regex should use java.util.regex.Pattern syntax. The second element in each pair is a list of linker flags. If the regex matches the platform, these flags are added to the linker command line when the output from this rule is used in a link operation.srcs: The set of halide sources to compile for this rule. The sources will be compiled and linked for the host architecture, and the resulting binary will be run to produce the object code for the Halide pipeline.supported_platforms_regex: If present, an un-anchored regex (in java.util.regex.Pattern syntax) that matches all platforms that this library supports. It will not be built for other platforms. Details​ Examples:  halide_library( # Your library name. name = 'brighter', # Your pipeline + compiler sources. srcs = ['halide/main.cpp'], # Any dependencies for your compiler. Note that targets that depend on # this rule WILL NOT include or link the output(s) of these targets. compiler_deps = [ # You'll need libHalide to use this rule; in our example, we assume it's # located in the 'third-party/halide' directory. '//third-party/halide:halide' ], # Any dependencies for your generated shader. Targets that depend on this # rule will include and/or link the output(s) of these targets. deps = [ # ... ], )   "},{"title":"haskell_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#haskell_binary","content":"def haskell_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _haskell_toolchain: str.type = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, enable_profiling: bool.type = _, ghci_platform_preload_deps: [(str.type, [str.type])] = _, ghci_preload_deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, link_deps_query_whole: bool.type = _, link_style: [None, str.type] = _, linker_flags: [str.type] = _, main: [None, str.type] = _, platform: [None, str.type] = _, platform_deps: [(str.type, [str.type])] = _, platform_linker_flags: [(str.type, [str.type])] = _, srcs: [[str.type], {str.type: str.type}] = _, template_deps: [str.type] = _ ) -&gt; None  A haskell_binary() rule represents a groups of Haskell sources and deps which build an executable. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecompiler_flags: Flags to pass to the Haskell compiler when compiling this rule's sources.deps: Either haskell\\_library()or prebuilt\\_haskell\\_library()rules from which this rules sources import modules or native linkable rules exporting symbols this rules sources call into.link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be either static, static_pic or shared.main: The main module serving as the entry point into the binary. If not specified, the compiler default is used.platform_deps: Platform specific dependencies. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of dependencies (same format as deps) that are exported if the platform matches the regex. See deps for more information.srcs: A list of Haskell sources to be built by this rule. Details​ Examples:  haskell_binary( name = 'foo', srcs = [ 'Foo.hs', ], )   "},{"title":"haskell_ghci​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#haskell_ghci","content":"def haskell_ghci( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _haskell_toolchain: str.type = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, enable_profiling: bool.type = _, extra_script_templates: [str.type] = _, ghci_bin_dep: [None, str.type] = _, ghci_init: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, linker_flags: [str.type] = _, platform: [None, str.type] = _, platform_deps: [(str.type, [str.type])] = _, platform_preload_deps: [(str.type, [str.type])] = _, preload_deps: [str.type] = _, srcs: [[str.type], {str.type: str.type}] = _, template_deps: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"haskell_haddock​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#haskell_haddock","content":"def haskell_haddock( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, haddock_flags: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, platform: [None, str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"haskell_ide​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#haskell_ide","content":"def haskell_ide( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _haskell_toolchain: str.type = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, extra_script_templates: [str.type] = _, include_projects: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, link_style: str.type, linker_flags: [str.type] = _, platform: [None, str.type] = _, platform_deps: [(str.type, [str.type])] = _, srcs: [[str.type], {str.type: str.type}] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"haskell_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#haskell_library","content":"def haskell_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _haskell_toolchain: str.type = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, enable_profiling: bool.type = _, ghci_platform_preload_deps: [(str.type, [str.type])] = _, ghci_preload_deps: [str.type] = _, haddock_flags: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, link_whole: bool.type = _, linker_flags: [str.type] = _, platform: [None, str.type] = _, platform_deps: [(str.type, [str.type])] = _, platform_linker_flags: [(str.type, [str.type])] = _, preferred_linkage: str.type = _, srcs: [[str.type], {str.type: str.type}] = _, template_deps: [str.type] = _ ) -&gt; None  A haskell_library() rule is used to identity a group of Haskell sources. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecompiler_flags: Flags to pass to the Haskell compiler when compiling this rule's sources.deps: Either haskell\\_library()or prebuilt\\_haskell\\_library()rules from which this rules sources import modules or native linkable rules exporting symbols this rules sources call into.platform_deps: Platform specific dependencies. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of dependencies (same format as deps) that are exported if the platform matches the regex. See deps for more information.srcs: A list of Haskell sources to be built by this rule. Details​ Examples:  haskell_library( name = 'fileutil', srcs = [ 'FileUtil.hs', ], )   "},{"title":"haskell_prebuilt_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#haskell_prebuilt_library","content":"def haskell_prebuilt_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, cxx_header_dirs: [str.type] = _, db: str.type, default_host_platform: [None, str.type] = _, deps: [str.type] = _, enable_profiling: bool.type = _, exported_compiler_flags: [str.type] = _, exported_linker_flags: [str.type] = _, id: str.type = _, import_dirs: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, pic_profiled_static_libs: [str.type] = _, pic_static_libs: [str.type] = _, profiled_static_libs: [str.type] = _, shared_libs: {str.type: str.type} = _, static_libs: [str.type] = _, version: str.type = _ ) -&gt; None  A prebuilt_haskell_library() rule is used to identify Haskell prebuilt libraries and their associated interface files. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: Other prebuilt_haskell_library() rules from which this library imports modules.exported_compiler_flags: Compiler flags used by dependent rules when compiling with this library.exported_linker_flags: Linker flags used by dependent rules when linking with this library.shared_libs: A map of shared library names to shared library paths to use when building a dynamically linked top-level target.static_libs: The libraries to use when building a statically linked top-level target. Details​ Examples:  prebuilt_haskell_library( name = 'file', static_interfaces = [ 'interfaces', ], shared_interfaces = [ 'interfaces_dyn', ], static_libs = [ 'libFileUtil.a', ], shared_libs = { 'libFileUtil.so': 'libFileUtil.so', }, )   "},{"title":"http_archive​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#http_archive","content":"def http_archive( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, excludes: [str.type] = _, exec_deps: str.type = _, labels: [str.type] = _, licenses: [str.type] = _, out: [None, str.type] = _, sha1: [None, str.type] = _, sha256: [None, str.type] = _, strip_prefix: [None, str.type] = _, sub_targets: [str.type] = _, type: [None, str.type] = _, urls: [str.type] = _, vpnless_urls: [str.type] = _ ) -&gt; None  An http_archive() rule is used to download and extract archives from the Internet to be used as dependencies for other rules. These rules are downloaded by running fetch, or can be downloaded as part of buildby setting .buckconfig Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneexcludes: An optional list of regex patterns. All file paths in the extracted archive which match any of the given patterns will be omitted.exec_deps: When using http_archive as an anon target, the rule invoking the anon target needs to mirror this attribute into its own attributes, and forward the provider into the anon target invocation. When using http_archive normally not as an anon target, the default value is always fine. out: An optional name to call the directory that the downloaded artifact is extracted into. Buck will generate a default name if one is not provided that uses the name of the rule.sha256: The SHA-256 hash of the downloaded artifact. Buck verifies this is correct and fails the fetch command if it doesn't match in order to guarantee repeatable builds.strip_prefix: If set, files under this path will be extracted to the root of the output directory. Siblings or cousins to this prefix will not be extracted at all. For example, if a tarball has the layout: foo/bar/bar-0.1.2/data.dat foo/baz/baz-0.2.3 foo_prime/bar-0.1.2 Only data.dat will be extracted, and it will be extracted into the output directory specified inÂ http\\_archive()out. sub_targets: A list of filepaths within the archive to be made accessible as sub-targets. For example if we have an http_archive with name = &quot;archive&quot; and sub_targets = [&quot;src/lib.rs&quot;], then other targets would be able to refer to that file as &quot;:archive[src/lib.rs]&quot;. type: Normally, archive type is determined by the file's extension. If type is set, then autodetection is overridden, and the specified type is used instead. Supported values are: zip, tar, tar.gz,tar.bz2, tar.xz, and tar.zst. urls: A list of urls to attempt to download from. They are tried in order, and subsequent ones are only tried if the download fails. If validation fails, a new URL is not used. Supported protocols are &quot;http&quot;, &quot;https&quot;, and &quot;mvn&quot;.vpnless_urls: Additional URLs from which this resource can be downloaded when off VPN. Meta-internal only. Details​ Examples: Using http_archive(), third party packages can be downloaded from an https URL and used in other library types.  http_archive( name = 'thrift-archive', urls = [ 'https://internal-mirror.example.com/bin/thrift-compiler-0.1.tar.gz.badextension', ], sha256 = '7baa80df284117e5b945b19b98d367a85ea7b7801bd358ff657946c3bd1b6596', type='tar.gz', strip_prefix='thrift-compiler-0.1' ) genrule( name = 'thrift-compiler-bin', out = 'thrift', cmd = 'cp $(location :thrift-archive)/bin/thrift $OUT', executable = True, ) genrule( name=&quot;my-thrift-lib-cpp2&quot;, cmd=&quot;$(exe :thrift-compiler-bin) --gen cpp2 -o $OUT $(location //:thrift-file)&quot;, out=&quot;gen-cpp2&quot;, )   "},{"title":"http_file​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#http_file","content":"def http_file( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, executable: [None, bool.type] = _, labels: [str.type] = _, licenses: [str.type] = _, out: [None, str.type] = _, sha1: [None, str.type] = _, sha256: [None, str.type] = _, urls: [str.type] = _, vpnless_urls: [str.type] = _ ) -&gt; None  An http_file() rule is used to download files from the Internet to be used as dependencies for other rules. This rule only downloads single files, and can optionally make them executable (see http\\_file()executable) These rules are downloaded by running fetch, or can be downloaded as part of buildby setting .buckconfig Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneexecutable: Whether or not the file should be made executable after downloading. If true, this can also be used via runand the $(exe ) string parameter macrosout: An optional name to call the downloaded artifact. Buck will generate a default name if one is not provided that uses the name of the rule.sha256: The SHA-256 hash of the downloaded artifact. Buck verifies this is correct and fails the fetch command if it doesn't match in order to guarantee repeatable builds.urls: A list of urls to attempt to download from. They are tried in order, and subsequent ones are only tried if the download fails. If validation fails, a new URL is not used. Supported protocols are &quot;http&quot;, &quot;https&quot;, and &quot;mvn&quot;.vpnless_urls: Additional URLs from which this resource can be downloaded when off VPN. Meta-internal only. Details​ Examples: Using http_file(), third party packages can be downloaded from an https URL and used in java libraries.  http_file( name = 'guava-23-bin', urls = [ 'http://search.maven.org/remotecontent?filepath=com/google/guava/guava/23.0/guava-23.0.jar', ], sha256 = '7baa80df284117e5b945b19b98d367a85ea7b7801bd358ff657946c3bd1b6596', ) http_file( name = 'guava-23-sources', urls = [ 'http://search.maven.org/remotecontent?filepath=com/google/guava/guava/23.0/guava-23.0-sources.jar', ], sha256 = '37fe8ba804fb3898c3c8f0cbac319cc9daa58400e5f0226a380ac94fb2c3ca14', ) prebuilt_java_library( name = 'guava-23', binary_jar = ':guava-23-bin', source_jar = ':guava-23-source', )  Tooling can also be fetched with http_file() and used by a genrule().  genrule( name=&quot;my-thrift-lib-cpp2&quot;, cmd=&quot;$(exe :thrift-compiler-bin) --gen cpp2 -o $OUT $(location //:thrift-file)&quot;, out=&quot;gen-cpp2&quot;, ) http_file( name = 'thrift-compiler-bin', url = 'https://internal-mirror.example.com/bin/thrift-compiler', sha256 = 'c24932ccabb66fffb2d7122298f7f1f91e0b1f14e05168e3036333f84bdf58dc', executable = True, )  Here's an example of a http_file() using a mvn URI which uses a Maven classifier.  http_file( name = 'guava-23-bin', urls = [ 'mvn:com.google.guava:guava:jar:23.0', ], sha256 = '7baa80df284117e5b945b19b98d367a85ea7b7801bd358ff657946c3bd1b6596', )   "},{"title":"jar_genrule​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#jar_genrule","content":"def jar_genrule( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _genrule_toolchain: str.type = _, _java_toolchain: str.type = _, bash: [None, str.type] = _, cacheable: [None, bool.type] = _, cmd: [None, str.type] = _, cmd_exe: [None, str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, enable_sandbox: [None, bool.type] = _, environment_expansion_separator: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, metadata_env_var: [None, str.type] = _, metadata_path: [None, str.type] = _, need_android_tools: bool.type = _, no_outputs_cleanup: bool.type = _, remote: [None, bool.type] = _, srcs: [[str.type], {str.type: str.type}] = _, type: [None, str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"java_annotation_processor​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#java_annotation_processor","content":"def java_annotation_processor( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _build_only_native_code: bool.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, does_not_affect_abi: bool.type = _, isolate_class_loader: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, processor_class: str.type = _, supports_abi_generation_from_source: bool.type = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"java_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#java_binary","content":"def java_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _build_only_native_code: bool.type = _, _java_toolchain: str.type = _, blacklist: [str.type] = _, contacts: [str.type] = _, default_cxx_platform: [None, str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, do_not_create_inner_jar: bool.type = _, generate_wrapper: bool.type = _, java_args_for_run_info: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, main_class: [None, str.type] = _, manifest_file: [None, str.type] = _, meta_inf_directory: [None, str.type] = _ ) -&gt; None  A java_binary() rule is used to create a JAR file of the compiled .class files and resources of the java_library() rules on which it depends. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneblacklist: A list of patterns that identify files to exclude from the final generated JAR file. Example:  java_binary( name = 'example', blacklist = [ # Excludes com.example.A and com.example.Alligator, # as well as their inner classes and any non-class files that happen to match # the pattern 'com.example.A', # Excludes all files from org/slf4j/**/*. 'org.slf4j', ], deps = [ ':example1', ':third-party-stuff', ], )  deps: Rules (normally of type java_library) that should be compiled and whose .class files and resources should be included in the generated JAR file.main_class: If provided, this will be the value specified as the Main-Class attribute of the META-INF/MANIFEST.MF file in the generated JAR file. Also, when this rule is used as an executable in a genrule(), main_class will indicate the class whose main() method will be invoked to process the command-line arguments. This is consistent with the expected usage of java -jar *&lt;name.jar&gt;* *&lt;args&gt;*.manifest_file: If provided, this manifest will be used when generating the JAR file. If combined with main_class, the specified manifest file will be used but the main_class will override the main class in the manifest.  "},{"title":"java_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#java_library","content":"def java_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _build_only_native_code: bool.type = _, _dex_min_sdk_version: [None, int.type] = _, _dex_toolchain: [None, str.type] = _, _is_building_android_binary: bool.type = _, _java_toolchain: str.type = _, abi_generation_mode: [None, str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, manifest_file: [None, str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resources: [str.type] = _, resources_root: [None, str.type] = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, srcs: [str.type] = _, target: [None, str.type] = _ ) -&gt; None  A java_library() rule defines a set of Java files that can be compiled together. The main output of a java_library() rule is a single JAR file containing all of the compiled class files, as well as the static files specified in the resources argument. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: Rules (usually other java_library rules) that are used to generate the classpath required to compile this java_library.exported_deps: Other rules that depend on this rule will also include its exported_deps in their classpaths. This is useful when the public API of a rule has return types or checked exceptions that are defined in another rule, which would otherwise require callers to add an extra dependency. It's also useful for exposing e.g. a collection of prebuilt_jar rules as a single target for callers to depend on. Targets in exported_deps are implicitly included in the deps of this rule, so they don't need to be repeated there.exported_provided_deps: This is a combination of provided_deps and exported_deps. Rules listed in this parameter will be added to classpath of rules that depend on this rule, but they will not be included in a binary if binary depends on a such target.extra_arguments: List of additional arguments to pass into the Java compiler. These arguments follow the ones specified in .buckconfig.java_version: Equivalent to setting both source and target to the given value. Setting this and source or target (or both!) is an error.on_unused_dependencies: Action performed when Buck detects that some dependencies are not used during Java compilation. Note that this feature is experimental and does not handle runtime dependencies. The valid values are: ignore (default): ignore unused dependencies,warn: emit a warning to the console,fail: fail the compilation. This option overrides the default value from . provided_deps: These represent dependencies that are known to be provided at run time, but are required in order for the code to compile. Examples of provided_deps include the JEE servlet APIs. When this rule is included in a , the provided_deps will not be packaged into the output.remove_classes: Specifies a list of Patterns that are used to exclude classes from the JAR. The pattern matching is based on the name of the class. This can be used to exclude a member class or delete a local view of a class that will be replaced during a later stage of the build.required_for_source_only_abi: Indicates that this rule must be present on the classpath during source-only ABI generation of any rule that depends on it. Typically this is done when a rule contains annotations, enums, constants, or interfaces. Having rules present on the classpath during source-only ABI generation prevents Buck from completely flattening the build graph, thus reducing the performance win from source-only ABI generation. These rules should be kept small (ideally just containing annotations, constants, enums, and interfaces) and with minimal dependencies of their own. resources: Static files to include with the compiled .class files. These files can be loaded via Class.getResource(). Note: If resources_root isn't set, Buck uses the .buckconfigproperty in .buckconfig to determine where resources should be placed within the generated JAR file. source: Specifies the version of Java (as a string) to interpret source files as. Overrides the value in &quot;source_level&quot; in the &quot;java&quot; section of .buckconfig.source_only_abi_deps: These are dependencies that must be present during source-only ABI generation. Typically such dependencies are added when some property of the code in this rule prevents source-only ABI generation from being correct without these dependencies being present. Having source_only_abi_deps prevents Buck from completely flattening the build graph, thus reducing the performance win from source-only ABI generation. They should be avoided when possible. Often only a small code change is needed to avoid them. For more information on such code changes, read aboutsource-only ABI generation. srcs: The set of .java files to compile for this rule. If any of the files in this list end in .src.zip, then the entries in the ZIP file that end in .java will be included as ordinary inputs to compilation. This is common when using a genrule()to auto-generate some Java source code that needs to be compiled with some hand-written Java code.target: Specifies the version of Java (as a string) for which to generate code. Overrides the value in &quot;target_level&quot; in the &quot;java&quot; section of .buckconfig. Details​ Examples:  # A rule that compiles a single .java file. java_library( name = 'JsonUtil', srcs = ['JsonUtil.java'], deps = [ '//third_party/guava:guava', '//third_party/jackson:jackson', ], ) # A rule that compiles all of the .java files under the directory in # which the rule is defined using glob(). It also excludes an # individual file that may have additional dependencies, so it is # compiled by a separate rule. java_library( name = 'messenger', srcs = glob(['**/*.java'], excludes = ['MessengerModule.java']), deps = [ '//src/com/facebook/base:base', '//third_party/guava:guava', ], ) java_library( name = 'MessengerModule', srcs = ['MessengerModule.java'], deps = [ '//src/com/facebook/base:base', '//src/com/google/inject:inject', '//third_party/guava:guava', '//third_party/jsr-330:jsr-330', ], ) # A rule that builds a library with both relative and # fully-qualified deps. java_library( name = 'testutil', srcs = glob(['tests/**/*.java'], excludes = 'tests/**/*Test.java'), deps = [ ':lib-fb4a', '//java/com/facebook/base:base', ], )   "},{"title":"java_plugin​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#java_plugin","content":"def java_plugin( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _build_only_native_code: bool.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, does_not_affect_abi: bool.type = _, isolate_class_loader: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, plugin_name: str.type = _, supports_abi_generation_from_source: bool.type = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"java_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#java_test","content":"def java_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _build_only_native_code: bool.type = _, _inject_test_env: str.type = _, _is_building_android_binary: bool.type = _, _java_test_toolchain: str.type = _, _java_toolchain: str.type = _, abi_generation_mode: [None, str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, contacts: [str.type] = _, cxx_library_whitelist: [str.type] = _, default_cxx_platform: [None, str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, env: {str.type: str.type} = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, fork_mode: str.type = _, java: [None, str.type] = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, manifest_file: [None, str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resources: [str.type] = _, resources_root: [None, str.type] = _, run_test_separately: bool.type = _, runner: [None, str.type] = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, specs: [None, str.type] = _, srcs: [str.type] = _, std_err_log_level: [None, int.type, str.type] = _, std_out_log_level: [None, int.type, str.type] = _, target: [None, str.type] = _, test_case_timeout_ms: [None, int.type] = _, test_rule_timeout_ms: [None, int.type] = _, test_type: [None, str.type] = _, use_cxx_libraries: [None, bool.type] = _, use_dependency_order_classpath: [None, bool.type] = _, vm_args: [str.type] = _ ) -&gt; None  A java_test() rule is used to define a set of .java files that contain tests to run via JUnit. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecxx_library_whitelist: EXPERIMENTAL. List of cxx_libraries to build, if use_cxx_libraries is true. This can be useful if some dependencies are Android-only and won't build on the default platform.deps: Same as java_library(). // org.junit.rules.Timeout was not introduced until 4.7. Must include JUnit (version 4.7 or later) as a dependency for JUnit tests. Must include TestNG (version 6.2 or later) and hamcrest as a dependencies for TestNG tests.env: A map of environment names and values to set when running the test.fork_mode: Controls whether tests will all be run in the same process or a process will be started for each set of tests in a class. (This is mainly useful when porting Java tests to Buck from Apache Ant which allows JUnit tasks to set a fork=&quot;yes&quot; property. It should not be used for new tests since it encourages tests to not cleanup after themselves and increases the tests' computational resources and running time.) noneAll tests will run in the same process.per_testA process will be started for each test class in which all tests of that test class will run. labels: A list of labels to be applied to these tests. These labels are arbitrary text strings and have no meaning within buck itself. They can, however, have meaning for you as a test author (e.g., smoke or fast). A label can be used to filter or include a specific test rule when executing buck testresources: Same as java_library().source: Java language level for compiling. Corresponds to the -source argument for javac.srcs: Like java_library(), all of the .java files specified by the srcs argument will be compiled when this rule is built. In addition, all of the corresponding .class files that are built by this rule will be passed as arguments to JUnit when this rule is run as a test. .class files that are passed to JUnit that do not have any methods annotated with @Test are considered failed tests, so make sure that only test case classes are specified as srcs. This is frequently done by specifying srcs as glob(['**/*Test.java']).std_err_log_level: Same as std_out_log_level, but for std err.std_out_log_level: Log level for messages from the source under test that buck will output to std out. Value must be a valid java.util.logging.Level value.target: Bytecode target level for compiling. Corresponds to the -target argument for javac.test_rule_timeout_ms: If set specifies the maximum amount of time (in milliseconds) in which all of the tests in this rule should complete. This overrides the default rule_timeout if any has been specified in .buckconfig .test_type: Specifies which test framework to use. The currently supported options are 'junit' and 'testng'.use_cxx_libraries: Whether or not to build and link against cxx\\_library()dependencies when testing.vm_args: Runtime arguments to the JVM running the tests.  "},{"title":"java_test_runner​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#java_test_runner","content":"def java_test_runner( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, abi_generation_mode: [None, str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, main_class: str.type = _, manifest_file: [None, str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resources: [str.type] = _, resources_root: [None, str.type] = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, srcs: [str.type] = _, target: [None, str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"js_bundle​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#js_bundle","content":"def js_bundle( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _is_release: bool.type = _, _platform: str.type = _, android_package: [None, str.type] = _, bundle_name: [None, str.type] = _, bundle_name_for_flavor: [(str.type, str.type)] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, entry: [str.type, [str.type]], extra_json: [None, str.type] = _, fallback_transform_profile: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, worker: str.type ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"js_bundle_genrule​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#js_bundle_genrule","content":"def js_bundle_genrule( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _genrule_toolchain: str.type = _, _is_release: bool.type = _, _platform: str.type = _, bash: [None, str.type] = _, bundle_name: [None, str.type] = _, bundle_name_for_flavor: [(str.type, str.type)] = _, cacheable: [None, bool.type] = _, cmd: [None, str.type] = _, cmd_exe: [None, str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, enable_sandbox: [None, bool.type] = _, environment_expansion_separator: [None, str.type] = _, js_bundle: str.type, labels: [str.type] = _, licenses: [str.type] = _, metadata_env_var: [None, str.type] = _, metadata_path: [None, str.type] = _, need_android_tools: bool.type = _, no_outputs_cleanup: bool.type = _, remote: [None, bool.type] = _, rewrite_deps_file: bool.type = _, rewrite_misc: bool.type = _, rewrite_sourcemap: bool.type = _, skip_resources: bool.type = _, srcs: [[str.type], {str.type: str.type}] = _, type: str.type = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"js_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#js_library","content":"def js_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _build_only_native_code: bool.type = _, _is_release: bool.type = _, _platform: str.type = _, asset_extensions: [None, [str.type]] = _, asset_platforms: [None, [str.type]] = _, base_path: [None, str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, extra_json: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, srcs: [[str.type, (str.type, str.type)]] = _, worker: str.type ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"julia_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#julia_binary","content":"def julia_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _julia_toolchain: str.type = _, deps: [str.type] = _, julia_args: [str.type] = _, julia_flags: [str.type] = _, main: str.type, srcs: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"julia_jll_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#julia_jll_library","content":"def julia_jll_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _julia_toolchain: str.type = _, jll_name: str.type, lib_mapping: [[str.type], {str.type: str.type}], uuid: str.type ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"julia_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#julia_library","content":"def julia_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _julia_toolchain: str.type = _, deps: [str.type] = _, project_toml: str.type, resources: [str.type] = _, srcs: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"julia_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#julia_test","content":"def julia_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _inject_test_env: str.type = _, _julia_toolchain: str.type = _, contacts: [str.type] = _, deps: [str.type] = _, julia_args: [str.type] = _, julia_flags: [str.type] = _, main: str.type, srcs: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"keystore​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#keystore","content":"def keystore( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, properties: str.type, store: str.type ) -&gt; None  A keystore() contains the data for a key pair created by the keytool executable that comes with the JDK. This is a required input for an android\\_binary()rule. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneproperties: The path to the .properties file that contains the following values:  # The value that you passed as the argument to -alias # when you ran keytool. key.alias=my_alias # The value that you entered in response to # the &quot;Enter keystore password:&quot; prompt. key.store.password=store_password # The value that you entered in response to # the &quot;Enter key password for &lt;my_alias&gt;&quot; prompt. key.alias.password=alias_password  store: The path to the file that contains the key. This is the path that was passed as the -keystore argument when you ran keytool.  "},{"title":"kotlin_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#kotlin_library","content":"def kotlin_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _build_only_native_code: bool.type = _, _dex_min_sdk_version: [None, int.type] = _, _dex_toolchain: [None, str.type] = _, _is_building_android_binary: bool.type = _, _java_toolchain: str.type = _, _kotlin_toolchain: str.type = _, abi_generation_mode: [None, str.type] = _, annotation_processing_tool: [None, str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, extra_kotlinc_arguments: [str.type] = _, extra_non_source_only_abi_kotlinc_arguments: [str.type] = _, friend_paths: [str.type] = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, kotlin_compiler_plugins: {str.type: {str.type: str.type}} = _, labels: [str.type] = _, licenses: [str.type] = _, manifest_file: [None, str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resources: [str.type] = _, resources_root: [None, str.type] = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, srcs: [str.type] = _, target: [None, str.type] = _, use_jvm_abi_gen: [None, bool.type] = _ ) -&gt; None  A kotlin_library() rule is used to define a set of Kotlin files that can be compiled together. The main output of a kotlin_library() rule is a single JAR file containing all of the compiled class files, as well as the static files specified in the resources argument. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneannotation_processing_tool: Specifies the tool to use for annotation processing. Possible values: &quot;kapt&quot; or &quot;javac&quot;. &quot;kapt&quot; allows running Java annotation processors against Kotlin sources while backporting it for Java sources too. &quot;javac&quot; works only against Java sources, Kotlin sources won't have access to generated classes at compile time.deps: Rules (usually other kotlin_library rules) that are used to generate the classpath required to compile this kotlin_library.exported_deps: Other rules that depend on this rule will also include its exported_deps in their classpaths. This is useful when the public API of a rule has return types or checked exceptions that are defined in another rule, which would otherwise require callers to add an extra dependency. It's also useful for exposing e.g. a collection of prebuilt_jar rules as a single target for callers to depend on. Targets in exported_deps are implicitly included in the deps of this rule, so they don't need to be repeated there.exported_provided_deps: This is a combination of provided_deps and exported_deps. Rules listed in this parameter will be added to classpath of rules that depend on this rule, but they will not be included in a binary if binary depends on a such target.extra_kotlinc_arguments: List of additional arguments to pass into the Kotlin compiler.friend_paths: List of source paths to pass into the Kotlin compiler as friend-paths, that is, modules you can have access to internal methods.kotlin_compiler_plugins: Use this to specify Kotlin compiler plugins to use when compiling this library. This takes a map, with each entry specify one plugin. Entry's key is plugin source path, and value is a map of plugin option key value pair. Unlike extra_kotlinc_arguments, these can be source paths, not just strings. A special option value is__codegen_dir__, in which case Buck will provide a default codegen folder's path as option value instead. E.g.  kotlin_compiler_plugins = { &quot;somePluginSourcePath&quot;: { &quot;plugin:somePluginId:somePluginOptionKey&quot;: &quot;somePluginOptionValue&quot;, &quot;plugin:somePluginId:someDirectoryRelatedOptionKey&quot;: &quot;__codegen_dir__&quot;, }, },  Each plugin source path will be prefixed with -Xplugin= and passed as extra arguments to the compiler. Plugin options will be appended after its plugin with -P. A specific example is, if you want to use kotlinx.serializationwith kotlin_library(), you need to specify kotlinx-serialization-compiler-plugin.jar under kotlin_compiler_plugins and kotlinx-serialization-runtime.jar (which you may have to fetch from Maven) in your deps:  kotlin_library( name = &quot;example&quot;, srcs = glob([&quot;*.kt&quot;]), deps = [ &quot;:kotlinx-serialization-runtime&quot;, ], kotlin_compiler_plugins = { # Likely copied from your $KOTLIN_HOME directory. &quot;kotlinx-serialization-compiler-plugin.jar&quot;: {}, }, ) prebuilt_jar( name = &quot;kotlinx-serialization-runtime&quot;, binary_jar = &quot;:kotlinx-serialization-runtime-0.10.0&quot;, ) # Note you probably want to set # maven_repo=http://jcenter.bintray.com/ in your .buckconfig until # https://github.com/Kotlin/kotlinx.serialization/issues/64 # is closed. remote_file( name = &quot;kotlinx-serialization-runtime-0.10.0&quot;, out = &quot;kotlinx-serialization-runtime-0.10.0.jar&quot;, url = &quot;mvn:org.jetbrains.kotlinx:kotlinx-serialization-runtime:jar:0.10.0&quot;, sha1 = &quot;23d777a5282c1957c7ce35946374fff0adab114c&quot; )  labels: Set of arbitrary strings which allow you to annotate a build rulewith tags that can be searched for over an entire dependency tree using buck query() .provided_deps: These represent dependencies that are known to be provided at run time, but are required in order for the code to compile. Examples of provided_deps include the JEE servlet APIs. When this rule is included in a , the provided_deps will not be packaged into the output.remove_classes: Specifies a list of Patterns that are used to exclude classes from the JAR. The pattern matching is based on the name of the class. This can be used to exclude a member class or delete a local view of a class that will be replaced during a later stage of the build.resources: Static files to include with the compiled .class files. These files can be loaded via Class.getResource(). Note: If resources_root isn't set, Buck uses the .buckconfigproperty in .buckconfig to determine where resources should be placed within the generated JAR file. srcs: The set of .kt, .java or .kts files to compile for this rule. If any of the files in this list end in .src.zip, then the entries in the ZIP file that end in .java or .kt will be included as ordinary inputs to compilation. Details​ Examples:  # A rule that compiles a single .kt file. kotlin_library( name = 'JsonUtil', srcs = ['JsonUtil.kt'], deps = [ '//third_party/guava:guava', '//third_party/jackson:jackson', ], ) # A rule that compiles all of the .kt files under the directory in # which the rule is defined using glob(). It also excludes an # individual file that may have additional dependencies, so it is # compiled by a separate rule. kotlin_library( name = 'messenger', srcs = glob(['**/*.kt'], excludes = ['MessengerModule.kt']), deps = [ '//src/com/facebook/base:base', '//third_party/guava:guava', ], ) kotlin_library( name = 'MessengerModule', srcs = ['MessengerModule.kt'], deps = [ '//src/com/facebook/base:base', '//src/com/google/inject:inject', '//third_party/guava:guava', '//third_party/jsr-330:jsr-330', ], ) # A rule that builds a library with both relative and # fully-qualified deps. kotlin_library( name = 'testutil', srcs = glob(['tests/**/*.kt'], excludes = 'tests/**/*Test.kt'), deps = [ ':lib-fb4a', '//java/com/facebook/base:base', ], )   "},{"title":"kotlin_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#kotlin_test","content":"def kotlin_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _build_only_native_code: bool.type = _, _inject_test_env: str.type = _, _is_building_android_binary: bool.type = _, _java_test_toolchain: str.type = _, _java_toolchain: str.type = _, _kotlin_toolchain: str.type = _, abi_generation_mode: [None, str.type] = _, annotation_processing_tool: [None, str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, contacts: [str.type] = _, cxx_library_whitelist: [str.type] = _, default_cxx_platform: [None, str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, env: {str.type: str.type} = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, extra_kotlinc_arguments: [str.type] = _, extra_non_source_only_abi_kotlinc_arguments: [str.type] = _, fork_mode: str.type = _, friend_paths: [str.type] = _, java: [None, str.type] = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, kotlin_compiler_plugins: {str.type: {str.type: str.type}} = _, labels: [str.type] = _, licenses: [str.type] = _, manifest_file: [None, str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resources: [str.type] = _, resources_root: [None, str.type] = _, run_test_separately: bool.type = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, srcs: [str.type] = _, std_err_log_level: [None, int.type, str.type] = _, std_out_log_level: [None, int.type, str.type] = _, target: [None, str.type] = _, test_case_timeout_ms: [None, int.type] = _, test_rule_timeout_ms: [None, int.type] = _, test_type: [None, str.type] = _, use_cxx_libraries: [None, bool.type] = _, use_dependency_order_classpath: [None, bool.type] = _, use_jvm_abi_gen: [None, bool.type] = _, vm_args: [str.type] = _ ) -&gt; None  A kotlin_test() rule is used to define a set of .kt files that contain tests to run via JUnit. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: Same as kotlin\\_library(). // org.junit.rules.Timeout was not introduced until 4.7. Must include JUnit (version 4.7 or later) as a dependency for JUnit tests. Must include TestNG (version 6.2 or later) and hamcrest as a dependencies for TestNG tests.env: A map of environment names and values to set when running the test.fork_mode: Controls whether tests will all be run in the same process or a process will be started for each set of tests in a class. (This is mainly useful when porting Java tests to Buck from Apache Ant which allows JUnit tasks to set a fork=&quot;yes&quot; property. It should not be used for new tests since it encourages tests to not cleanup after themselves and increases the tests' computational resources and running time.) noneAll tests will run in the same process.per_testA process will be started for each test class in which all tests of that test class will run. labels: A list of labels to be applied to these tests. These labels are arbitrary text strings and have no meaning within buck itself. They can, however, have meaning for you as a test author (e.g., smoke or fast). A label can be used to filter or include a specific test rule when executing buck testresources: Same as kotlin\\_library().srcs: Like kotlin_library(), all of the .kt files specified by the srcs argument will be compiled when this rule is built. In addition, all of the corresponding .class files that are built by this rule will be passed as arguments to JUnit when this rule is run as a test. .class files that are passed to JUnit that do not have any methods annotated with @Test are considered failed tests, so make sure that only test case classes are specified as srcs. This is frequently done by specifying srcs as glob(['**/*Test.kt']).std_err_log_level: Same as std_out_log_level, but for std err.std_out_log_level: Log level for messages from the source under test that buck will output to std out. Value must be a valid java.util.logging.Level value.test_rule_timeout_ms: If set specifies the maximum amount of time (in milliseconds) in which all of the tests in this rule should complete. This overrides the default rule_timeout if any has been specified in .buckconfig .test_type: Specifies which test framework to use. The currently supported options are 'junit' and 'testng'.vm_args: Runtime arguments to the JVM running the tests.  "},{"title":"legacy_toolchain​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#legacy_toolchain","content":"def legacy_toolchain( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, toolchain_name: str.type = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"lua_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#lua_binary","content":"def lua_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, main_module: str.type = _, native_starter_library: [None, str.type] = _, package_style: [None, str.type] = _, platform: [None, str.type] = _, platform_deps: [(str.type, [str.type])] = _, python_platform: [None, str.type] = _ ) -&gt; None  A lua_library() rule is used to group together Lua sources to be packaged into a top-level lua\\_binary()rule. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: lua\\_library()rules to this binary will access.main_module: The module which serves as the entry point for this rule. Details​ Examples:  lua_binary( name = 'tailer', main_module = 'tailer', deps = [ ':tailerutils', ], ) lua_library( name = 'tailerutils', srcs = glob(['*.lua']), )   "},{"title":"lua_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#lua_library","content":"def lua_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, base_module: [None, str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, platform_deps: [(str.type, [str.type])] = _, srcs: [[str.type], {str.type: str.type}] = _ ) -&gt; None  A lua_library() rule is used to group together Lua sources to be packaged into a top-level lua\\_binary()rule. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onebase_module: The package for which the given specified sources and resources should reside in their final location in the top-level binary. If unset, the project relative directory that houses the BUCK file is used.deps: Other lua_library() rules which list srcs from which this rule imports modules.srcs: The set of .lua files included in this library. Details​ Examples:  # A rule that includes a single .py file. lua_library( name = 'fileutil', srcs = ['fileutil.lua'], ) # A rule that uses glob() to include all sources in the directory which the # rule is defined. It also lists a resource file that gets packaged with # the sources in this rule. lua_library( name = 'testutil', srcs = glob(['testutil/**/*.lua'], )   "},{"title":"ndk_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#ndk_library","content":"def ndk_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, flags: [str.type] = _, is_asset: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, srcs: [str.type] = _ ) -&gt; None  An ndk_library() is used to define a set of C/C++ files, an Android.mk and an Application.mk file that are used by the NDK's ndk-build tool to generate one or more shared objects. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: List of build targets to build before this rule.flags: Array of strings passed verbatim to ndk-build. Normally this is not needed, but in some cases you may want to put something here. For example, this can be used to build the libraries in debug mode (NDK_DEBUG=1) or set the number of jobs spawned by ndk-build (by default, the same as the number of cores).is_asset: Normally native shared objects end up in a directory in the root of the APK named lib/. If this parameter is set to True, then these objects are placed in assets/lib/. Placing shared objects in a non-standard location prevents Android from extracting them to the device's internal storage.srcs: The set of files to compile for this rule. If not provided, buck assumes that all files with the following extensions are part of the build: c, cpp, cc, cxx, h, hpp, mk. Details​ Additional notes: An android_binary() that includes this library will aggregate all of the native shared objects into a directory in the root of the APK named lib/ or assets/lib/. Unlike the default invocation of ndk-build,buck will put all intermediate files and build output into a subdirectory under buck-out/gen.  "},{"title":"ndk_toolchain​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#ndk_toolchain","content":"def ndk_toolchain( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, cxx_runtime: [None, str.type] = _, cxx_toolchain: str.type, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, objdump: str.type, shared_runtime_path: [None, str.type] = _, strip_apk_libs_flags: [None, [str.type]] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"ocaml_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#ocaml_binary","content":"def ocaml_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _ocaml_toolchain: str.type = _, bytecode_only: [None, bool.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, linker_flags: [str.type] = _, ocamldep_flags: [str.type] = _, platform: [None, str.type] = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_linker_flags: [(str.type, [str.type])] = _, srcs: [None, [str.type], {str.type: str.type}] = _, warnings_flags: [None, str.type] = _ ) -&gt; None  A ocaml_binary() rule builds both native and bytecode executables from the supplied set of OCaml and C source files and dependencies. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecompiler_flags: The set of additional compiler flags to pass to ocaml compiler. It supports specifying ppx (see for example).deps: The set of dependencies of this rule. It could include references to ocaml_library and cxx_library rules.platform_deps: Platform specific dependencies. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of dependencies (same format as deps) that are exported if the platform matches the regex. See deps for more information.srcs: The set of source files to be compiled by this rule. It supports *.ml, *.mli, *.mly, *.mll, and *.c files. (see this test as C interop example and this test as parser and lexer example). Details​ Note: Buck is currently tested with 4.X OCaml series. Examples: For more examples, check out our integration tests.  ocaml_binary( name='greet', srcs=[ 'main.ml', 'lex.mll', 'parser.mly', 'hashtable.c', ], deps=[ ':greeting', ':bridge', ], ) ocaml_library( name='greeting', srcs=[ 'greeting.ml', ], deps=[ ':join', ], ) ocaml_library( name='join', srcs=[ 'join.ml', ], ) cxx_library( name='bridge', srcs=[ 'bridge.c', ], )   "},{"title":"ocaml_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#ocaml_library","content":"def ocaml_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _ocaml_toolchain: str.type = _, bytecode_only: bool.type = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, linker_flags: [str.type] = _, native_plugin: bool.type = _, ocamldep_flags: [str.type] = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, srcs: [None, [str.type], {str.type: str.type}] = _, warnings_flags: [None, str.type] = _ ) -&gt; None  A ocaml_library() rule builds a native and a bytecode libraries from the supplied set of OCaml source files and dependencies. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecompiler_flags: The set of additional compiler flags to pass to ocaml compiler. It supports specifying ppx (see for example).deps: The set of dependencies of this rule. It could include references to ocaml_library and cxx_library rules.platform_deps: Platform specific dependencies. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of dependencies (same format as deps) that are exported if the platform matches the regex. See deps for more information.srcs: The set of source files to be compiled by this rule. It supports *.ml, *.mli, *.mly, *.mll, and *.c files. (see this test as C interop example and this test as parser and lexer example). Details​ Note: Buck is currently tested with 4.X OCaml series. Examples: For more examples, check out our integration tests.  ocaml_library( name='greeting', srcs=[ 'greeting.ml', ], deps=[ ':join', ], )   "},{"title":"ocaml_object​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#ocaml_object","content":"def ocaml_object( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _ocaml_toolchain: str.type = _, bytecode_only: [None, bool.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, linker_flags: [str.type] = _, ocamldep_flags: [str.type] = _, platform: [None, str.type] = _, platform_deps: [(str.type, [str.type])] = _, platform_linker_flags: [(str.type, [str.type])] = _, srcs: [None, [str.type], {str.type: str.type}] = _, warnings_flags: [None, str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"ocaml_shared​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#ocaml_shared","content":"def ocaml_shared( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _ocaml_toolchain: str.type = _, bytecode_only: [None, bool.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, linker_flags: [str.type] = _, ocamldep_flags: [str.type] = _, platform: [None, str.type] = _, platform_deps: [(str.type, [str.type])] = _, platform_linker_flags: [(str.type, [str.type])] = _, srcs: [None, [str.type], {str.type: str.type}] = _, warnings_flags: [None, str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"platform​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#platform","content":"def platform( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, constraint_values: [str.type] = _, deps: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"prebuilt_apple_framework​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#prebuilt_apple_framework","content":"def prebuilt_apple_framework( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _apple_toolchain: str.type = _, _omnibus_environment: [None, str.type] = _, code_sign_on_copy: [None, bool.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, exported_linker_flags: [str.type] = _, exported_platform_linker_flags: [(str.type, [str.type])] = _, framework: [None, str.type] = _, frameworks: [str.type] = _, labels: [str.type] = _, libraries: [str.type] = _, licenses: [str.type] = _, preferred_linkage: str.type = _, supported_platforms_regex: [None, str.type] = _ ) -&gt; None  A prebuilt_apple_framework() rule represents a set of Objective-C/C++ source files and is very similar to a prebuilt_cxx_library() rule. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one Details​ Examples:  prebuilt_apple_framework( name = 'MyPrebuiltFramework', framework = 'myPrebuiltFramework.framework', preferred_linkage = 'static', visibility = [ 'PUBLIC' ] )   "},{"title":"prebuilt_cxx_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#prebuilt_cxx_library","content":"def prebuilt_cxx_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _omnibus_environment: [None, str.type] = _, _target_os_type: str.type = _, can_be_asset: bool.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, exported_deps: [str.type] = _, exported_header_style: str.type = _, exported_headers: [[str.type], {str.type: str.type}] = _, exported_lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, exported_lang_preprocessor_flags: {str.type: [str.type]} = _, exported_linker_flags: [str.type] = _, exported_platform_deps: [(str.type, [str.type])] = _, exported_platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, exported_platform_linker_flags: [(str.type, [str.type])] = _, exported_platform_preprocessor_flags: [(str.type, [str.type])] = _, exported_post_linker_flags: [str.type] = _, exported_post_platform_linker_flags: [(str.type, [str.type])] = _, exported_preprocessor_flags: [str.type] = _, force_static: bool.type = _, frameworks: [str.type] = _, header_dirs: [None, [str.type]] = _, header_namespace: [None, str.type] = _, header_only: bool.type = _, import_lib: [None, str.type] = _, include_in_android_merge_map_output: bool.type = _, labels: [str.type] = _, libraries: [str.type] = _, licenses: [str.type] = _, link_whole: bool.type = _, link_without_soname: bool.type = _, linker_flags: [str.type] = _, platform_header_dirs: [None, [(str.type, [str.type])]] = _, platform_import_lib: [None, [(str.type, str.type)]] = _, platform_shared_lib: [None, [(str.type, str.type)]] = _, platform_static_lib: [None, [(str.type, str.type)]] = _, platform_static_pic_lib: [None, [(str.type, str.type)]] = _, preferred_linkage: str.type = _, provided: bool.type = _, public_include_directories: [str.type] = _, public_system_include_directories: [str.type] = _, raw_headers: [str.type] = _, shared_lib: [None, str.type] = _, soname: [None, str.type] = _, static_lib: [None, str.type] = _, static_pic_lib: [None, str.type] = _, supported_platforms_regex: [None, str.type] = _, supports_merged_linking: [None, bool.type] = _, supports_python_dlopen: bool.type = _, supports_shared_library_interface: bool.type = _, versioned_exported_lang_platform_preprocessor_flags: [({str.type: str.type}, {str.type: [(str.type, [str.type])]})] = _, versioned_exported_lang_preprocessor_flags: [({str.type: str.type}, {str.type: [str.type]})] = _, versioned_exported_platform_preprocessor_flags: [({str.type: str.type}, [(str.type, [str.type])])] = _, versioned_exported_preprocessor_flags: [({str.type: str.type}, [str.type])] = _, versioned_header_dirs: [None, [({str.type: str.type}, [str.type])]] = _, versioned_import_lib: [None, [({str.type: str.type}, str.type)]] = _, versioned_shared_lib: [None, [({str.type: str.type}, str.type)]] = _, versioned_soname: [None, [({str.type: str.type}, str.type)]] = _, versioned_static_lib: [None, [({str.type: str.type}, str.type)]] = _, versioned_static_pic_lib: [None, [({str.type: str.type}, str.type)]] = _ ) -&gt; None  A prebuilt_cxx_library() rule represents a set of native libraries and C/C++ header files and provides various flags to control how they are linked and exported. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneexported_deps: Dependencies that will also appear to belong to any rules that depend on this one. This has two effects: Exported dependencies will also be included in the link line of dependents of this rules, but normal dependencies will not. When reexport_all_header_dependencies = False, only exported headers of the rules specified here are re-exported.exported_headers: The set of header files that are made available for inclusion to the source files in the target and all targets that transitively depend on it. These should be specified as either a list of header files or a dictionary of header names to header files. The headers can be included with #include &quot;$HEADER_NAMESPACE/$HEADER_NAME&quot; or #include &lt;$HEADER_NAMESPACE/$HEADER_NAME&gt;, where $HEADER_NAMESPACE is the value of the target's header_namespace attribute, and $HEADER_NAME is the header name if specified, and the filename of the header file otherwise. Note that the header name can contain forward slashes (/). See header_namespace for more information.exported_linker_flags: Flags to add to the linker command line when the output from this rule, or the output from any rule that transitively depends on this rule, is used in a link operation.exported_platform_deps: Platform specific dependencies that will also appear to belong to any rules that depend on this one. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of external dependencies (same format as exported_deps) that are exported if the platform matches the regex. See exported_deps for more information.exported_platform_headers: Platform specific header files. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is either a list of header files or a dictionary of header names to header files that will be made available for inclusion to the source files in the target and all targets that transitively depend on it if the platform matches the regex. See headers for more information.exported_platform_preprocessor_flags: Platform specific exported preprocessor flags. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of flags to use when preprocessing the source files in the target and all targets that transitively depend on it if the platform matches the regex. See exported_preprocessor_flags for more information.header_namespace: A path prefix when including headers of this target. Defaults to the path from the root of the repository to the directory where this target is defined. Can contain forward slashes (/), but cannot start with one. See headers for more information.header_only: Indicates if this library only consists of headers or not. If this is set to True, Buck will not link this library into any library that depends on it.platform_shared_lib: Platform specific shared library. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element the path to the library. See shared_lib for more information.platform_static_lib: Platform specific static library. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element the path to the library. See static_lib for more information.platform_static_pic_lib: Platform specific static PIC library. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element the path to the library. See static_pic_lib for more information.shared_lib: The path to the library to use when performing shared linking.static_lib: The path to the library to use when performing static linking.static_pic_lib: The path to the library to use when performing static PIC linking.supported_platforms_regex: If present, an un-anchored regex (in java.util.regex.Pattern syntax) that matches all platforms that this library supports. It will not be built for other platforms.supports_merged_linking: Whether this rule supports building with the merged linking strategy when building for non-native binaries (e.g. when using .buckconfig s merged setting). Details​ Examples: A prebuilt library containing only headers that other libraries may need.  prebuilt_cxx_library( name = 'stdutil', header_only = True, header_dirs = [ 'include', ], )  A prebuilt library with static and shared libs.  prebuilt_cxx_library( name = 'mylib', soname = 'libmylib.so', static_lib = 'libmylib.a', static_pic_lib = 'libmylib_pic.a', shared_lib = 'libmylib.so', exported_headers = [ 'mylib.h', ], )  A prebuilt library with multiple builds for multiple platforms.  prebuilt_cxx_library( name = 'mylib', soname = 'libmylib.so', platform_shared_lib = [ ('android-arm', 'android-arm/libmylib.so'), ('android-x86', 'android-x86/libmylib.so'), ('iphonesimulator-x86_64', 'iphonesimulator-x86_64/libmylib.so'), ], platform_static_lib = [ ('android-arm', 'android-arm/libmylib.a'), ('android-x86', 'android-x86/libmylib.a'), ('iphonesimulator-x86_64', 'iphonesimulator-x86_64/libmylib.a'), ], exported_headers = [ 'mylib.h', ], )   "},{"title":"prebuilt_cxx_library_group​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#prebuilt_cxx_library_group","content":"def prebuilt_cxx_library_group( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, exported_deps: [str.type] = _, exported_platform_deps: [(str.type, [str.type])] = _, exported_preprocessor_flags: [str.type] = _, import_libs: {str.type: str.type} = _, include_dirs: [str.type] = _, include_in_android_merge_map_output: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, provided_shared_libs: {str.type: str.type} = _, shared_libs: {str.type: str.type} = _, shared_link: [str.type] = _, static_libs: [str.type] = _, static_link: [str.type] = _, static_pic_libs: [str.type] = _, static_pic_link: [str.type] = _, supported_platforms_regex: [None, str.type] = _ ) -&gt; None  A prebuilt_cxx_library_group() rule represents a group of native libraries which should be handled together in a single rule, perhaps using special link-line construction. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneexported_deps: Dependencies that will also appear to belong to any rules that depend on this one. This has two effects: Exported dependencies will also be included in the link line of dependents of this rules, but normal dependencies will not. When reexport_all_header_dependencies = False, only exported headers of the rules specified here are re-exported.exported_platform_deps: Platform specific dependencies that will also appear to belong to any rules that depend on this one. These should be specified as a list of pairs where the first element is an un-anchored regex (in java.util.regex.Pattern syntax) against which the platform name is matched, and the second element is a list of external dependencies (same format as exported_deps) that are exported if the platform matches the regex. See exported_deps for more information.provided_shared_libs: The map of system-provided shared library names to paths used when using the shared link style. The shared_link parameter should refer to these libs using their library name.shared_libs: The map of shared library names to paths used when using the shared link style. The shared_link parameter should refer to these libs using their library name.shared_link: The arguments to use when linking this library group using the shared link style. The actual paths to libraries should be listed in the shared_libs parameter, and referenced via the the $(lib [name]) macro (or the $(rel-lib [name]) macro, when the shared library should be linked using the -L[dir] -l[name] style) in these args.static_libs: The paths to the libraries used when using the static link style. The static_link parameter should refer to these libs using their index number.static_link: The arguments to use when linking this library group using the static link style. The actual paths to libraries should be listed in the static_libs parameter, and referenced via the the $(lib [index]) macro in these args.static_pic_libs: The paths to the libraries used when using the static link style. The static_pic_link parameter should refer to these libs using their index number.static_pic_link: The arguments to use when linking this library group using the static-pic link style. The actual paths to libraries should be listed in the static_pic_libs parameter, and referenced via the the $(lib [index]) macro in these args. Details​ Examples: A prebuilt library group wrapping two libraries that must be linked together.  prebuilt_cxx_library_group( name = 'util', static_link = [ '-Wl,--start-group', '$(lib 0)', '$(lib 1)', '-Wl,--end-group', ], static_libs = [ 'lib/liba.a', 'lib/libb.a', ], static_pic_link = [ '-Wl,--start-group', '$(lib 0)', '$(lib 1)', '-Wl,--end-group', ], static_libs = [ 'lib/liba_pic.a', 'lib/libb_pic.a', ], shared_link = [ '$(rel-lib liba.so)', '$(rel-lib libb.so)', ], shared_libs = { 'liba.so': 'lib/liba.so', }, provided_shared_libs = { 'libb.so': 'lib/libb.so', }, )   "},{"title":"prebuilt_dotnet_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#prebuilt_dotnet_library","content":"def prebuilt_dotnet_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, assembly: str.type, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _ ) -&gt; None  A prebuilt_dotnet_library() rule is used to include prebuilt .Net assembles into your .Net code. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneassembly: The path to the DLL that this rule provides. Details​ Examples:  prebuilt_dotnet_library( name = 'log4net', assembly = 'log4net.dll', ) csharp_library( name = 'example', srcs = [ 'Hello.cs', ], framework_ver = 'net46', deps = [ ':log4net', 'System.dll', ], )   "},{"title":"prebuilt_go_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#prebuilt_go_library","content":"def prebuilt_go_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, exported_deps: [str.type] = _, labels: [str.type] = _, library: str.type, licenses: [str.type] = _, package_name: [None, str.type] = _ ) -&gt; None  A prebuilt_go_library() rule provides a native library from the specified file. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: The set of dependencies of this rule. Currently, this only supports go_library rules.library: Path to the precompiled Go library - typically of the form 'foo.a'.package_name: Sets the full name of the package being compiled. This defaults to the path from the buck root. (e.g. given a ./.buckconfig, a rule in ./a/b/BUCK defaults to package &quot;a/b&quot;) Details​ Examples: For more examples, check out our integration tests.  prebuilt_go_library( name='greeting', package_name='greeting', library='greeting.a', deps=[ ':join', ], )   "},{"title":"prebuilt_jar​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#prebuilt_jar","content":"def prebuilt_jar( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _build_only_native_code: bool.type = _, _dex_min_sdk_version: [None, int.type] = _, _dex_toolchain: [None, str.type] = _, _prebuilt_jar_toolchain: str.type = _, binary_jar: str.type, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, generate_abi: bool.type = _, javadoc_url: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: bool.type = _, required_for_source_only_abi: bool.type = _, source_jar: [None, str.type] = _ ) -&gt; None  A prebuilt_jar() rule is used to identify a JAR file that is checked into our repository as a precompiled binary rather than one that is built from source by Buck. Frequently, these are used to reference third-party JAR files (such as junit.jar) and are used as dependencies of java_library() rules. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onebinary_jar: Path to the pre-built JAR file.deps: Rules that must be built before this rule. Because the binary_jar is already built, there should be nothing to build, so this should be empty.javadoc_url: URL to the Javadoc for the .class files in the binary_jar.source_jar: Path to a JAR file that contains the .java files to create the .class in the binary_jar. This is frequently provided for debugging purposes. Details​ Examples:  prebuilt_jar( name = 'junit', binary_jar = 'junit-4.8.2.jar', source_jar = 'junit-4.8.2-sources.jar', javadoc_url = 'http://kentbeck.github.com/junit/javadoc/4.8/', ) java_library( name = 'tests', srcs = glob(['tests/**/*Test.java']), deps = [ ':junit', ], )   "},{"title":"prebuilt_native_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#prebuilt_native_library","content":"def prebuilt_native_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, has_wrap_script: bool.type = _, is_asset: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, native_libs: str.type ) -&gt; None  A prebuilt_native_library() rule is used to bundle native libraries (i.e., .so files) for Android. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onehas_wrap_script: When using an exopackage, if this parameter is set to True, then the libraries for this rule are included in the primary APK even if native libraries would otherwise not be placed in it. This is intended for a native library directory that contains a wrap.sh script, which must be included in the primary APK to take effect. Only one of is_asset and has_wrap_script can be set for a rule.is_asset: Normally native shared objects end up in a directory in the root of the APK named lib/. If this parameter is set to True, then these objects are placed in assets/lib/. Placing shared objects in a non-standard location prevents Android from extracting them to the device's internal storage. Details​ Examples: Most of the time, a prebuilt_native_library is private to the android\\_library()that uses it:  prebuilt_native_library( name = 'native_libs', native_libs = 'libs', ) android_library( name = 'my_lib', srcs = glob(['*.java']), deps = [ ':native_libs', ], )   "},{"title":"prebuilt_ocaml_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#prebuilt_ocaml_library","content":"def prebuilt_ocaml_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, bytecode_c_libs: [str.type] = _, bytecode_lib: [None, str.type] = _, bytecode_only: bool.type = _, c_libs: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, include_dir: [None, str.type] = _, labels: [str.type] = _, lib_dir: str.type = _, lib_name: str.type = _, licenses: [str.type] = _, native_c_libs: [str.type] = _, native_lib: [None, str.type] = _, platform_deps: [(str.type, [str.type])] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"prebuilt_python_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#prebuilt_python_library","content":"def prebuilt_python_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _create_manifest_for_source_dir: str.type = _, _extract: str.type = _, _python_toolchain: str.type = _, binary_src: str.type, compile: bool.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, exclude_deps_from_merged_linking: bool.type = _, ignore_compile_errors: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _ ) -&gt; None  A prebuilt_python_library() rule is used to include prebuilt python packages into the output of a top-level python\\_binary()or python\\_test()rule. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onebinary_src: The path to the .whl or .egg to use. Note: .egg files have a very particular naming convention that must be followed - otherwise pex will not find the dependency properly at runtime! deps: Other prebuilt_python_library() rules which this library depends on. These may also be python_library rules if you want to depend on a source-based copy of the library.exclude_deps_from_merged_linking: When linking the top-level binary with a merged .buckconfig, do not merge or re-link any native transitive deps of this library. This is useful if this library wraps prebuilt native extensions which cannot be re-linked as part of library merging.labels: Set of arbitrary strings which allow you to annotate a build rulewith tags that can be searched for over an entire dependency tree using buck query() . Details​ These prebuilt libraries can either be whl files or eggs whls for most packages are available for download from PyPI. The whl used may be downloaded with remote\\_file(). However, Buck does not attempt to infer dependency information from pip, so that information will have to be imparted by the user. To create an egg for a package, run python setup.py bdist_egg in the package source distribution. Examples:  # A simple prebuilt_python_library with no external dependencies. remote_file( name = &quot;requests-download&quot;, url = &quot;https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl&quot;, sha1 = &quot;e1fc28120002395fe1f2da9aacea4e15a449d9ee&quot;, out = &quot;requests-2.22.0-py2.py3-none-any.whl&quot;, ) prebuilt_python_library( name = &quot;requests&quot;, binary_src = &quot;:requests-download&quot;, ) # A slightly more complex example prebuilt_python_library( name = &quot;greenlet&quot;, binary_src = &quot;greenlet-0.4.7-py2.7-macosx-10.10-x86_64.egg&quot;, ) prebuilt_python_library( name = &quot;gevent&quot;, binary_src = &quot;gevent-1.0.2-py2.7-macosx-10.10-x86_64.egg&quot;, deps = [ &quot;:greenlet&quot;, ], )   "},{"title":"prebuilt_rust_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#prebuilt_rust_library","content":"def prebuilt_rust_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _rust_toolchain: str.type = _, contacts: [str.type] = _, crate: str.type = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, link_style: [None, str.type] = _, proc_macro: bool.type = _, rlib: str.type ) -&gt; None  A prebuilt_rust_library() specifies a pre-built Rust crate, and any dependencies it may have on other crates (typically also prebuilt). Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onedeps: The set of dependencies of this rule. Currently, this supports rust_library and prebuilt_rust_library rules.rlib: Path to the precompiled Rust crate - typically of the form 'libfoo.rlib', or 'libfoo-abc123def456.rlib' if it has symbol versioning metadata. Details​ Note: Buck is currently tested with (and therefore supports) version 1.32.0 of Rust. Examples:  prebuilt_rust_library( name = 'dailygreet', rlib = 'libdailygreet.rlib', deps = [ ':jinsy', ], ) prebuilt_rust_library( name = 'jinsy', rlib = 'libarbiter-6337e9cb899bd295.rlib', )   "},{"title":"python_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#python_binary","content":"def python_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _create_manifest_for_source_dir: str.type = _, _cxx_hacks: str.type = _, _cxx_toolchain: str.type = _, _exec_os_type: str.type = _, _omnibus_environment: [None, str.type] = _, _package_remotely: bool.type = _, _python_toolchain: str.type = _, _target_os_type: str.type = _, auto_link_groups: bool.type = _, base_module: [None, str.type] = _, binary_linker_flags: [str.type] = _, bolt_flags: [str.type] = _, bolt_gdb_index: [None, str.type] = _, bolt_profile: [None, str.type] = _, build_args: [str.type] = _, compile: [None, bool.type] = _, compiler_flags: [str.type] = _, constraint_overrides: [str.type] = _, contacts: [str.type] = _, cxx_main: str.type = _, cxx_platform: [None, str.type] = _, cxx_runtime_type: [None, str.type] = _, deduplicate_merged_link_roots: [None, bool.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, deps_query: [None, str.type] = _, devirt_enabled: bool.type = _, dummy_omnibus: [None, str.type] = _, enable_distributed_thinlto: bool.type = _, executable_deps: [str.type] = _, executable_name: [None, str.type] = _, extension: [None, str.type] = _, fat_lto: bool.type = _, focused_list_target: [None, str.type] = _, frameworks: [str.type] = _, header_namespace: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, inplace_build_args: [str.type] = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, link_deps_query_whole: bool.type = _, link_execution_preference: [None, str.type] = _, link_group: [None, str.type] = _, link_group_map: [None, str.type, [(str.type, [([None, str.type], str.type, [None, str.type, [str.type]], [None, str.type])], [None, {str.type: &quot;&quot;}])]] = _, link_group_min_binary_node_count: [None, int.type] = _, link_ordering: [None, str.type] = _, link_style: str.type = _, link_whole: bool.type = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, main: [None, str.type] = _, main_module: [None, str.type] = _, make_pex: [None, str.type] = _, manifest_module_entries: [None, {str.type: {str.type: &quot;&quot;}}] = _, native_link_strategy: [None, str.type] = _, package_split_dwarf_dwp: bool.type = _, package_style: [None, str.type] = _, par_style: [None, str.type] = _, platform: [None, str.type] = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preload_deps: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, prefer_stripped_native_objects: bool.type = _, prefer_stripped_objects: bool.type = _, prefix_header: [None, str.type] = _, preload_deps: [str.type] = _, preprocessor_flags: [str.type] = _, raw_headers: [str.type] = _, resources: [[str.type], {str.type: str.type}] = _, standalone_build_args: [str.type] = _, static_extension_finder: str.type = _, static_extension_utils: str.type = _, thin_lto: bool.type = _, version_universe: [None, str.type] = _, weak_framework_names: [str.type] = _, zip_safe: [None, bool.type] = _ ) -&gt; None  A python_binary() rule is used to build a PEX fileâan executable Python packageâthat includes Python sources and resources from all transitive python\\_library()dependencies. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onebase_module: The package in which the main module should reside in its final location in the binary. If unset, Buck uses the project-relative directory that contains the BUCK file.deduplicate_merged_link_roots: When linking multiple top-level binaries with the merged .buckconfig, coalesce root link rules which are identical across independent merged links.deps: A list of python\\_library()rules that specify Python modules to include in the PEX fileâincluding all transitive dependencies of these rules.labels: Set of arbitrary strings which allow you to annotate a build rulewith tags that can be searched for over an entire dependency tree using buck query() .linker_flags: Additional linker flags that should be applied to any linking which is specific to this rule. Note that whether these flags are used is dependent on the native link strategy selected in .buckconfig and currently applies only to the merged .buckconfig; the separate link strategy pulls in shared libraries that are linked in the context of the rules that own them, such as cxx\\_library().main: The Python file which serves as the entry point for the PEX. The interpreter initiates execution of the PEX with the code in this file.main_module: The python module that should be the entry point of the binary. This should be a module name within a python_library that this binary depends on. Note that module names take base_module of the library into account. This property is mutually exclusive with main, and should be preferred to main, which is deprecated.package_style: Used to override the global packaging style that is set in [.buckconfig ].platform: The name of the Python platform flavor to build against by default as defined in the buckconfig#pythonsection of .buckconfig.preload_deps: A list of C/C++ library dependencies that need to be loaded before any other libraries when the PEX starts up. This requires dynamic loader support, such as LD_PRELOAD, found on most systems. This list is order- sensitive and the preload libraries listed here are passed down to the dynamic linker in the same order. Details​ Examples: Build a PEX from the Python files in the BUCK directory.  # BUCK python_binary( name = 'tailer', main_module = 'tailer', deps = [ ':tailerutils', ], ) python_library( name = 'tailerutils', # The main module, tailer.py, is specified here. # (Separated out from the glob pattern for clarity.) srcs = glob(['tailer.py', '*.py']), )  Use the platform argument to select the [python#py2] platform as defined in .buckconfig.  ; .buckconfig [python#py2] interpreter = /usr/bin/python2.7   # BUCK python_binary( name = 'bin', platform = 'py2', main_module = 'main', deps = [ ':bar', ], )   "},{"title":"python_bootstrap_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#python_bootstrap_binary","content":"def python_bootstrap_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _exec_os_type: str.type = _, _python_bootstrap_toolchain: str.type = _, _win_python_wrapper: [None, str.type] = _, deps: [str.type] = _, main: str.type ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"python_bootstrap_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#python_bootstrap_library","content":"def python_bootstrap_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, srcs: [str.type] ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"python_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#python_library","content":"def python_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _create_manifest_for_source_dir: str.type = _, _cxx_toolchain: str.type = _, _python_toolchain: str.type = _, base_module: [None, str.type] = _, contacts: [str.type] = _, cxx_platform: [None, str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, exclude_deps_from_merged_linking: bool.type = _, ignore_compile_errors: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, platform: [None, str.type] = _, platform_deps: [(str.type, [str.type])] = _, platform_resources: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_srcs: [(str.type, [[str.type], {str.type: str.type}])] = _, resources: [[str.type], {str.type: str.type}] = _, srcs: [[str.type], {str.type: str.type}] = _, type_stubs: [[str.type], {str.type: str.type}] = _, version_universe: [None, str.type] = _, versioned_resources: [None, [({str.type: str.type}, [[str.type], {str.type: str.type}])]] = _, versioned_srcs: [None, [({str.type: str.type}, [[str.type], {str.type: str.type}])]] = _, zip_safe: [None, bool.type] = _ ) -&gt; None  A python_library() rule is used to group together Python source files and resources to package them into a PEX using a top-level python\\_binary()rule. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onebase_module: The package in which the specified source files and resources should reside in their final location in the top-level binary. If unset, Buck uses the project-relative directory that contains the BUCK file.deps: Other python_library() rules that list srcs from which this rule imports modules.exclude_deps_from_merged_linking: When linking the top-level binary with a merged .buckconfig, do not merge or re-link any native transitive deps of this library. This is useful if this library wraps prebuilt native extensions which cannot be re-linked as part of library merging.labels: Set of arbitrary strings which allow you to annotate a build rulewith tags that can be searched for over an entire dependency tree using buck query() .platform_resources: Python-platform-specific resource files. These should be specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched, and the second element is a list of resource files. The regex should use java.util.regex.Pattern syntax. The platform name is a Python platform flavor defined in the buckconfig#pythonsection of .buckconfig.platform_srcs: Python-platform-specific source files. These should be specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched, and the second element is a list of source files. The regex should use java.util.regex.Pattern syntax. The platform name is a Python platform flavor defined in the buckconfig#pythonsection of .buckconfig.srcs: The set of Python (.py) files to include in this library. Details​ Examples: Include Python source files and resource files.  # BUCK # A rule that includes a single Python file. python_library( name = 'fileutil', srcs = ['fileutil.py'], deps = [ '//third_party/python-magic:python-magic', ], ) # A rule that uses glob() to include all Python source files in the # directory in which the rule is defined. The rule also specifies a # resource file that gets packaged with the source file. python_library( name = 'testutil', srcs = glob(['testutil/**/*.py']), resources = [ 'testdata.dat', ], )  Use the platform_srcs and platform_resources arguments to pull in source files and resources only when building for a specific Python platform.  ; .buckconfig [python#py2] interpreter = /usr/bin/python2.7 [python#py3] interpreter = /usr/bin/python3.4   # BUCK python_library( name = 'utils', platform_srcs = [ ('py2', ['foo.py']), ('py3', ['bar.py']), ], platform_resources = [ ('py2', ['foo.dat']), ('py3', ['bar.dat']), ], )   "},{"title":"python_needed_coverage_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#python_needed_coverage_test","content":"def python_needed_coverage_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _inject_test_env: str.type = _, contacts: [str.type] = _, env: {str.type: str.type} = _, labels: [str.type] = _, needed_coverage: [(int.type, str.type, [None, str.type])] = _, remote_execution: [None, {str.type: [None, bool.type, str.type, {str.type: str.type}]}] = _, test: str.type ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"python_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#python_test","content":"def python_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _create_manifest_for_source_dir: str.type = _, _cxx_hacks: str.type = _, _cxx_toolchain: str.type = _, _exec_os_type: str.type = _, _inject_test_env: str.type = _, _omnibus_environment: [None, str.type] = _, _python_toolchain: str.type = _, _target_os_type: str.type = _, _test_main: str.type = _, additional_coverage_targets: [str.type] = _, auto_link_groups: bool.type = _, base_module: [None, str.type] = _, binary_linker_flags: [str.type] = _, bolt_flags: [str.type] = _, bolt_gdb_index: [None, str.type] = _, bolt_profile: [None, str.type] = _, build_args: [str.type] = _, compile: [None, bool.type] = _, compiler_flags: [str.type] = _, constraint_overrides: [str.type] = _, contacts: [str.type] = _, cxx_main: str.type = _, cxx_platform: [None, str.type] = _, cxx_runtime_type: [None, str.type] = _, deduplicate_merged_link_roots: [None, bool.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, defaults: {str.type: str.type} = _, deps: [str.type] = _, deps_query: [None, str.type] = _, devirt_enabled: bool.type = _, dummy_omnibus: [None, str.type] = _, enable_distributed_thinlto: bool.type = _, env: {str.type: str.type} = _, exclude_deps_from_merged_linking: bool.type = _, executable_deps: [str.type] = _, executable_name: [None, str.type] = _, extension: [None, str.type] = _, fat_lto: bool.type = _, focused_list_target: [None, str.type] = _, frameworks: [str.type] = _, header_namespace: [None, str.type] = _, headers: [[str.type], {str.type: str.type}] = _, headers_as_raw_headers_mode: [None, str.type] = _, include_directories: [str.type] = _, inplace_build_args: [str.type] = _, labels: [str.type] = _, lang_compiler_flags: {str.type: [str.type]} = _, lang_platform_compiler_flags: {str.type: [(str.type, [str.type])]} = _, lang_platform_preprocessor_flags: {str.type: [(str.type, [str.type])]} = _, lang_preprocessor_flags: {str.type: [str.type]} = _, libraries: [str.type] = _, licenses: [str.type] = _, link_deps_query_whole: bool.type = _, link_execution_preference: [None, str.type] = _, link_group: [None, str.type] = _, link_group_map: [None, str.type, [(str.type, [([None, str.type], str.type, [None, str.type, [str.type]], [None, str.type])], [None, {str.type: &quot;&quot;}])]] = _, link_group_min_binary_node_count: [None, int.type] = _, link_ordering: [None, str.type] = _, link_style: str.type = _, link_whole: bool.type = _, linker_extra_outputs: [str.type] = _, linker_flags: [str.type] = _, main_module: [None, str.type] = _, make_pex: [None, str.type] = _, manifest_module_entries: [None, {str.type: {str.type: &quot;&quot;}}] = _, native_link_strategy: [None, str.type] = _, needed_coverage: [(int.type, str.type, [None, str.type])] = _, package_split_dwarf_dwp: bool.type = _, package_style: [None, str.type] = _, par_style: [None, str.type] = _, platform: [None, str.type] = _, platform_compiler_flags: [(str.type, [str.type])] = _, platform_deps: [(str.type, [str.type])] = _, platform_headers: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_linker_flags: [(str.type, [str.type])] = _, platform_preload_deps: [(str.type, [str.type])] = _, platform_preprocessor_flags: [(str.type, [str.type])] = _, platform_resources: [(str.type, [[str.type], {str.type: str.type}])] = _, platform_srcs: [(str.type, [[str.type, (str.type, [str.type])]])] = _, post_linker_flags: [str.type] = _, post_platform_linker_flags: [(str.type, [str.type])] = _, precompiled_header: [None, str.type] = _, prefer_stripped_native_objects: bool.type = _, prefer_stripped_objects: bool.type = _, prefix_header: [None, str.type] = _, preload_deps: [str.type] = _, preprocessor_flags: [str.type] = _, raw_headers: [str.type] = _, remote_execution: [None, {str.type: [None, bool.type, str.type, {str.type: str.type}]}] = _, resources: [[str.type], {str.type: str.type}] = _, runner: [None, str.type] = _, specs: [None, str.type] = _, srcs: [[str.type], {str.type: str.type}] = _, standalone_build_args: [str.type] = _, static_extension_finder: str.type = _, static_extension_utils: str.type = _, test_rule_timeout_ms: [None, int.type] = _, thin_lto: bool.type = _, version_universe: [None, str.type] = _, versioned_resources: [None, [({str.type: str.type}, [[str.type], {str.type: str.type}])]] = _, versioned_srcs: [None, [({str.type: str.type}, [[str.type], {str.type: str.type}])]] = _, weak_framework_names: [str.type] = _, zip_safe: [None, bool.type] = _ ) -&gt; None  A python_test() rule defines a set of .py files that contain tests to run via the Python unit testing framework. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onebase_module: The package in which the specified source files and resources should reside in their final location in the top-level binary. If unset, Buck uses the project-relative directory that contains the BUCK file.deduplicate_merged_link_roots: When linking multiple top-level binaries with the merged .buckconfig, coalesce root link rules which are identical across independent merged links.deps: python\\_library()rules used by the tests in this rules sources.env: A map of environment names and values to set when running the test. It is also possible to expand references to other rules within the values of these environment variables, using builtin string parameter macros: $(location //path/to:target)Expands to the location of the output of the build rule. This means that you can refer to these without needing to be aware of how Buck is storing data on the disk mid-build. exclude_deps_from_merged_linking: When linking the top-level binary with a merged .buckconfig, do not merge or re-link any native transitive deps of this library. This is useful if this library wraps prebuilt native extensions which cannot be re-linked as part of library merging.labels: Set of arbitrary strings which allow you to annotate a build rulewith tags that can be searched for over an entire dependency tree using buck query() .linker_flags: Additional linker flags that should be applied to any linking which is specific to this rule. Note that whether these flags are used is dependent on the native link strategy selected in .buckconfig and currently applies only to the merged .buckconfig; the separate link strategy pulls in shared libraries that are linked in the context of the rules that own them, such as cxx\\_library().main_module: The main module used to run the tests. This parameter is normally not needed, as Buck will provide a default main module that runs all tests. However, you can override this with your own module to perform custom initialization or command line processing. Your custom module can import the standard Buck test main as __test_main__, and can invoke it's normal main function as __test_main__.main(sys.argv).package_style: Used to override the global packaging style that is set in [.buckconfig ].platform: The name of the Python platform flavor to build against by default as defined in the buckconfig#pythonsection of .buckconfig.platform_resources: Python-platform-specific resource files. These should be specified as a list of pairs where the first element in each pair is an un-anchored regex against which the platform name is matched, and the second element is a list of resource files. The regex should use java.util.regex.Pattern syntax. The platform name is a Python platform flavor defined in the buckconfig#pythonsection of .buckconfig.preload_deps: A list of C/C++ library dependencies that need to be loaded before any other libraries when the PEX starts up. This requires dynamic loader support, such as LD_PRELOAD, found on most systems. This list is order- sensitive and the preload libraries listed here are passed down to the dynamic linker in the same order.srcs: The set of Python (.py) files to include in this library.test_rule_timeout_ms: If set specifies the maximum amount of time (in milliseconds) in which all of the tests in this rule should complete. This overrides the default rule_timeout if any has been specified in .buckconfig . Details​ If your test requires static files you should specify these in the resources or platform_resources arguments. If you do not specify these files, they won't be available when your test runs. Examples:  # A rule that includes a single .py file containing tests. python_test( name = 'fileutil_test', srcs = ['fileutil_tests.py'], deps = [ ':fileutil', ], ) # A rule that uses glob() to include all sources in the directory which the # rule is defined. It also lists a resource file that gets packaged with # the sources in this rule. python_library( name = 'fileutil', srcs = glob(['fileutil/**/*.py']), resources = [ 'testdata.dat', ], )  Here is an example of using the platform\\_srcs and platform\\_resourcesparameters to pull in sources/resources only when building for a specific Python platform:  ; .buckconfig [python#py2] interpreter = /usr/bin/python2.7 [python#py3] interpreter = /usr/bin/python3.4   # BUCK python_test( name = 'test', platform_srcs = [ ('py2', ['foo.py']), ('py3', ['bar.py']), ], platform_resources = [ ('py2', ['foo.dat']), ('py3', ['bar.dat']), ], )  Here is an example of using the platform parameter to select the &quot;py2&quot; Python platform as defined in .buckconfig above:  # BUCK python_test( name = 'bin', platform = 'py2', srcs = [ 'foo.py', ], )   "},{"title":"python_test_runner​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#python_test_runner","content":"def python_test_runner( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, main_module: str.type = _, src: str.type ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onelabels: Set of arbitrary strings which allow you to annotate a build rulewith tags that can be searched for over an entire dependency tree using buck query() .  "},{"title":"remote_file​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#remote_file","content":"def remote_file( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _unzip_tool: str.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, out: [None, str.type] = _, sha1: [None, str.type] = _, sha256: [None, str.type] = _, type: [None, str.type] = _, url: str.type, vpnless_url: [None, str.type] = _ ) -&gt; None  A remote_file() rule is used to download files from the Internet to be used as dependencies for other rules. These rules are downloaded by running fetch, or can be downloaded as part of build. See the note there about the .buckconfig setting to configure that. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneout: An optional name to call the downloaded artifact. Buck will generate a default name if one is not provided that uses the name of the rule.type: An optional type of the downloaded file. dataRegular data file.executable Executable file. Buck will ensure that output has appropriate permissions if applicable. exploded_zip Zip archive which will be automatically unzipped into an output directory. url: You can specify an http, https, or a mvn URL. If you specify a mvn URL, it will be decoded as described in the javadocs for MavenUrlDecoder See the example section below.vpnless_url: An optional additional URL from which this resource can be downloaded when off VPN. Meta-internal only. Details​ Examples: Here's an example of a remote_file() using an https URL.  remote_file( name = 'android-ndk-r10e-darwin-x86_64', url = 'https://dl.google.com/android/ndk/android-ndk-r10e-darwin-x86_64.bin', sha1 = 'b57c2b9213251180dcab794352bfc9a241bf2557', )  Here's an example of a remote_file() using a mvn URL being referenced by a prebuilt\\_jar().  prebuilt_jar( name = 'jetty-all', binary_jar = 'jetty-all-9.2.10.v20150310.jar', source_jar = ':jetty-source', ) remote_file( name = 'jetty-source', out = 'jetty-all-9.2.10.v20150310-sources.jar', url = 'mvn:org.eclipse.jetty.aggregate:jetty-all:src:9.2.10.v20150310', sha1 = '311da310416d2feb3de227081d7c3f48742d7075', )  Here's an example of a remote_file() using a mvn URI which uses a non-default maven repository host.  remote_file( name = 'jetty-source', out = 'jetty-all-9.2.10.v20150310-sources.jar', url = 'mvn:https://maven-repo.com:org.eclipse.jetty.aggregate:jetty-all:src:9.2.10.v20150310', sha1 = '311da310416d2feb3de227081d7c3f48742d7075', )  Here's an example of a remote_file() using a mvn URI which uses a Maven classifier.  remote_file( name = 'groovy-groovysh-indy', out = 'jetty-all-9.2.10.v20150310-sources.jar', url = 'mvn:org.codehaus.groovy:groovy-groovysh:jar:indy:2.4.1', sha1 = '1600fde728c885cc9506cb102deb1b494bd7c130', )   "},{"title":"robolectric_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#robolectric_test","content":"def robolectric_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _android_toolchain: str.type = _, _build_only_native_code: bool.type = _, _inject_test_env: str.type = _, _is_building_android_binary: bool.type = _, _java_test_toolchain: str.type = _, _java_toolchain: str.type = _, _kotlin_toolchain: str.type = _, abi_generation_mode: [None, str.type] = _, annotation_processing_tool: [None, str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, contacts: [str.type] = _, cxx_library_whitelist: [str.type] = _, default_cxx_platform: [None, str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, env: {str.type: str.type} = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, extra_kotlinc_arguments: [str.type] = _, extra_non_source_only_abi_kotlinc_arguments: [str.type] = _, fork_mode: str.type = _, friend_paths: [str.type] = _, java: [None, str.type] = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, kotlin_compiler_plugins: {str.type: {str.type: str.type}} = _, labels: [str.type] = _, language: [None, str.type] = _, licenses: [str.type] = _, locales_for_binary_resources: [str.type] = _, manifest: [None, str.type] = _, manifest_entries: {str.type: &quot;&quot;} = _, manifest_file: [None, str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, preferred_density_for_binary_resources: [None, str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, provided_deps_query: [None, str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resource_union_package: [None, str.type] = _, resources: [str.type] = _, resources_root: [None, str.type] = _, robolectric_manifest: str.type, robolectric_runtime_dependencies: [str.type] = _, robolectric_runtime_dependency: [None, str.type] = _, run_test_separately: bool.type = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, srcs: [str.type] = _, std_err_log_level: [None, int.type, str.type] = _, std_out_log_level: [None, int.type, str.type] = _, target: [None, str.type] = _, test_case_timeout_ms: [None, int.type] = _, test_rule_timeout_ms: [None, int.type] = _, test_type: [None, str.type] = _, use_cxx_libraries: [None, bool.type] = _, use_dependency_order_classpath: [None, bool.type] = _, use_jvm_abi_gen: [None, bool.type] = _, vm_args: [str.type] = _ ) -&gt; None  A robolectric_test() rule is used to define a set of .java files that contain tests to run via JUnit with Robolectric test runner. It extends from java_test() rule. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneextra_kotlinc_arguments: List of additional arguments to pass into the Kotlin compiler.robolectric_manifest: An Android Manifest for the rule to declare any permissions or intents it may need or want to handle. May either be a file or a android\\_manifest()target.robolectric_runtime_dependency: Robolectric only runs in offline mode with buck. Specify the relative directory containing all the jars Robolectric uses at runtime.  "},{"title":"rust_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#rust_binary","content":"def rust_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _exec_os_type: str.type = _, _rust_toolchain: str.type = _, _target_os_type: str.type = _, contacts: [str.type] = _, coverage: bool.type = _, crate: [None, str.type] = _, crate_root: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, deps: [str.type] = _, edition: [None, str.type] = _, env: {str.type: str.type} = _, features: [str.type] = _, flagged_deps: [(str.type, [str.type])] = _, framework: bool.type = _, incremental_build_mode: [None, str.type] = _, incremental_enabled: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, link_style: [None, str.type] = _, linker_flags: [str.type] = _, mapped_srcs: {str.type: str.type} = _, named_deps: {str.type: str.type} = _, resources: [[str.type], {str.type: str.type}] = _, rpath: bool.type = _, rustc_flags: [str.type] = _, rustdoc_flags: [str.type] = _, srcs: [str.type] = _, version_universe: [None, str.type] = _ ) -&gt; None  A rust_binary() rule builds a native executable from the supplied set of Rust source files and dependencies. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecrate_root: Set the name of the top-level source file for the crate, which can be used to override the default (see srcs).deps: The set of dependencies of this rule. Currently, this supports rust_library and prebuilt_rust_library rules.edition: Set the language edition to be used for this rule. Can be set to any edition the compiler supports (2018 right now). If unset it uses the compiler's default (2015).env: Set environment variables for this rule's invocations of rustc. The environment variable values may include macros which are expanded.features: The set of features to be enabled for this rule. These are passed to rustc with --cfg feature=&quot;{feature}&quot;, and can be used in the code with #[cfg(feature = &quot;{feature}&quot;)]. link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be either static, static_pic or shared.linker_flags: The set of additional flags to pass to the linker.mapped_srcs: Add source files along with a local path mapping. Rust is sensitive to the layout of source files, as the directory structure follows the module structure. However this is awkward if the source file is, for example, generated by another rule. In this case, you can set up a mapping from the actual source path to something that makes sense locally. For example mapped_srcs = {&quot;:generate-module&quot;, &quot;src/generated.rs&quot; }. These are added to the regular srcs, so a file should not be listed in both.named_deps: Add crate dependencies and define a local name by which to use that dependency by. This allows a crate to have multiple dependencies with the same crate name. For example: named_deps = {&quot;local_name&quot;, &quot;:some_rust_crate&quot; }. The dependencies may also be non-Rust, but the alias is ignored. It has no effect on the symbols provided by a C/C++ library.rpath: Set the &quot;rpath&quot; in the executable when using a shared link style.rustc_flags: The set of additional compiler flags to pass to rustc.srcs: The set of Rust source files to be compiled by this rule. One of the source files is the root module of the crate. By default this is lib.rs for libraries, main.rs for executables, or the crate's name with .rs appended. This can be overridden with the crate_root rule parameter. Details​ If you invoke a build with the check flavor, then Buck will invoke rustc to check the code (typecheck, produce warnings, etc), but won't generate an executable code. When applied to binaries it produces no output; for libraries it produces metadata for consumers of the library. When building with check, extra compiler flags from the rust.rustc_check_flags are added to the compiler's command line options, to allow for extra warnings, etc. Note: Buck is currently tested with (and therefore supports) version 1.32.0 of Rust. Examples: For more examples, check out our integration tests.  rust_binary( name='greet', srcs=[ 'greet.rs', ], deps=[ ':greeting', ], ) rust_library( name='greeting', srcs=[ 'greeting.rs', ], deps=[ ':join', ], ) rust_library( name='join', srcs=[ 'join.rs', ], )   "},{"title":"rust_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#rust_library","content":"def rust_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _exec_os_type: str.type = _, _omnibus_environment: [None, str.type] = _, _rust_toolchain: str.type = _, _target_os_type: str.type = _, contacts: [str.type] = _, coverage: bool.type = _, crate: [None, str.type] = _, crate_dynamic: [None, str.type] = _, crate_root: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, deps: [str.type] = _, doc_deps: [str.type] = _, doc_env: {str.type: [None, str.type]} = _, doc_linker_flags: [str.type] = _, doc_named_deps: {str.type: str.type} = _, doctest_link_style: [None, str.type] = _, doctests: [None, bool.type] = _, edition: [None, str.type] = _, env: {str.type: str.type} = _, features: [str.type] = _, flagged_deps: [(str.type, [str.type])] = _, incremental_build_mode: [None, str.type] = _, incremental_enabled: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, linker_flags: [str.type] = _, mapped_srcs: {str.type: str.type} = _, named_deps: {str.type: str.type} = _, preferred_linkage: str.type = _, proc_macro: bool.type = _, resources: [[str.type], {str.type: str.type}] = _, rustc_flags: [str.type] = _, rustdoc_flags: [str.type] = _, srcs: [str.type] = _, supports_python_dlopen: [None, bool.type] = _, version_universe: [None, str.type] = _ ) -&gt; None  A rust_library() rule builds a native library from the supplied set of Rust source files and dependencies. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecrate_root: Set the name of the top-level source file for the crate, which can be used to override the default (see srcs).deps: The set of dependencies of this rule. Currently, this supports rust_library and prebuilt_rust_library rules.doctest_link_style: Like link_style on binaries, but applies specifically to doctests.edition: Set the language edition to be used for this rule. Can be set to any edition the compiler supports (2018 right now). If unset it uses the compiler's default (2015).env: Set environment variables for this rule's invocations of rustc. The environment variable values may include macros which are expanded.features: The set of features to be enabled for this rule. These are passed to rustc with --cfg feature=&quot;{feature}&quot;, and can be used in the code with #[cfg(feature = &quot;{feature}&quot;)]. mapped_srcs: Add source files along with a local path mapping. Rust is sensitive to the layout of source files, as the directory structure follows the module structure. However this is awkward if the source file is, for example, generated by another rule. In this case, you can set up a mapping from the actual source path to something that makes sense locally. For example mapped_srcs = {&quot;:generate-module&quot;, &quot;src/generated.rs&quot; }. These are added to the regular srcs, so a file should not be listed in both.named_deps: Add crate dependencies and define a local name by which to use that dependency by. This allows a crate to have multiple dependencies with the same crate name. For example: named_deps = {&quot;local_name&quot;, &quot;:some_rust_crate&quot; }. The dependencies may also be non-Rust, but the alias is ignored. It has no effect on the symbols provided by a C/C++ library.rustc_flags: The set of additional compiler flags to pass to rustc.srcs: The set of Rust source files to be compiled by this rule. One of the source files is the root module of the crate. By default this is lib.rs for libraries, main.rs for executables, or the crate's name with .rs appended. This can be overridden with the crate_root rule parameter. Details​ If you invoke a build with the check flavor, then Buck will invoke rustc to check the code (typecheck, produce warnings, etc), but won't generate an executable code. When applied to binaries it produces no output; for libraries it produces metadata for consumers of the library. When building with check, extra compiler flags from the rust.rustc_check_flags are added to the compiler's command line options, to allow for extra warnings, etc. Note: Buck is currently tested with (and therefore supports) version 1.32.0 of Rust. Examples: For more examples, check out our integration tests.  rust_library( name='greeting', srcs=[ 'greeting.rs', ], deps=[ ':join', ], )   "},{"title":"rust_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#rust_test","content":"def rust_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _cxx_toolchain: str.type = _, _exec_os_type: str.type = _, _inject_test_env: str.type = _, _rust_toolchain: str.type = _, _target_os_type: str.type = _, contacts: [str.type] = _, coverage: bool.type = _, crate: [None, str.type] = _, crate_root: [None, str.type] = _, default_host_platform: [None, str.type] = _, default_platform: [None, str.type] = _, deps: [str.type] = _, edition: [None, str.type] = _, env: {str.type: str.type} = _, features: [str.type] = _, flagged_deps: [(str.type, [str.type])] = _, framework: bool.type = _, incremental_build_mode: [None, str.type] = _, incremental_enabled: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, link_style: [None, str.type] = _, linker_flags: [str.type] = _, mapped_srcs: {str.type: str.type} = _, named_deps: {str.type: str.type} = _, remote_execution: [None, {str.type: [None, bool.type, str.type, {str.type: str.type}]}] = _, resources: [[str.type], {str.type: str.type}] = _, rpath: bool.type = _, rustc_flags: [str.type] = _, rustdoc_flags: [str.type] = _, srcs: [str.type] = _, version_universe: [None, str.type] = _ ) -&gt; None  A rust_test() rule builds a Rust test native executable from the supplied set of Rust source files and dependencies and runs this test. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onecrate_root: Set the name of the top-level source file for the crate, which can be used to override the default (see srcs).deps: The set of dependencies of this rule. Currently, this supports rust_library and prebuilt_rust_library rules.edition: Set the language edition to be used for this rule. Can be set to any edition the compiler supports (2018 right now). If unset it uses the compiler's default (2015).env: Set environment variables for this rule's invocations of rustc. The environment variable values may include macros which are expanded.features: The set of features to be enabled for this rule. These are passed to rustc with --cfg feature=&quot;{feature}&quot;, and can be used in the code with #[cfg(feature = &quot;{feature}&quot;)]. link_style: Determines whether to build and link this rule's dependencies statically or dynamically. Can be either static, static_pic or shared.mapped_srcs: Add source files along with a local path mapping. Rust is sensitive to the layout of source files, as the directory structure follows the module structure. However this is awkward if the source file is, for example, generated by another rule. In this case, you can set up a mapping from the actual source path to something that makes sense locally. For example mapped_srcs = {&quot;:generate-module&quot;, &quot;src/generated.rs&quot; }. These are added to the regular srcs, so a file should not be listed in both.named_deps: Add crate dependencies and define a local name by which to use that dependency by. This allows a crate to have multiple dependencies with the same crate name. For example: named_deps = {&quot;local_name&quot;, &quot;:some_rust_crate&quot; }. The dependencies may also be non-Rust, but the alias is ignored. It has no effect on the symbols provided by a C/C++ library.rustc_flags: The set of additional compiler flags to pass to rustc.srcs: The set of Rust source files to be compiled by this rule. One of the source files is the root module of the crate. By default this is lib.rs for libraries, main.rs for executables, or the crate's name with .rs appended. This can be overridden with the crate_root rule parameter. Details​ Note: Buck is currently tested with (and therefore supports) version 1.32.0 of Rust. Examples: For more examples, check out our integration tests.  rust_test( name='greet', srcs=[ 'greet.rs', ], deps=[ ':greeting', ], ) rust_library( name='greeting', srcs=[ 'greeting.rs', ], deps=[ ':join', ], ) rust_library( name='join', srcs=[ 'join.rs', ], )   "},{"title":"scala_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#scala_library","content":"def scala_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, abi_generation_mode: [None, str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, manifest_file: [None, str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resources: [str.type] = _, resources_root: [None, str.type] = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, srcs: [str.type] = _, target: [None, str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"scala_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#scala_test","content":"def scala_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, abi_generation_mode: [None, str.type] = _, annotation_processor_deps: [str.type] = _, annotation_processor_params: [str.type] = _, annotation_processors: [str.type] = _, contacts: [str.type] = _, cxx_library_whitelist: [str.type] = _, default_cxx_platform: [None, str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, deps_query: [None, str.type] = _, env: {str.type: str.type} = _, exported_deps: [str.type] = _, exported_provided_deps: [str.type] = _, extra_arguments: [str.type] = _, fork_mode: str.type = _, java_version: [None, str.type] = _, javac: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, manifest_file: [None, str.type] = _, maven_coords: [None, str.type] = _, never_mark_as_unused_dependency: [None, bool.type] = _, on_unused_dependencies: [None, str.type] = _, plugins: [str.type] = _, proguard_config: [None, str.type] = _, provided_deps: [str.type] = _, remove_classes: [str.type] = _, required_for_source_only_abi: bool.type = _, resources: [str.type] = _, resources_root: [None, str.type] = _, run_test_separately: bool.type = _, runtime_deps: [str.type] = _, source: [None, str.type] = _, source_abi_verification_mode: [None, str.type] = _, source_only_abi_deps: [str.type] = _, srcs: [str.type] = _, std_err_log_level: [None, int.type, str.type] = _, std_out_log_level: [None, int.type, str.type] = _, target: [None, str.type] = _, test_case_timeout_ms: [None, int.type] = _, test_rule_timeout_ms: [None, int.type] = _, test_type: [None, str.type] = _, use_cxx_libraries: [None, bool.type] = _, use_dependency_order_classpath: [None, bool.type] = _, vm_args: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"scene_kit_assets​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#scene_kit_assets","content":"def scene_kit_assets( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, path: str.type ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"sh_binary​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#sh_binary","content":"def sh_binary( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _target_os_type: str.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, main: str.type, resources: [str.type] = _ ) -&gt; None  An sh_binary() is used to execute a shell script. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this onemain: Either the path to the script (relative to the build file), or a build target. This file must be executable in order to be run.resources: A list of files or build rules that this rule requires in order to run. These could be things such as random data files. When the script runs, the $BUCK_DEFAULT_RUNTIME_RESOURCESenvironment variable specifies the directory that contains these resources. This directory's location is determined entirely by Buck; the script should not assume the directory's location. The resources are also made available in a tree structure that mirrors their locations in the source and buck-out trees. The environment variable $BUCK_PROJECT_ROOT specifies a directory that contains all the resources, laid out in their locations relative to the original buck project root. Details​ Examples: This sh_binary() just cats a sample data file back at the user.  # $REPO/BUCK sh_binary( name = &quot;script&quot;, main = &quot;script.sh&quot;, resources = [ &quot;data.dat&quot;, ], )   # Sample data file with data we need at runtime $ echo &quot;I'm a datafile&quot; &gt; data.dat # Create a simple script that prints out the resource $ cat &gt; script.sh #!/bin/sh cat $BUCK_DEFAULT_RUNTIME_RESOURCES/data.dat # Make sure the script is executable $ chmod u+x script.sh # Run the script, and see that it prints out the resource we provided $ buck run //:script Jobs completed: 4. Time elapsed: 0.2s. BUILD SUCCEEDED I'm a datafile   "},{"title":"sh_test​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#sh_test","content":"def sh_test( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _inject_test_env: str.type = _, args: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, env: {str.type: str.type} = _, labels: [str.type] = _, licenses: [str.type] = _, list_args: [None, [str.type]] = _, list_env: [None, {str.type: str.type}] = _, remote_execution: [None, {str.type: [None, bool.type, str.type, {str.type: str.type}]}] = _, resources: [str.type] = _, run_args: [str.type] = _, run_env: {str.type: str.type} = _, run_test_separately: bool.type = _, test: [None, str.type] = _, test_rule_timeout_ms: [None, int.type] = _, type: [None, str.type] = _ ) -&gt; None  A sh_test() is a test rule that can pass results to the test runner by invoking a shell script. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneargs: The list of arguments to invoke this script with. These are literal values, and no shell interpolation is done. These can contain string parameter macros, for example, to give the location of a generated binary to the test script. env: Environment variable overrides that should be used when running the script. The key is the variable name, and the value is its value. The values can contain string parameter macrossuch as the location of a generated binary to be used by the test script. test: Either the path to the script (relative to the build file), or a build target. This file must be executable in order to be run.type: If provided, this will be sent to any configured .buckconfig Details​ NOTE: This rule is not currently supported on Windows. Examples: This sh_test() fails if a string does not match a value.  # $REPO/BUCK sh_test( name = &quot;script_pass&quot;, test = &quot;script.sh&quot;, args = [&quot;--pass&quot;], ) sh_test( name = &quot;script_fail&quot;, test = &quot;script.sh&quot;, args = [&quot;--fail&quot;], )   # Create a simple script that prints out the resource $ cat &gt; script.sh #!/bin/sh for arg in $@; do if [ &quot;$arg&quot; == &quot;--pass&quot; ]; then echo &quot;Passed&quot; exit 0; fi done echo &quot;Failed&quot; exit 1 # Make sure the script is executable $ chmod u+x script.sh # Run the script, and see that one test passes, one fails $ buck test //:script_pass //:script_fail FAILURE script.sh sh_test Building: finished in 0.0 sec (100%) 2/2 jobs, 0 updated Total time: 0.0 sec Testing: finished in 0.0 sec (1 PASS/1 FAIL) RESULTS FOR //:script_fail //:script_pass FAIL &lt;100ms 0 Passed 0 Skipped 1 Failed //:script_fail FAILURE script.sh sh_test ====STANDARD OUT==== Failed PASS &lt;100ms 1 Passed 0 Skipped 0 Failed //:script_pass TESTS FAILED: 1 FAILURE Failed target: //:script_fail FAIL //:script_fail   "},{"title":"supermodule_target_graph​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#supermodule_target_graph","content":"def supermodule_target_graph( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, label_pattern: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, on_duplicate_entry: str.type = _, out: str.type = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"swift_library​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#swift_library","content":"def swift_library( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, bridging_header: [None, str.type] = _, compiler_flags: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, deps: [str.type] = _, enable_cxx_interop: bool.type = _, frameworks: [str.type] = _, labels: [str.type] = _, libraries: [str.type] = _, licenses: [str.type] = _, module_name: [None, str.type] = _, preferred_linkage: str.type = _, sdk_modules: [str.type] = _, serialize_debugging_options: bool.type = _, soname: [None, str.type] = _, srcs: [str.type] = _, supported_platforms_regex: [None, str.type] = _, target_sdk_version: [None, str.type] = _, uses_explicit_modules: bool.type = _, version: [None, str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"swift_toolchain​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#swift_toolchain","content":"def swift_toolchain( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _internal_platform_path: [None, str.type] = _, _internal_sdk_path: [None, str.type] = _, _swiftc_wrapper: str.type = _, architecture: [None, str.type] = _, can_toolchain_emit_obj_c_header_textually: bool.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, explicit_modules_uses_gmodules: bool.type = _, labels: [str.type] = _, licenses: [str.type] = _, object_format: str.type = _, placeholder_tool: [None, str.type] = _, platform_path: [None, str.type] = _, prefix_serialized_debug_info: bool.type = _, resource_dir: [None, str.type] = _, runtime_paths_for_bundling: [str.type] = _, runtime_paths_for_linking: [str.type] = _, runtime_run_paths: [str.type] = _, sdk_dependencies_path: [None, str.type] = _, sdk_modules: [str.type] = _, sdk_path: [None, str.type] = _, static_runtime_paths: [str.type] = _, swift_stdlib_tool: str.type, swift_stdlib_tool_flags: [str.type] = _, swiftc: str.type, swiftc_flags: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"test_suite​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#test_suite","content":"def test_suite( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, test_deps: [str.type] = _ ) -&gt; None  A test_suite() is used to create a grouping of tests that should all be run by just testing this rule. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one Details​ This rule can then be given to buck test, and all tests that it depends on will be invoked. Note that the test_suite() target is not tested itself, it just tells buck to run other tests. It will not show up in calls to the external runner nor in the normal test output. Examples: This test_suite() sets up two different sets of tests to run, 'all' tests and 'slow' tests. Note that all_tests can depend on slow_tests, and all three tests are run.  # instrumentation_tests/BUCK: sh_test( name = &quot;instrumentation_tests&quot;, test = &quot;instrumentation_tests.sh&quot;, visibility = [&quot;PUBLIC&quot;], ) # integration_tests/BUCK: sh_test( name = &quot;integration_tests&quot;, test = &quot;integration_tests.sh&quot;, visibility = [&quot;PUBLIC&quot;], ) # unit_tests/BUCK: sh_test( name = &quot;unit_tests&quot;, test = &quot;unit_tests.sh&quot;, visibility = [&quot;PUBLIC&quot;], ) # BUCK: test_suite( name = &quot;slow_tests&quot;, tests = [ &quot;//instrumentation_tests:instrumentation_tests&quot;, &quot;//integration_tests:integration_tests&quot;, ], ) test_suite( name = &quot;all_tests&quot;, tests = [ &quot;:slow_tests&quot;, &quot;//unit_tests:unit_tests&quot;, ], )  Yields output like this when run:  $ buck test //:slow_tests ... RESULTS FOR //instrumentation_tests:instrumentation_tests //integration_tests:integration_tests PASS &lt;100ms 1 Passed 0 Skipped 0 Failed //instrumentation_tests:instrumentation_tests PASS &lt;100ms 1 Passed 0 Skipped 0 Failed //integration_tests:integration_tests TESTS PASSED ... $ buck test //:all_tests RESULTS FOR //instrumentation_tests:instrumentation_tests //integration_tests:integration_tests //unit_tests:unit_tests PASS &lt;100ms 1 Passed 0 Skipped 0 Failed //instrumentation_tests:instrumentation_tests PASS &lt;100ms 1 Passed 0 Skipped 0 Failed //integration_tests:integration_tests PASS &lt;100ms 1 Passed 0 Skipped 0 Failed //unit_tests:unit_tests TESTS PASSED   "},{"title":"versioned_alias​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#versioned_alias","content":"def versioned_alias( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, versions: {str.type: str.type} = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"worker_tool​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#worker_tool","content":"def worker_tool( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _worker_tool_runner: str.type = _, args: [str.type, [str.type]] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, env: {str.type: str.type} = _, exe: [None, str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, max_workers: [None, int.type] = _, max_workers_per_thread_percent: [None, int.type] = _, persistent: [None, bool.type] = _ ) -&gt; None  Some external tools have high startup costs. To amortize those costs over the whole build rather than paying them for each rule invocation, use the worker_tool() rule in conjunction with genrule(). Buck then starts the external tool once and reuses it by communicating with it over stdin and stdout using a simple JSON protocol. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneargs: A string of args that is passed to the executable represented by exe on initial startup.env: A map of environment variables that is passed to the executable represented by exe on initial startup.exe: A build targetfor a rule that outputs an executable, such as an sh\\_binary(). Buck runs this executable only once per build.max_workers: The maximum number of workers of this type that Buck starts. Use -1 to allow the creation of as many workers as necessary.max_workers_per_thread_percent: The maximum ratio of workers of this type that Buck starts per thread, specified as a positive integer percentage (1-100). Must be greater than or equal to 1 and less than or equal to 100. Only one of max_workers and max_workers_per_thread_percent may be specified.persistent: If set to true, Buck does not restart the tool unless the tool itself changes. This means the tool persists across multiple Buck commands without being shut down and may see the same rule being built more than once. Be careful not to use this setting with tools that don't expect to process the same input—with different contents—twice! Details​ A worker_tool rule can be referenced in the cmd parameter of a genrule by using the macro:  $(worker //path/to:target)  Examples: Consider the following build rules:  # # Buck # worker_tool( name = 'ExternalToolWorker', exe = ':ExternalTool', args = '--arg1 --arg2' ) sh_binary( name = 'ExternalTool', main = 'external_tool.sh', ) genrule( name = 'TransformA', out = 'OutputA.txt', cmd = '$(worker :ExternalToolWorker) argA', ) genrule( name = 'TransformB', out = 'OutputB.txt', cmd = '$(worker :ExternalToolWorker) argB', ) genrule( name = 'TransformC', out = 'OutputC.txt', cmd = '$(worker :ExternalToolWorker) argC', )  When doing a buck build on all three of the above genrules, Buck first creates the worker process by invoking:  ./external_tool.sh --arg1 --arg2  Buck then communicates with this process using JSON over stdin, starting with a handshake:  [ { &quot;id&quot;: 0, &quot;type&quot;: &quot;handshake&quot;, &quot;protocol_version&quot;: &quot;0&quot;, &quot;capabilities&quot;: [] }  Buck then waits for the tool to reply on stdout:  [ { &quot;id&quot;: 0, &quot;type&quot;: &quot;handshake&quot;, &quot;protocol_version&quot;: &quot;0&quot;, &quot;capabilities&quot;: [] }  Then, when building the first genrule, Buck writes to stdin:  ,{ &quot;id&quot;: 1, &quot;type&quot;: &quot;command&quot;, &quot;args_path&quot;: &quot;/tmp/1.args&quot;, &quot;stdout_path&quot;: &quot;/tmp/1.out&quot;, &quot;stderr_path&quot;: &quot;/tmp/1.err&quot; }  The file /tmp/1.args contains argA. The tool should perform the necessary work for this job and then write the job's output to the files supplied by Buck—in this case, /tmp/1.out and /tmp/1.err. Once the job is done, the tool should reply to Buck on stdout with:  ,{ &quot;id&quot;: 1, &quot;type&quot;: &quot;result&quot;, &quot;exit_code&quot;: 0 }  Once Buck hears back from the first genrule's job, it submits the second genrule's job in the same fashion and awaits the response. When the build is all finished, Buck closes the JSON by writing to stdin:  ]  which signals the tool that it should exit after replying on stdout with:  ]  In this example, Buck is guaranteed to invoke  ./external_tool.sh --arg1 --arg2  only once during the build. The three jobs corresponding to the three genrules are submitted synchronously to the single worker process. Note that the id values in the messages are not necessarily increasing or sequential, but they do have to match between the request message and the response message of a given job as well as in the initial handshake. If the tool receives a message type it cannot interpret it should answer with:  { &quot;id&quot;: &amp;ltn&gt;, &quot;type&quot;: &quot;error&quot;, &quot;exit_code&quot;: 1 }  If the tool receives a message type it can interpret, but the other attributes of the message are in an inconsistent state, it should answer with:  { &quot;id&quot;: &amp;ltn&gt;, &quot;type&quot;: &quot;error&quot;, &quot;exit_code&quot;: 2 }   "},{"title":"xcode_postbuild_script​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#xcode_postbuild_script","content":"def xcode_postbuild_script( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, cmd: str.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, input_file_lists: [str.type] = _, inputs: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, output_file_lists: [str.type] = _, outputs: [str.type] = _, srcs: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"xcode_prebuild_script​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#xcode_prebuild_script","content":"def xcode_prebuild_script( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, cmd: str.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, input_file_lists: [str.type] = _, inputs: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, output_file_lists: [str.type] = _, outputs: [str.type] = _, srcs: [str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"xcode_workspace_config​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#xcode_workspace_config","content":"def xcode_workspace_config( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, action_config_names: {str.type: str.type} = _, additional_scheme_actions: [None, {str.type: {str.type: [str.type]}}] = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, environment_variables: [None, {str.type: {str.type: str.type}}] = _, explicit_runnable_path: [None, str.type] = _, extra_schemes: {str.type: str.type} = _, extra_shallow_targets: [str.type] = _, extra_targets: [str.type] = _, extra_tests: [str.type] = _, is_remote_runnable: [None, bool.type] = _, labels: [str.type] = _, launch_style: [None, str.type] = _, licenses: [str.type] = _, notification_payload_file: [None, str.type] = _, src_target: [None, str.type] = _, was_created_for_app_extension: [None, bool.type] = _, watch_interface: [None, str.type] = _, workspace_name: [None, str.type] = _ ) -&gt; None  Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this one  "},{"title":"zip_file​","type":1,"pageTitle":"Rules","url":"/docs/api/rules/#zip_file","content":"def zip_file( *, name: str.type, default_target_platform: [None, str.type] = _, target_compatible_with: [str.type] = _, compatible_with: [str.type] = _, exec_compatible_with: [str.type] = _, visibility: [str.type] = _, within_view: [str.type] = _, tests: [str.type] = _, _zip_file_toolchain: str.type = _, contacts: [str.type] = _, default_host_platform: [None, str.type] = _, entries_to_exclude: [str.type] = _, labels: [str.type] = _, licenses: [str.type] = _, on_duplicate_entry: str.type = _, out: str.type = _, srcs: [str.type] = _, zip_srcs: [str.type] = _ ) -&gt; None  A zip_file() allows builds to create basic zip files in a platform-agnostic way. Parameters​ name: name of the targetdefault_target_platform: specifies the default target platform, used when no platforms are specified on the command linetarget_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationcompatible_with: a list of constraints that are required to be satisfied for this target to be compatible with a configurationexec_compatible_with: a list of constraints that are required to be satisfied for this target to be compatible with an execution platformvisibility: a list of visibility patterns restricting what targets can depend on this onewithin_view: a list of visibility patterns restricting what this target can depend ontests: a list of targets that provide tests for this oneentries_to_exclude: List of regex expressions that describe entries that should not be included in the output zip file. The regexes must be defined using java.util.regex.Pattern syntax. on_duplicate_entry: Action performed when Buck detects that zip_file input contains multiple entries with the same name. The valid values are: overwrite (default): the last entry overwrites all previous entries with the same name.append: all entries are added to the output file.fail: fail the build when duplicate entries are present.out: The name of the zip file that should be generated. This allows builds to use a meaningful target name coupled with a meaningful zip file name. The default value takes the rule's name and appends .zip.srcs: The set of files to include in the zip. Each src will be added to the zip as follows: If the src is the output of another rule, the output will be included using just the output's file name.If the src is a file relative to the rule's declaration, it will be included in the zip with its relative file name.zip_srcs: The set of zip files whose content to include in the output zip file. Note that the order of files in zip_srcs matters because the same zip entry can be included from multiple files. See the on_duplicate_entry argument to learn how to control the behavior when there are multiple entries with the same name. The entries from zip_srcs are added before files from srcs. Details​ Examples: This example will create a simple zip file.  zip_file( # The output will be &quot;example.zip&quot; name = 'example', srcs = # These files will be found in the zip under &quot;dir/&quot; glob(['dir/**/*']) + [ # Imagine this generates the output # &quot;buck-out/gen/foo/hello.txt&quot;. This output will # be found in the zip at &quot;hello.txt&quot; '//some/other:target', ], zip_srcs = [ # The contents of this zip will be added to the generated zip. 'amazing-library-1.0-sources.zip', ], entries_to_exclude = [ &quot;com/example/amazinglibrary/Source1.java&quot;, ], )  If you were to examine the generated zip, the contents would look something like (assuming the output of &quot;//some/other:target&quot; was a file who's path ended withhello.txt, the &quot;dir&quot; glob found two files, and &quot;amazing-library-1.0-sources.zip&quot; contained two Java source files):  dir/file1.txt dir/subdir/file2.txt hello.txt com/example/amazinglibrary/Source2.java  "}]